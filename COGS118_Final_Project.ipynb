{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the Parameter Grids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize  splits\n",
    "split_ratios = [0.2, 0.5, 0.8]\n",
    "results_summary = {}\n",
    "\n",
    "# random forest parameter grid\n",
    "Random_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],       \n",
    "    'classifier__max_depth': [None, 10, 20, 30],      \n",
    "    'classifier__min_samples_split': [2, 5, 10],      \n",
    "    'classifier__min_samples_leaf': [1, 2, 4]         \n",
    "}\n",
    "\n",
    "#SVM parameter grid\n",
    "\n",
    "SVM_grid = {\n",
    "    'classifier__C': [10**i for i in range(-7, 4)]\n",
    "}\n",
    "\n",
    "# KNN parameter grid\n",
    "KNN_grid = {\n",
    "    'classifier__n_neighbors': [3, 5, 7, 9, 11]\n",
    "}\n",
    "\n",
    "#logistic regression grid\n",
    "logreg_grid = {\n",
    "    'classifier__C': [10**i for i in range(-4, 4)],\n",
    "    'classifier__penalty': ['l2'],\n",
    "    'classifier__max_iter': [500, 1000]\n",
    "}\n",
    "\n",
    "\n",
    "#decsion tree\n",
    "decision_tree_grid = {\n",
    "    'classifier__criterion': ['gini', 'entropy'],      \n",
    "    'classifier__max_depth': [3, 5, 10, None],        \n",
    "    'classifier__min_samples_split': [2, 5, 10],      \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_classifier(dataset, classifier_name, param_grid, preprocessor, classifier, X, y):\n",
    "    model_results = []  \n",
    "    \n",
    "    # run model for each split ratio\n",
    "    for split_ratio in split_ratios:\n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, train_size=split_ratio, random_state=42, stratify=y)\n",
    "        \n",
    "        # pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "\n",
    "        # initialize and fit GridSearchCV \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=param_grid,\n",
    "            cv=3,\n",
    "            scoring='accuracy',\n",
    "            verbose=1, # verbose produces an output\n",
    "            n_jobs=-1  # uses all CPU cores       \n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_train_pred = best_model.predict(X_train)\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # store all cv_results as a dictionary to make heat maps later on \n",
    "        cv_results_dict = {}\n",
    "        for key in grid_search.cv_results_.keys():\n",
    "            if hasattr(grid_search.cv_results_[key], 'tolist'):\n",
    "                cv_results_dict[key] = grid_search.cv_results_[key].tolist()\n",
    "            else:\n",
    "                cv_results_dict[key] = grid_search.cv_results_[key]\n",
    "        \n",
    "        # calculate train accuracy and test accuracy \n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        \n",
    "        # append to the sckitit learn results to model_results (an instance of results_summary)\n",
    "        model_results.append({\n",
    "            'split_ratio': split_ratio,\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'best_validation_accuracy': grid_search.best_score_,\n",
    "            'train_accuracy': train_accuracy,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'cv_results': cv_results_dict  \n",
    "        })\n",
    "    \n",
    "    # store results globaly in results summary -- key is the data swet and the classifier name \n",
    "    results_summary[f\"{dataset} {classifier_name}\"] = model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vegas Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User country</th>\n",
       "      <th>Nr. reviews</th>\n",
       "      <th>Nr. hotel reviews</th>\n",
       "      <th>Helpful votes</th>\n",
       "      <th>Score</th>\n",
       "      <th>Period of stay</th>\n",
       "      <th>Traveler type</th>\n",
       "      <th>Pool</th>\n",
       "      <th>Gym</th>\n",
       "      <th>Tennis court</th>\n",
       "      <th>Spa</th>\n",
       "      <th>Casino</th>\n",
       "      <th>Free internet</th>\n",
       "      <th>Hotel name</th>\n",
       "      <th>Hotel stars</th>\n",
       "      <th>Nr. rooms</th>\n",
       "      <th>User continent</th>\n",
       "      <th>Member years</th>\n",
       "      <th>Review month</th>\n",
       "      <th>Review weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USA</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>Dec-Feb</td>\n",
       "      <td>Friends</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
       "      <td>3</td>\n",
       "      <td>3773</td>\n",
       "      <td>North America</td>\n",
       "      <td>9</td>\n",
       "      <td>January</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA</td>\n",
       "      <td>119</td>\n",
       "      <td>21</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>Dec-Feb</td>\n",
       "      <td>Business</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
       "      <td>3</td>\n",
       "      <td>3773</td>\n",
       "      <td>North America</td>\n",
       "      <td>3</td>\n",
       "      <td>January</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USA</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>Mar-May</td>\n",
       "      <td>Families</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
       "      <td>3</td>\n",
       "      <td>3773</td>\n",
       "      <td>North America</td>\n",
       "      <td>2</td>\n",
       "      <td>February</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UK</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>Mar-May</td>\n",
       "      <td>Friends</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
       "      <td>3</td>\n",
       "      <td>3773</td>\n",
       "      <td>Europe</td>\n",
       "      <td>6</td>\n",
       "      <td>February</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Mar-May</td>\n",
       "      <td>Solo</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
       "      <td>3</td>\n",
       "      <td>3773</td>\n",
       "      <td>North America</td>\n",
       "      <td>7</td>\n",
       "      <td>March</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>UK</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>Sep-Nov</td>\n",
       "      <td>Couples</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>The Westin las Vegas Hotel Casino &amp; Spa</td>\n",
       "      <td>4</td>\n",
       "      <td>826</td>\n",
       "      <td>Europe</td>\n",
       "      <td>1</td>\n",
       "      <td>October</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Canada</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>Sep-Nov</td>\n",
       "      <td>Couples</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>The Westin las Vegas Hotel Casino &amp; Spa</td>\n",
       "      <td>4</td>\n",
       "      <td>826</td>\n",
       "      <td>North America</td>\n",
       "      <td>8</td>\n",
       "      <td>November</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>USA</td>\n",
       "      <td>154</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>Sep-Nov</td>\n",
       "      <td>Friends</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>The Westin las Vegas Hotel Casino &amp; Spa</td>\n",
       "      <td>4</td>\n",
       "      <td>826</td>\n",
       "      <td>North America</td>\n",
       "      <td>4</td>\n",
       "      <td>November</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>USA</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Dec-Feb</td>\n",
       "      <td>Families</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>The Westin las Vegas Hotel Casino &amp; Spa</td>\n",
       "      <td>4</td>\n",
       "      <td>826</td>\n",
       "      <td>North America</td>\n",
       "      <td>9</td>\n",
       "      <td>December</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>USA</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>Dec-Feb</td>\n",
       "      <td>Families</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>The Westin las Vegas Hotel Casino &amp; Spa</td>\n",
       "      <td>4</td>\n",
       "      <td>826</td>\n",
       "      <td>North America</td>\n",
       "      <td>5</td>\n",
       "      <td>December</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    User country  Nr. reviews  Nr. hotel reviews  Helpful votes  Score  \\\n",
       "0            USA           11                  4             13      5   \n",
       "1            USA          119                 21             75      3   \n",
       "2            USA           36                  9             25      5   \n",
       "3             UK           14                  7             14      4   \n",
       "4         Canada            5                  5              2      4   \n",
       "..           ...          ...                ...            ...    ...   \n",
       "499           UK           15                  4              8      5   \n",
       "500       Canada           50                 13             29      4   \n",
       "501          USA          154                 23             31      4   \n",
       "502          USA            9                  6              5      2   \n",
       "503          USA           20                 19            112      4   \n",
       "\n",
       "    Period of stay Traveler type Pool  Gym Tennis court  Spa Casino  \\\n",
       "0          Dec-Feb       Friends   NO  YES           NO   NO    YES   \n",
       "1          Dec-Feb      Business   NO  YES           NO   NO    YES   \n",
       "2          Mar-May      Families   NO  YES           NO   NO    YES   \n",
       "3          Mar-May       Friends   NO  YES           NO   NO    YES   \n",
       "4          Mar-May          Solo   NO  YES           NO   NO    YES   \n",
       "..             ...           ...  ...  ...          ...  ...    ...   \n",
       "499        Sep-Nov       Couples  YES  YES           NO  YES    YES   \n",
       "500        Sep-Nov       Couples  YES  YES           NO  YES    YES   \n",
       "501        Sep-Nov       Friends  YES  YES           NO  YES    YES   \n",
       "502        Dec-Feb      Families  YES  YES           NO  YES    YES   \n",
       "503        Dec-Feb      Families  YES  YES           NO  YES    YES   \n",
       "\n",
       "    Free internet                               Hotel name Hotel stars  \\\n",
       "0             YES   Circus Circus Hotel & Casino Las Vegas           3   \n",
       "1             YES   Circus Circus Hotel & Casino Las Vegas           3   \n",
       "2             YES   Circus Circus Hotel & Casino Las Vegas           3   \n",
       "3             YES   Circus Circus Hotel & Casino Las Vegas           3   \n",
       "4             YES   Circus Circus Hotel & Casino Las Vegas           3   \n",
       "..            ...                                      ...         ...   \n",
       "499           YES  The Westin las Vegas Hotel Casino & Spa           4   \n",
       "500           YES  The Westin las Vegas Hotel Casino & Spa           4   \n",
       "501           YES  The Westin las Vegas Hotel Casino & Spa           4   \n",
       "502           YES  The Westin las Vegas Hotel Casino & Spa           4   \n",
       "503           YES  The Westin las Vegas Hotel Casino & Spa           4   \n",
       "\n",
       "     Nr. rooms User continent  Member years Review month Review weekday  \n",
       "0         3773  North America             9      January       Thursday  \n",
       "1         3773  North America             3      January         Friday  \n",
       "2         3773  North America             2     February       Saturday  \n",
       "3         3773         Europe             6     February         Friday  \n",
       "4         3773  North America             7        March        Tuesday  \n",
       "..         ...            ...           ...          ...            ...  \n",
       "499        826         Europe             1      October         Sunday  \n",
       "500        826  North America             8     November       Thursday  \n",
       "501        826  North America             4     November       Thursday  \n",
       "502        826  North America             9     December      Wednesday  \n",
       "503        826  North America             5     December        Tuesday  \n",
       "\n",
       "[504 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Load data\n",
    "Vegas = pd.read_csv(\"C:/Users/leofl/OneDrive/Desktop/COGS118A/Final Project/LasVegasTripAdvisorReviews-Dataset.csv\", sep=\";\")\n",
    "Vegas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature columns being used:\n",
      "Numerical: ['Nr. reviews', 'Nr. hotel reviews', 'Helpful votes', 'Hotel stars', 'Member years']\n",
      "Categorical: ['Traveler type', 'User country', 'Period of stay', 'Hotel name', 'User continent', 'Review month']\n",
      "Binary: ['Pool', 'Gym', 'Casino', 'Free internet', 'Tennis court', 'Spa']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "numerical_cols = ['Nr. reviews', 'Nr. hotel reviews', 'Helpful votes',\n",
    "                 'Hotel stars', 'Member years'] \n",
    "\n",
    "for col in numerical_cols:\n",
    "    if Vegas[col].dtype == 'object':\n",
    "        Vegas[col] = Vegas[col].str.replace(',', '.').astype(float)\n",
    "\n",
    "\n",
    "Vegas['Target'] = Vegas['Score'].apply(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "\n",
    "categorical_cols = ['Traveler type', 'User country', 'Period of stay', 'Hotel name', 'User continent',\n",
    "                   'Review month'] \n",
    "\n",
    "binary_cols = ['Pool', 'Gym', 'Casino', 'Free internet', 'Tennis court', 'Spa']\n",
    "\n",
    "Vegas[binary_cols] = Vegas[binary_cols].replace({'NO': 0, 'YES': 1})\n",
    "\n",
    "\n",
    "print(\"\\nFeature columns being used:\")\n",
    "print(\"Numerical:\", numerical_cols)\n",
    "print(\"Categorical:\", categorical_cols)\n",
    "print(\"Binary:\", binary_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "# one hot encodes categorical variables \n",
    "# normalizes numericaCategoricalng standardscaler \n",
    "\n",
    "Vegas = Vegas.dropna()\n",
    "\n",
    "vegas_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_cols),\n",
    "        ('passthrough', 'passthrough', binary_cols) \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare X and y\n",
    "vegas_X = Vegas[categorical_cols + numerical_cols + binary_cols]\n",
    "vegas_y = Vegas['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    }
   ],
   "source": [
    "apply_classifier('vegas','random_forest', Random_grid, vegas_preprocessor, RandomForestClassifier(), vegas_X, vegas_y)\n",
    "apply_classifier('vegas','SVM', SVM_grid, vegas_preprocessor,  SVC(kernel='rbf'), vegas_X, vegas_y)\n",
    "apply_classifier('vegas','KNN', KNN_grid, vegas_preprocessor, KNeighborsClassifier(), vegas_X, vegas_y)\n",
    "apply_classifier('vegas','log_reg',logreg_grid, vegas_preprocessor, LogisticRegression(), vegas_X, vegas_y)\n",
    "apply_classifier('vegas','decision_tree', decision_tree_grid, vegas_preprocessor, DecisionTreeClassifier(), vegas_X, vegas_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taiwan Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bankrupt?</th>\n",
       "      <th>ROA(C) before interest and depreciation before interest</th>\n",
       "      <th>ROA(A) before interest and % after tax</th>\n",
       "      <th>ROA(B) before interest and depreciation after tax</th>\n",
       "      <th>Operating Gross Margin</th>\n",
       "      <th>Realized Sales Gross Margin</th>\n",
       "      <th>Operating Profit Rate</th>\n",
       "      <th>Pre-tax net Interest Rate</th>\n",
       "      <th>After-tax net Interest Rate</th>\n",
       "      <th>Non-industry income and expenditure/revenue</th>\n",
       "      <th>Continuous interest rate (after tax)</th>\n",
       "      <th>Operating Expense Rate</th>\n",
       "      <th>Research and development expense rate</th>\n",
       "      <th>Cash flow rate</th>\n",
       "      <th>Interest-bearing debt interest rate</th>\n",
       "      <th>Tax rate (A)</th>\n",
       "      <th>Net Value Per Share (B)</th>\n",
       "      <th>Net Value Per Share (A)</th>\n",
       "      <th>Net Value Per Share (C)</th>\n",
       "      <th>Persistent EPS in the Last Four Seasons</th>\n",
       "      <th>Cash Flow Per Share</th>\n",
       "      <th>Revenue Per Share (Yuan ¥)</th>\n",
       "      <th>Operating Profit Per Share (Yuan ¥)</th>\n",
       "      <th>Per Share Net profit before tax (Yuan ¥)</th>\n",
       "      <th>Realized Sales Gross Profit Growth Rate</th>\n",
       "      <th>Operating Profit Growth Rate</th>\n",
       "      <th>After-tax Net Profit Growth Rate</th>\n",
       "      <th>Regular Net Profit Growth Rate</th>\n",
       "      <th>Continuous Net Profit Growth Rate</th>\n",
       "      <th>Total Asset Growth Rate</th>\n",
       "      <th>Net Value Growth Rate</th>\n",
       "      <th>Total Asset Return Growth Rate Ratio</th>\n",
       "      <th>Cash Reinvestment %</th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Quick Ratio</th>\n",
       "      <th>Interest Expense Ratio</th>\n",
       "      <th>Total debt/Total net worth</th>\n",
       "      <th>Debt ratio %</th>\n",
       "      <th>Net worth/Assets</th>\n",
       "      <th>Long-term fund suitability ratio (A)</th>\n",
       "      <th>Borrowing dependency</th>\n",
       "      <th>Contingent liabilities/Net worth</th>\n",
       "      <th>Operating profit/Paid-in capital</th>\n",
       "      <th>Net profit before tax/Paid-in capital</th>\n",
       "      <th>Inventory and accounts receivable/Net value</th>\n",
       "      <th>Total Asset Turnover</th>\n",
       "      <th>Accounts Receivable Turnover</th>\n",
       "      <th>Average Collection Days</th>\n",
       "      <th>Inventory Turnover Rate (times)</th>\n",
       "      <th>Fixed Assets Turnover Frequency</th>\n",
       "      <th>Net Worth Turnover Rate (times)</th>\n",
       "      <th>Revenue per person</th>\n",
       "      <th>Operating profit per person</th>\n",
       "      <th>Allocation rate per person</th>\n",
       "      <th>Working Capital to Total Assets</th>\n",
       "      <th>Quick Assets/Total Assets</th>\n",
       "      <th>Current Assets/Total Assets</th>\n",
       "      <th>Cash/Total Assets</th>\n",
       "      <th>Quick Assets/Current Liability</th>\n",
       "      <th>Cash/Current Liability</th>\n",
       "      <th>Current Liability to Assets</th>\n",
       "      <th>Operating Funds to Liability</th>\n",
       "      <th>Inventory/Working Capital</th>\n",
       "      <th>Inventory/Current Liability</th>\n",
       "      <th>Current Liabilities/Liability</th>\n",
       "      <th>Working Capital/Equity</th>\n",
       "      <th>Current Liabilities/Equity</th>\n",
       "      <th>Long-term Liability to Current Assets</th>\n",
       "      <th>Retained Earnings to Total Assets</th>\n",
       "      <th>Total income/Total expense</th>\n",
       "      <th>Total expense/Assets</th>\n",
       "      <th>Current Asset Turnover Rate</th>\n",
       "      <th>Quick Asset Turnover Rate</th>\n",
       "      <th>Working capitcal Turnover Rate</th>\n",
       "      <th>Cash Turnover Rate</th>\n",
       "      <th>Cash Flow to Sales</th>\n",
       "      <th>Fixed Assets to Assets</th>\n",
       "      <th>Current Liability to Liability</th>\n",
       "      <th>Current Liability to Equity</th>\n",
       "      <th>Equity to Long-term Liability</th>\n",
       "      <th>Cash Flow to Total Assets</th>\n",
       "      <th>Cash Flow to Liability</th>\n",
       "      <th>CFO to Assets</th>\n",
       "      <th>Cash Flow to Equity</th>\n",
       "      <th>Current Liability to Current Assets</th>\n",
       "      <th>Liability-Assets Flag</th>\n",
       "      <th>Net Income to Total Assets</th>\n",
       "      <th>Total assets to GNP price</th>\n",
       "      <th>No-credit Interval</th>\n",
       "      <th>Gross Profit to Sales</th>\n",
       "      <th>Net Income to Stockholder's Equity</th>\n",
       "      <th>Liability to Equity</th>\n",
       "      <th>Degree of Financial Leverage (DFL)</th>\n",
       "      <th>Interest Coverage Ratio (Interest expense to EBIT)</th>\n",
       "      <th>Net Income Flag</th>\n",
       "      <th>Equity to Liability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.370594</td>\n",
       "      <td>0.424389</td>\n",
       "      <td>0.405750</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.998969</td>\n",
       "      <td>0.796887</td>\n",
       "      <td>0.808809</td>\n",
       "      <td>0.302646</td>\n",
       "      <td>0.780985</td>\n",
       "      <td>1.256969e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.458143</td>\n",
       "      <td>7.250725e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147950</td>\n",
       "      <td>0.147950</td>\n",
       "      <td>0.147950</td>\n",
       "      <td>0.169141</td>\n",
       "      <td>0.311664</td>\n",
       "      <td>0.017560</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.138736</td>\n",
       "      <td>0.022102</td>\n",
       "      <td>0.848195</td>\n",
       "      <td>0.688979</td>\n",
       "      <td>0.688979</td>\n",
       "      <td>0.217535</td>\n",
       "      <td>4.980000e+09</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.263100</td>\n",
       "      <td>0.363725</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.629951</td>\n",
       "      <td>0.021266</td>\n",
       "      <td>0.207576</td>\n",
       "      <td>0.792424</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.390284</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>0.095885</td>\n",
       "      <td>0.137757</td>\n",
       "      <td>0.398036</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>1.820926e-04</td>\n",
       "      <td>1.165007e-04</td>\n",
       "      <td>0.032903</td>\n",
       "      <td>0.034164</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>0.037135</td>\n",
       "      <td>0.672775</td>\n",
       "      <td>0.166673</td>\n",
       "      <td>0.190643</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>1.473360e-04</td>\n",
       "      <td>0.147308</td>\n",
       "      <td>0.334015</td>\n",
       "      <td>0.276920</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.676269</td>\n",
       "      <td>0.721275</td>\n",
       "      <td>0.339077</td>\n",
       "      <td>2.559237e-02</td>\n",
       "      <td>0.903225</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.064856</td>\n",
       "      <td>7.010000e+08</td>\n",
       "      <td>6.550000e+09</td>\n",
       "      <td>0.593831</td>\n",
       "      <td>4.580000e+08</td>\n",
       "      <td>0.671568</td>\n",
       "      <td>0.424206</td>\n",
       "      <td>0.676269</td>\n",
       "      <td>0.339077</td>\n",
       "      <td>0.126549</td>\n",
       "      <td>0.637555</td>\n",
       "      <td>0.458609</td>\n",
       "      <td>0.520382</td>\n",
       "      <td>0.312905</td>\n",
       "      <td>0.118250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.716845</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.622879</td>\n",
       "      <td>0.601453</td>\n",
       "      <td>0.827890</td>\n",
       "      <td>0.290202</td>\n",
       "      <td>0.026601</td>\n",
       "      <td>0.564050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.464291</td>\n",
       "      <td>0.538214</td>\n",
       "      <td>0.516730</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>0.797380</td>\n",
       "      <td>0.809301</td>\n",
       "      <td>0.303556</td>\n",
       "      <td>0.781506</td>\n",
       "      <td>2.897851e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.461867</td>\n",
       "      <td>6.470647e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182251</td>\n",
       "      <td>0.182251</td>\n",
       "      <td>0.182251</td>\n",
       "      <td>0.208944</td>\n",
       "      <td>0.318137</td>\n",
       "      <td>0.021144</td>\n",
       "      <td>0.093722</td>\n",
       "      <td>0.169918</td>\n",
       "      <td>0.022080</td>\n",
       "      <td>0.848088</td>\n",
       "      <td>0.689693</td>\n",
       "      <td>0.689702</td>\n",
       "      <td>0.217620</td>\n",
       "      <td>6.110000e+09</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.264516</td>\n",
       "      <td>0.376709</td>\n",
       "      <td>0.006016</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>0.635172</td>\n",
       "      <td>0.012502</td>\n",
       "      <td>0.171176</td>\n",
       "      <td>0.828824</td>\n",
       "      <td>0.005059</td>\n",
       "      <td>0.376760</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>0.093743</td>\n",
       "      <td>0.168962</td>\n",
       "      <td>0.397725</td>\n",
       "      <td>0.064468</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>9.360000e+09</td>\n",
       "      <td>7.190000e+08</td>\n",
       "      <td>0.025484</td>\n",
       "      <td>0.006889</td>\n",
       "      <td>0.391590</td>\n",
       "      <td>0.012335</td>\n",
       "      <td>0.751111</td>\n",
       "      <td>0.127236</td>\n",
       "      <td>0.182419</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>1.383910e-03</td>\n",
       "      <td>0.056963</td>\n",
       "      <td>0.341106</td>\n",
       "      <td>0.289642</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>0.308589</td>\n",
       "      <td>0.731975</td>\n",
       "      <td>0.329740</td>\n",
       "      <td>2.394682e-02</td>\n",
       "      <td>0.931065</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.025516</td>\n",
       "      <td>1.065198e-04</td>\n",
       "      <td>7.700000e+09</td>\n",
       "      <td>0.593916</td>\n",
       "      <td>2.490000e+09</td>\n",
       "      <td>0.671570</td>\n",
       "      <td>0.468828</td>\n",
       "      <td>0.308589</td>\n",
       "      <td>0.329740</td>\n",
       "      <td>0.120916</td>\n",
       "      <td>0.641100</td>\n",
       "      <td>0.459001</td>\n",
       "      <td>0.567101</td>\n",
       "      <td>0.314163</td>\n",
       "      <td>0.047775</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795297</td>\n",
       "      <td>0.008323</td>\n",
       "      <td>0.623652</td>\n",
       "      <td>0.610237</td>\n",
       "      <td>0.839969</td>\n",
       "      <td>0.283846</td>\n",
       "      <td>0.264577</td>\n",
       "      <td>0.570175</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.426071</td>\n",
       "      <td>0.499019</td>\n",
       "      <td>0.472295</td>\n",
       "      <td>0.601450</td>\n",
       "      <td>0.601364</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.796403</td>\n",
       "      <td>0.808388</td>\n",
       "      <td>0.302035</td>\n",
       "      <td>0.780284</td>\n",
       "      <td>2.361297e-04</td>\n",
       "      <td>2.550000e+07</td>\n",
       "      <td>0.458521</td>\n",
       "      <td>7.900790e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177911</td>\n",
       "      <td>0.177911</td>\n",
       "      <td>0.193713</td>\n",
       "      <td>0.180581</td>\n",
       "      <td>0.307102</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>0.092338</td>\n",
       "      <td>0.142803</td>\n",
       "      <td>0.022760</td>\n",
       "      <td>0.848094</td>\n",
       "      <td>0.689463</td>\n",
       "      <td>0.689470</td>\n",
       "      <td>0.217601</td>\n",
       "      <td>7.280000e+09</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.264184</td>\n",
       "      <td>0.368913</td>\n",
       "      <td>0.011543</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.629631</td>\n",
       "      <td>0.021248</td>\n",
       "      <td>0.207516</td>\n",
       "      <td>0.792484</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.379093</td>\n",
       "      <td>0.006562</td>\n",
       "      <td>0.092318</td>\n",
       "      <td>0.148036</td>\n",
       "      <td>0.406580</td>\n",
       "      <td>0.014993</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>6.500000e+07</td>\n",
       "      <td>2.650000e+09</td>\n",
       "      <td>0.013387</td>\n",
       "      <td>0.028997</td>\n",
       "      <td>0.381968</td>\n",
       "      <td>0.141016</td>\n",
       "      <td>0.829502</td>\n",
       "      <td>0.340201</td>\n",
       "      <td>0.602806</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.006302</td>\n",
       "      <td>5.340000e+09</td>\n",
       "      <td>0.098162</td>\n",
       "      <td>0.336731</td>\n",
       "      <td>0.277456</td>\n",
       "      <td>0.013879</td>\n",
       "      <td>0.446027</td>\n",
       "      <td>0.742729</td>\n",
       "      <td>0.334777</td>\n",
       "      <td>3.715116e-03</td>\n",
       "      <td>0.909903</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.021387</td>\n",
       "      <td>1.791094e-03</td>\n",
       "      <td>1.022676e-03</td>\n",
       "      <td>0.594502</td>\n",
       "      <td>7.610000e+08</td>\n",
       "      <td>0.671571</td>\n",
       "      <td>0.276179</td>\n",
       "      <td>0.446027</td>\n",
       "      <td>0.334777</td>\n",
       "      <td>0.117922</td>\n",
       "      <td>0.642765</td>\n",
       "      <td>0.459254</td>\n",
       "      <td>0.538491</td>\n",
       "      <td>0.314515</td>\n",
       "      <td>0.025346</td>\n",
       "      <td>0</td>\n",
       "      <td>0.774670</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>0.623841</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>0.836774</td>\n",
       "      <td>0.290189</td>\n",
       "      <td>0.026555</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.399844</td>\n",
       "      <td>0.451265</td>\n",
       "      <td>0.457733</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.796967</td>\n",
       "      <td>0.808966</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>0.781241</td>\n",
       "      <td>1.078888e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.465705</td>\n",
       "      <td>4.490449e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154187</td>\n",
       "      <td>0.154187</td>\n",
       "      <td>0.154187</td>\n",
       "      <td>0.193722</td>\n",
       "      <td>0.321674</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.077762</td>\n",
       "      <td>0.148603</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.848005</td>\n",
       "      <td>0.689110</td>\n",
       "      <td>0.689110</td>\n",
       "      <td>0.217568</td>\n",
       "      <td>4.880000e+09</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.263371</td>\n",
       "      <td>0.384077</td>\n",
       "      <td>0.004194</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.630228</td>\n",
       "      <td>0.009572</td>\n",
       "      <td>0.151465</td>\n",
       "      <td>0.848535</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>0.379743</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.077727</td>\n",
       "      <td>0.147561</td>\n",
       "      <td>0.397925</td>\n",
       "      <td>0.089955</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>7.130000e+09</td>\n",
       "      <td>9.150000e+09</td>\n",
       "      <td>0.028065</td>\n",
       "      <td>0.015463</td>\n",
       "      <td>0.378497</td>\n",
       "      <td>0.021320</td>\n",
       "      <td>0.725754</td>\n",
       "      <td>0.161575</td>\n",
       "      <td>0.225815</td>\n",
       "      <td>0.018851</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>1.010646e-03</td>\n",
       "      <td>0.098715</td>\n",
       "      <td>0.348716</td>\n",
       "      <td>0.276580</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.615848</td>\n",
       "      <td>0.729825</td>\n",
       "      <td>0.331509</td>\n",
       "      <td>2.216520e-02</td>\n",
       "      <td>0.906902</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.024161</td>\n",
       "      <td>8.140000e+09</td>\n",
       "      <td>6.050000e+09</td>\n",
       "      <td>0.593889</td>\n",
       "      <td>2.030000e+09</td>\n",
       "      <td>0.671519</td>\n",
       "      <td>0.559144</td>\n",
       "      <td>0.615848</td>\n",
       "      <td>0.331509</td>\n",
       "      <td>0.120760</td>\n",
       "      <td>0.579039</td>\n",
       "      <td>0.448518</td>\n",
       "      <td>0.604105</td>\n",
       "      <td>0.302382</td>\n",
       "      <td>0.067250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.739555</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.622929</td>\n",
       "      <td>0.583538</td>\n",
       "      <td>0.834697</td>\n",
       "      <td>0.281721</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.564663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.465022</td>\n",
       "      <td>0.538432</td>\n",
       "      <td>0.522298</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.797366</td>\n",
       "      <td>0.809304</td>\n",
       "      <td>0.303475</td>\n",
       "      <td>0.781550</td>\n",
       "      <td>7.890000e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.462746</td>\n",
       "      <td>6.860686e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>0.167502</td>\n",
       "      <td>0.212537</td>\n",
       "      <td>0.319162</td>\n",
       "      <td>0.029690</td>\n",
       "      <td>0.096898</td>\n",
       "      <td>0.168412</td>\n",
       "      <td>0.022096</td>\n",
       "      <td>0.848258</td>\n",
       "      <td>0.689697</td>\n",
       "      <td>0.689697</td>\n",
       "      <td>0.217626</td>\n",
       "      <td>5.510000e+09</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.265218</td>\n",
       "      <td>0.379690</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.636055</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.106509</td>\n",
       "      <td>0.893491</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.375025</td>\n",
       "      <td>0.006624</td>\n",
       "      <td>0.096927</td>\n",
       "      <td>0.167461</td>\n",
       "      <td>0.400079</td>\n",
       "      <td>0.175412</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>1.633674e-04</td>\n",
       "      <td>2.935211e-04</td>\n",
       "      <td>0.040161</td>\n",
       "      <td>0.058111</td>\n",
       "      <td>0.394371</td>\n",
       "      <td>0.023988</td>\n",
       "      <td>0.751822</td>\n",
       "      <td>0.260330</td>\n",
       "      <td>0.358380</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>6.804636e-04</td>\n",
       "      <td>0.110195</td>\n",
       "      <td>0.344639</td>\n",
       "      <td>0.287913</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.975007</td>\n",
       "      <td>0.732000</td>\n",
       "      <td>0.330726</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.913850</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.026385</td>\n",
       "      <td>6.680000e+09</td>\n",
       "      <td>5.050000e+09</td>\n",
       "      <td>0.593915</td>\n",
       "      <td>8.240000e+08</td>\n",
       "      <td>0.671563</td>\n",
       "      <td>0.309555</td>\n",
       "      <td>0.975007</td>\n",
       "      <td>0.330726</td>\n",
       "      <td>0.110933</td>\n",
       "      <td>0.622374</td>\n",
       "      <td>0.454411</td>\n",
       "      <td>0.578469</td>\n",
       "      <td>0.311567</td>\n",
       "      <td>0.047725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795016</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.623521</td>\n",
       "      <td>0.598782</td>\n",
       "      <td>0.839973</td>\n",
       "      <td>0.278514</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.575617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6814</th>\n",
       "      <td>0</td>\n",
       "      <td>0.493687</td>\n",
       "      <td>0.539468</td>\n",
       "      <td>0.543230</td>\n",
       "      <td>0.604455</td>\n",
       "      <td>0.604462</td>\n",
       "      <td>0.998992</td>\n",
       "      <td>0.797409</td>\n",
       "      <td>0.809331</td>\n",
       "      <td>0.303510</td>\n",
       "      <td>0.781588</td>\n",
       "      <td>1.510213e-04</td>\n",
       "      <td>4.500000e+09</td>\n",
       "      <td>0.463734</td>\n",
       "      <td>1.790179e-04</td>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.175045</td>\n",
       "      <td>0.175045</td>\n",
       "      <td>0.175045</td>\n",
       "      <td>0.216602</td>\n",
       "      <td>0.320966</td>\n",
       "      <td>0.020766</td>\n",
       "      <td>0.098200</td>\n",
       "      <td>0.172102</td>\n",
       "      <td>0.022374</td>\n",
       "      <td>0.848205</td>\n",
       "      <td>0.689778</td>\n",
       "      <td>0.689778</td>\n",
       "      <td>0.217635</td>\n",
       "      <td>7.070000e+09</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.264517</td>\n",
       "      <td>0.380155</td>\n",
       "      <td>0.010451</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>0.631415</td>\n",
       "      <td>0.006655</td>\n",
       "      <td>0.124618</td>\n",
       "      <td>0.875382</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.373823</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.098222</td>\n",
       "      <td>0.171111</td>\n",
       "      <td>0.404804</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>4.030000e+07</td>\n",
       "      <td>1.429781e-04</td>\n",
       "      <td>0.027903</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.392596</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.817769</td>\n",
       "      <td>0.312840</td>\n",
       "      <td>0.578455</td>\n",
       "      <td>0.099481</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>5.071548e-03</td>\n",
       "      <td>0.103838</td>\n",
       "      <td>0.346224</td>\n",
       "      <td>0.277543</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>0.786888</td>\n",
       "      <td>0.736716</td>\n",
       "      <td>0.330914</td>\n",
       "      <td>1.792237e-03</td>\n",
       "      <td>0.925611</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.019060</td>\n",
       "      <td>2.294154e-04</td>\n",
       "      <td>1.244230e-04</td>\n",
       "      <td>0.593985</td>\n",
       "      <td>1.077940e-04</td>\n",
       "      <td>0.671570</td>\n",
       "      <td>0.400338</td>\n",
       "      <td>0.786888</td>\n",
       "      <td>0.330914</td>\n",
       "      <td>0.112622</td>\n",
       "      <td>0.639806</td>\n",
       "      <td>0.458639</td>\n",
       "      <td>0.587178</td>\n",
       "      <td>0.314063</td>\n",
       "      <td>0.027951</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799927</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.623620</td>\n",
       "      <td>0.604455</td>\n",
       "      <td>0.840359</td>\n",
       "      <td>0.279606</td>\n",
       "      <td>0.027064</td>\n",
       "      <td>0.566193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815</th>\n",
       "      <td>0</td>\n",
       "      <td>0.475162</td>\n",
       "      <td>0.538269</td>\n",
       "      <td>0.524172</td>\n",
       "      <td>0.598308</td>\n",
       "      <td>0.598308</td>\n",
       "      <td>0.998992</td>\n",
       "      <td>0.797414</td>\n",
       "      <td>0.809327</td>\n",
       "      <td>0.303520</td>\n",
       "      <td>0.781586</td>\n",
       "      <td>5.220000e+09</td>\n",
       "      <td>1.440000e+09</td>\n",
       "      <td>0.461978</td>\n",
       "      <td>2.370237e-04</td>\n",
       "      <td>0.371596</td>\n",
       "      <td>0.181324</td>\n",
       "      <td>0.181324</td>\n",
       "      <td>0.181324</td>\n",
       "      <td>0.216697</td>\n",
       "      <td>0.318278</td>\n",
       "      <td>0.023050</td>\n",
       "      <td>0.098608</td>\n",
       "      <td>0.172780</td>\n",
       "      <td>0.022159</td>\n",
       "      <td>0.848245</td>\n",
       "      <td>0.689734</td>\n",
       "      <td>0.689734</td>\n",
       "      <td>0.217631</td>\n",
       "      <td>5.220000e+09</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.264730</td>\n",
       "      <td>0.377389</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>0.631489</td>\n",
       "      <td>0.004623</td>\n",
       "      <td>0.099253</td>\n",
       "      <td>0.900747</td>\n",
       "      <td>0.006772</td>\n",
       "      <td>0.372505</td>\n",
       "      <td>0.008619</td>\n",
       "      <td>0.098572</td>\n",
       "      <td>0.171805</td>\n",
       "      <td>0.399926</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>9.940000e+09</td>\n",
       "      <td>6.051982e-04</td>\n",
       "      <td>0.027419</td>\n",
       "      <td>0.016083</td>\n",
       "      <td>0.393625</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.793387</td>\n",
       "      <td>0.335085</td>\n",
       "      <td>0.444043</td>\n",
       "      <td>0.080337</td>\n",
       "      <td>0.006790</td>\n",
       "      <td>4.727181e-03</td>\n",
       "      <td>0.089901</td>\n",
       "      <td>0.342166</td>\n",
       "      <td>0.277368</td>\n",
       "      <td>0.006730</td>\n",
       "      <td>0.849898</td>\n",
       "      <td>0.734584</td>\n",
       "      <td>0.329753</td>\n",
       "      <td>2.204673e-03</td>\n",
       "      <td>0.932629</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>1.517299e-04</td>\n",
       "      <td>1.173396e-04</td>\n",
       "      <td>0.593954</td>\n",
       "      <td>7.710000e+09</td>\n",
       "      <td>0.671572</td>\n",
       "      <td>0.096136</td>\n",
       "      <td>0.849898</td>\n",
       "      <td>0.329753</td>\n",
       "      <td>0.112329</td>\n",
       "      <td>0.642072</td>\n",
       "      <td>0.459058</td>\n",
       "      <td>0.569498</td>\n",
       "      <td>0.314446</td>\n",
       "      <td>0.031470</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799748</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.623931</td>\n",
       "      <td>0.598306</td>\n",
       "      <td>0.840306</td>\n",
       "      <td>0.278132</td>\n",
       "      <td>0.027009</td>\n",
       "      <td>0.566018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6816</th>\n",
       "      <td>0</td>\n",
       "      <td>0.472725</td>\n",
       "      <td>0.533744</td>\n",
       "      <td>0.520638</td>\n",
       "      <td>0.610444</td>\n",
       "      <td>0.610213</td>\n",
       "      <td>0.998984</td>\n",
       "      <td>0.797401</td>\n",
       "      <td>0.809317</td>\n",
       "      <td>0.303512</td>\n",
       "      <td>0.781546</td>\n",
       "      <td>2.509312e-04</td>\n",
       "      <td>1.039086e-04</td>\n",
       "      <td>0.472189</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.490839</td>\n",
       "      <td>0.269521</td>\n",
       "      <td>0.269521</td>\n",
       "      <td>0.269521</td>\n",
       "      <td>0.210929</td>\n",
       "      <td>0.324857</td>\n",
       "      <td>0.044255</td>\n",
       "      <td>0.100073</td>\n",
       "      <td>0.173232</td>\n",
       "      <td>0.022068</td>\n",
       "      <td>0.847978</td>\n",
       "      <td>0.689202</td>\n",
       "      <td>0.689202</td>\n",
       "      <td>0.217547</td>\n",
       "      <td>5.990000e+09</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.263858</td>\n",
       "      <td>0.379392</td>\n",
       "      <td>0.038424</td>\n",
       "      <td>0.035112</td>\n",
       "      <td>0.630612</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.038939</td>\n",
       "      <td>0.961061</td>\n",
       "      <td>0.009149</td>\n",
       "      <td>0.369637</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.100103</td>\n",
       "      <td>0.172287</td>\n",
       "      <td>0.395592</td>\n",
       "      <td>0.106447</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.004188</td>\n",
       "      <td>2.797309e-04</td>\n",
       "      <td>1.024298e-03</td>\n",
       "      <td>0.022419</td>\n",
       "      <td>0.022097</td>\n",
       "      <td>0.393693</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>0.866047</td>\n",
       "      <td>0.476747</td>\n",
       "      <td>0.496053</td>\n",
       "      <td>0.412885</td>\n",
       "      <td>0.035531</td>\n",
       "      <td>8.821248e-02</td>\n",
       "      <td>0.024414</td>\n",
       "      <td>0.358847</td>\n",
       "      <td>0.277022</td>\n",
       "      <td>0.007810</td>\n",
       "      <td>0.553964</td>\n",
       "      <td>0.737432</td>\n",
       "      <td>0.326921</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.035446</td>\n",
       "      <td>1.762272e-04</td>\n",
       "      <td>1.749713e-04</td>\n",
       "      <td>0.594025</td>\n",
       "      <td>4.074263e-04</td>\n",
       "      <td>0.671564</td>\n",
       "      <td>0.055509</td>\n",
       "      <td>0.553964</td>\n",
       "      <td>0.326921</td>\n",
       "      <td>0.110933</td>\n",
       "      <td>0.631678</td>\n",
       "      <td>0.452465</td>\n",
       "      <td>0.589341</td>\n",
       "      <td>0.313353</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0</td>\n",
       "      <td>0.797778</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.624156</td>\n",
       "      <td>0.610441</td>\n",
       "      <td>0.840138</td>\n",
       "      <td>0.275789</td>\n",
       "      <td>0.026791</td>\n",
       "      <td>0.565158</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6817</th>\n",
       "      <td>0</td>\n",
       "      <td>0.506264</td>\n",
       "      <td>0.559911</td>\n",
       "      <td>0.554045</td>\n",
       "      <td>0.607850</td>\n",
       "      <td>0.607850</td>\n",
       "      <td>0.999074</td>\n",
       "      <td>0.797500</td>\n",
       "      <td>0.809399</td>\n",
       "      <td>0.303498</td>\n",
       "      <td>0.781663</td>\n",
       "      <td>1.236154e-04</td>\n",
       "      <td>2.510000e+09</td>\n",
       "      <td>0.476123</td>\n",
       "      <td>2.110211e-04</td>\n",
       "      <td>0.181294</td>\n",
       "      <td>0.213392</td>\n",
       "      <td>0.213392</td>\n",
       "      <td>0.213392</td>\n",
       "      <td>0.228326</td>\n",
       "      <td>0.346573</td>\n",
       "      <td>0.031535</td>\n",
       "      <td>0.111799</td>\n",
       "      <td>0.185584</td>\n",
       "      <td>0.022350</td>\n",
       "      <td>0.854064</td>\n",
       "      <td>0.696113</td>\n",
       "      <td>0.696113</td>\n",
       "      <td>0.218006</td>\n",
       "      <td>7.250000e+09</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.264409</td>\n",
       "      <td>0.401028</td>\n",
       "      <td>0.012782</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>0.630731</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>0.086979</td>\n",
       "      <td>0.913021</td>\n",
       "      <td>0.005529</td>\n",
       "      <td>0.369649</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>0.111722</td>\n",
       "      <td>0.182498</td>\n",
       "      <td>0.401540</td>\n",
       "      <td>0.109445</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.008829</td>\n",
       "      <td>4.550000e+09</td>\n",
       "      <td>2.330013e-04</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>0.012749</td>\n",
       "      <td>0.396735</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.832340</td>\n",
       "      <td>0.353624</td>\n",
       "      <td>0.564439</td>\n",
       "      <td>0.112238</td>\n",
       "      <td>0.007753</td>\n",
       "      <td>7.133218e-03</td>\n",
       "      <td>0.083199</td>\n",
       "      <td>0.380251</td>\n",
       "      <td>0.277353</td>\n",
       "      <td>0.013334</td>\n",
       "      <td>0.893241</td>\n",
       "      <td>0.736713</td>\n",
       "      <td>0.329294</td>\n",
       "      <td>3.200000e+09</td>\n",
       "      <td>0.939613</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.016443</td>\n",
       "      <td>2.135940e-04</td>\n",
       "      <td>1.351937e-04</td>\n",
       "      <td>0.593997</td>\n",
       "      <td>1.165392e-04</td>\n",
       "      <td>0.671606</td>\n",
       "      <td>0.246805</td>\n",
       "      <td>0.893241</td>\n",
       "      <td>0.329294</td>\n",
       "      <td>0.110957</td>\n",
       "      <td>0.684857</td>\n",
       "      <td>0.471313</td>\n",
       "      <td>0.678338</td>\n",
       "      <td>0.320118</td>\n",
       "      <td>0.022916</td>\n",
       "      <td>0</td>\n",
       "      <td>0.811808</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.623957</td>\n",
       "      <td>0.607846</td>\n",
       "      <td>0.841084</td>\n",
       "      <td>0.277547</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>0.565302</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6818</th>\n",
       "      <td>0</td>\n",
       "      <td>0.493053</td>\n",
       "      <td>0.570105</td>\n",
       "      <td>0.549548</td>\n",
       "      <td>0.627409</td>\n",
       "      <td>0.627409</td>\n",
       "      <td>0.998080</td>\n",
       "      <td>0.801987</td>\n",
       "      <td>0.813800</td>\n",
       "      <td>0.313415</td>\n",
       "      <td>0.786079</td>\n",
       "      <td>1.431695e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.427721</td>\n",
       "      <td>5.900000e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220766</td>\n",
       "      <td>0.220766</td>\n",
       "      <td>0.220766</td>\n",
       "      <td>0.227758</td>\n",
       "      <td>0.305793</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.092501</td>\n",
       "      <td>0.182119</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.848053</td>\n",
       "      <td>0.689527</td>\n",
       "      <td>0.689527</td>\n",
       "      <td>0.217605</td>\n",
       "      <td>9.350000e+09</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.264186</td>\n",
       "      <td>0.360102</td>\n",
       "      <td>0.051348</td>\n",
       "      <td>0.040897</td>\n",
       "      <td>0.630618</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.014149</td>\n",
       "      <td>0.985851</td>\n",
       "      <td>0.058476</td>\n",
       "      <td>0.370049</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>0.092465</td>\n",
       "      <td>0.179911</td>\n",
       "      <td>0.393883</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.019474</td>\n",
       "      <td>1.910000e+07</td>\n",
       "      <td>2.995731e-04</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.385767</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.873759</td>\n",
       "      <td>0.527136</td>\n",
       "      <td>0.505010</td>\n",
       "      <td>0.238147</td>\n",
       "      <td>0.051481</td>\n",
       "      <td>6.667354e-02</td>\n",
       "      <td>0.018517</td>\n",
       "      <td>0.239585</td>\n",
       "      <td>0.276975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.737286</td>\n",
       "      <td>0.326690</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.938005</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.006089</td>\n",
       "      <td>7.863781e-03</td>\n",
       "      <td>8.238471e-03</td>\n",
       "      <td>0.598674</td>\n",
       "      <td>9.505992e-03</td>\n",
       "      <td>0.672096</td>\n",
       "      <td>0.005016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.326690</td>\n",
       "      <td>0.110933</td>\n",
       "      <td>0.659917</td>\n",
       "      <td>0.483285</td>\n",
       "      <td>0.505531</td>\n",
       "      <td>0.316238</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>0</td>\n",
       "      <td>0.815956</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.626680</td>\n",
       "      <td>0.627408</td>\n",
       "      <td>0.841019</td>\n",
       "      <td>0.275114</td>\n",
       "      <td>0.026793</td>\n",
       "      <td>0.565167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.233902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6819 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bankrupt?   ROA(C) before interest and depreciation before interest  \\\n",
       "0             1                                           0.370594          \n",
       "1             1                                           0.464291          \n",
       "2             1                                           0.426071          \n",
       "3             1                                           0.399844          \n",
       "4             1                                           0.465022          \n",
       "...         ...                                                ...          \n",
       "6814          0                                           0.493687          \n",
       "6815          0                                           0.475162          \n",
       "6816          0                                           0.472725          \n",
       "6817          0                                           0.506264          \n",
       "6818          0                                           0.493053          \n",
       "\n",
       "       ROA(A) before interest and % after tax  \\\n",
       "0                                    0.424389   \n",
       "1                                    0.538214   \n",
       "2                                    0.499019   \n",
       "3                                    0.451265   \n",
       "4                                    0.538432   \n",
       "...                                       ...   \n",
       "6814                                 0.539468   \n",
       "6815                                 0.538269   \n",
       "6816                                 0.533744   \n",
       "6817                                 0.559911   \n",
       "6818                                 0.570105   \n",
       "\n",
       "       ROA(B) before interest and depreciation after tax  \\\n",
       "0                                              0.405750    \n",
       "1                                              0.516730    \n",
       "2                                              0.472295    \n",
       "3                                              0.457733    \n",
       "4                                              0.522298    \n",
       "...                                                 ...    \n",
       "6814                                           0.543230    \n",
       "6815                                           0.524172    \n",
       "6816                                           0.520638    \n",
       "6817                                           0.554045    \n",
       "6818                                           0.549548    \n",
       "\n",
       "       Operating Gross Margin   Realized Sales Gross Margin  \\\n",
       "0                    0.601457                      0.601457   \n",
       "1                    0.610235                      0.610235   \n",
       "2                    0.601450                      0.601364   \n",
       "3                    0.583541                      0.583541   \n",
       "4                    0.598783                      0.598783   \n",
       "...                       ...                           ...   \n",
       "6814                 0.604455                      0.604462   \n",
       "6815                 0.598308                      0.598308   \n",
       "6816                 0.610444                      0.610213   \n",
       "6817                 0.607850                      0.607850   \n",
       "6818                 0.627409                      0.627409   \n",
       "\n",
       "       Operating Profit Rate   Pre-tax net Interest Rate  \\\n",
       "0                   0.998969                    0.796887   \n",
       "1                   0.998946                    0.797380   \n",
       "2                   0.998857                    0.796403   \n",
       "3                   0.998700                    0.796967   \n",
       "4                   0.998973                    0.797366   \n",
       "...                      ...                         ...   \n",
       "6814                0.998992                    0.797409   \n",
       "6815                0.998992                    0.797414   \n",
       "6816                0.998984                    0.797401   \n",
       "6817                0.999074                    0.797500   \n",
       "6818                0.998080                    0.801987   \n",
       "\n",
       "       After-tax net Interest Rate  \\\n",
       "0                         0.808809   \n",
       "1                         0.809301   \n",
       "2                         0.808388   \n",
       "3                         0.808966   \n",
       "4                         0.809304   \n",
       "...                            ...   \n",
       "6814                      0.809331   \n",
       "6815                      0.809327   \n",
       "6816                      0.809317   \n",
       "6817                      0.809399   \n",
       "6818                      0.813800   \n",
       "\n",
       "       Non-industry income and expenditure/revenue  \\\n",
       "0                                         0.302646   \n",
       "1                                         0.303556   \n",
       "2                                         0.302035   \n",
       "3                                         0.303350   \n",
       "4                                         0.303475   \n",
       "...                                            ...   \n",
       "6814                                      0.303510   \n",
       "6815                                      0.303520   \n",
       "6816                                      0.303512   \n",
       "6817                                      0.303498   \n",
       "6818                                      0.313415   \n",
       "\n",
       "       Continuous interest rate (after tax)   Operating Expense Rate  \\\n",
       "0                                  0.780985             1.256969e-04   \n",
       "1                                  0.781506             2.897851e-04   \n",
       "2                                  0.780284             2.361297e-04   \n",
       "3                                  0.781241             1.078888e-04   \n",
       "4                                  0.781550             7.890000e+09   \n",
       "...                                     ...                      ...   \n",
       "6814                               0.781588             1.510213e-04   \n",
       "6815                               0.781586             5.220000e+09   \n",
       "6816                               0.781546             2.509312e-04   \n",
       "6817                               0.781663             1.236154e-04   \n",
       "6818                               0.786079             1.431695e-03   \n",
       "\n",
       "       Research and development expense rate   Cash flow rate  \\\n",
       "0                               0.000000e+00         0.458143   \n",
       "1                               0.000000e+00         0.461867   \n",
       "2                               2.550000e+07         0.458521   \n",
       "3                               0.000000e+00         0.465705   \n",
       "4                               0.000000e+00         0.462746   \n",
       "...                                      ...              ...   \n",
       "6814                            4.500000e+09         0.463734   \n",
       "6815                            1.440000e+09         0.461978   \n",
       "6816                            1.039086e-04         0.472189   \n",
       "6817                            2.510000e+09         0.476123   \n",
       "6818                            0.000000e+00         0.427721   \n",
       "\n",
       "       Interest-bearing debt interest rate   Tax rate (A)  \\\n",
       "0                             7.250725e-04       0.000000   \n",
       "1                             6.470647e-04       0.000000   \n",
       "2                             7.900790e-04       0.000000   \n",
       "3                             4.490449e-04       0.000000   \n",
       "4                             6.860686e-04       0.000000   \n",
       "...                                    ...            ...   \n",
       "6814                          1.790179e-04       0.113372   \n",
       "6815                          2.370237e-04       0.371596   \n",
       "6816                          0.000000e+00       0.490839   \n",
       "6817                          2.110211e-04       0.181294   \n",
       "6818                          5.900000e+08       0.000000   \n",
       "\n",
       "       Net Value Per Share (B)   Net Value Per Share (A)  \\\n",
       "0                     0.147950                  0.147950   \n",
       "1                     0.182251                  0.182251   \n",
       "2                     0.177911                  0.177911   \n",
       "3                     0.154187                  0.154187   \n",
       "4                     0.167502                  0.167502   \n",
       "...                        ...                       ...   \n",
       "6814                  0.175045                  0.175045   \n",
       "6815                  0.181324                  0.181324   \n",
       "6816                  0.269521                  0.269521   \n",
       "6817                  0.213392                  0.213392   \n",
       "6818                  0.220766                  0.220766   \n",
       "\n",
       "       Net Value Per Share (C)   Persistent EPS in the Last Four Seasons  \\\n",
       "0                     0.147950                                  0.169141   \n",
       "1                     0.182251                                  0.208944   \n",
       "2                     0.193713                                  0.180581   \n",
       "3                     0.154187                                  0.193722   \n",
       "4                     0.167502                                  0.212537   \n",
       "...                        ...                                       ...   \n",
       "6814                  0.175045                                  0.216602   \n",
       "6815                  0.181324                                  0.216697   \n",
       "6816                  0.269521                                  0.210929   \n",
       "6817                  0.213392                                  0.228326   \n",
       "6818                  0.220766                                  0.227758   \n",
       "\n",
       "       Cash Flow Per Share   Revenue Per Share (Yuan ¥)  \\\n",
       "0                 0.311664                     0.017560   \n",
       "1                 0.318137                     0.021144   \n",
       "2                 0.307102                     0.005944   \n",
       "3                 0.321674                     0.014368   \n",
       "4                 0.319162                     0.029690   \n",
       "...                    ...                          ...   \n",
       "6814              0.320966                     0.020766   \n",
       "6815              0.318278                     0.023050   \n",
       "6816              0.324857                     0.044255   \n",
       "6817              0.346573                     0.031535   \n",
       "6818              0.305793                     0.000665   \n",
       "\n",
       "       Operating Profit Per Share (Yuan ¥)  \\\n",
       "0                                 0.095921   \n",
       "1                                 0.093722   \n",
       "2                                 0.092338   \n",
       "3                                 0.077762   \n",
       "4                                 0.096898   \n",
       "...                                    ...   \n",
       "6814                              0.098200   \n",
       "6815                              0.098608   \n",
       "6816                              0.100073   \n",
       "6817                              0.111799   \n",
       "6818                              0.092501   \n",
       "\n",
       "       Per Share Net profit before tax (Yuan ¥)  \\\n",
       "0                                      0.138736   \n",
       "1                                      0.169918   \n",
       "2                                      0.142803   \n",
       "3                                      0.148603   \n",
       "4                                      0.168412   \n",
       "...                                         ...   \n",
       "6814                                   0.172102   \n",
       "6815                                   0.172780   \n",
       "6816                                   0.173232   \n",
       "6817                                   0.185584   \n",
       "6818                                   0.182119   \n",
       "\n",
       "       Realized Sales Gross Profit Growth Rate   Operating Profit Growth Rate  \\\n",
       "0                                     0.022102                       0.848195   \n",
       "1                                     0.022080                       0.848088   \n",
       "2                                     0.022760                       0.848094   \n",
       "3                                     0.022046                       0.848005   \n",
       "4                                     0.022096                       0.848258   \n",
       "...                                        ...                            ...   \n",
       "6814                                  0.022374                       0.848205   \n",
       "6815                                  0.022159                       0.848245   \n",
       "6816                                  0.022068                       0.847978   \n",
       "6817                                  0.022350                       0.854064   \n",
       "6818                                  0.025316                       0.848053   \n",
       "\n",
       "       After-tax Net Profit Growth Rate   Regular Net Profit Growth Rate  \\\n",
       "0                              0.688979                         0.688979   \n",
       "1                              0.689693                         0.689702   \n",
       "2                              0.689463                         0.689470   \n",
       "3                              0.689110                         0.689110   \n",
       "4                              0.689697                         0.689697   \n",
       "...                                 ...                              ...   \n",
       "6814                           0.689778                         0.689778   \n",
       "6815                           0.689734                         0.689734   \n",
       "6816                           0.689202                         0.689202   \n",
       "6817                           0.696113                         0.696113   \n",
       "6818                           0.689527                         0.689527   \n",
       "\n",
       "       Continuous Net Profit Growth Rate   Total Asset Growth Rate  \\\n",
       "0                               0.217535              4.980000e+09   \n",
       "1                               0.217620              6.110000e+09   \n",
       "2                               0.217601              7.280000e+09   \n",
       "3                               0.217568              4.880000e+09   \n",
       "4                               0.217626              5.510000e+09   \n",
       "...                                  ...                       ...   \n",
       "6814                            0.217635              7.070000e+09   \n",
       "6815                            0.217631              5.220000e+09   \n",
       "6816                            0.217547              5.990000e+09   \n",
       "6817                            0.218006              7.250000e+09   \n",
       "6818                            0.217605              9.350000e+09   \n",
       "\n",
       "       Net Value Growth Rate   Total Asset Return Growth Rate Ratio  \\\n",
       "0                   0.000327                               0.263100   \n",
       "1                   0.000443                               0.264516   \n",
       "2                   0.000396                               0.264184   \n",
       "3                   0.000382                               0.263371   \n",
       "4                   0.000439                               0.265218   \n",
       "...                      ...                                    ...   \n",
       "6814                0.000450                               0.264517   \n",
       "6815                0.000445                               0.264730   \n",
       "6816                0.000435                               0.263858   \n",
       "6817                0.000529                               0.264409   \n",
       "6818                0.000519                               0.264186   \n",
       "\n",
       "       Cash Reinvestment %   Current Ratio   Quick Ratio  \\\n",
       "0                 0.363725        0.002259      0.001208   \n",
       "1                 0.376709        0.006016      0.004039   \n",
       "2                 0.368913        0.011543      0.005348   \n",
       "3                 0.384077        0.004194      0.002896   \n",
       "4                 0.379690        0.006022      0.003727   \n",
       "...                    ...             ...           ...   \n",
       "6814              0.380155        0.010451      0.005457   \n",
       "6815              0.377389        0.009259      0.006741   \n",
       "6816              0.379392        0.038424      0.035112   \n",
       "6817              0.401028        0.012782      0.007256   \n",
       "6818              0.360102        0.051348      0.040897   \n",
       "\n",
       "       Interest Expense Ratio   Total debt/Total net worth   Debt ratio %  \\\n",
       "0                    0.629951                     0.021266       0.207576   \n",
       "1                    0.635172                     0.012502       0.171176   \n",
       "2                    0.629631                     0.021248       0.207516   \n",
       "3                    0.630228                     0.009572       0.151465   \n",
       "4                    0.636055                     0.005150       0.106509   \n",
       "...                       ...                          ...            ...   \n",
       "6814                 0.631415                     0.006655       0.124618   \n",
       "6815                 0.631489                     0.004623       0.099253   \n",
       "6816                 0.630612                     0.001392       0.038939   \n",
       "6817                 0.630731                     0.003816       0.086979   \n",
       "6818                 0.630618                     0.000461       0.014149   \n",
       "\n",
       "       Net worth/Assets   Long-term fund suitability ratio (A)  \\\n",
       "0              0.792424                               0.005024   \n",
       "1              0.828824                               0.005059   \n",
       "2              0.792484                               0.005100   \n",
       "3              0.848535                               0.005047   \n",
       "4              0.893491                               0.005303   \n",
       "...                 ...                                    ...   \n",
       "6814           0.875382                               0.005150   \n",
       "6815           0.900747                               0.006772   \n",
       "6816           0.961061                               0.009149   \n",
       "6817           0.913021                               0.005529   \n",
       "6818           0.985851                               0.058476   \n",
       "\n",
       "       Borrowing dependency   Contingent liabilities/Net worth  \\\n",
       "0                  0.390284                           0.006479   \n",
       "1                  0.376760                           0.005835   \n",
       "2                  0.379093                           0.006562   \n",
       "3                  0.379743                           0.005366   \n",
       "4                  0.375025                           0.006624   \n",
       "...                     ...                                ...   \n",
       "6814               0.373823                           0.005366   \n",
       "6815               0.372505                           0.008619   \n",
       "6816               0.369637                           0.005366   \n",
       "6817               0.369649                           0.007068   \n",
       "6818               0.370049                           0.006368   \n",
       "\n",
       "       Operating profit/Paid-in capital  \\\n",
       "0                              0.095885   \n",
       "1                              0.093743   \n",
       "2                              0.092318   \n",
       "3                              0.077727   \n",
       "4                              0.096927   \n",
       "...                                 ...   \n",
       "6814                           0.098222   \n",
       "6815                           0.098572   \n",
       "6816                           0.100103   \n",
       "6817                           0.111722   \n",
       "6818                           0.092465   \n",
       "\n",
       "       Net profit before tax/Paid-in capital  \\\n",
       "0                                   0.137757   \n",
       "1                                   0.168962   \n",
       "2                                   0.148036   \n",
       "3                                   0.147561   \n",
       "4                                   0.167461   \n",
       "...                                      ...   \n",
       "6814                                0.171111   \n",
       "6815                                0.171805   \n",
       "6816                                0.172287   \n",
       "6817                                0.182498   \n",
       "6818                                0.179911   \n",
       "\n",
       "       Inventory and accounts receivable/Net value   Total Asset Turnover  \\\n",
       "0                                         0.398036               0.086957   \n",
       "1                                         0.397725               0.064468   \n",
       "2                                         0.406580               0.014993   \n",
       "3                                         0.397925               0.089955   \n",
       "4                                         0.400079               0.175412   \n",
       "...                                            ...                    ...   \n",
       "6814                                      0.404804               0.103448   \n",
       "6815                                      0.399926               0.103448   \n",
       "6816                                      0.395592               0.106447   \n",
       "6817                                      0.401540               0.109445   \n",
       "6818                                      0.393883               0.002999   \n",
       "\n",
       "       Accounts Receivable Turnover   Average Collection Days  \\\n",
       "0                          0.001814                  0.003487   \n",
       "1                          0.001286                  0.004917   \n",
       "2                          0.001495                  0.004227   \n",
       "3                          0.001966                  0.003215   \n",
       "4                          0.001449                  0.004367   \n",
       "...                             ...                       ...   \n",
       "6814                       0.000690                  0.009177   \n",
       "6815                       0.000655                  0.009652   \n",
       "6816                       0.001510                  0.004188   \n",
       "6817                       0.000716                  0.008829   \n",
       "6818                       0.000325                  0.019474   \n",
       "\n",
       "       Inventory Turnover Rate (times)   Fixed Assets Turnover Frequency  \\\n",
       "0                         1.820926e-04                      1.165007e-04   \n",
       "1                         9.360000e+09                      7.190000e+08   \n",
       "2                         6.500000e+07                      2.650000e+09   \n",
       "3                         7.130000e+09                      9.150000e+09   \n",
       "4                         1.633674e-04                      2.935211e-04   \n",
       "...                                ...                               ...   \n",
       "6814                      4.030000e+07                      1.429781e-04   \n",
       "6815                      9.940000e+09                      6.051982e-04   \n",
       "6816                      2.797309e-04                      1.024298e-03   \n",
       "6817                      4.550000e+09                      2.330013e-04   \n",
       "6818                      1.910000e+07                      2.995731e-04   \n",
       "\n",
       "       Net Worth Turnover Rate (times)   Revenue per person  \\\n",
       "0                             0.032903             0.034164   \n",
       "1                             0.025484             0.006889   \n",
       "2                             0.013387             0.028997   \n",
       "3                             0.028065             0.015463   \n",
       "4                             0.040161             0.058111   \n",
       "...                                ...                  ...   \n",
       "6814                          0.027903             0.006348   \n",
       "6815                          0.027419             0.016083   \n",
       "6816                          0.022419             0.022097   \n",
       "6817                          0.027258             0.012749   \n",
       "6818                          0.009194             0.002097   \n",
       "\n",
       "       Operating profit per person   Allocation rate per person  \\\n",
       "0                         0.392913                     0.037135   \n",
       "1                         0.391590                     0.012335   \n",
       "2                         0.381968                     0.141016   \n",
       "3                         0.378497                     0.021320   \n",
       "4                         0.394371                     0.023988   \n",
       "...                            ...                          ...   \n",
       "6814                      0.392596                     0.006312   \n",
       "6815                      0.393625                     0.003401   \n",
       "6816                      0.393693                     0.002774   \n",
       "6817                      0.396735                     0.007489   \n",
       "6818                      0.385767                     0.000963   \n",
       "\n",
       "       Working Capital to Total Assets   Quick Assets/Total Assets  \\\n",
       "0                             0.672775                    0.166673   \n",
       "1                             0.751111                    0.127236   \n",
       "2                             0.829502                    0.340201   \n",
       "3                             0.725754                    0.161575   \n",
       "4                             0.751822                    0.260330   \n",
       "...                                ...                         ...   \n",
       "6814                          0.817769                    0.312840   \n",
       "6815                          0.793387                    0.335085   \n",
       "6816                          0.866047                    0.476747   \n",
       "6817                          0.832340                    0.353624   \n",
       "6818                          0.873759                    0.527136   \n",
       "\n",
       "       Current Assets/Total Assets   Cash/Total Assets  \\\n",
       "0                         0.190643            0.004094   \n",
       "1                         0.182419            0.014948   \n",
       "2                         0.602806            0.000991   \n",
       "3                         0.225815            0.018851   \n",
       "4                         0.358380            0.014161   \n",
       "...                            ...                 ...   \n",
       "6814                      0.578455            0.099481   \n",
       "6815                      0.444043            0.080337   \n",
       "6816                      0.496053            0.412885   \n",
       "6817                      0.564439            0.112238   \n",
       "6818                      0.505010            0.238147   \n",
       "\n",
       "       Quick Assets/Current Liability   Cash/Current Liability  \\\n",
       "0                            0.001997             1.473360e-04   \n",
       "1                            0.004136             1.383910e-03   \n",
       "2                            0.006302             5.340000e+09   \n",
       "3                            0.002961             1.010646e-03   \n",
       "4                            0.004275             6.804636e-04   \n",
       "...                               ...                      ...   \n",
       "6814                         0.005469             5.071548e-03   \n",
       "6815                         0.006790             4.727181e-03   \n",
       "6816                         0.035531             8.821248e-02   \n",
       "6817                         0.007753             7.133218e-03   \n",
       "6818                         0.051481             6.667354e-02   \n",
       "\n",
       "       Current Liability to Assets   Operating Funds to Liability  \\\n",
       "0                         0.147308                       0.334015   \n",
       "1                         0.056963                       0.341106   \n",
       "2                         0.098162                       0.336731   \n",
       "3                         0.098715                       0.348716   \n",
       "4                         0.110195                       0.344639   \n",
       "...                            ...                            ...   \n",
       "6814                      0.103838                       0.346224   \n",
       "6815                      0.089901                       0.342166   \n",
       "6816                      0.024414                       0.358847   \n",
       "6817                      0.083199                       0.380251   \n",
       "6818                      0.018517                       0.239585   \n",
       "\n",
       "       Inventory/Working Capital   Inventory/Current Liability  \\\n",
       "0                       0.276920                      0.001036   \n",
       "1                       0.289642                      0.005210   \n",
       "2                       0.277456                      0.013879   \n",
       "3                       0.276580                      0.003540   \n",
       "4                       0.287913                      0.004869   \n",
       "...                          ...                           ...   \n",
       "6814                    0.277543                      0.013212   \n",
       "6815                    0.277368                      0.006730   \n",
       "6816                    0.277022                      0.007810   \n",
       "6817                    0.277353                      0.013334   \n",
       "6818                    0.276975                      0.000000   \n",
       "\n",
       "       Current Liabilities/Liability   Working Capital/Equity  \\\n",
       "0                           0.676269                 0.721275   \n",
       "1                           0.308589                 0.731975   \n",
       "2                           0.446027                 0.742729   \n",
       "3                           0.615848                 0.729825   \n",
       "4                           0.975007                 0.732000   \n",
       "...                              ...                      ...   \n",
       "6814                        0.786888                 0.736716   \n",
       "6815                        0.849898                 0.734584   \n",
       "6816                        0.553964                 0.737432   \n",
       "6817                        0.893241                 0.736713   \n",
       "6818                        1.000000                 0.737286   \n",
       "\n",
       "       Current Liabilities/Equity   Long-term Liability to Current Assets  \\\n",
       "0                        0.339077                            2.559237e-02   \n",
       "1                        0.329740                            2.394682e-02   \n",
       "2                        0.334777                            3.715116e-03   \n",
       "3                        0.331509                            2.216520e-02   \n",
       "4                        0.330726                            0.000000e+00   \n",
       "...                           ...                                     ...   \n",
       "6814                     0.330914                            1.792237e-03   \n",
       "6815                     0.329753                            2.204673e-03   \n",
       "6816                     0.326921                            0.000000e+00   \n",
       "6817                     0.329294                            3.200000e+09   \n",
       "6818                     0.326690                            0.000000e+00   \n",
       "\n",
       "       Retained Earnings to Total Assets   Total income/Total expense  \\\n",
       "0                               0.903225                     0.002022   \n",
       "1                               0.931065                     0.002226   \n",
       "2                               0.909903                     0.002060   \n",
       "3                               0.906902                     0.001831   \n",
       "4                               0.913850                     0.002224   \n",
       "...                                  ...                          ...   \n",
       "6814                            0.925611                     0.002266   \n",
       "6815                            0.932629                     0.002288   \n",
       "6816                            0.932000                     0.002239   \n",
       "6817                            0.939613                     0.002395   \n",
       "6818                            0.938005                     0.002791   \n",
       "\n",
       "       Total expense/Assets   Current Asset Turnover Rate  \\\n",
       "0                  0.064856                  7.010000e+08   \n",
       "1                  0.025516                  1.065198e-04   \n",
       "2                  0.021387                  1.791094e-03   \n",
       "3                  0.024161                  8.140000e+09   \n",
       "4                  0.026385                  6.680000e+09   \n",
       "...                     ...                           ...   \n",
       "6814               0.019060                  2.294154e-04   \n",
       "6815               0.011118                  1.517299e-04   \n",
       "6816               0.035446                  1.762272e-04   \n",
       "6817               0.016443                  2.135940e-04   \n",
       "6818               0.006089                  7.863781e-03   \n",
       "\n",
       "       Quick Asset Turnover Rate   Working capitcal Turnover Rate  \\\n",
       "0                   6.550000e+09                         0.593831   \n",
       "1                   7.700000e+09                         0.593916   \n",
       "2                   1.022676e-03                         0.594502   \n",
       "3                   6.050000e+09                         0.593889   \n",
       "4                   5.050000e+09                         0.593915   \n",
       "...                          ...                              ...   \n",
       "6814                1.244230e-04                         0.593985   \n",
       "6815                1.173396e-04                         0.593954   \n",
       "6816                1.749713e-04                         0.594025   \n",
       "6817                1.351937e-04                         0.593997   \n",
       "6818                8.238471e-03                         0.598674   \n",
       "\n",
       "       Cash Turnover Rate   Cash Flow to Sales   Fixed Assets to Assets  \\\n",
       "0            4.580000e+08             0.671568                 0.424206   \n",
       "1            2.490000e+09             0.671570                 0.468828   \n",
       "2            7.610000e+08             0.671571                 0.276179   \n",
       "3            2.030000e+09             0.671519                 0.559144   \n",
       "4            8.240000e+08             0.671563                 0.309555   \n",
       "...                   ...                  ...                      ...   \n",
       "6814         1.077940e-04             0.671570                 0.400338   \n",
       "6815         7.710000e+09             0.671572                 0.096136   \n",
       "6816         4.074263e-04             0.671564                 0.055509   \n",
       "6817         1.165392e-04             0.671606                 0.246805   \n",
       "6818         9.505992e-03             0.672096                 0.005016   \n",
       "\n",
       "       Current Liability to Liability   Current Liability to Equity  \\\n",
       "0                            0.676269                      0.339077   \n",
       "1                            0.308589                      0.329740   \n",
       "2                            0.446027                      0.334777   \n",
       "3                            0.615848                      0.331509   \n",
       "4                            0.975007                      0.330726   \n",
       "...                               ...                           ...   \n",
       "6814                         0.786888                      0.330914   \n",
       "6815                         0.849898                      0.329753   \n",
       "6816                         0.553964                      0.326921   \n",
       "6817                         0.893241                      0.329294   \n",
       "6818                         1.000000                      0.326690   \n",
       "\n",
       "       Equity to Long-term Liability   Cash Flow to Total Assets  \\\n",
       "0                           0.126549                    0.637555   \n",
       "1                           0.120916                    0.641100   \n",
       "2                           0.117922                    0.642765   \n",
       "3                           0.120760                    0.579039   \n",
       "4                           0.110933                    0.622374   \n",
       "...                              ...                         ...   \n",
       "6814                        0.112622                    0.639806   \n",
       "6815                        0.112329                    0.642072   \n",
       "6816                        0.110933                    0.631678   \n",
       "6817                        0.110957                    0.684857   \n",
       "6818                        0.110933                    0.659917   \n",
       "\n",
       "       Cash Flow to Liability   CFO to Assets   Cash Flow to Equity  \\\n",
       "0                    0.458609        0.520382              0.312905   \n",
       "1                    0.459001        0.567101              0.314163   \n",
       "2                    0.459254        0.538491              0.314515   \n",
       "3                    0.448518        0.604105              0.302382   \n",
       "4                    0.454411        0.578469              0.311567   \n",
       "...                       ...             ...                   ...   \n",
       "6814                 0.458639        0.587178              0.314063   \n",
       "6815                 0.459058        0.569498              0.314446   \n",
       "6816                 0.452465        0.589341              0.313353   \n",
       "6817                 0.471313        0.678338              0.320118   \n",
       "6818                 0.483285        0.505531              0.316238   \n",
       "\n",
       "       Current Liability to Current Assets   Liability-Assets Flag  \\\n",
       "0                                 0.118250                       0   \n",
       "1                                 0.047775                       0   \n",
       "2                                 0.025346                       0   \n",
       "3                                 0.067250                       0   \n",
       "4                                 0.047725                       0   \n",
       "...                                    ...                     ...   \n",
       "6814                              0.027951                       0   \n",
       "6815                              0.031470                       0   \n",
       "6816                              0.007542                       0   \n",
       "6817                              0.022916                       0   \n",
       "6818                              0.005579                       0   \n",
       "\n",
       "       Net Income to Total Assets   Total assets to GNP price  \\\n",
       "0                        0.716845                    0.009219   \n",
       "1                        0.795297                    0.008323   \n",
       "2                        0.774670                    0.040003   \n",
       "3                        0.739555                    0.003252   \n",
       "4                        0.795016                    0.003878   \n",
       "...                           ...                         ...   \n",
       "6814                     0.799927                    0.000466   \n",
       "6815                     0.799748                    0.001959   \n",
       "6816                     0.797778                    0.002840   \n",
       "6817                     0.811808                    0.002837   \n",
       "6818                     0.815956                    0.000707   \n",
       "\n",
       "       No-credit Interval   Gross Profit to Sales  \\\n",
       "0                0.622879                0.601453   \n",
       "1                0.623652                0.610237   \n",
       "2                0.623841                0.601449   \n",
       "3                0.622929                0.583538   \n",
       "4                0.623521                0.598782   \n",
       "...                   ...                     ...   \n",
       "6814             0.623620                0.604455   \n",
       "6815             0.623931                0.598306   \n",
       "6816             0.624156                0.610441   \n",
       "6817             0.623957                0.607846   \n",
       "6818             0.626680                0.627408   \n",
       "\n",
       "       Net Income to Stockholder's Equity   Liability to Equity  \\\n",
       "0                                0.827890              0.290202   \n",
       "1                                0.839969              0.283846   \n",
       "2                                0.836774              0.290189   \n",
       "3                                0.834697              0.281721   \n",
       "4                                0.839973              0.278514   \n",
       "...                                   ...                   ...   \n",
       "6814                             0.840359              0.279606   \n",
       "6815                             0.840306              0.278132   \n",
       "6816                             0.840138              0.275789   \n",
       "6817                             0.841084              0.277547   \n",
       "6818                             0.841019              0.275114   \n",
       "\n",
       "       Degree of Financial Leverage (DFL)  \\\n",
       "0                                0.026601   \n",
       "1                                0.264577   \n",
       "2                                0.026555   \n",
       "3                                0.026697   \n",
       "4                                0.024752   \n",
       "...                                   ...   \n",
       "6814                             0.027064   \n",
       "6815                             0.027009   \n",
       "6816                             0.026791   \n",
       "6817                             0.026822   \n",
       "6818                             0.026793   \n",
       "\n",
       "       Interest Coverage Ratio (Interest expense to EBIT)   Net Income Flag  \\\n",
       "0                                              0.564050                   1   \n",
       "1                                              0.570175                   1   \n",
       "2                                              0.563706                   1   \n",
       "3                                              0.564663                   1   \n",
       "4                                              0.575617                   1   \n",
       "...                                                 ...                 ...   \n",
       "6814                                           0.566193                   1   \n",
       "6815                                           0.566018                   1   \n",
       "6816                                           0.565158                   1   \n",
       "6817                                           0.565302                   1   \n",
       "6818                                           0.565167                   1   \n",
       "\n",
       "       Equity to Liability  \n",
       "0                 0.016469  \n",
       "1                 0.020794  \n",
       "2                 0.016474  \n",
       "3                 0.023982  \n",
       "4                 0.035490  \n",
       "...                    ...  \n",
       "6814              0.029890  \n",
       "6815              0.038284  \n",
       "6816              0.097649  \n",
       "6817              0.044009  \n",
       "6818              0.233902  \n",
       "\n",
       "[6819 rows x 96 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taiwan = pd.read_csv(\"C:/Users/leofl/OneDrive/Desktop/COGS118A/Final Project/taiwan.csv\")\n",
    "taiwan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "taiwan_numerical = [\n",
    "    'ROA(A) before interest and % after tax',\n",
    "    \"ROA(B) before interest and depreciation after tax\",\n",
    "    \"Operating Gross Margin\",\n",
    "    \"Realized Sales Gross Margin\",\n",
    "    \"Operating Profit Rate\",\n",
    "    \"Current Ratio\",\n",
    "    \"Quick Ratio\",\n",
    "    \"Total debt/Total net worth\",\n",
    "    \"Debt ratio %\",\n",
    "    \"Cash flow rate\",\n",
    "    \"Cash Reinvestment %\",\n",
    "    \"Realized Sales Gross Profit Growth Rate\",\n",
    "    \"Operating Profit Growth Rate\",\n",
    "    \"Total Asset Growth Rate\",\n",
    "    \"Net Value Growth Rate\",\n",
    "    \"Total Asset Turnover\",\n",
    "    \"Accounts Receivable Turnover\",\n",
    "    \"Inventory Turnover Rate (times)\",\n",
    "    \"Cash Flow to Sales\",\n",
    "    \"Net Income to Stockholder's Equity\"\n",
    "]\n",
    "\n",
    "taiwan = taiwan.dropna()\n",
    "taiwan = taiwan[:500]\n",
    "\n",
    "taiwan_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), taiwan_numerical)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading and trailing spaces from column names\n",
    "taiwan.columns = taiwan.columns.str.strip()\n",
    "\n",
    "taiwan_X = taiwan[taiwan_numerical]\n",
    "taiwan_y = taiwan['Bankrupt?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    }
   ],
   "source": [
    "apply_classifier(\"taiwan\", \"random_forest\", Random_grid, taiwan_preprocessor, RandomForestClassifier(), taiwan_X, taiwan_y)\n",
    "apply_classifier(\"taiwan\", \"SVM\", SVM_grid, taiwan_preprocessor, SVC(kernel='rbf'), taiwan_X, taiwan_y)\n",
    "apply_classifier(\"taiwan\", \"KNN\", KNN_grid, taiwan_preprocessor, KNeighborsClassifier(weights='uniform', metric='minkowski'), taiwan_X, taiwan_y)\n",
    "apply_classifier(\"taiwan\", \"log_reg\", logreg_grid, taiwan_preprocessor, LogisticRegression(), taiwan_X, taiwan_y)\n",
    "apply_classifier(\"taiwan\", \"decision_tree\", decision_tree_grid, taiwan_preprocessor, DecisionTreeClassifier(), taiwan_X, taiwan_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Money Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Error connecting to server",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\urllib\\request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m     h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1349\u001b[0m               encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\http\\client.py:1283\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1283\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\http\\client.py:1329\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1328\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders(body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\http\\client.py:1278\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\http\\client.py:1038\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1038\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1041\u001b[0m \n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\http\\client.py:976\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 976\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\http\\client.py:1455\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1453\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m-> 1455\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mwrap_socket(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock,\n\u001b[0;32m   1456\u001b[0m                                       server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname)\n",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\ssl.py:517\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    512\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    513\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    514\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msslsocket_class\u001b[38;5;241m.\u001b[39m_create(\n\u001b[0;32m    518\u001b[0m         sock\u001b[38;5;241m=\u001b[39msock,\n\u001b[0;32m    519\u001b[0m         server_side\u001b[38;5;241m=\u001b[39mserver_side,\n\u001b[0;32m    520\u001b[0m         do_handshake_on_connect\u001b[38;5;241m=\u001b[39mdo_handshake_on_connect,\n\u001b[0;32m    521\u001b[0m         suppress_ragged_eofs\u001b[38;5;241m=\u001b[39msuppress_ragged_eofs,\n\u001b[0;32m    522\u001b[0m         server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[0;32m    523\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    524\u001b[0m         session\u001b[38;5;241m=\u001b[39msession\n\u001b[0;32m    525\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\ssl.py:1075\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1074\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1075\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\ssl.py:1346\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1345\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1346\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1002)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\site-packages\\ucimlrepo\\fetch.py:68\u001b[0m, in \u001b[0;36mfetch_ucirepo\u001b[1;34m(name, id)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 68\u001b[0m     response \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(api_url, context\u001b[38;5;241m=\u001b[39mssl\u001b[38;5;241m.\u001b[39mcreate_default_context(cafile\u001b[38;5;241m=\u001b[39mcertifi\u001b[38;5;241m.\u001b[39mwhere()))\n\u001b[0;32m     69\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(response)\n",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    537\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    495\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\urllib\\request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPSConnection, req,\n\u001b[0;32m   1392\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context, check_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_hostname)\n",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\urllib\\request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1352\u001b[0m r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1002)>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# fetch dataset \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m census_income \u001b[38;5;241m=\u001b[39m fetch_ucirepo(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m) \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# data (as pandas dataframes) \u001b[39;00m\n\u001b[0;32m      5\u001b[0m money_X \u001b[38;5;241m=\u001b[39m census_income\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfeatures \n",
      "File \u001b[1;32mc:\\Users\\leofl\\anaconda3\\Lib\\site-packages\\ucimlrepo\\fetch.py:71\u001b[0m, in \u001b[0;36mfetch_ucirepo\u001b[1;34m(name, id)\u001b[0m\n\u001b[0;32m     69\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(response)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError):\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError connecting to server\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# verify that dataset exists \u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "\u001b[1;31mConnectionError\u001b[0m: Error connecting to server"
     ]
    }
   ],
   "source": [
    "# fetch dataset \n",
    "census_income = fetch_ucirepo(id=20) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "money_X = census_income.data.features \n",
    "money_y = census_income.data.targets \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'money_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m money_y[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincome\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m money_y[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincome\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.$\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m money_y[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincome\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m money_y[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincome\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<=50K\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>50K\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'money_y' is not defined"
     ]
    }
   ],
   "source": [
    "money_y['income'] = money_y['income'].str.replace(r'\\.$', '', regex=True)\n",
    "money_y['income'] = money_y['income'].map({'<=50K': 0, '>50K': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values = money_y['income'].unique()\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48836</th>\n",
       "      <td>33</td>\n",
       "      <td>Private</td>\n",
       "      <td>245211</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47621 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt  education  education-num  \\\n",
       "0       39         State-gov   77516  Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2       38           Private  215646    HS-grad              9   \n",
       "3       53           Private  234721       11th              7   \n",
       "4       28           Private  338409  Bachelors             13   \n",
       "...    ...               ...     ...        ...            ...   \n",
       "48836   33           Private  245211  Bachelors             13   \n",
       "48837   39           Private  215419  Bachelors             13   \n",
       "48839   38           Private  374983  Bachelors             13   \n",
       "48840   44           Private   83891  Bachelors             13   \n",
       "48841   35      Self-emp-inc  182148  Bachelors             13   \n",
       "\n",
       "           marital-status         occupation   relationship  \\\n",
       "0           Never-married       Adm-clerical  Not-in-family   \n",
       "1      Married-civ-spouse    Exec-managerial        Husband   \n",
       "2                Divorced  Handlers-cleaners  Not-in-family   \n",
       "3      Married-civ-spouse  Handlers-cleaners        Husband   \n",
       "4      Married-civ-spouse     Prof-specialty           Wife   \n",
       "...                   ...                ...            ...   \n",
       "48836       Never-married     Prof-specialty      Own-child   \n",
       "48837            Divorced     Prof-specialty  Not-in-family   \n",
       "48839  Married-civ-spouse     Prof-specialty        Husband   \n",
       "48840            Divorced       Adm-clerical      Own-child   \n",
       "48841  Married-civ-spouse    Exec-managerial        Husband   \n",
       "\n",
       "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                   White    Male          2174             0              40   \n",
       "1                   White    Male             0             0              13   \n",
       "2                   White    Male             0             0              40   \n",
       "3                   Black    Male             0             0              40   \n",
       "4                   Black  Female             0             0              40   \n",
       "...                   ...     ...           ...           ...             ...   \n",
       "48836               White    Male             0             0              40   \n",
       "48837               White  Female             0             0              36   \n",
       "48839               White    Male             0             0              50   \n",
       "48840  Asian-Pac-Islander    Male          5455             0              40   \n",
       "48841               White    Male             0             0              60   \n",
       "\n",
       "      native-country  income  \n",
       "0      United-States       0  \n",
       "1      United-States       0  \n",
       "2      United-States       0  \n",
       "3      United-States       0  \n",
       "4               Cuba       0  \n",
       "...              ...     ...  \n",
       "48836  United-States       0  \n",
       "48837  United-States       0  \n",
       "48839  United-States       0  \n",
       "48840  United-States       0  \n",
       "48841  United-States       1  \n",
       "\n",
       "[47621 rows x 15 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = money_X.join(money_y)\n",
    "joined.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "money_categorical = ['workclass', 'education','marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "money_numerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "money_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), money_numerical),\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), money_categorical)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Money_X = joined[money_categorical + money_numerical]\n",
    "Money_X = money_X[:500]\n",
    "Money_y = joined['income']\n",
    "Money_y = Money_y[:500]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    }
   ],
   "source": [
    "apply_classifier(\"money\", \"random_forest\", Random_grid, money_preprocessor, RandomForestClassifier(), Money_X, Money_y)\n",
    "apply_classifier(\"money\", \"SVM\", SVM_grid, money_preprocessor, SVC(kernel='rbf'), Money_X, Money_y)\n",
    "apply_classifier(\"money\", \"KNN\", KNN_grid, money_preprocessor, KNeighborsClassifier(weights='uniform', metric='minkowski'), Money_X, Money_y)\n",
    "apply_classifier(\"money\", \"log_reg\", logreg_grid, money_preprocessor, LogisticRegression(), Money_X, Money_y)\n",
    "apply_classifier(\"money\", \"decision_tree\", decision_tree_grid, money_preprocessor, DecisionTreeClassifier(), Money_X, Money_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diabetes Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "early_stage_diabetes_risk_prediction = fetch_ucirepo(id=529) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "pre_diabetes_X = early_stage_diabetes_risk_prediction.data.features \n",
    "pre_diabetes_y = early_stage_diabetes_risk_prediction.data.targets \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_joined = pre_diabetes_y.join(pre_diabetes_X)\n",
    "diabetes_joined = diabetes_joined.dropna()\n",
    "\n",
    "diabetes_joined['class'] = diabetes_joined['class'].map({'Negative': 0, 'Positive': 1})\n",
    "diabetes_joined['gender'] = diabetes_joined['gender'].map({'Female': 0, 'Male': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>polyuria</th>\n",
       "      <th>polydipsia</th>\n",
       "      <th>sudden_weight_loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>polyphagia</th>\n",
       "      <th>genital_thrush</th>\n",
       "      <th>visual_blurring</th>\n",
       "      <th>itching</th>\n",
       "      <th>irritability</th>\n",
       "      <th>delayed_healing</th>\n",
       "      <th>partial_paresis</th>\n",
       "      <th>muscle_stiffness</th>\n",
       "      <th>alopecia</th>\n",
       "      <th>obesity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class  age  gender  polyuria  polydipsia  sudden_weight_loss  weakness  \\\n",
       "0        1   40       1         0           1                   0         1   \n",
       "1        1   58       1         0           0                   0         1   \n",
       "2        1   41       1         1           0                   0         1   \n",
       "3        1   45       1         0           0                   1         1   \n",
       "4        1   60       1         1           1                   1         1   \n",
       "..     ...  ...     ...       ...         ...                 ...       ...   \n",
       "495      0   43       1         0           0                   0         1   \n",
       "496      0   53       1         0           0                   0         1   \n",
       "497      0   47       1         0           0                   0         0   \n",
       "498      1   68       0         1           1                   0         1   \n",
       "499      0   64       1         0           0                   0         1   \n",
       "\n",
       "     polyphagia  genital_thrush  visual_blurring  itching  irritability  \\\n",
       "0             0               0                0        1             0   \n",
       "1             0               0                1        0             0   \n",
       "2             1               0                0        1             0   \n",
       "3             1               1                0        1             0   \n",
       "4             1               0                1        1             1   \n",
       "..          ...             ...              ...      ...           ...   \n",
       "495           0               1                0        1             0   \n",
       "496           0               0                1        1             0   \n",
       "497           0               0                0        0             1   \n",
       "498           1               0                1        1             0   \n",
       "499           1               0                1        1             1   \n",
       "\n",
       "     delayed_healing  partial_paresis  muscle_stiffness  alopecia  obesity  \n",
       "0                  1                0                 1         1        1  \n",
       "1                  0                1                 0         1        0  \n",
       "2                  1                0                 1         1        0  \n",
       "3                  1                0                 0         0        0  \n",
       "4                  1                1                 1         1        1  \n",
       "..               ...              ...               ...       ...      ...  \n",
       "495                0                0                 0         1        0  \n",
       "496                1                0                 1         1        0  \n",
       "497                0                1                 0         0        1  \n",
       "498                1                1                 0         0        0  \n",
       "499                1                0                 1         1        0  \n",
       "\n",
       "[500 rows x 17 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_convert = diabetes_joined.drop(['class', 'age', 'gender'], axis = 1)\n",
    "columns_to_convert = columns_to_convert.columns\n",
    "diabetes_joined[columns_to_convert] = diabetes_joined[columns_to_convert].replace({'No': 0, 'Yes': 1})\n",
    "diabetes_joined[:500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_through_columns = columns_to_convert.to_list()\n",
    "diabetes_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['age']),\n",
    "        ('passthrough', 'passthrough', pass_through_columns) \n",
    "    ])\n",
    "\n",
    "diabetes_X = diabetes_joined.drop('class', axis = 1)\n",
    "diabetes_y = diabetes_joined['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    }
   ],
   "source": [
    "apply_classifier('diabetes', 'random_forest', Random_grid, diabetes_preprocessor, RandomForestClassifier(), diabetes_X, diabetes_y)\n",
    "apply_classifier('diabetes', 'SVM', SVM_grid, diabetes_preprocessor, SVC(kernel = 'rbf'), diabetes_X, diabetes_y)\n",
    "apply_classifier('diabetes', 'KNN', KNN_grid, diabetes_preprocessor, KNeighborsClassifier(), diabetes_X, diabetes_y)\n",
    "apply_classifier('diabetes', 'log_reg', logreg_grid, diabetes_preprocessor, LogisticRegression(), diabetes_X, diabetes_y)\n",
    "apply_classifier('diabetes', 'decision_tree', decision_tree_grid, diabetes_preprocessor, DecisionTreeClassifier(), diabetes_X, diabetes_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_plot(data_dict, dataset_name):\n",
    "    # get the split ratios and the models\n",
    "    models = ['random_forest', 'SVM', 'KNN', 'log_reg', 'decision_tree']\n",
    "    split_ratios = [0.2, 0.5, 0.8]  \n",
    "    \n",
    "    # use subplots since will be plotting a lot different things in the same graph\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # set positions for bars using np.arange\n",
    "    y_pos = np.arange(len(models))\n",
    "    bar_width = 0.25\n",
    "    \n",
    "    # colors\n",
    "    colors = ['#2ecc71', '#3498db', '#9b59b6']\n",
    "   \n",
    "    for i, split in enumerate(split_ratios):\n",
    "        accuracies = []\n",
    "        for model in models:\n",
    "            # match key with the data set and teh current model we are using \n",
    "            key = f\"{dataset_name} {model}\"\n",
    "            \n",
    "            #match the result with the correct split ratio\n",
    "            for result in data_dict[key]:\n",
    "                if result['split_ratio'] == split:\n",
    "                    accuracies.append(result['test_accuracy'])\n",
    "                    break\n",
    "        \n",
    "        ax.barh(y_pos + i*bar_width, accuracies, bar_width, \n",
    "                label=f'Split {split}', alpha=0.8, color=colors[i])\n",
    "    \n",
    "    \n",
    "    ax.set_yticks(y_pos + bar_width)\n",
    "    ax.set_yticklabels(['Random Forest', 'SVM', 'KNN', 'Logistic Regression', 'Decision Tree'])\n",
    "    ax.set_xlabel('Test Accuracy')\n",
    "    ax.set_title(f'{dataset_name.capitalize()} Dataset - Test Accuracy by Model and Split Ratio')\n",
    "    ax.set_xlim(0.5, 1.0)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_all_datasets(data_dict):\n",
    "    datasets = ['vegas', 'taiwan', 'money', 'diabetes']\n",
    "    \n",
    "    # this function creates it it for every data set\n",
    "    figs = []\n",
    "    for dataset in datasets:\n",
    "        fig = create_dataset_plot(data_dict, dataset)\n",
    "        figs.append(fig)\n",
    "        plt.show()\n",
    "    \n",
    "    return figs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6ZElEQVR4nOzdd3xO9///8eeVvWQgCyGxR+1VexTRovZo1R71QRUdRkuMqtIqbXUqQqmqTe0VbdHSFq1SWrs1gkpiVEhyfn/45fq6JOGKJudKedxvt9za6+R9znmdk7wS1zPnvI/FMAxDAAAAAAAAgImcHF0AAAAAAAAAHj6EUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgCA/7QxY8bIYrHc17rh4eFq3rx5FlcEICfq3r27fHx8HF1Gtvk3Pwu7d++u8PDwrC3oX4iJiZHFYlFMTIzp+46OjpbFYtHx48ety+rXr6/69eubXsv9+jffCwBgNkIpAECOkfpmIPXDw8ND+fLlU2RkpN59911dvnzZ0SXe1bVr1zRmzBiHvJFKfROX+uHu7q7g4GDVr19fr7/+us6fP3/f2z5w4IDGjBlj8ybNkT7//HNNmzYtS7d55/deRh9Z9cZ9x44dGjNmjOLi4jK9bocOHWSxWDRs2LAsqQVZKzw8XBaLRY0aNUr38zNmzLB+P/3www8mV/fg+eWXX9SuXTsVKlRIHh4eyp8/vxo3bqz33nsv2/Z5+vRpjRkzRnv37rVr/J0/X1xcXJQ/f351795df/31133V4MjfNwCQlVwcXQAAAHcaN26cIiIidPPmTZ09e1YxMTEaPHiw3n77ba1cuVLlypWzjn311Vc1fPhwB1b7f65du6axY8dKksP+qj5o0CBVrVpVycnJOn/+vHbs2KGoqCi9/fbb+vLLL9WwYcNMb/PAgQMaO3as6tevnyOupvj888+1f/9+DR48OMu2WbduXX322Wc2y3r37q1q1aqpb9++1mVZdaXNjh07NHbsWHXv3l3+/v52r5eQkKBVq1YpPDxcCxYs0BtvvMEVETmQh4eHtm7dqrNnzyokJMTmc/Pnz5eHh4euX7/uoOoeHDt27FCDBg1UsGBB9enTRyEhITp16pS+++47vfPOO3ruueeyZD8bNmyweX369GmNHTtW4eHhqlChgt3bSf3ddv36dX333XeKjo7Wt99+q/3798vDwyNTNd3t901O+r0IAPdCKAUAyHEef/xxValSxfp6xIgR2rJli5o3b64nn3xSBw8elKenpyTJxcVFLi78OktVp04dtWvXzmbZvn371KRJE7Vt21YHDhxQaGiog6rLuQoXLqzChQvbLOvXr58KFy6sZ555xkFVpbVkyRIlJydr1qxZatiwob7++mvVq1fP0WWlYRiGrl+/bu3Th02tWrW0e/duLVy4UM8//7x1+Z9//qlvvvlGrVu31pIlSxxY4YNhwoQJ8vPz0+7du9OEu7GxsVm2Hzc3tyzZzu2/23r37q28efNq0qRJWrlypTp06JAl+5D4vQjgv4Xb9wAA/wkNGzbUqFGjdOLECc2bN8+6PL25M2bPnq2GDRsqKChI7u7uKl26tD788MMMt71hwwZVqFBBHh4eKl26tJYuXZpmTFxcnAYPHqywsDC5u7uraNGimjRpklJSUiRJx48fV2BgoCRp7Nix1ts0xowZY93Gb7/9pnbt2il37tzy8PBQlSpVtHLlSpv93Lx5U2PHjlWxYsXk4eGhPHnyqHbt2tq4cWOmz1mq8uXLa9q0aYqLi9P06dOty0+cOKH+/furRIkS8vT0VJ48edS+fXub2/Sio6PVvn17SVKDBg2sx5V6y8iKFSvUrFkz5cuXT+7u7ipSpIjGjx+v5ORkmxp+//13tW3bViEhIfLw8FCBAgXUqVMnxcfH24ybN2+eKleuLE9PT+XOnVudOnXSqVOnrJ+vX7++Vq9erRMnTmT5LXX2+Ouvv9SzZ08FBwfL3d1dZcqU0axZs9KMe++991SmTBl5eXkpICBAVapU0eeffy7p1vfsSy+9JEmKiIiwHoc9t0fOnz9fjRs3VoMGDVSqVCnNnz8/3XG//fabOnTooMDAQHl6eqpEiRJ65ZVX0hxLr169rF+7iIgI/e9//9ONGzesdaZ3FVZ6c+6kzs+2fv16ValSRZ6envr4448lZa4f165dq3r16ilXrlzy9fVV1apVrectKipKrq6u6d6K2rdvX/n7+9t19dHRo0cVGRkpb29v5cuXT+PGjZNhGJJuhWnh4eFq2bJlmvWuX78uPz8/Pfvss/fch4eHh9q0aWOtPdWCBQsUEBCgyMjIdNfbsmWL6tSpI29vb/n7+6tly5Y6ePBgmnHffvutqlatKg8PDxUpUsR6rtNzr57KDHv7vX79+nrkkUd04MABNWjQQF5eXsqfP78mT56cZpt//vmnWrVqJW9vbwUFBWnIkCFKTEy0q54jR46oTJky6V5tGBQUZPPaYrFo4MCBmj9/vkqUKCEPDw9VrlxZX3/99T33c/ucUjExMapataokqUePHtb+jY6Otqvm29WpU8d6HKlu3Lih0aNHq3LlyvLz85O3t7fq1KmjrVu3Wsfc6/dNer2blJSk8ePHq0iRInJ3d1d4eLhGjhxp97kGgOxChA4A+M/o0qWLRo4cqQ0bNqhPnz4Zjvvwww9VpkwZPfnkk3JxcdGqVavUv39/paSkaMCAATZjf//9d3Xs2FH9+vVTt27dNHv2bLVv317r1q1T48aNJd26TaJevXr666+/9Oyzz6pgwYLasWOHRowYoTNnzmjatGkKDAzUhx9+qP/9739q3bq12rRpI0nWWw1//fVX1apVS/nz59fw4cPl7e2tL7/8Uq1atdKSJUvUunVrSbfeTEycONF661hCQoJ++OEH/fTTT9Z67ke7du3Uq1cvbdiwQRMmTJAk7d69Wzt27FCnTp1UoEABHT9+XB9++KHq16+vAwcOyMvLS3Xr1tWgQYP07rvvauTIkSpVqpQkWf8bHR0tHx8fDR06VD4+PtqyZYtGjx6thIQEvfnmm5JuvcmKjIxUYmKinnvuOYWEhOivv/7SV199pbi4OPn5+Um6ddXDqFGj1KFDB/Xu3Vvnz5/Xe++9p7p162rPnj3y9/fXK6+8ovj4eP3555+aOnWqpKy7pe5ezp07p0cffdT65jYwMFBr165Vr169lJCQYL2dcMaMGRo0aJDatWun559/XtevX9fPP/+s77//Xk8//bTatGmjw4cPa8GCBZo6dary5s0rSdY3mRk5ffq0tm7dqjlz5kiSnnrqKU2dOlXTp0+3uZLj559/Vp06deTq6qq+ffsqPDxcR44c0apVq6xf+9OnT6tatWqKi4tT3759VbJkSf31119avHixrl27dl9Xhhw6dEhPPfWUnn32WfXp00clSpSQZH8/RkdHq2fPnipTpoxGjBghf39/7dmzR+vWrdPTTz+tLl26aNy4cVq4cKEGDhxoXe/GjRtavHix2rZte89boJKTk9W0aVM9+uijmjx5statW6eoqCglJSVp3LhxslgseuaZZzR58mT9/fffyp07t3XdVatWKSEhwe4r555++mk1adJER44cUZEiRSTduvW0Xbt2cnV1TTN+06ZNevzxx1W4cGGNGTNG//zzj9577z3VqlVLP/30kzV8/eWXX9SkSRMFBgZqzJgxSkpKUlRUlIKDg9Ns056eygx7+j3VpUuX1LRpU7Vp00YdOnTQ4sWLNWzYMJUtW1aPP/64JOmff/7RY489ppMnT2rQoEHKly+fPvvsM23ZssWuegoVKqSdO3dq//79euSRR+45ftu2bVq4cKEGDRokd3d3ffDBB2ratKl27dpl1/rSrZ9948aN0+jRo9W3b19rsFSzZk271r9darAbEBBgXZaQkKBPP/1UTz31lPr06aPLly9r5syZioyM1K5du1ShQoV7/r5JT+/evTVnzhy1a9dOL7zwgr7//ntNnDhRBw8e1LJlyzJdOwBkGQMAgBxi9uzZhiRj9+7dGY7x8/MzKlasaH0dFRVl3Pnr7Nq1a2nWi4yMNAoXLmyzrFChQoYkY8mSJdZl8fHxRmhoqM0+xo8fb3h7exuHDx+2WX/48OGGs7OzcfLkScMwDOP8+fOGJCMqKirN/h977DGjbNmyxvXr163LUlJSjJo1axrFihWzLitfvrzRrFmzDI8/I1u3bjUkGYsWLcpwTPny5Y2AgADr6/TO086dOw1Jxty5c63LFi1aZEgytm7dmmZ8ett49tlnDS8vL+ux7tmz5561HT9+3HB2djYmTJhgs/yXX34xXFxcbJY3a9bMKFSoUIbbyire3t5Gt27drK979eplhIaGGhcuXLAZ16lTJ8PPz896Llq2bGmUKVPmrtt+8803DUnGsWPH7K7nrbfeMjw9PY2EhATDMAzj8OHDhiRj2bJlNuPq1q1r5MqVyzhx4oTN8pSUFOv/d+3a1XByckq311LHpddbhvF/fXp77am9tG7dujTj7enHuLg4I1euXEb16tWNf/75J8O6a9SoYVSvXt3m80uXLs3w+/N23bp1MyQZzz33nM22mzVrZri5uRnnz583DMMwDh06ZEgyPvzwQ5v1n3zySSM8PNymnvQUKlTIaNasmZGUlGSEhIQY48ePNwzDMA4cOGBIMrZt25buz7oKFSoYQUFBxsWLF63L9u3bZzg5ORldu3a1LmvVqpXh4eFh8/U9cOCA4ezsbPP1ykxPdevWza6esqffDcMw6tWrl+bnSGJiohESEmK0bdvWumzatGmGJOPLL7+0Lrt69apRtGhRu76mGzZsMJydnQ1nZ2ejRo0axssvv2ysX7/euHHjRpqxkgxJxg8//GBdduLECcPDw8No3bq1dVl639/16tUz6tWrZ329e/duQ5Ixe/bsu9Z35zY3bdpknD9/3jh16pSxePFiIzAw0HB3dzdOnTplHZuUlGQkJibarH/p0iUjODjY6Nmzp3XZ3X7f3Nm7e/fuNSQZvXv3thn34osvGpKMLVu22HUcAJAduH0PAPCf4uPjc8+n8N0+j018fLwuXLigevXq6ejRo2luF8uXL5/1KiVJ8vX1VdeuXbVnzx6dPXtWkrRo0SLVqVNHAQEBunDhgvWjUaNGSk5OvuftH3///be2bNmiDh066PLly9b1L168qMjISP3+++/WJzD5+/vr119/1e+//56p82KPO8/d7efp5s2bunjxoooWLSp/f3/99NNPdm3z9m2kHludOnV07do1/fbbb5JkvRJq/fr1unbtWrrbWbp0qVJSUtShQwebcxwSEqJixYrZ3LriCIZhaMmSJWrRooUMw7CpMTIyUvHx8dZz5u/vrz///FO7d+/O0hrmz5+vZs2aKVeuXJKkYsWKqXLlyja38J0/f15ff/21evbsqYIFC9qsn3o7T0pKipYvX64WLVrYzN1257jMioiISPe2NHv6cePGjbp8+bKGDx+e5mqn2+vp2rWrvv/+e5vbnebPn6+wsDC759a6/Sqr1Kvebty4oU2bNkmSihcvrurVq9uc17///ltr165V586d7T4/zs7O6tChgxYsWGBTZ+qVNbc7c+aM9u7dq+7du9tcnVWuXDk1btxYa9askXTrSq/169erVatWNl/fUqVKpTn32dFT9vR7Kh8fH5urytzc3FStWjUdPXrUumzNmjUKDQ21mQfPy8vL5uECd9O4cWPt3LlTTz75pPbt26fJkycrMjJS+fPnT3NrtCTVqFFDlStXtr4uWLCgWrZsqfXr16e5BTE7NGrUSIGBgQoLC1O7du3k7e2tlStXqkCBAtYxzs7O1isVU1JS9PfffyspKUlVqlSx++fynVK/f4YOHWqz/IUXXpAkrV69+r62CwBZgVAKAPCfcuXKFeub8oxs375djRo1ss7LEhgYqJEjR0pSmlCqaNGiad5kFi9eXNL/3Vrx+++/a926dQoMDLT5SH3k+70m1P3jjz9kGIZGjRqVZhtRUVE22xg3bpzi4uJUvHhxlS1bVi+99JJ+/vlnO87Mvd157v755x+NHj3aOk9W3rx5FRgYqLi4uDTnKSO//vqrWrduLT8/P/n6+iowMND6RjR1GxERERo6dKg+/fRT5c2bV5GRkXr//fdt9vH777/LMAwVK1YszTk6ePDgfU9a/Pfff+vs2bPWD3uP607nz59XXFycPvnkkzT19ejRQ9L/fQ2HDRsmHx8fVatWTcWKFdOAAQO0ffv2+9pvqoMHD2rPnj2qVauW/vjjD+tH/fr19dVXXykhIUGSrG/473Yr0vnz55WQkGD37Ur2ioiISHe5Pf2YGjLdq6aOHTvK3d3dGhjFx8frq6++sjsscnJySjOh/Z39Lt0Kv7Zv364TJ05IuhVM37x5U126dLnnPm739NNP68CBA9q3b58+//xzderUKd06U/eTesvj7UqVKqULFy7o6tWrOn/+vP755x8VK1Yszbg7182OnrKn31MVKFAgzbEGBATo0qVLNsed3s/g9M5DRqpWraqlS5fq0qVL2rVrl0aMGKHLly+rXbt2OnDggM3Y9M5b8eLFde3atXTnKstq77//vjZu3KjFixfriSee0IULF+Tu7p5m3Jw5c1SuXDnrvIKBgYFavXr1ff/8OnHihJycnFS0aFGb5SEhIfL397d+/wGAIzCnFADgP+PPP/9UfHx8mn9Y3+7IkSN67LHHVLJkSb399tsKCwuTm5ub1qxZo6lTp1onJs+MlJQUNW7cWC+//HK6n099U3u39SXpxRdfzHCC49Rjqlu3ro4cOaIVK1Zow4YN+vTTTzV16lR99NFH6t27d6ZrT3Xz5k0dPnzY5k3/c889p9mzZ2vw4MGqUaOG/Pz8ZLFY1KlTJ7vOU1xcnOrVqydfX1+NGzdORYoUkYeHh3766ScNGzbMZhtTpkxR9+7drcc1aNAgTZw4Ud99950KFCiglJQUWSwWrV27Vs7Ozmn2db/zRrVp00bbtm2zvu7Wrdt9TUiceizPPPOMunXrlu6Y1PlcSpUqpUOHDumrr77SunXrtGTJEn3wwQcaPXq09RHumZU6uf+QIUM0ZMiQNJ9fsmSJNRzLKhmFPBldUZLek/ayuh8DAgLUvHlzzZ8/X6NHj9bixYuVmJiY5U9I7NSpk4YMGaL58+dr5MiRmjdvnqpUqZKpsESSqlevriJFimjw4ME6duyYnn766Syt826yuqcy0++S0t2nJOuk8lnNzc1NVatWVdWqVVW8eHH16NFDixYtsgb/OUG1atWsVye2atVKtWvX1tNPP61Dhw5Zvx7z5s1T9+7d1apVK7300ksKCgqSs7OzJk6caHOF4P2436sgASA7EUoBAP4zPvvsM0nKMNiRbk1GnJiYqJUrV9rc3pLRrSqpVzHd/o/1w4cPS5J1YuEiRYroypUr1iujMpLRP/hTr8xwdXW95zYkKXfu3OrRo4d69OihK1euqG7duhozZsy/CqUWL16sf/75x+bcLV68WN26ddOUKVOsy65fv664uDibdTM6rpiYGF28eFFLly5V3bp1rcuPHTuW7viyZcuqbNmyevXVV7Vjxw7VqlVLH330kV577TUVKVJEhmEoIiLiniFfZt5YTZkyxebKjHz58tm97u0CAwOVK1cuJScn2/U19Pb2VseOHdWxY0fduHFDbdq00YQJEzRixAh5eHhk6hgMw9Dnn3+uBg0aqH///mk+P378eM2fP189evSwfq/t37//rsfi6+t71zHS/02+HBcXZzMhdmauqrC3H1MnAt+/f/9dQ2fp1lVMLVu21O7duzV//nxVrFhRZcqUsauelJQUHT161OZ77M5+l271YLNmzTR//nx17txZ27dv17Rp0+zax52eeuopvfbaaypVqpQqVKiQ7phChQpJujVZ/J1+++035c2bV97e3vLw8JCnp2e6t/feuW5mesoeme13exQqVEj79+9P8zM4vfOQGanBz5kzZ2yWp3feDh8+LC8vr3s+aOB2WRHupAZNDRo00PTp0zV8+HBJt34uFy5cWEuXLrXZz53hWmZqKFSokFJSUvT7779bH1Ih3Xp4Q1xcnPX7DwAcgdv3AAD/CVu2bNH48eMVERGhzp07Zzgu9a/zt/81Pj4+XrNnz053/OnTp22ePJSQkKC5c+eqQoUKCgkJkSR16NBBO3fu1Pr169OsHxcXp6SkJEm35kJJXXa7oKAg1a9fXx9//HGaN0mSbG4buXjxos3nfHx8VLRo0X/12O59+/Zp8ODBCggIsHnambOzc5qrFt577700V8J4e3tLSntc6Z3rGzdu6IMPPrAZl5CQYD1HqcqWLSsnJyfrcbVp00bOzs4aO3ZsmpoMw7A5L97e3nbfxlK5cmU1atTI+lG6dGm71ruTs7Oz2rZtqyVLlqQb5tzta+jm5qbSpUvLMAzdvHnTegxS2nOanu3bt+v48ePq0aOH2rVrl+ajY8eO2rp1q06fPq3AwEDVrVtXs2bN0smTJ222k3penZyc1KpVK61atUo//PBDmv2ljksNim6fM+3q1avWp//Zw95+bNKkiXLlyqWJEyfq+vXr6daT6vHHH1fevHk1adIkbdu2LdNXSU2fPt1m29OnT5erq6see+wxm3FdunTRgQMH9NJLL8nZ2VmdOnXK1H5S9e7dW1FRUTbh751CQ0NVoUIFzZkzx+Z7Yv/+/dqwYYOeeOIJSbfOZ2RkpJYvX27z9T148GCan0+Z6Sl72NvvmfHEE0/o9OnTWrx4sXXZtWvX9Mknn9i1/tatW9O98ip1DqU7r2zbuXOnzbxMp06d0ooVK9SkSZMMr+xKT2b6927q16+vatWqadq0adbv+/TO8/fff6+dO3farJvR75v0pH7/3Bmsvv3225KkZs2a3Vf9AJAVuFIKAJDjrF27Vr/99puSkpJ07tw5bdmyRRs3blShQoW0cuXKuz72vUmTJnJzc1OLFi307LPP6sqVK5oxY4aCgoLSDYSKFy+uXr16affu3QoODtasWbN07tw5mzfNL730klauXKnmzZure/fuqly5sq5evapffvlFixcv1vHjx5U3b155enqqdOnSWrhwoYoXL67cuXPrkUce0SOPPKL3339ftWvXVtmyZdWnTx8VLlxY586d086dO/Xnn39q3759kqTSpUurfv36qly5snLnzq0ffvhBixcvtpmc+W6++eYbXb9+XcnJybp48aK2b9+ulStXys/PT8uWLbMGbZLUvHlzffbZZ/Lz81Pp0qW1c+dObdq0SXny5LHZZoUKFeTs7KxJkyYpPj5e7u7uatiwoWrWrKmAgAB169ZNgwYNksVi0WeffZbmTeKWLVs0cOBAtW/fXsWLF1dSUpI+++wza9Aj3QpAXnvtNY0YMULHjx9Xq1atlCtXLh07dkzLli1T37599eKLL0q6FTQtXLhQQ4cOVdWqVeXj46MWLVrYdX7+jTfeeENbt25V9erV1adPH5UuXVp///23fvrpJ23atEl///23pFvfgyEhIapVq5aCg4N18OBBTZ8+3WaS8tTJll955RV16tRJrq6uatGihfXN7u3mz58vZ2fnDN84Pvnkk3rllVf0xRdfaOjQoXr33XdVu3ZtVapUSX379lVERISOHz+u1atXa+/evZKk119/XRs2bFC9evXUt29flSpVSmfOnNGiRYv07bffyt/fX02aNFHBggXVq1cvazAza9YsBQYGpgm8MmJvP/r6+mrq1Knq3bu3qlatqqeffloBAQHat2+frl27ZhOEubq6qlOnTpo+fbqcnZ311FNP2VWLJHl4eGjdunXq1q2bqlevrrVr12r16tUaOXJkmitlmjVrpjx58mjRokV6/PHHFRQUZPd+bleoUCGNGTPmnuPefPNNPf7446pRo4Z69eqlf/75R++99578/Pxs1h87dqzWrVunOnXqqH///kpKStJ7772nMmXK2Mw/l5mesoe9/Z4Zffr00fTp09W1a1f9+OOPCg0N1WeffWYNXO7lueee07Vr19S6dWuVLFlSN27c0I4dO7Rw4UKFh4enuaX1kUceUWRkpAYNGiR3d3droJbZ22qLFCkif39/ffTRR8qVK5e8vb1VvXr1DOdVu5uXXnpJ7du3V3R0tPr166fmzZtr6dKlat26tZo1a6Zjx47po48+UunSpXXlyhXrenf7fXOn8uXLq1u3bvrkk0+st2Hu2rVLc+bMUatWrdSgQYNM1w0AWcaUZ/wBAGCH1Mdmp364ubkZISEhRuPGjY133nnHSEhISLNOeo+tX7lypVGuXDnDw8PDCA8PNyZNmmTMmjUr3cfYN2vWzFi/fr1Rrlw5w93d3ShZsqSxaNGiNPu5fPmyMWLECKNo0aKGm5ubkTdvXqNmzZrGW2+9ZfP48R07dhiVK1c23Nzc0jyu+8iRI0bXrl2NkJAQw9XV1cifP7/RvHlzY/HixdYxr732mlGtWjXD39/f8PT0NEqWLGlMmDAh3Uec327r1q02587V1dUIDAw06tata0yYMMGIjY1Ns86lS5eMHj16GHnz5jV8fHyMyMhI47fffjMKFSpkdOvWzWbsjBkzjMKFC1sfO5/6qPbt27cbjz76qOHp6Wnky5fP+kj228ccPXrU6Nmzp1GkSBHDw8PDyJ07t9GgQQNj06ZNaWpasmSJUbt2bcPb29vw9vY2SpYsaQwYMMA4dOiQdcyVK1eMp59+2vD39zck2fUo+/vh7e2d5jycO3fOGDBggBEWFma4uroaISEhxmOPPWZ88skn1jEff/yxUbduXSNPnjyGu7u7UaRIEeOll14y4uPjbbY1fvx4I3/+/IaTk1Oa781UN27cMPLkyWPUqVPnrrVGREQYFStWtL7ev3+/0bp1a8Pf39/w8PAwSpQoYYwaNcpmnRMnThhdu3a1Ppa+cOHCxoABA2weR//jjz8a1atXN9zc3IyCBQsab7/9trVP0+ul9Njbj6lja9asaXh6ehq+vr5GtWrVjAULFqTZ5q5duwxJRpMmTe56Xm7XrVs3w9vb2zhy5IjRpEkTw8vLywgODjaioqKM5OTkdNfp37+/Icn4/PPP7d7P3c5FqtRzuHv3bpvlmzZtMmrVqmU9/hYtWhgHDhxIs/62bdusP2cKFy5sfPTRR+n+LDQM+3qqW7dudvWRPf1uGIZRr149o0yZMmnWT28/J06cMJ588knDy8vLyJs3r/H8888b69atS7PN9Kxdu9bo2bOnUbJkScPHx8dwc3MzihYtajz33HPGuXPnbMZKMgYMGGDMmzfPKFasmOHu7m5UrFgxzT7S+/6uV6+eUa9ePZtxK1asMEqXLm24uLgYkozZs2dnWGdGX2/DMIzk5GSjSJEiRpEiRYykpCQjJSXFeP31141ChQpZa/zqq6/SPXcZ/b5J73vh5s2bxtixY42IiAjD1dXVCAsLM0aMGGFcv349w7oBwAwWw8im2QYBAACAbLBv3z5VqFBBc+fOzfQT8TJjyJAhmjlzps6ePWv31TvImSwWiwYMGGBz+yYAwPGYUwoAAAD/KTNmzJCPj4/atGmTbfu4fv265s2bp7Zt2xJIAQCQTZhTCgAAAP8Jq1at0oEDB/TJJ59o4MCB6c7B9W/FxsZq06ZNWrx4sS5evKjnn38+y/cBAABuIZQCAADAf8Jzzz2nc+fO6Yknnsj05NT2OnDggDp37qygoCC9++67qlChQrbsBwAASMwpBQAAAAAAANMxpxQAAAAAAABMRygFAAAAAAAA0zGnFLJVSkqKTp8+rVy5cslisTi6HAAAAAAAcB8Mw9Dly5eVL18+OTllzTVOhFLIVqdPn1ZYWJijywAAAAAAAFng1KlTKlCgQJZsi1AK2SpXrlySpBMnTsjf39+xxQA5WEpKis6fP6/AwMAs+6sD8CCiVwD70CuA/egXwD5xcXEqVKiQ9X1+ViCUQrZKvWXP19dXvr6+Dq4GyLlSUlJ0/fp1+fr68o8h4C7oFcA+9ApgP/oFsE9KSookZenUPHQcAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0zCkFAAAAAABMkZycrJs3bzq6DKTD1dVVzs7Opu6TUAoAAAAAAGQrwzB09uxZxcXFOboU3IW/v79CQkKydDLzuyGUAgAAAAAA2So1kAoKCpKXl5dpoQfsYxiGrl27ptjYWElSaGioKfsllAIAAAAAANkmOTnZGkjlyZPH0eUgA56enpKk2NhYBQUFmXIrHxOdAwAAAACAbJM6h5SXl5eDK8G9pH6NzJr3i1AKAAAAAABkO27Zy/nM/hoRSgEAAAAAAMB0hFIAAAAAAADZ4Pjx47JYLNq7d68kKSYmRhaLhacQ/n9MdA4AAAAAAEz31MG3Td3fglJDMzX+/PnzGj16tFavXq1z584pICBA5cuX1+jRo1WrVq37qqFmzZo6c+aM/Pz8JEnR0dEaPHiwXSFVTEyMhg4dql9//VVhYWF69dVX1b1797uOnzp1qnbt2qWEhAQVK1ZML730kjp37nxftWcHQikAAAAAAIA7tG3bVjdu3NCcOXNUuHBhnTt3Tps3b9bFixfve5tubm4KCQnJ9HrHjh1Ts2bN1K9fP82fP1+bN29W7969FRoaqsjIyHTX2bFjh8qVK6dhw4YpODhYX331lbp27So/Pz81b978vo8hKxFKAQAAAAAA3CYuLk7ffPONYmJiVK9ePUlSoUKFVK1aNZtxFotFH3zwgVauXKmYmBiFhoZq8uTJateuXbrbjYmJUYMGDXTp0iXt3btXPXr0sG5HkqKiojRmzJg063300UeKiIjQlClTJEmlSpXSt99+q6lTp2YYSo0cOdLm9fPPP68NGzZo6dKlOSaUYk4pAAAAAACA2/j4+MjHx0fLly9XYmLiXceOGjVKbdu21b59+9S5c2d16tRJBw8evOc+atasqWnTpsnX11dnzpzRmTNn9OKLL6Y7dufOnWrUqJHNssjISO3cudP+g5IUHx+v3LlzZ2qd7EQoBQAAAAAAcBsXFxdFR0drzpw58vf3V61atTRy5Ej9/PPPaca2b99evXv3VvHixTV+/HhVqVJF77333j334ebmJj8/P1ksFoWEhCgkJEQ+Pj7pjj179qyCg4NtlgUHByshIUH//POPXcf05Zdfavfu3dars3ICQikAAAAAAIA7tG3bVqdPn9bKlSvVtGlTxcTEqFKlSoqOjrYZV6NGjTSv7blSykxbt25Vjx49NGPGDJUpU8bR5VgRSgEAAAAAAKTDw8NDjRs31qhRo7Rjxw51795dUVFRptcREhKic+fO2Sw7d+6cfH195enpedd1t23bphYtWmjq1Knq2rVrdpaZaYRSAAAAAAAAdihdurSuXr1qs+y7775L87pUqVJ2bc/NzU3Jycn3HFejRg1t3rzZZtnGjRvTXKV1p5iYGDVr1kyTJk1S37597arJTIRSAAAAAAAAt7l48aIaNmyoefPm6eeff9axY8e0aNEiTZ48WS1btrQZu2jRIs2aNUuHDx9WVFSUdu3apYEDB9q1n/DwcF25ckWbN2/WhQsXdO3atXTH9evXT0ePHtXLL7+s3377TR988IG+/PJLDRkyxDpm+vTpeuyxx6yvt27dqmbNmmnQoEFq27atzp49q7Nnz+rvv/++jzOSPVwcXQAeDmte+15e7ulP2AZAkgzJ/4YU94cki6OLAXIwegWwD70C2I9+yW4uPhaF1vdS/Lmr+sclybo86UaKqXVc+uuK3WNvJkrlS1fUW5On6NiJY0q6eVP58+XXM526aejAF222NXbsWH3xxRfq37+/QkNDtWDBApUuXdqu/dSsWVP9+vVTx44ddfHiRUVFRWnMmDFpxkVERGj16tUaMmSI3nnnHRUoUECffvqpIiMjrWMuXLigI0eOWF/PmTNH165d08SJEzVx4kTr8nr16ikmJsbuc5GdLIZhGI4uAg+uhIQE+fn5af4L6wilgLtK/ceQm/jHEHA39ApgH3oFsB/9kt1SQ6kC+cLk5uLu6HKyVO4CubRs2TK1atXK0aVkievXr+vYsWOKiIiQh4eHzefi4uIUEBCg+Ph4+fr6Zsn+uH0PAAAAAAAApiOUAgAAAAAAgOmYUwoAAAAAAOA+/P3nZQXkZ6qa+8WVUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAACQDY4fPy6LxaK9e/dKkmJiYmSxWBQXF+fQunIKF0cXAAAAAAAAHj4Dvrlg6v7er5M3U+MvXDyviW9N0IbN63X+Qqz8/fxVpnRZvTR4mB6tWuO+aqhZs6bOnDkjPz8/SVJ0dLQGDx5sV0gVExOjoUOH6tdff1VYWJheffVVde/ePcPxx48fV0RERJrlO3fu1KOPPnpf9Wc1QikAAAAAAIA7dOv7jG7cuKEPpn6s8ELhij0fq6+3x+jSpb/ve5tubm4KCQnJ9HrHjh1Ts2bN1K9fP82fP1+bN29W7969FRoaqsjIyLuuu2nTJpUpU8b6Ok+ePJnef3YhlAIAAAAAALhNfHycdn6/Q6sWrVWtGrUlSWEFCqpyxSo243IXyKUPPvhAK1euVExMjEJDQzV58mS1a9cu3e3GxMSoQYMGunTpkvbu3asePXpIkiwWiyQpKipKY8aMSbPeRx99pIiICE2ZMkWSVKpUKX377beaOnXqPUOpPHny3FcQZgbmlAIAAAAAALiNt7ePfLx9tHr9V0pMTLzr2FGjRqlt27bat2+fOnfurE6dOungwYP33EfNmjU1bdo0+fr66syZMzpz5oxefPHFdMfu3LlTjRo1slkWGRmpnTt33nM/Tz75pIKCglS7dm2tXLnynuPNRCgFAAAAAABwGxcXF01/+yN9sehzRZQuoKatGmn8G2P064H9aca2b99evXv3VvHixTV+/HhVqVJF77333j334ebmJj8/P1ksFoWEhCgkJEQ+Pj7pjj179qyCg4NtlgUHByshIUH//PNPuuv4+PhoypQpWrRokVavXq3atWurVatWOSqY4vY9AAAAAACAOzzZrKWaPBapnbt26IefdmvT1g1698NpeufN6Xq6wzPWcTVq2E56XqNGDevT9hwpb968Gjp0qPV11apVdfr0ab355pt68sknHVjZ/+FKKQAAAAAAgHR4eHioQd2GemnwMK1fsVlPte+sN6a8bnodISEhOnfunM2yc+fOydfXV56ennZvp3r16vrjjz+yurz7RigFAAAAAABghxLFS+ratas2y7777rs0r0uVKmXX9tzc3JScnHzPcTVq1NDmzZttlm3cuDHNVVr3snfvXoWGhmZqnezE7XsAAAAAAAC3+fvSRfV4tqs6d+yiMqUekY+Pj/b8vEfvfThNjzdpZjN20aJFqlKlimrXrq358+dr165dmjlzpl37CQ8P15UrV7R582aVL19eXl5e8vLySjOuX79+mj59ul5++WX17NlTW7Zs0ZdffqnVq1dbx0yfPl3Lli2zhldz5syRm5ubKlasKElaunSpZs2apU8//fR+T0uWI5QCAAAAAAC4jbeXjypXrKIPP31fx04cU9LNm8qfL7+6PN1dQwfaPiFv7Nix+uKLL9S/f3+FhoZqwYIFKl26tF37qVmzpvr166eOHTvq4sWLioqK0pgxY9KMi4iI0OrVqzVkyBC98847KlCggD799FNFRkZax1y4cEFHjhyxWW/8+PE6ceKEXFxcVLJkSS1cuFDt2rXL/AnJJhbDMAxHF4EHV0JCgvz8/DT/hXXyck//KQIAJMmQ/G9IcW6SLI4uBsjB6BXAPvQKYD/6Jbu5+FgUWt9LBfKFyc3F3dHlZKncBXJp2bJlatWqlaNLyRLXr1/XsWPHFBERIQ8PD5vPxcXFKSAgQPHx8fL19c2S/TGnFAAAAAAAAEzH7XswxaryBeTqlTVJKvAgsshQiCVeZw0/GfyFDsgQvQLYh14B7Jfd/TK3bViWb/O/JvXqG79g7zRX3+DhRigFAAAAAABwH5gR6d/h9j0AAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlDqXwgPD9e0adOyfCwAAAAAAMCD7oELpbp37y6LxSKLxSJXV1cFBwercePGmjVrllJSUrJ0X7t371bfvn2zfOz9uP240/sIDw/Ptn0DAAAAAIC0jh8/LovFor1790qSYmJiZLFYFBcX59C6cgoXRxeQHZo2barZs2crOTlZ586d07p16/T8889r8eLFWrlypVxcsuawAwMDs2Xs/XjnnXf0xhtvWF+HhoZq9uzZatq0qSTJ2dnZZvyNGzfk5uaWrTUBAAAAAJCR5a9sN3V/rSbUytT48+fPa/To0Vq9erXOnTungIAAlS9fXqNHj1atWpnbVqqaNWvqzJkz8vPzkyRFR0dr8ODBdoVUMTExGjp0qH799VeFhYXp1VdfVffu3e+6zvr16xUVFaVff/1VHh4eqlu3rqZMmZJjLlx54K6UkiR3d3eFhIQof/78qlSpkkaOHKkVK1Zo7dq1io6Oto6Li4tT7969FRgYKF9fXzVs2FD79u2z2daqVatUtWpVeXh4KG/evGrdurX1c7ffkmcYhsaMGaOCBQvK3d1d+fLl06BBg9IdK0knT55Uy5Yt5ePjI19fX3Xo0EHnzp2zfn7MmDGqUKGCPvvsM4WHh8vPz0+dOnXS5cuX0z1mPz8/hYSEWD8kyd/f3/q6atWqGj9+vLp27SpfX1/rVVvffvut6tSpI09PT4WFhWnQoEG6evWqdbuJiYl68cUXlT9/fnl7e6t69eqKiYnJ1NcDAAAAAID/mrZt22rPnj2aM2eODh8+rJUrV6p+/fq6ePHifW/Tzc1NISEhslgsmVrv2LFjatasmRo0aKC9e/dq8ODB6t27t9avX3/XdVq2bKmGDRtq7969Wr9+vS5cuKA2bdrcd/1Z7YG8Uio9DRs2VPny5bV06VL17t1bktS+fXt5enpq7dq18vPz08cff6zHHntMhw8fVu7cubV69Wq1bt1ar7zyiubOnasbN25ozZo16W5/yZIlmjp1qr744guVKVNGZ8+eTRNwpUpJSbEGUtu2bVNSUpIGDBigjh072gQ+R44c0fLly/XVV1/p0qVL6tChg9544w1NmDDhvs7BW2+9pdGjRysqKsq6/aZNm+q1117TrFmzdP78eQ0cOFADBw7U7NmzJUkDBw7UgQMH9MUXXyhfvnxatmyZmjZtql9++UXFihVLs4/ExEQlJiZaXyckJEiSLDJkkXFfdQMPg1v9QZ8A90KvAPahVwD7ZXe/ZPU0Mv9FKSkpMgzD+uEomdl3XFycvvnmG23dulX16tWTJBUsWFBVq1a12ZaTk5Pef/99rVq1SjExMQoNDdWkSZPUrl07m3Gpxx4TE6OGDRvq77//1t69e9WjRw9JsoZUo0eP1pgxY9LU8+GHHyoiIkJvvfWWJKlkyZL69ttvNXXqVDVp0iTdY/jhhx+UnJys8ePHy8np1jVJL7zwglq1aqUbN27I1dU13XNkGIZSUlLSfO9mx/fyQxNKSbe+aD///LOkW1cI7dq1S7GxsXJ3d5d0K7RZvny5Fi9erL59+2rChAnq1KmTxo4da91G+fLl0932yZMnFRISokaNGsnV1VUFCxZUtWrV0h27efNm/fLLLzp27JjCwsIkSXPnzlWZMmW0e/du6zd5SkqKoqOjlStXLklSly5dtHnz5vsOpRo2bKgXXnjB+rp3797q3LmzBg8eLEkqVqyY3n33XdWrV08ffvihYmNjNXv2bJ08eVL58uWTJL344otat26dZs+erddffz3NPiZOnGhzvlIFWS7L3cI/ioC7CdA1KZN/MQEeRvQKYB96BbBfdvZLbCzTpty8eVMpKSlKSkpSUlKSdbnZAdXt+74XDw8P+fj4aNmyZapSpYo1N0jP6NGjNWHCBL311luaP3++nnrqKZUoUUKlSpWy7jP12JOTk62vq1WrpilTpmjs2LHav3+/JMnHxyfdOnfu3KmGDRvafK5Ro0Z64YUXMjyu8uXLy8nJSTNnzlTXrl115coVzZ07V4899pgsFku66yUlJSklJUUXL15ME1rFx8ff46xl3kMVShmGYU0f9+3bpytXrihPnjw2Y/755x8dOXJEkrR371716dPHrm23b99e06ZNU+HChdW0aVM98cQTatGiRbrzVx08eFBhYWHWQEqSSpcuLX9/fx08eNAaSoWHh1sDKenWPFGxsbGZO+jbVKlSxeb1vn379PPPP2v+/PnWZamJ6LFjx3T06FElJyerePHiNuslJiamOW+pRowYoaFDh1pfJyQkKCwsTLFGLrkavvddO/Cgs8iQLIbOGb4yxBsIICP0CmAfegWwX3b3S1BQUJZv87/m+vXrunz5slxcXGzeI2f2FrZ/KzPzS7u4uGj27Nnq27evPvnkE1WqVEl169ZVp06dVK5cOZux7dq1s06RM2HCBG3ZskUffvihPvjgA+s+U489db5nFxcXeXl5KSAgQBaLRQUKFLhrPefOnVNISIjNMYSGhiohIUE3b96Up6dnmnWKFSum9evXq2PHjurfv7+Sk5NVo0YNrV69OsNz4eLiIicnJ+XJk0ceHh42n8uOeakfqlDq4MGDioiIkCRduXJFoaGh6c6P5O/vL0npflEzEhYWpkOHDmnTpk3auHGj+vfvrzfffFPbtm1L95I4e9y5nsVi+VeXy3l7e9u8vnLlip599lmbua9SFSxYUD///LOcnZ31448/ppko3cfHJ919uLu7p5sgG///Bj4Ad2OhVwC70CuAfegVwH7Z1y+pt009zJycnGyeDu8omd13u3bt1Lx5c33zzTf67rvvtHbtWr355pv69NNPbSYYr1mzps22a9Soob1799oc753Hn95re+q/fdyd27rT2bNn1bdvX3Xr1k1PPfWULl++rNGjR6t9+/bauHFjuuukbsvJySnN9252fC8/NKHUli1b9Msvv2jIkCGSpEqVKuns2bNycXHJcNb5cuXKafPmzdZ7PO/F09NTLVq0UIsWLTRgwACVLFlSv/zyiypVqmQzrlSpUjp16pROnTplvVrqwIEDiouLU+nSpe//IDOpUqVKOnDggIoWLZru5ytWrKjk5GTFxsaqTp06ptUFAAAAAEBO4OHhocaNG6tx48YaNWqUevfuraioqHs+9S6rhYSE2DwcTbp19ZSvr2+GF9S8//778vPz0+TJk63L5s2bp7CwMH3//fd69NFHs7VmezyQkW1iYqLOnj2rv/76Sz/99JNef/11tWzZUs2bN1fXrl0l3br3skaNGmrVqpU2bNig48ePa8eOHXrllVf0ww8/SJKioqK0YMECRUVF6eDBg/rll180adKkdPcZHR2tmTNnav/+/Tp69KjmzZsnT09PFSpUKM3YRo0aqWzZsurcubN++ukn7dq1S127dlW9evXS3GKXnYYNG6YdO3Zo4MCB2rt3r37//XetWLFCAwcOlCQVL15cnTt3VteuXbV06VIdO3ZMu3bt0sSJE7V69WrT6gQAAAAAICcoXbq0zRPrJem7775L87pUqVJ2bc/Nzc06z9Td1KhRQ5s3b7ZZtnHjRtWoUSPDda5du5bm6qbUu6ByygT8D2QotW7dOoWGhio8PFxNmzbV1q1b9e6772rFihXWL4DFYtGaNWtUt25d9ejRQ8WLF1enTp104sQJBQcHS5Lq16+vRYsWaeXKlapQoYIaNmyoXbt2pbtPf39/zZgxQ7Vq1VK5cuW0adMmrVq1Kt25lywWi1asWKGAgADVrVtXjRo1UuHChbVw4cLsOynpKFeunLZt26bDhw+rTp06qlixokaPHm2d1FySZs+era5du+qFF15QiRIl1KpVK+3evVsFCxY0tVYAAAAAAMxy8eJFNWzYUPPmzdPPP/+sY8eOadGiRZo8ebJatmxpM3bRokWaNWuWDh8+rKioKO3atct6sce9hIeH68qVK9q8ebMuXLiga9eupTuuX79+Onr0qF5++WX99ttv+uCDD/Tll19a7waTpOnTp+uxxx6zvm7WrJl2796tcePG6ffff9dPP/2kHj16qFChQqpYseJ9nJWsZzEc+TxGPPASEhLk5+enTnP3y9WLic6BjFhkKMQSr7OGH3N/AHdBrwD2oVcA+2V3v8xtG3bvQQ+469ev69ixY4qIiLCZPHv5K9tNraPVhFp2j01MTNSYMWO0YcMGHTlyRDdv3lRYWJjat2+vkSNHWm+Zs1gsev/997V8+XJ9/fXXCg0N1aRJk9ShQwdJ0vHjxxUREaE9e/aoQoUKiomJUYMGDXTp0iXrfNb/+9//tGjRIl28eFFRUVEaM2ZMujXFxMRoyJAhOnDggAoUKKBRo0bZ3EY4ZswYRUdH6/jx49ZlX3zxhSZPnqzDhw/Ly8tLNWrU0KRJk1SyZMl095HR10qS4uLiFBAQoPj4ePn6Zs37e0IpZCtCKcA+vHkA7EOvAPahVwD7EUplv7sFHf91FotFy5YtU6tWrRxdSpYwO5R6IG/fAwAAAAAAQM5GKAUAAAAAAADTuTi6AAAAAAAAgP8iZkT6d7hSCgAAAAAAAKYjlAIAAAAAANmOq4pyPrO/Rty+B1MklVgh5XqwnrIAZCWLISVd9dJN72syeEgSkCF6BbAPvfLgWFBqqKNLeOClpKQoNtZNQUFBcnLiuo3s4OrqKkm6du2aPD09HVwN7ubatWuS/u9rlt0IpQAAAAAAQLZxdnaWv7+/YmNjJUleXl6yWEjMcxLDMHTt2jXFxsbK399fzs7OpuyXUAoAAAAAAGSrkJAQSbIGU8iZ/P39rV8rMxBKAQAAAACAbGWxWBQaGqqgoCDdvHnT0eUgHa6urqZdIZWKUAoAAAAAAJjC2dnZ9OADORezuAEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATOfi6ALwcJhRvL/8/f0dXQaQY6WkpCg2NlZBQUFycuLvBUBG6BXAPvQKAOC/gN9QAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTuTi6ADwc1rz2vbzcfRxdBpCDGZL/DSnuD0kWRxcD5GD0CmAfegWwH/2SXVpNqOXoEpDDcaUUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0Lo4uAA+HVeULyNXL19FlADmWRYZCLPE6a/jJkMXR5QA5Fr0C2IdegSPMbRvm6BLuS0pKimJjYxUUFCQnJ67bAMxExwEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0OS6UCg8P17Rp0+57/ejoaPn7+2dZPQ+Sf3tuAQAAAAAAskqmQqnu3burVatW2VTKLbt371bfvn3tGpteyNKxY0cdPnz4vvcfHR0ti8Uii8UiJycnhYaGqmPHjjp58uR9bzOnyMy5BQAAAAAAyE457kqpwMBAeXl53ff6np6eCgoK+lc1+Pr66syZM/rrr7+0ZMkSHTp0SO3bt/9X27THzZs3s3X7//bcAgAAAAAAZJUsDaW2bdumatWqyd3dXaGhoRo+fLiSkpKsn798+bI6d+4sb29vhYaGaurUqapfv74GDx5sHXP71U+GYWjMmDEqWLCg3N3dlS9fPg0aNEiSVL9+fZ04cUJDhgyxXtkkpX/73qpVq1S1alV5eHgob968at269V2Pw2KxKCQkRKGhoapZs6Z69eqlXbt2KSEhwTpmxYoVqlSpkjw8PFS4cGGNHTvW5lh/++031a5dWx4eHipdurQ2bdoki8Wi5cuXS5KOHz8ui8WihQsXql69evLw8ND8+fMlSZ9++qlKlSolDw8PlSxZUh988IF1uzdu3NDAgQMVGhoqDw8PFSpUSBMnTrzn+brz3ErSyZMn1bJlS/n4+MjX11cdOnTQuXPnrJ8fM2aMKlSooM8++0zh4eHy8/NTp06ddPny5buePwAAAAAAgHtxyaoN/fXXX3riiSfUvXt3zZ07V7/99pv69OkjDw8PjRkzRpI0dOhQbd++XStXrlRwcLBGjx6tn376SRUqVEh3m0uWLNHUqVP1xRdfqEyZMjp79qz27dsnSVq6dKnKly+vvn37qk+fPhnWtXr1arVu3VqvvPKK5s6dqxs3bmjNmjV2H1dsbKyWLVsmZ2dnOTs7S5K++eYbde3aVe+++67q1KmjI0eOWG+Li4qKUnJyslq1aqWCBQvq+++/1+XLl/XCCy+ku/3hw4drypQpqlixojWYGj16tKZPn66KFStqz5496tOnj7y9vdWtWze9++67Wrlypb788ksVLFhQp06d0qlTp+55vu6UkpJiDaS2bdumpKQkDRgwQB07dlRMTIx13JEjR7R8+XJ99dVXunTpkjp06KA33nhDEyZMsPscAgAAAAAA3CnLQqkPPvhAYWFhmj59uiwWi0qWLKnTp09r2LBhGj16tK5evao5c+bo888/12OPPSZJmj17tvLly5fhNk+ePKmQkBA1atRIrq6uKliwoKpVqyZJyp07t5ydnZUrVy6FhIRkuI0JEyaoU6dOGjt2rHVZ+fLl73os8fHx8vHxkWEYunbtmiRp0KBB8vb2liSNHTtWw4cPV7du3SRJhQsX1vjx4/Xyyy8rKipKGzdu1JEjRxQTE2OtbcKECWrcuHGafQ0ePFht2rSxvo6KitKUKVOsyyIiInTgwAF9/PHH6tatm06ePKlixYqpdu3aslgsKlSokF3n606bN2/WL7/8omPHjiksLEySNHfuXJUpU0a7d+9W1apVJd0Kr6Kjo5UrVy5JUpcuXbR58+YMQ6nExEQlJiZaX6deXWaRIYuMu5534GF2qz/oE+Be6BXAPvQKHCElJcXRJdyXlJQUGYbxn60fMEt29EiWhVIHDx5UjRo1rLfRSVKtWrV05coV/fnnn7p06ZJu3rxpE5L4+fmpRIkSGW6zffv2mjZtmgoXLqymTZvqiSeeUIsWLeTiYn/Ze/fuveuVVOnJlSuXfvrpJ928eVNr167V/PnzbUKYffv2afv27TbLkpOTdf36dV27dk2HDh1SWFiYTViWUThUpUoV6/9fvXpVR44cUa9evWxqTkpKkp+fn6Rbk803btxYJUqUUNOmTdW8eXM1adJEUubO18GDBxUWFmYNpCSpdOnS8vf318GDB62hVHh4uDWQkqTQ0FDFxsZmeO4mTpxoEwCmCrJclruFfxQBdxOga9JtP0MBpI9eAexDr8BssbFuji7hvqSkpCg+Pl6GYcjJKcdNuwzkGPHx8Vm+zSwLpbJDWFiYDh06pE2bNmnjxo3q37+/3nzzTW3btk2urq52bcPT0zPT+3VyclLRokUlSaVKldKRI0f0v//9T5999pkk6cqVKxo7dqzNFU6pPDw8MrWv1KuvUrcrSTNmzFD16tVtxqXeOlipUiUdO3ZMa9eu1aZNm9ShQwc1atRIixcvzpLzdac717NYLHdNR0eMGKGhQ4daXyckJCgsLEyxRi65Gr73VQPwMLDIkCyGzhm+MsQbCCAj9ApgH3oFjvBvHzjlKCkpKbJYLAoMDCSUAu7CzS3rg+csC6VKlSqlJUuWyDAM69VS27dvV65cuVSgQAEFBATI1dVVu3fvVsGCBSXdStkOHz6sunXrZrhdT09PtWjRQi1atNCAAQNUsmRJ/fLLL6pUqZLc3NyUnJx817rKlSunzZs3q0ePHvd9bMOHD1eRIkU0ZMgQVapUSZUqVdKhQ4eswdWdSpQooVOnTuncuXMKDg6WJO3evfue+wkODla+fPl09OhRde7cOcNxvr6+6tixozp27Kh27dqpadOm+vvvv5U7d+67nq/blSpVyjofVerVUgcOHFBcXJxKly5t76lJw93dXe7u7mmWG///Bj4Ad2OhVwC70CuAfegVmOu/HOhYLBY5OTn9p48ByG7Z0R+ZDqXi4+O1d+9em2V58uRR//79NW3aND333HMaOHCgDh06pKioKA0dOlROTk7KlSuXunXrppdeekm5c+dWUFCQoqKi5OTkZHPL3+2io6OVnJys6tWry8vLS/PmzZOnp6d1HqXw8HB9/fXX6tSpk9zd3ZU3b94024iKitJjjz2mIkWKqFOnTkpKStKaNWs0bNgwu485LCxMrVu31ujRo/XVV19p9OjRat68uQoWLKh27drJyclJ+/bt0/79+/Xaa6+pcePGKlKkiLp166bJkyfr8uXLevXVVyUpw2NNNXbsWA0aNEh+fn5q2rSpEhMT9cMPP+jSpUsaOnSo3n77bYWGhqpixYpycnLSokWLFBISIn9//3uer9s1atRIZcuWVefOnTVt2jQlJSWpf//+qlevns0thQAAAAAAANkh0zFXTEyMKlasaPMxduxY5c+fX2vWrNGuXbtUvnx59evXT7169bKGMZL09ttvq0aNGmrevLkaNWqkWrVqqVSpUhne8ubv768ZM2aoVq1aKleunDZt2qRVq1YpT548kqRx48bp+PHjKlKkiAIDA9PdRv369bVo0SKtXLlSFSpUUMOGDbVr167MHraGDBmi1atXa9euXYqMjNRXX32lDRs2qGrVqnr00Uc1depUa/jj7Oys5cuX68qVK6patap69+6tV155RdK9b+/r3bu3Pv30U82ePVtly5ZVvXr1FB0drYiICEm35ruaPHmyqlSpoqpVq+r48eNas2aNnJyc7nm+bmexWLRixQoFBASobt26atSokQoXLqyFCxdm+twAAAAAAABklsUwDIfNPn316lXlz59fU6ZMUa9evRxVhim2b9+u2rVr648//lCRIkUcXY5pEhIS5Ofnp05z98vVizmlgIxYZCjEEq+zhh+3WQB3Qa8A9qFX4Ahz24bde1AOlJKSotjYWAUFBXH7HnAXcXFxCggIUHx8vHx9s+b9vakTne/Zs0e//fabqlWrpvj4eI0bN06S1LJlSzPLMMWyZcvk4+OjYsWK6Y8//tDzzz+vWrVqPVSBFAAAAAAAQEZMf/reW2+9pUOHDsnNzU2VK1fWN998k+5cUP91ly9f1rBhw3Ty5EnlzZtXjRo10pQpUxxdFgAAAAAAQI5gaihVsWJF/fjjj2bu0mG6du2qrl27OroMAAAAAACAHIkbZgEAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApjN9onM8nJJKrJByeTi6DCDHshhS0lUv3fS+JoMndwMZolcA+9ArkKQFpYY6ugQAuCuulAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmM7F0QXg4TCjeH/5+/s7ugwgx0pJSVFsbKyCgoLk5MTfC4CM0CuAfegVAMB/Ab+hAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmc3F0AXg4rHnte3m5+zi6DCAHMyT/G1LcH5Isji4GyMHoFcA+9ApgP/rlYdRqQi1HlwBxpRQAAAAAAAAcgFAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOlcHF0AHg6ryheQq5evo8sAciyLDIVY4nXW8JMhi6PLAXIsegWwD70C2I9+yT5z24Y5ugTkcFwpBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaHUA6R79+5q1aqVzbLFixfLw8NDU6ZMUffu3WWxWPTGG2/YjFm+fLksFov1dUxMjCwWi8qUKaPk5GSbsf7+/oqOjs6uQwAAAAAAAA8JQqkH2KeffqrOnTvrww8/1AsvvCBJ8vDw0KRJk3Tp0qV7rn/06FHNnTs3u8sEAAAAAAAPIUKpB9TkyZP13HPP6YsvvlCPHj2syxs1aqSQkBBNnDjxntt47rnnFBUVpcTExOwsFQAAAAAAPIQIpR5Aw4YN0/jx4/XVV1+pdevWNp9zdnbW66+/rvfee09//vnnXbczePBgJSUl6b333svOcgEAAAAAwEPIxdEFIGutXbtWK1as0ObNm9WwYcN0x7Ru3VoVKlRQVFSUZs6cmeG2vLy8FBUVpZEjR6pPnz7y8/O75/4TExNtrqxKSEiQJFlkyCIjk0cDPDxu9Qd9AtwLvQLYh14B7Ee/ZJ+UlBRHl4AslB1fT0KpB0y5cuV04cIFRUVFqVq1avLx8Ul33KRJk9SwYUO9+OKLd91er169NGXKFE2aNEmvv/76Pfc/ceJEjR07Ns3yIMtluVv4IQ/cTYCuSbc9dABA+ugVwD70CmA/+iV7xMa6OboEZKH4+Pgs3yah1AMmf/78Wrx4sRo0aKCmTZtq7dq1ypUrV5pxdevWVWRkpEaMGKHu3btnuD0XFxdNmDBB3bt318CBA++5/xEjRmjo0KHW1wkJCQoLC1OskUuuhu99HRPwMLDIkCyGzhm+MsQ/iICM0CuAfegVwH70S/YJCgpydAnIQm5uWR8yEko9gAoVKqRt27ZZg6l169alG0y98cYbqlChgkqUKHHX7bVv315vvvlmuldA3cnd3V3u7u5plhv//wY+AHdjoVcAu9ArgH3oFcB+9Et2cHJiGusHSXZ8PfkOeUCFhYUpJiZGsbGxioyMtM7tdLuyZcuqc+fOevfdd++5vTfeeEOzZs3S1atXs6NcAAAAAADwkCGUeoAVKFBAMTExunDhQobB1Lhx4+yarKxhw4Zq2LChkpKSsqNUAAAAAADwkOH2vQdIdHR0mmX58+fX4cOHM1wnPDzc5ml5klS/fn0ZRtpJydevX/+vawQAAAAAAJC4UgoAAAAAAAAOQCgFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA07k4ugA8HJJKrJByeTi6DCDHshhS0lUv3fS+JsPi6GqAnIteAexDr+DfWFBqqKNLMFVKSopiY90UFBQkJyeu2wDMRMcBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAEzn4ugC8HCYUby//P39HV0GkGOlpKQoNjZWQUFBcnLi7wVARugVwD70CgDgv4DfUAAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA07k4ugA8HNa89r283H0cXQaQgxmS/w0p7g9JFkcXA+Rg9ApgH3oFsB/9ggdXqwm1HF3CXXGlFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdC6OLgAPh1XlC8jVy9fRZQA5lkWGQizxOmv4yZDF0eUAORa9AtiHXgHsR79kn7ltwxxdAnI4rpQCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUOoBcv78ef3vf/9TwYIF5e7urpCQEEVGRmrbtm3Kmzev3njjjXTXGz9+vIKDg3Xz5k1FR0fLYrGoVKlSacYtWrRIFotF4eHh2XwkAAAAAADgQUco9QBp27at9uzZozlz5ujw4cNauXKl6tevr/j4eD3zzDOaPXt2mnUMw1B0dLS6du0qV1dXSZK3t7diY2O1c+dOm7EzZ85UwYIFTTkWAAAAAADwYHNxdAHIGnFxcfrmm28UExOjevXqSZIKFSqkatWqSZIiIiL0zjvv6Ntvv1Xt2rWt623btk1Hjx5Vr169rMtcXFz09NNPa9asWapRo4Yk6c8//1RMTIyGDBmiBQsWmHhkAAAAAADgQUQo9YDw8fGRj4+Pli9frkcffVTu7u42ny9btqyqVq2qWbNm2YRSs2fPVs2aNVWyZEmb8T179lT9+vX1zjvvyMvLS9HR0WratKmCg4PvWkdiYqISExOtrxMSEiRJFhmyyPi3hwk8sG71B30C3Au9AtiHXgHsR79kn5SUFEeXgCyUHV9PQqkHhIuLi6Kjo9WnTx999NFHqlSpkurVq6dOnTqpXLlykqRevXrpxRdf1LvvvisfHx9dvnxZixcv1rvvvptmexUrVlThwoW1ePFidenSRdHR0Xr77bd19OjRu9YxceJEjR07Ns3yIMtluVv4IQ/cTYCuSRaLo8sAcjx6BbAPvQLYj37JHrGxbo4uAVkoPj4+y7dJKPUAadu2rZo1a6ZvvvlG3333ndauXavJkyfr008/Vffu3fXUU09pyJAh+vLLL9WzZ08tXLhQTk5O6tixY7rb69mzp2bPnq2CBQvq6tWreuKJJzR9+vS71jBixAgNHTrU+johIUFhYWGKNXLJ1fDN0uMFHiQWGZLF0DnDV4b4BxGQEXoFsA+9AtiPfsk+QUFBji4BWcjNLetDRkKpB4yHh4caN26sxo0ba9SoUerdu7eioqLUvXt3+fr6ql27dpo9e7Y1cOrQoYN8fHzS3Vbnzp318ssva8yYMerSpYtcXO797eLu7p7m1kEp9WJYfsADd2ehVwC70CuAfegVwH70S3ZwcuLZag+S7Ph68h3ygCtdurSuXr1qfd2rVy99++23+uqrr7Rjxw6bCc7vlDt3bj355JPatm2bevbsaUa5AAAAAADgIUEo9YC4ePGiGjZsqHnz5unnn3/WsWPHtGjRIk2ePFktW7a0jqtbt66KFi2qrl27qmTJkqpZs+ZdtxsdHa0LFy6kmQgdAAAAAADg3+D2vQeEj4+PqlevrqlTp+rIkSO6efOmwsLC1KdPH40cOdI6zmKxqGfPnho5cqRGjBhxz+16enrK09MzO0sHAAAAAAAPIYthGDwSDdkmISFBfn5+6jR3v1y9mOgcyIhFhkIs8Tpr+DGXAXAX9ApgH3oFsB/9kn3mtg1zdAnIQnFxcQoICFB8fLx8fbPm/T237wEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0Lo4uAA+HpBIrpFweji4DyLEshpR01Us3va/J4KEvQIboFcA+9ApgP/rl7haUGuroEvAA40opAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpXBxdAB4OM4r3l7+/v6PLAHKslJQUxcbGKigoSE5O/L0AyAi9AtiHXgHsR78AjkPHAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABM5+LoAvBwWPPa9/Jy93F0GUAOZkj+N6S4PyRZHF0MkIPRK4B96BXAfvQLYI9riVeyfJtcKQUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAEzn4ugC8HBYVb6AXL18HV0GkGNZZCjEEq+zhp8MWRxdDpBj0SuAfegVwH70C9Izt22Yo0vIceLi4qQpWbtNrpQCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6Qil7sJisWj58uWOLgMAAAAAAOCBk6NDqe7du8tischiscjV1VURERF6+eWXdf36dUeXlq1uP+7bP/744w+H1tSqVSuH7R8AAAAAADxYXBxdwL00bdpUs2fP1s2bN/Xjjz+qW7duslgsmjRpkqNLy1apx327wMDA+9rWjRs35ObmlhVlAQAAAAAAZIkcfaWUJLm7uyskJERhYWFq1aqVGjVqpI0bN1o/f/HiRT311FPKnz+/vLy8VLZsWS1YsMBmG/Xr19egQYP08ssvK3fu3AoJCdGYMWNsxvz++++qW7euPDw8VLp0aZt9pPrll1/UsGFDeXp6Kk+ePOrbt6+uXLli/Xzq1USvv/66goOD5e/vr3HjxikpKUkvvfSScufOrQIFCqQJm+523Ld/ODs7S5K2bdumatWqyd3dXaGhoRo+fLiSkpJsjnfgwIEaPHiw8ubNq8jISEnS/v379fjjj8vHx0fBwcHq0qWLLly4YF1v8eLFKlu2rPX4GjVqpKtXr2rMmDGaM2eOVqxYYb1qKyYm5p7HAAAAAAAAkJEcH0rdbv/+/dqxY4fNVT/Xr19X5cqVtXr1au3fv199+/ZVly5dtGvXLpt158yZI29vb33//feaPHmyxo0bZw2eUlJS1KZNG7m5uen777/XRx99pGHDhtmsf/XqVUVGRiogIEC7d+/WokWLtGnTJg0cONBm3JYtW3T69Gl9/fXXevvttxUVFaXmzZsrICBA33//vfr166dnn31Wf/75532dg7/++ktPPPGEqlatqn379unDDz/UzJkz9dprr6U5Xjc3N23fvl0fffSR4uLi1LBhQ1WsWFE//PCD1q1bp3PnzqlDhw6SpDNnzuipp55Sz549dfDgQcXExKhNmzYyDEMvvviiOnTooKZNm+rMmTM6c+aMataseV/1AwAAAAAASJLFMAzD0UVkpHv37po3b548PDyUlJSkxMREOTk56csvv1Tbtm0zXK958+YqWbKk3nrrLUm3rhxKTk7WN998Yx1TrVo1NWzYUG+88YY2bNigZs2a6cSJE8qXL58kad26dXr88ce1bNkytWrVSjNmzNCwYcN06tQpeXt7S5LWrFmjFi1a6PTp0woODlb37t0VExOjo0ePysnpVt5XsmRJBQUF6euvv5YkJScny8/PT59++qk6dep0z+NO9fjjj2vRokV65ZVXtGTJEh08eFAWi0WS9MEHH2jYsGGKj4+Xk5OT6tevr4SEBP3000/W9V977TV98803Wr9+vXXZn3/+qbCwMB06dEhXrlxR5cqVdfz4cRUqVCjdmuLi4u458XtiYqISExOtrxMSEhQWFqan5v4iVy/fu64LPMwsMhRsidc5w0+GLI4uB8ix6BXAPvQKYD/6BemZ3bqAo0vIceLi4pQnTx7Fx8fL1zdr3t/n+DmlGjRooA8//FBXr17V1KlT5eLiYhNIJScn6/XXX9eXX36pv/76Szdu3FBiYqK8vLxstlOuXDmb16GhoYqNjZUkHTx4UGFhYdZASpJq1KhhM/7gwYMqX768NZCSpFq1aiklJUWHDh1ScHCwJKlMmTLWQEqSgoOD9cgjj1hfOzs7K0+ePNZ93+u4U6Xu9+DBg6pRo4Y1kEqt48qVK/rzzz9VsGBBSVLlypVttrdv3z5t3bpVPj4+afZ15MgRNWnSRI899pjKli2ryMhINWnSRO3atVNAQMBd67zTxIkTNXbs2DTLgyyX5W7JsfknkCME6Jpk4R9CwL3QK4B96BXAfvQL7hQby7zMd4qPj8/ybeb4UMrb21tFixaVJM2aNUvly5fXzJkz1atXL0nSm2++qXfeeUfTpk1T2bJl5e3trcGDB+vGjRs223F1dbV5bbFYlJKSkuX1pref+9n37cd9P24PzyTpypUratGiRboTxIeGhsrZ2VkbN27Ujh07tGHDBr333nt65ZVX9P333ysiIsLu/Y4YMUJDhw61vk69UirWyCVXgyulgIxYZEgWQ+cMX/5CB9wFvQLYh14B7Ee/ID1BQUGOLiHHyY4HqOX4UOp2Tk5OGjlypIYOHaqnn35anp6e2r59u1q2bKlnnnlG0q35oQ4fPqzSpUvbvd1SpUrp1KlTOnPmjEJDQyVJ3333XZox0dHRunr1qjXw2b59u5ycnFSiRIksOkL7al2yZIkMw7BeLbV9+3blypVLBQpkfHlhpUqVtGTJEoWHh8vFJf0vu8ViUa1atVSrVi2NHj1ahQoV0rJlyzR06FC5ubkpOTn5nvW5u7vL3d09zXJDFn7AA/dkoVcAu9ArgH3oFcB+9Ats3X4HFG7JjnPynzvL7du3l7Ozs95//31JUrFixaxX+Bw8eFDPPvuszp07l6ltNmrUSMWLF1e3bt20b98+ffPNN3rllVdsxnTu3FkeHh7q1q2b9u/fr61bt+q5555Tly5drLfumaF///46deqUnnvuOf32229asWKFoqKiNHTo0Lt+gwwYMEB///23nnrqKe3evVtHjhzR+vXr1aNHDyUnJ+v777/X66+/rh9++EEnT57U0qVLdf78eZUqVUqSFB4erp9//lmHDh3ShQsXdPPmTbMOGQAAAAAAPID+c6GUi4uLBg4cqMmTJ+vq1at69dVXValSJUVGRqp+/foKCQlRq1atMrVNJycnLVu2TP/884+qVaum3r17a8KECTZjvLy8tH79ev3999+qWrWq2rVrp8cee0zTp0/PwqO7t/z582vNmjXatWuXypcvr379+qlXr1569dVX77pevnz5tH37diUnJ6tJkyYqW7asBg8eLH9/fzk5OcnX11dff/21nnjiCRUvXlyvvvqqpkyZoscff1yS1KdPH5UoUUJVqlRRYGCgtm/fbsbhAgAAAACAB1SOfvoe/vsSEhLk5+enTnP38/Q94C4sMhRiiddZnvoC3BW9AtiHXgHsR78gPXPbhjm6hBwnLi5OAQEBWfr0vf/clVIAAAAAAAD47yOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOlcHF0AHg5JJVZIuTwcXQaQY1kMKemql256X5PBk4iBDNErgH3oFdhrQamhji7B4VJSUhQb66agoCA5OXHdBmAmOg4AAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDoXRxeAh8OM4v3l7+/v6DKAHCslJUWxsbEKCgqSkxN/LwAyQq8A9qFXAAD/BfyGAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOlcHF0AHmyGYUiSEhIS5OREBgpkJCUlRZcvX5aHhwe9AtwFvQLYh14B7Ee/APZJSEiQ9H/v87MCoRSy1cWLFyVJhQoVcnAlAAAAAADg37p48aL8/PyyZFuEUshWuXPnliSdPHkyy75pgQdRQkKCwsLCdOrUKfn6+jq6HCDHolcA+9ArgP3oF8A+8fHxKliwoPV9flYglEK2Sr381c/Pjx/wgB18fX3pFcAO9ApgH3oFsB/9AtgnK29z5YZZAAAAAAAAmI5QCgAAAAAAAKYjlEK2cnd3V1RUlNzd3R1dCpCj0SuAfegVwD70CmA/+gWwT3b0isXIymf5AQAAAAAAAHbgSikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpfCvvf/++woPD5eHh4eqV6+uXbt2ZTg2OjpaFovF5sPDw8PEagHHyUyvSFJcXJwGDBig0NBQubu7q3jx4lqzZo1J1QKOk5leqV+/fprfKxaLRc2aNTOxYsAxMvt7Zdq0aSpRooQ8PT0VFhamIUOG6Pr16yZVCzhWZvrl5s2bGjdunIoUKSIPDw+VL19e69atM7FawDG+/vprtWjRQvny5ZPFYtHy5cvvuU5MTIwqVaokd3d3FS1aVNHR0ZnaJ6EU/pWFCxdq6NChioqK0k8//aTy5csrMjJSsbGxGa7j6+urM2fOWD9OnDhhYsWAY2S2V27cuKHGjRvr+PHjWrx4sQ4dOqQZM2Yof/78JlcOmCuzvbJ06VKb3yn79++Xs7Oz2rdvb3LlgLky2yuff/65hg8frqioKB08eFAzZ87UwoULNXLkSJMrB8yX2X559dVX9fHHH+u9997TgQMH1K9fP7Vu3Vp79uwxuXLAXFevXlX58uX1/vvv2zX+2LFjatasmRo0aKC9e/dq8ODB6t27t9avX2//Tg3gX6hWrZoxYMAA6+vk5GQjX758xsSJE9MdP3v2bMPPz8+k6oCcI7O98uGHHxqFCxc2bty4YVaJQI6Q2V6509SpU41cuXIZV65cya4SgRwhs70yYMAAo2HDhjbLhg4datSqVStb6wRygsz2S2hoqDF9+nSbZW3atDE6d+6crXUCOYkkY9myZXcd8/LLLxtlypSxWdaxY0cjMjLS7v1wpRTu240bN/Tjjz+qUaNG1mVOTk5q1KiRdu7cmeF6V65cUaFChRQWFqaWLVvq119/NaNcwGHup1dWrlypGjVqaMCAAQoODtYjjzyi119/XcnJyWaVDZjufn+v3G7mzJnq1KmTvL29s6tMwOHup1dq1qypH3/80XrL0tGjR7VmzRo98cQTptQMOMr99EtiYmKaKUY8PT317bffZmutwH/Nzp07bXpLkiIjI+3+d5vE7Xv4Fy5cuKDk5GQFBwfbLA8ODtbZs2fTXadEiRKaNWuWVqxYoXnz5iklJUU1a9bUn3/+aUbJgEPcT68cPXpUixcvVnJystasWaNRo0ZpypQpeu2118woGXCI++mV2+3atUv79+9X7969s6tEIEe4n155+umnNW7cONWuXVuurq4qUqSI6tevz+17eODdT79ERkbq7bff1u+//66UlBRt3LjRers4gP9z9uzZdHsrISFB//zzj13bIJSCqWrUqKGuXbuqQoUKqlevnpYuXarAwEB9/PHHji4NyFFSUlIUFBSkTz75RJUrV1bHjh31yiuv6KOPPnJ0aUCONXPmTJUtW1bVqlVzdClAjhMTE6PXX39dH3zwgX766SctXbpUq1ev1vjx4x1dGpDjvPPOOypWrJhKliwpNzc3DRw4UD169JCTE2+fgazm4ugC8N+VN29eOTs769y5czbLz507p5CQELu24erqqooVK+qPP/7IjhKBHOF+eiU0NFSurq5ydna2LitVqpTOnj2rGzduyM3NLVtrBhzh3/xeuXr1qr744guNGzcuO0sEcoT76ZVRo0apS5cu1isJy5Ytq6tXr6pv37565ZVXeLONB9b99EtgYKCWL1+u69ev6+LFi8qXL5+GDx+uwoULm1Ey8J8REhKSbm/5+vrK09PTrm3w2wf3zc3NTZUrV9bmzZuty1JSUrR582bVqFHDrm0kJyfrl19+UWhoaHaVCTjc/fRKrVq19McffyglJcW67PDhwwoNDSWQwgPr3/xeWbRokRITE/XMM89kd5mAw91Pr1y7di1N8JT6h49b89kCD6Z/87vFw8ND+fPnV1JSkpYsWaKWLVtmd7nAf0qNGjVsekuSNm7caHceIImn7+Hf+eKLLwx3d3cjOjraOHDggNG3b1/D39/fOHv2rGEYhtGlSxdj+PDh1vFjx4411q9fbxw5csT48ccfjU6dOhkeHh7Gr7/+6qhDAEyR2V45efKkkStXLmPgwIHGoUOHjK+++soICgoyXnvtNUcdAmCKzPZKqtq1axsdO3Y0u1zAYTLbK1FRUUauXLmMBQsWGEePHjU2bNhgFClSxOjQoYOjDgEwTWb75bvvvjOWLFliHDlyxPj666+Nhg0bGhEREcalS5ccdASAOS5fvmzs2bPH2LNnjyHJePvtt409e/YYJ06cMAzDMIYPH2506dLFOv7o0aOGl5eX8dJLLxkHDx403n//fcPZ2dlYt26d3fvk9j38Kx07dtT58+c1evRonT17VhUqVNC6deusk52dPHnS5q9yly5dUp8+fXT27FkFBASocuXK2rFjh0qXLu2oQwBMkdleCQsL0/r16zVkyBCVK1dO+fPn1/PPP69hw4Y56hAAU2S2VyTp0KFD+vbbb7VhwwZHlAw4RGZ75dVXX5XFYtGrr76qv/76S4GBgWrRooUmTJjgqEMATJPZfrl+/bpeffVVHT16VD4+PnriiSf02Wefyd/f30FHAJjjhx9+UIMGDayvhw4dKknq1q2boqOjdebMGZ08edL6+YiICK1evVpDhgzRO++8owIFCujTTz9VZGSk3fu0GAbX6wIAAAAAAMBczCkFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAA5AAWi+WuH2PGjPlX216+fLnd45999lk5Oztr0aJF971PAACAe3FxdAEAAACQzpw5Y/3/hQsXavTo0Tp06JB1mY+Pjyl1XLt2TV988YVefvllzZo1S+3btzdlvxm5ceOG3NzcHFoDAADIHlwpBQAAkAOEhIRYP/z8/GSxWGyWffHFFypVqpQ8PDxUsmRJffDBB9Z1b9y4oYEDByo0NFQeHh4qVKiQJk6cKEkKDw+XJLVu3VoWi8X6OiOLFi1S6dKlNXz4cH399dc6deqUzecTExM1bNgwhYWFyd3dXUWLFtXMmTOtn//111/VvHlz+fr6KleuXKpTp46OHDkiSapfv74GDx5ss71WrVqpe/fu1tfh4eEaP368unbtKl9fX/Xt21eSNGzYMBUvXlxeXl4qXLiwRo0apZs3b9psa9WqVapatao8PDyUN29etW7dWpI0btw4PfLII2mOtUKFCho1atRdzwcAAMg+hFIAAAA53Pz58zV69GhNmDBBBw8e1Ouvv65Ro0Zpzpw5kqR3331XK1eu1JdffqlDhw5p/vz51vBp9+7dkqTZs2frzJkz1tcZmTlzpp555hn5+fnp8ccfV3R0tM3nu3btqgULFujdd9/VwYMH9fHHH1uv4vrrr79Ut25dubu7a8uWLfrxxx/Vs2dPJSUlZep433rrLZUvX1579uyxhka5cuVSdHS0Dhw4oHfeeUczZszQ1KlTreusXr1arVu31hNPPKE9e/Zo8+bNqlatmiSpZ8+eOnjwoM2x79mzRz///LN69OiRqdoAAEDW4fY9AACAHC4qKkpTpkxRmzZtJEkRERE6cOCAPv74Y3Xr1k0nT55UsWLFVLt2bVksFhUqVMi6bmBgoCTJ399fISEhd93P77//ru+++05Lly6VJD3zzDMaOvT/tXd/IU29cRzHP85/RNL6Y2VR9EeWFphariCJ1SZMioJo6EBotfTGRHAFEQ1iUDeBXhQRZLq8qFYGQrAFmUIXWYjQLrwK+qNXVlBGCpWtdSEdfsvU/vzaT/y9XzDYec5zzvMcdjM+PM/3+OT3+5WSkqInT57o5s2b6uzsVFlZmSRp7dq1xvUXLlyQ2WxWKBRSenq6JGndunW//Lx2u11Hjx5NaPP7/cb31atX69ixY8Y2Q0k6c+aM3G63AoGA0a+wsFCStGLFCjmdTgWDQVmtVknjIZ3NZkuYPwAASC5WSgEAAMxgo6Ojevr0qQ4fPqysrCzjc/r0aWNb3MGDBxWNRpWXl6f6+nrdvXv3t8ZqbW2V0+lUdna2JGnXrl169+6duru7JUnRaFSpqamy2Ww/vD4ajWr79u1GIPW7SkpKJrTduHFDpaWlysnJUVZWlvx+vwYHBxPGdjgck96zpqZG169f14cPH/Tp0yddu3ZNXq/3j+YJAAD+DCulAAAAZrCRkRFJUnNzs7Zu3ZpwLjU1VZK0adMmPX/+XHfu3NG9e/dUUVGhsrIy3bp166fHicViamtr09DQkNLS0hLaW1tb5XA4NGfOnCnvMd15k8mkeDye0PZ9XShJmjt3bsLxw4cPVVVVpUAgIKfTaazGamxs/Omx9+zZo8zMTHV0dCgjI0NjY2NyuVxTXgMAAP4uQikAAIAZbOnSpVq+fLmePXumqqqqSfvNmzdPlZWVqqyslMvlUnl5ud68eaOFCxcqPT1dsVhsynEikYjev3+vx48fG2GXJPX39+vQoUMaHh5WQUGBvnz5ovv37xvb9/5p48aNamtr09jY2A9XSy1evDjhLYOxWEz9/f3auXPnlHPr6enRqlWrdPLkSaNtYGBgwthdXV2T1ohKS0uTx+NRMBhURkaG3G73tEEWAAD4uwilAAAAZrhAIKD6+nqZzWaVl5fr48eP6uvr09u3b+Xz+dTU1KRly5apuLhYJpNJ7e3tysnJ0fz58yWN12Dq6upSaWmpMjMztWDBggljtLS0aPfu3UYdpm82bNighoYGXb16VUeOHJHH45HX69W5c+dUWFiogYEBvXr1ShUVFaqrq9P58+fldrt14sQJmc1mPXr0SFu2bFFeXp7sdrt8Pp/C4bByc3PV1NSk4eHhaZ/fYrFocHBQoVBIVqtV4XBYHR0dCX1OnTolh8Oh3Nxcud1uff78WZFIRMePHzf6VFdXa/369ZKkBw8e/OKvAAAA/m3UlAIAAJjhqqurdfnyZQWDQRUUFMhms+nKlStas2aNpPE30509e1YlJSWyWq168eKFIpGITKbxv3qNjY3q7OzUypUrVVxcPOH+L1++VDgc1v79+yecM5lM2rdvn1paWiRJFy9elMvlUm1trfLz81VTU6PR0VFJ0qJFi9Td3a2RkRHZbDZt3rxZzc3Nxqopr9crj8ejAwcOGEXGp1slJUl79+5VQ0OD6urqVFRUpJ6eHuOtfN/s2LFD7e3tun37toqKimS329Xb25vQx2KxaNu2bcrPz5+wFRIAACRfSvz7jf0AAADALBSPx2WxWFRbWyufz/dfTwcAgP89tu8BAABg1nv9+rVCoZCGhoYmrTsFAACSi1AKAAAAs96SJUuUnZ2tS5cu/bCmFgAASD5CKQAAAMx6VKwAAGDmodA5AAAAAAAAko5QCgAAAAAAAElHKAUAAAAAAICkI5QCAAAAAABA0hFKAQAAAAAAIOkIpQAAAAAAAJB0hFIAAAAAAABIOkIpAAAAAAAAJB2hFAAAAAAAAJLuK5gBzYdnME+xAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<Figure size 1200x600 with 1 Axes>,\n",
       " <Figure size 1200x600 with 1 Axes>,\n",
       " <Figure size 1200x600 with 1 Axes>,\n",
       " <Figure size 1200x600 with 1 Axes>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_all_datasets(results_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAz4AAAK9CAYAAADlmLkaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACRJklEQVR4nOzde3zO9f/H8ee12ckw5rAZszmUwxy/k2UkpwgNRY4xhHyRw0rNYeSc0shxqUQih+hISoukRISEnKPEEIZhY9fn98d+ru91tY1tjcs+Pe6323W72fvz/rw/7+tzXa5dr73en9fHYhiGIQAAAAAwMRdnTwAAAAAA7jQCHwAAAACmR+ADAAAAwPQIfAAAAACYHoEPAAAAANMj8AEAAABgegQ+AAAAAEyPwAcAAACA6RH4AAAAADA9Ah8A2XLw4EE1a9ZMPj4+slgs+uijj5w9pVzTsGFDNWzY0NnT+Ff6t537BQsWyGKx6LfffnPK8Xv06KECBQr8ozFeffVVlStXTq6urqpZs2buTCyb/v6++e2332SxWLRgwYJsj/XSSy/JYrHo7NmzuTdBAPcUAp88Ys6cObJYLAoLC3P2VO45wcHBeuyxxzLctmHDBlksFn3wwQd37PhXrlzRSy+9pA0bNtyxY9xLIiMjtXv3bk2cOFGLFi1S7dq1nT2lbNm7d69eeuklp33hzMycOXNy9GUNyMyd/Gz68ssv9cILL6hevXp65513NGnSpFw/hhksWbJE06dPd/Y0APy/fM6eALJm8eLFCg4O1tatW3Xo0CFVqFDB2VPC/7ty5YrGjh0rSab/i/XVq1e1efNmjRw5UgMHDnT2dHJk7969Gjt2rBo2bKjg4GCHbV9++aVzJqW0wKdYsWLq0aOH0+YAc7mTn01ff/21XFxc9Pbbb8vd3T1Xx/4ngoKCdPXqVbm5uTl7KpLSAp9ffvlFQ4YMcfZUAIiMT55w9OhRff/994qNjVXx4sW1ePHiuz4Hq9Wqa9eu3fXj4t5y5swZSVLhwoWdO5E7xN3d/Z76EvdPXbt2TVar1dnTgAmdPn1aXl5eufb/xTAMXb169R+PY7FY5OnpKVdX11yYFQCzIfDJAxYvXqwiRYqoVatWat++vUPgc/36dfn6+qpnz57p9rt48aI8PT31/PPP29qSk5M1ZswYVahQQR4eHgoMDNQLL7yg5ORkh30tFosGDhyoxYsXKyQkRB4eHlq7dq0kaerUqQoPD1fRokXl5eWl0NDQDJeSXb16VYMGDVKxYsVUsGBBtW7dWidOnJDFYtFLL73k0PfEiRPq1auX/Pz85OHhoZCQEM2fP/+fnLZbysrxUlJSNHr0aIWGhsrHx0fe3t566KGHtH79eluf3377TcWLF5ckjR07VhaLxeH53VxHf/z4cT322GMqUKCASpUqpdmzZ0uSdu/ercaNG8vb21tBQUFasmSJwxzOnTun559/XtWqVVOBAgVUqFAhtWjRQrt27XLod3NJ37JlyzRixAj5+/vL29tbrVu31u+//56lc7Jjxw61aNFChQoVUoECBdSkSRP98MMPtu0vvfSSgoKCJEnDhg2TxWJJlzHJaE7Lly/XxIkTVbp0aXl6eqpJkyY6dOhQluZk78KFCxoyZIgCAwPl4eGhChUqaMqUKem+2C9dulShoaEqWLCgChUqpGrVqun111+XlHZdxZNPPilJatSoke31urkU6O/XC9g/h7Fjx6pUqVIqWLCg2rdvr8TERCUnJ2vIkCEqUaKEChQooJ49e6b7v/TOO++ocePGKlGihDw8PFSlShXNnTvXoU9wcLD27Nmjb775xjYn+3kcOXJETz75pHx9fZU/f349+OCDWr16dYbne+nSpRo1apRKlSql/Pnz6+LFi7p+/brGjh2r++67T56enipatKjq16+vdevW3fKcZ/f9l9XXet68eSpfvry8vLxUp04dffvtt7ech72bn00rVqxQlSpV5OXlpbp162r37t2SpDfeeEMVKlSQp6enGjZsmG5J47fffqsnn3xSZcqUsX0GDh061OFL9+nTp1W8eHE1bNhQhmHY2g8dOiRvb2917Ngxy/OVpD179qhx48by8vJS6dKlNWHChEwD0s8//1wPPfSQvL29VbBgQbVq1Up79uxx6HPzc+XIkSNq3ry5vL29FRAQoHHjxtnme7vPpptOnDihtm3bqkCBAipevLief/55paam3vL5WCwWvfPOO0pKSrKNe3OZ5o0bNzR+/HiVL19eHh4eCg4O1ogRI9L9v7i5RPmLL75Q7dq15eXlpTfeeOOWx83K+yaja3x+/vln9ejRQ+XKlZOnp6f8/f3Vq1cv/fXXXxke5+zZs+rQoYMKFSqkokWLavDgwRn+4e+9995TaGiovLy85Ovrq06dOjl83jZs2FCrV6/WsWPHbOfJ/jMzq7+P161bp/r166tw4cIqUKCAKlasqBEjRtzyXAHIhIF7XqVKlYynn37aMAzD2LhxoyHJ2Lp1q217r169jMKFCxvJyckO+y1cuNCQZPz444+GYRhGamqq0axZMyN//vzGkCFDjDfeeMMYOHCgkS9fPqNNmzYO+0oyKleubBQvXtwYO3asMXv2bGPHjh2GYRhG6dKljf79+xuzZs0yYmNjjTp16hiSjM8++8xhjA4dOhiSjG7duhmzZ882OnToYNSoUcOQZIwZM8bW79SpU0bp0qWNwMBAY9y4ccbcuXON1q1bG5KMadOm3fb8BAUFGc2aNTPOnDmT7vHRRx8ZkowVK1Zk+3hnzpwxSpYsaURFRRlz5841XnnlFaNixYqGm5ub7VxcvnzZmDt3riHJePzxx41FixYZixYtMnbt2mUYhmFERkYanp6eRpUqVYx+/foZs2fPNsLDww1JxjvvvGMEBAQYw4YNM2bOnGmEhIQYrq6uxpEjR2xz+PHHH43y5csb0dHRxhtvvGGMGzfOKFWqlOHj42OcOHHC1m/9+vWGJKNatWpG9erVjdjYWCM6Otrw9PQ07r//fuPKlSu3PIe//PKL4e3tbZQsWdIYP3688fLLLxtly5Y1PDw8jB9++MEwDMPYtWuXMW3aNEOS0blzZ2PRokXGhx9+mOmYN+dUq1YtIzQ01Jg2bZrx0ksvGfnz5zfq1Klz29fVXlJSklG9enWjaNGixogRI4y4uDije/fuhsViMQYPHmzr9+WXXxqSjCZNmhizZ882Zs+ebQwcONB48sknDcMwjMOHDxuDBg0yJBkjRoywvV6nTp0yDMMwHn74YePhhx9O9xxq1qxp1K1b15gxY4YxaNAgw2KxGJ06dTK6dOlitGjRwpg9e7bRrVs3Q5IxduxYh7k/8MADRo8ePYxp06YZM2fONJo1a2ZIMmbNmmXr8+GHHxqlS5c2KlWqZJvTl19+aRhG2vvVz8/PKFiwoDFy5EgjNjbWqFGjhuHi4mKsWrUq3VyrVKli1KxZ04iNjTUmT55sJCUlGSNGjDAsFovRp08f48033zRee+01o3PnzsbLL798y/Oe3fdfVl7rt956y5BkhIeHGzNmzDCGDBliFC5c2ChXrpzDuc+MJKN69epGYGCg8fLLLxsvv/yy4ePjY5QpU8aYNWuWUaVKFeO1114zRo0aZbi7uxuNGjVy2P/ZZ581WrZsaUyaNMl44403jKefftpwdXU12rdv79BvxYoVhiTj9ddfNwwj7fOzXr16hp+fn3H27NnbzvOmkydPGsWLFzeKFClivPTSS8arr75q3HfffUb16tUNScbRo0dtfd99913DYrEYjz76qDFz5kxjypQpRnBwsFG4cGGHfjc/V+677z6jW7duxqxZs4zHHnvMkGTExMQYhpH1z6aQkBCjV69exty5c4127doZkow5c+bc8jktWrTIeOihhwwPDw/buIcPH7aNK8lo3769MXv2bKN79+6GJKNt27YOYwQFBRkVKlQwihQpYkRHRxtxcXHG+vXrMz1mVt83R48etX2+3jR16lTjoYceMsaNG2fMmzfPGDx4sOHl5WXUqVPHsFqttn5jxoyxfY5GREQYs2bNMp566inb7zF7EyZMMCwWi9GxY0djzpw5xtixY41ixYoZwcHBxvnz5w3DSPs8qlmzplGsWDHbebr5mZnV38e//PKL4e7ubtSuXdt4/fXXjbi4OOP55583GjRocMvXCEDGCHzucdu2bTMkGevWrTMMwzCsVqtRunRphy97X3zxhSHJ+PTTTx32bdmypVGuXDnbz4sWLTJcXFyMb7/91qFfXFycIcn47rvvbG2SDBcXF2PPnj3p5vT3L9EpKSlG1apVjcaNG9vatm/fbkgyhgwZ4tC3R48e6QKfp59+2ihZsmS6LxOdOnUyfHx8bvulPSgoyJB0y4d94JPV4924cSNdMHn+/HnDz8/P6NWrl63tzJkz6Z7TTTe/BEyaNMlhDC8vL8NisRhLly61tf/666/pxrl27ZqRmprqMObRo0cNDw8PY9y4cba2m188S5UqZVy8eNHWvnz5cocvb5lp27at4e7ubvvyYhiG8eeffxoFCxZ0+AV780vFq6++esvx7OdUuXJlh/P4+uuvG5KM3bt333aMm8aPH294e3sbBw4ccGiPjo42XF1djePHjxuGYRiDBw82ChUqZNy4cSPTsW5+oc3oS1ZmgU/VqlWNlJQUW3vnzp0Ni8VitGjRwmH/unXrGkFBQQ5tGb1/mzdv7vB/0zAMIyQkJMMv/kOGDDEkOfy/vXTpklG2bFkjODjY9v64Oddy5cqlO2aNGjWMVq1apRv7drL7/rvda52SkmKUKFHCqFmzpkO/efPmGZKyHPh4eHg4BAJvvPGGIcnw9/d3eP8PHz48XXCR0esxefJkw2KxGMeOHXNo79y5s5E/f37jwIEDxquvvmpIMj766KPbztHezddvy5YttrbTp08bPj4+DnO7dOmSUbhwYaNPnz4O+586dcrw8fFxaL/5ufLss8/a2qxWq9GqVSvD3d3dOHPmjGEYWftssn8dDcOwBa+3ExkZaXh7ezu07dy505Bk9O7d26H9+eefNyQZX3/9ta3t5uf22rVrb3us7LxvMgp8MnrN33//fUOSsXHjRlvbzcCndevWDn379+9vSLIFjb/99pvh6upqTJw40aHf7t27jXz58jm0t2rVKt1ngmFk/ffxzT823XxNAfwzLHW7xy1evFh+fn5q1KiRpLQlBh07dtTSpUttyxEaN26sYsWKadmyZbb9zp8/r3Xr1jksyVixYoUqV66sSpUq6ezZs7ZH48aNJclhCZckPfzww6pSpUq6OXl5eTkcJzExUQ899JB++uknW/vNZXH9+/d32PfZZ591+NkwDK1cuVIREREyDMNhXs2bN1diYqLDuJkJCwvTunXr0j2mTp2a4+O5urra1q9brVadO3dON27cUO3atbM0J3u9e/e2/btw4cKqWLGivL291aFDB1t7xYoVVbhwYR05csTW5uHhIReXtP+mqamp+uuvv2xLHTKaQ/fu3VWwYEHbz+3bt1fJkiW1Zs2aTOeWmpqqL7/8Um3btlW5cuVs7SVLllSXLl20adMmXbx4MVvP117Pnj0drgN46KGHJMnhed7OihUr9NBDD6lIkSIOr1nTpk2VmpqqjRs3Sko7t0lJSbddwpVd3bt3d7hYOiwsTIZhqFevXg79wsLC9Pvvv+vGjRu2Nvv/L4mJiTp79qwefvhhHTlyRImJibc99po1a1SnTh3Vr1/f1lagQAH17dtXv/32m/bu3evQPzIy0uGYUtp52bNnjw4ePJi1J/z/svv+u91rvW3bNp0+fVr9+vVz6NejRw/5+PhkeV5NmjRxWDJ0s9plu3btHN7/N9vt32v25yYpKUlnz55VeHi4DMPQjh07HI4za9Ys+fj4qH379oqJiVG3bt3Upk2bLM9TSnv9HnzwQdWpU8fWVrx4cXXt2tWh37p163ThwgV17tzZ4T3u6uqqsLCwdJ/PkhwKjNxcApiSkqKvvvoqy/Pr16+fw88PPfRQtv5v2rv5ORMVFeXQ/txzz0lSuuWZZcuWVfPmzW877j9939i/5teuXdPZs2f14IMPSlKG7+MBAwY4/Hzz99bN57dq1SpZrVZ16NDB4bXy9/fXfffdl+Fr9XdZ/X1883rKjz/+mOv1gFxAVbd7WGpqqpYuXapGjRrp6NGjtvawsDC99tprio+PV7NmzZQvXz61a9dOS5YsUXJysjw8PLRq1Spdv37dIfA5ePCg9u3bZ1v3/XenT592+Lls2bIZ9vvss880YcIE7dy502EtssVisf372LFjcnFxSTfG36vRnTlzRhcuXNC8efM0b968LM0rI8WKFVPTpk3TtefL5/gWz+7xFi5cqNdee02//vqrrl+/bmvP7NxkxNPTM9059/HxUenSpR3O2c328+fP2362Wq16/fXXNWfOHB09etRh7X3RokXTHeu+++5z+NlisahChQq3LN185swZXblyRRUrVky3rXLlyrJarfr9998VEhJyy+eZmTJlyjj8XKRIEUlyeJ63c/DgQf3888+3fe/2799fy5cvV4sWLVSqVCk1a9ZMHTp00KOPPpqjud/09+dw88tWYGBgunar1arExETb6/Pdd99pzJgx2rx5s65cueLQPzEx8bZf3I4dO5ZhGfvKlSvbtletWtXWntF7c9y4cWrTpo3uv/9+Va1aVY8++qi6deum6tWr3/LY2X3/3e61PnbsmKT071M3NzeHoPt2svN62B9fko4fP67Ro0frk08+Sfce/Hsg6uvrqxkzZujJJ5+Un5+fZsyYkeU53pTZ6/f3/283g9KbX3z/rlChQg4/u7i4pDtn999/vyRluVR7Rp9NRYoUydb/TXs3P/f//jnv7++vwoUL217/m7L6OfpP3zfnzp3T2LFjtXTp0nS/TzL648Pfj1O+fHm5uLjYzuvBgwdlGEa6fvbzup2s/j7u2LGj3nrrLfXu3VvR0dFq0qSJnnjiCbVv3972RwkAWUfgcw/7+uuvdfLkSS1dulRLly5Nt33x4sVq1qyZJKlTp05644039Pnnn6tt27Zavny5KlWqpBo1atj6W61WVatWTbGxsRke7+9fGv7+V2Mp7cLg1q1bq0GDBpozZ45KliwpNzc3vfPOO+kuzM+Km3/BeuqppxQZGZlhn9t9ObtTx3vvvffUo0cPtW3bVsOGDVOJEiXk6uqqyZMn6/Dhw1k+ZmbVhTJrN+wupp40aZJiYmLUq1cvjR8/Xr6+vnJxcdGQIUPyzF//svI8b8dqteqRRx7RCy+8kOH2m1/4SpQooZ07d+qLL77Q559/rs8//1zvvPOOunfvroULF2Z/8v8vp6/h4cOH1aRJE1WqVEmxsbEKDAyUu7u71qxZo2nTpt2R1zCj/7cNGjTQ4cOH9fHHH+vLL7/UW2+9pWnTpikuLs4hG/l32X3/5cZrnRU5fT1SU1P1yCOP6Ny5c3rxxRdVqVIleXt768SJE+rRo0eGz+mLL76QlBY8/fHHH3esouHNYy9atEj+/v7ptv/9jzi54U5VPvv7H3Qyk9F79U7o0KGDvv/+ew0bNkw1a9ZUgQIFZLVa9eijj2bp/+Dfn4/VapXFYtHnn3+e4TnMyo1hs/r72MvLSxs3btT69eu1evVqrV27VsuWLVPjxo315ZdfUr0OyCYCn3vY4sWLVaJECVsFMHurVq3Shx9+qLi4OHl5ealBgwYqWbKkli1bpvr16+vrr7/WyJEjHfYpX768du3apSZNmmT5F9PfrVy5Up6envriiy/k4eFha3/nnXcc+gUFBclqtero0aMOfxX7e4Wn4sWLq2DBgkpNTc0wY5PbsnO8Dz74QOXKldOqVasczteYMWMc+uX0XGbFBx98oEaNGuntt992aL9w4YKKFSuWrv/flzIZhqFDhw7dMngsXry48ufPr/3796fb9uuvv8rFxSVdUHy3lS9fXpcvX87Se8Td3V0RERGKiIiQ1WpV//799cYbbygmJkYVKlS4o6/X33366adKTk7WJ5984pClyGgpTGbzCgoKyvS1ubk9K25Wf+zZs6cuX76sBg0a6KWXXrpl4JPd99/t3JzrwYMHHTIb169f19GjRx3+UHMn7N69WwcOHNDChQvVvXt3W3tmSyPXrl2rt956Sy+88IIWL16syMhIbdmyJVtBSFBQUIZLDP/+mpYvX15SWvCelfe51WrVkSNHbEG/JB04cECSbMsA7+Z7Xfrf5/7BgwdtGUlJSkhI0IULF7L8Xs1oXCln75vz588rPj5eY8eO1ejRo23tt1r2efDgQYds1KFDh2S1Wm3ntXz58jIMQ2XLlnU4/xnJ7DXIzu9jFxcXNWnSRE2aNFFsbKwmTZqkkSNHav369Xfl9yZgJuRJ71FXr17VqlWr9Nhjj6l9+/bpHgMHDtSlS5f0ySefSEr7YGzfvr0+/fRTLVq0SDdu3EhXcrVDhw46ceKE3nzzzQyPl5SUdNt5ubq6ymKxOCx5+e233/TRRx859Lu5bnvOnDkO7TNnzkw3Xrt27bRy5Ur98ssv6Y53874xuSU7x7v5lzT7v1Zv2bJFmzdvdtgnf/78ktK+DOY2V1fXdH8tX7FihU6cOJFh/3fffVeXLl2y/fzBBx/o5MmTatGixS2P0axZM3388ccOS2QSEhK0ZMkS1a9fP90ym7utQ4cO2rx5s+2v7/YuXLhgu6bm7+VpXVxcbEHfzWWZ3t7etv3utIzeQ4mJien+UHBzXhnNqWXLltq6davD+y4pKUnz5s1TcHBwhtfh/d3fz0uBAgVUoUKFdGVzM5p/dt5/t1O7dm0VL15ccXFxSklJsbUvWLDAaa+HYRi2cuf2Lly4oN69e6tOnTqaNGmS3nrrLf3000+aNGlSto7ZsmVL/fDDD9q6daut7cyZM+nux9a8eXMVKlRIkyZNclhWa7/P382aNcvhecyaNUtubm5q0qSJpDv72ZSRli1bSpKmT5/u0H4zq9GqVascjftP3jcZveYZzdHe3//YePP31s3P0SeeeEKurq4aO3ZsunENw3D4/+bt7Z3hcrqs/j4+d+5cuu01a9aUpNv+/wWQHhmfe9Qnn3yiS5cuqXXr1hluf/DBB203M70Z4HTs2FEzZ87UmDFjVK1aNYe/uElSt27dtHz5cvXr10/r169XvXr1lJqaql9//VXLly+33U/hVlq1aqXY2Fg9+uij6tKli06fPq3Zs2erQoUK+vnnn239QkND1a5dO02fPl1//fWXHnzwQX3zzTe2v0ja/4Xr5Zdf1vr16xUWFqY+ffqoSpUqOnfunH766Sd99dVXGX7w/xNZPd5jjz2mVatW6fHHH1erVq109OhRxcXFqUqVKrp8+bJtPC8vL1WpUkXLli3T/fffL19fX1WtWtXhuouceuyxxzRu3Dj17NlT4eHh2r17txYvXpzpunZfX1/Vr19fPXv2VEJCgqZPn64KFSqoT58+tzzOhAkTbPeK6N+/v/Lly6c33nhDycnJeuWVV/7x8/inhg0bpk8++USPPfaYevToodDQUCUlJWn37t364IMP9Ntvv6lYsWLq3bu3zp07p8aNG6t06dI6duyYZs6cqZo1a9r+P9SsWVOurq6aMmWKEhMT5eHhYbvPTm5r1qyZLQP1zDPP6PLly3rzzTdVokQJnTx50qFvaGio5s6dqwkTJqhChQoqUaKEGjdurOjoaL3//vtq0aKFBg0aJF9fXy1cuFBHjx7VypUrs7TOv0qVKmrYsKFCQ0Pl6+urbdu26YMPPnC4OD4j2X3/3Y6bm5smTJigZ555Ro0bN1bHjh119OhRvfPOOzkeMzsqVaqk8uXL6/nnn9eJEydUqFAhrVy5MsNrWgYPHqy//vpLX331lVxdXfXoo4+qd+/emjBhgtq0aZPl7NQLL7ygRYsW6dFHH9XgwYPl7e2tefPmKSgoyOEzs1ChQpo7d666deum//znP+rUqZOKFy+u48ePa/Xq1apXr55DoOPp6am1a9cqMjJSYWFh+vzzz7V69WqNGDHCdt3InfxsykiNGjUUGRmpefPm6cKFC3r44Ye1detWLVy4UG3btrUV6cmuf/K+KVSokBo0aKBXXnlF169fV6lSpfTll186XDf7d0ePHlXr1q316KOPavPmzXrvvffUpUsX22tevnx5TZgwQcOHD9dvv/2mtm3bqmDBgjp69Kg+/PBD9e3b13b/vNDQUC1btkxRUVF64IEHVKBAAUVERGT59/G4ceO0ceNGtWrVSkFBQTp9+rTmzJmj0qVLOxQ8AZBFd6+AHLIjIiLC8PT0NJKSkjLt06NHD8PNzc1WltlqtRqBgYGGJGPChAkZ7pOSkmJMmTLFCAkJMTw8PIwiRYoYoaGhxtixY43ExERbP0nGgAEDMhzj7bffNu677z7Dw8PDqFSpkvHOO+/YyoDaS0pKMgYMGGD4+voaBQoUMNq2bWvs37/fkJTu/iEJCQnGgAEDjMDAQMPNzc3w9/c3mjRpYsybN++25yooKCjTUr03y+zal7PO6vGsVqsxadIkIygoyPDw8DBq1aplfPbZZ0ZkZGS68qTff/+9ERoaari7uzuUj82o5KthpJVNDgkJue1zuXbtmvHcc88ZJUuWNLy8vIx69eoZmzdvzrTs8vvvv28MHz7cKFGihOHl5WW0atUqXYnezPz0009G8+bNjQIFChj58+c3GjVqZHz//fcOfXJSzvrv5z6jcrNZcenSJWP48OFGhQoVDHd3d6NYsWJGeHi4MXXqVFup6Q8++MBo1qyZUaJECcPd3d0oU6aM8cwzzxgnT550GOvNN980ypUrZ7i6ujqUts7svP79ObzzzjuG7O6RddPN/wf2pWc/+eQTo3r16oanp6cRHBxsTJkyxZg/f366MsunTp0yWrVqZRQsWDBdid7Dhw8b7du3NwoXLmx4enoaderUSXffrMzmahhp9xypU6eOUbhwYcPLy8uoVKmSMXHiRIcS3RnJ7vsvq6/1nDlzbPeJql27trFx48Z0Y2Ymo8+mzN6XGc1r7969RtOmTY0CBQoYxYoVM/r06WPs2rXLYZ4ff/yxIcl47bXXHMa7ePGiERQUZNSoUeO2587ezz//bDz88MOGp6enUapUKWP8+PHG22+/ne49cHPOzZs3N3x8fAxPT0+jfPnyRo8ePYxt27bZ+tz8XDl8+LDtXjB+fn7GmDFj0pUfz+5nU0af5RnJbP/r168bY8eONcqWLWu4ubkZgYGBxvDhw41r16459LvV53ZmsvK+yeg998cffxiPP/64UbhwYcPHx8d48sknjT///DNdqe+bz33v3r1G+/btjYIFCxpFihQxBg4caFy9ejXdfFauXGnUr1/f8Pb2Nry9vY1KlSoZAwYMMPbv32/rc/nyZaNLly5G4cKFDUkOvzuy8vs4Pj7eaNOmjREQEGC4u7sbAQEBRufOndOV9geQNRbDyOWrToFb2Llzp2rVqqX33nsvXTlX5NyGDRvUqFEjrVixQu3bt3f2dADcQT169NAHH3zgkHkGANwe1/jgjrl69Wq6tunTp8vFxUUNGjRwwowAAADwb8U1PrhjXnnlFW3fvl2NGjVSvnz5bOWF+/bt6/QqYbg3XL169bY38fT19XW4aSFwL+C9CwB5D4EP7pjw8HCtW7dO48eP1+XLl1WmTBm99NJL6cps499r2bJl6tmz5y37rF+/Xg0bNrw7EwKyiPcuAOQ9XOMDwGlOnjypPXv23LJPaGioihQpcpdmBGQN710AyHsIfAAAAACYHsUNAAAAAJgegQ8AAAAA0zNlcYOOm/s5ewpAnrTrZICzpwDkSXvD33P2FIA8x8X/gLOnkCnrqfuddux7+bzkdWR8AAAAAJieKTM+AAAAQE5ZZXXasclK3DmcWwAAAACmR8YHAAAAsJNqOC/jw5fzO4eMDwAAAADTI/ABAAAAYHpk0wAAAAA7VhnOngLuADI+AAAAAEyPjA8AAABgx5nlrHHnkPEBAAAAYHoEPgAAAABMj6VuAAAAgJ1Ug+IGZkTGBwAAAIDpkfEBAAAA7FDO2pzI+AAAAAAwPTI+AAAAgJ1UMj6mRMYHAAAAgOkR+AAAAAAwPZa6AQAAAHYobmBOZHwAAAAAmB4ZHwAAAMAONzA1JzI+AAAAAEyPwAcAAACA6bHUDQAAALBjdfYEcEeQ8QEAAABgemR8AAAAADuplLM2JTI+AAAAAEyPjA8AAABgJ5WEjymR8QEAAABgegQ+AAAAAEyPpW4AAACAHcpZmxMZHwAAAACmR+ADAAAA2EmVxWmPnJg9e7aCg4Pl6empsLAwbd269Zb9p0+frooVK8rLy0uBgYEaOnSorl27Ztt+6dIlDRkyREFBQfLy8lJ4eLh+/PFHhzEMw9Do0aNVsmRJeXl5qWnTpjp48KBDn3Pnzqlr164qVKiQChcurKefflqXL1/O0XPMDQQ+AAAAQB61bNkyRUVFacyYMfrpp59Uo0YNNW/eXKdPn86w/5IlSxQdHa0xY8Zo3759evvtt7Vs2TKNGDHC1qd3795at26dFi1apN27d6tZs2Zq2rSpTpw4YevzyiuvaMaMGYqLi9OWLVvk7e2t5s2bOwRQXbt21Z49e7Ru3Tp99tln2rhxo/r27XvnTsZtWAzDMF3Bvo6b+zl7CkCetOtkgLOnAORJe8Pfc/YUgDzHxf+As6eQqYN/OO/34X2l/8xW/7CwMD3wwAOaNWuWJMlqtSowMFDPPvusoqOj0/UfOHCg9u3bp/j4eFvbc889py1btmjTpk26evWqChYsqI8//litWrWy9QkNDVWLFi00YcIEGYahgIAAPffcc3r++eclSYmJifLz89OCBQvUqVMn7du3T1WqVNGPP/6o2rVrS5LWrl2rli1b6o8//lBAwN0/x2R8AAAAADtWw3mP5ORkXbx40eGRnJyc4TxTUlK0fft2NW3a1Nbm4uKipk2bavPmzRnuEx4eru3bt9uWwx05ckRr1qxRy5YtJUk3btxQamqqPD09Hfbz8vLSpk2bJElHjx7VqVOnHI7r4+OjsLAw23E3b96swoUL24IeSWratKlcXFy0ZcuW7L4kuYLABwAAALhHTJ48WT4+Pg6PyZMnZ9j37NmzSk1NlZ+fn0O7n5+fTp06leE+Xbp00bhx41S/fn25ubmpfPnyatiwoW2pW8GCBVW3bl2NHz9ef/75p1JTU/Xee+9p8+bNOnnypCTZxr7VcU+dOqUSJUo4bM+XL598fX0zndudRuADAAAA2HFmcYPhw4crMTHR4TF8+PBce24bNmzQpEmTNGfOHP30009atWqVVq9erfHjx9v6LFq0SIZhqFSpUvLw8NCMGTPUuXNnubjk7dCB+/gAAAAA9wgPDw95eHhkqW+xYsXk6uqqhIQEh/aEhAT5+/tnuE9MTIy6deum3r17S5KqVaumpKQk9e3bVyNHjpSLi4vKly+vb775RklJSbp48aJKliypjh07qly5cpJkGzshIUElS5Z0OG7NmjVtff5eYOHGjRs6d+5cpnO70/J22AYAAADksrxSztrd3V2hoaEOhQqsVqvi4+NVt27dDPe5cuVKusyNq6urpLQS1fa8vb1VsmRJnT9/Xl988YXatGkjSSpbtqz8/f0djnvx4kVt2bLFdty6devqwoUL2r59u63P119/LavVqrCwsGw9z9xCxgcAAADIo6KiohQZGanatWurTp06mj59upKSktSzZ09JUvfu3VWqVCnbdUIRERGKjY1VrVq1FBYWpkOHDikmJkYRERG2AOiLL76QYRiqWLGiDh06pGHDhqlSpUq2MS0Wi4YMGaIJEybovvvuU9myZRUTE6OAgAC1bdtWklS5cmU9+uij6tOnj+Li4nT9+nUNHDhQnTp1ckpFN4nABwAAAMizOnbsqDNnzmj06NE6deqUatasqbVr19oKDxw/ftwhwzNq1ChZLBaNGjVKJ06cUPHixRUREaGJEyfa+ty8ruiPP/6Qr6+v2rVrp4kTJ8rNzc3W54UXXrAtkbtw4YLq16+vtWvXOlSDW7x4sQYOHKgmTZrIxcVF7dq104wZM+7CWckY9/EBYMN9fICc4T4+QPbdy/fx2XU80GnHrlHmd6cd2+y4xgcAAACA6bHUDQAAALCT3SIDyBvI+AAAAAAwPQIfAAAAAKbHUjcAAADATiq5AVPiVQUAAABgemR8AAAAADtWg+IGZkTGBwAAAIDpEfgAAAAAMD2WugEAAAB2uI+POZHxAQAAAGB6ZHwAAAAAO6kGuQEz4lUFAAAAYHpkfAAAAAA7VnIDpsSrCgAAAMD0CHwAAAAAmB5L3QAAAAA7lLM2JzI+AAAAAEyPjA8AAABgh3LW5sSrCgAAAMD0CHwAAAAAmB5L3QAAAAA7VoobmBIZHwAAAACmR8YHAAAAsJNKbsCUeFUBAAAAmB4ZHwAAAMAO5azNiVcVAAAAgOkR+AAAAAAwPZa6AQAAAHas5AZMiVcVAAAAgOmR8QEAAADspBrcwNSMyPgAAAAAMD0CHwAAAACmx1I3AAAAwE4quQFT4lUFAAAAYHpkfAAAAAA7VoPcgBnxqgIAAAAwPTI+AAAAgB2u8TEnXlUAAAAApkfgAwAAAMD0WOoGAAAA2Ek1LM6eAu4AMj4AAAAATI+MDwAAAGDHSm7AlHhVAQAAAJgegQ8AAAAA02OpGwAAAGAn1SA3YEa8qgAAAABMj4wPAAAAYMcqylmbERkfAAAAAKZ3T2R8Tp06pS1btujUqVOSJH9/f4WFhcnf39/JMwMAAMC/Ddf4mJNTA5+kpCQ988wzWrp0qSwWi3x9fSVJ586dk2EY6ty5s9544w3lz5/fmdMEAAAAkMc5NZwdPHiwtm7dqtWrV+vatWtKSEhQQkKCrl27pjVr1mjr1q0aPHiwM6cIAAAAwAScGvisXLlSCxYsUPPmzeXq6mprd3V1VbNmzTR//nx98MEHTpwhAAAA/m1S5eK0B+4cpy51s1qtcnd3z3S7u7u7rFbrXZwRbufMV3/o9Oe/60ZiirzKeKvUU/fLu1yhTPuf/uJ3/bX+hFL+Sla+gm4qXLu4SrYvJxf3tEDXsBo69eFRnd+coOuJKXIr7C7f+iXl1zpIFktaRZXriSn6c/lhXdpzTqlXbqjA/YVV+qn75OHPEkjkDV3K1dbT94WrmGcB/ZqYoAm7Ptfu839m2r97+TB1Lheqkvl9dD75ir44sU+xe+KVYk2VJLnIooFVHlbrwGoq5llAp69e0ofHd2nur9/axijq4a3nqzZRvRLlVdDNU9v+OqYJO9fqWNK5O/58gdyy+ENp/lLp7DmpUnlp5GCpeuXM+y9cIS39WDqZIBXxkZo1lKL6SB4eaduTrkivvy199a107rxU+T5pxLNSNbsxDUOaOV9a8Zl06bJUq5o0JkoKLn1HnyqAu8CpYeVjjz2mvn37aseOHem27dixQ//9738VERHhhJkhI+e3JOjPpYfk3zZYFcfWlldgAR2ZukvXL6Zk3H9zgk6uOCL/NmVVaVIdBfaqpPNbT+vkyiO2PqdXH9PZ9X+q1FP3qdKkOgroUF6nPz+us1+dkCQZhqGjM3Yr5cxVlRtUTRXHPiD3Yp469OpOpSan3pXnDfwTLUpVUXS1Zpr96zd64ut52p94Sm/V6ypfj4wD98dKV9VzVZto9r6NarVujkb99Klalg5RVEgTW58+Feupc9naGr9rrVqtm6PXfolX7/vC1a18HVuf2Q92VGnvIur/wzI98fU8/XklUfMfekperm53/DkDuWHN19KU2dKASGnlm1LF8lKf56W/zmfc/7N1Uuy8tP6r35UmvCh9/rU07c3/9Rn1ivT9NmnKSOnjd6R6D0i9npMSzvyvz1vvS++tkl56TloWJ+X3TDtucvKdfb64t1gNi9MeuHOcGvjMmjVLfn5+Cg0NVdGiRVW5cmVVrlxZRYsWVe3atVWiRAnNmjXLmVOEnTNf/K6iDweo6EMl5VnKW6UjK8rF3UXnNp7MsH/SoUR531dIRer6yaO4lwpV9VWRMD9dOXLJrs9F+dQqJp+axeRR3EuFHyihgiG+unLkoiQpOeGqrhy+qNKRFZW/XCF5lsyv0t3vl5Fi1YUfEu7K8wb+iR731dWK337SqmO7dPjSWY3ZsVrXUq+rXVCtDPvXKlpaP/31uz774xeduJKo704f0eo/flG1IgH/6+NbWvEn9+ubUwd14kqivvhzn747fcTWJ7iAr2oWLa2xO9bol/N/6ujlv/TSjtXydHFTq8Cqd+V5A//UwuXSk49JT7SUKgSnBSKentKqNRn337FH+k9V6bFHpFIl04KaVk2k3b+mbb+WLK3bKD3fT3qghhRUWhrYUypTSnr/47Q+hiG9u0Lq101qUj8t2Hp5hHT6L+mrTXflaQO4g5wa+BQpUkSff/659uzZo6lTp6p79+7q3r27pk6dqj179mjNmjUqXLiwM6eI/2e9YdWV3y6rQJUitjaLi0UFQnyVdPhihvt4V/DRld8uK+lmEHP6qi7+/JcKVfe161NIl/ae17VTVyRJV49fVtLBCypYLa2PcT1tqaOL2//eqhYXiyxuLrp8IDF3nySQy9wsLgopXFLfnz5qazMkbT59VDV9M143s+OvPxRSuKQtiCmdv7Aa+FXQxoRD/+tz7g/VLV5WwQXS/p9U9PHTf4oG2vq4u6StYk623nA4bor1hkKLBubmUwTuiJTr0p4DUt3Q/7W5uKT9vHNPxvvUCknb5+d9aT///qe08QepQVjaz6mpUmqqRR5/W2Hv6SH9tDvt33+clM6eszgct2CBtOV1uzI5LoC84564j8/NTE9OJCcnK/lv+efUlFS5urtmsgdyIvXSdclqyM3H8TeGWyE3JZ9MynCfInX9dOPydR2a+JMMSUo1VLRRgPwigm19SrQKUurVVP06fIvkYpGshkq2Kyff8LR7OHmWzC+3oh46ueKwSveoKBcPV5354nddP5esG4msO8C9rYhHfuVzcdFfyY7/R84mJ6lswWIZ7vPZH7+oiEd+LX64pyyS3Fxc9f6RbXpj///+3Dxv/yZ55/PQmkcGKNWwytXioul7vtZnv/8iSTpy6axOXLmgqJDGGrNjta7eSFHkfQ+qZH4fFfcseMeeL5BbLiSmBSlFixgO7UWLSEePZ7zPY49I5xOlpwamZW5upFrUsbWhZ7qlbffOL9UMMTT3Xal8UNpYq+PTAqkypdL6nP3/S+CK+jqOXayIdIbL4/5VKDJgTk4PfFJSUvTRRx9p8+bNDjcwDQ8PV5s2bW5Z/ECSJk+erLFjxzq0VekVqqq9a9+xOSNrLu07r4RPj6l09/uVv1whJZ++qhOLD+rUx7/Jv02wJOnC1tM6/0OCgp6pIs9S3rp6/LJOLDloK3Jgyeeiss9W0/G3f9UvAzZJLhYVrFJEBav7pv0JGzCZOsWC1LdifY3buUY/nzuhMgWKaET1R/XfSg/Zihe0KB2iiMCqev7HVTp08Ywq+fhpRPXmOn3tkj46/rNuGFYN+mGFJvwnQlsjXtANq1WbzxzRN6cOyiLWj8Octu6Q5i2WYoZKNSpLx04YmjxTmrNQ6h+Z1mfKSGnkFOnhdha5uhqqcl/acrg9+507dwB3h1MDn0OHDql58+b6888/FRYWJj8/P0lphQ3i4uJUunRpff7556pQoUKmYwwfPlxRUVEObb12PHdH5/1v5FrQTXKx6HqiYyGD6xevK5+PR4b7nPrwqIqE+6now2lLdrwCC8ianKrfF+yXX0SQLC4W/bn8sEq0LKMiD/rZ+qT8dU0Jnx2Xb/2SkqT8wQVVafwDSr1yQ8YNq/IVcteBcduUPzjzanLAveB88hXdsFpV1MPbob2Yh7fOXruc4T6DqjTSJ8d/1ge/pRV9OXDxtLxc3TWu1mOK+/VbGZKGVW2qNw98pzV/7LH1CchfWH0r1tdHx3+WJO25cFKPfz1PBfJ5yM3FVedTrmhZw6f1yy2qyQH3isI+kqurka6QwV/npWK+Ge8z422pdbO064Ik6f7y0tVr0pipadfsuLikZXYWzZCuXDV0+YpUoqg09CWp9P9fQndz7L/OpW276ex5qXLmX0VgQlaDjI8ZOfVV/e9//6tq1aopISFBGzZs0LJly7Rs2TJt2LBBCQkJCgkJ0YABA245hoeHhwoVKuTwYJlb7nPJ56L8wQV0ee//fgsZVkOX956Xd/mMAxBrcqosLo5/Xf77z5n2MdKnc1zz51O+Qu5KPnVFV45eUqH/ZLxUCLhXXDes2nPhpOqWKGtrs0h6sERZ7Tz3R4b7eLnmk/Vv73+rYf3/fS3/38ctwz4uGWRzLt9I1vmUKwry9lXVIiX19Un+tI17n7ubFHK/9MP2/7VZrdIPP0k1QzLe52qyZPnbfwHX//+W8/dfKfm90gKbxEvSdz9KTeqltZcuKRXzNfTDT//rezkp7bqhGpkcF0De4dSMz3fffaetW7eqUKH0X5wLFSqk8ePHKywszAkzQ0aKNw/U8Td/Vf6yBZW/XCGd+fIPWZNT5ftQWmbm2Ly9civioYAny0uSCtUspjNf/C6vMgWUv3whpSRc1clVR+VTs5gt2ClUs5gSPj0mN18P21K301/8rqL/P6aUthzOtaCb3It66tofl/XH4kPy+U9xFaqayZ/9gHvIgoOb9XLttvrl/J/6+fyfiqwQJi9XN606tlOS9HJoG52+dkmxe76WJK0/dVA9KjyofYmntOvcCQUV8NWgKo20/tQBWf9/fef6UwfUr9JDOnn1og5dPK3Khf3V474HtfK3nbbjNi9VWeeTr+jPK4m636eERlZ/VPF/7td3p4/8fYrAPSmygzR8slS1klStkvTuB9LVq9LjLdK2vzhR8isuRfVN+7lRuLRgedq9eWpUkY79Ic2YLzUMl27eI33T1rQgqGyZtO1T49L+/XjLtO0Wi9T9SSnu3bSqb6X908YoUVRqWv/unwM4TyrLgk3JqYFP4cKF9dtvv6lq1YzLq/72229UdbuHFAnz041L13Xyw6P/fwPTAir3XHVbwYOUvxz/3ObfOkgWi3Ry1VFdP592A1OfmsXk3+5/f/0u/dR9OrnqqP5YdEA3Ll6XW2F3FWsYIL//vwZISruB6Ymlh3QjMUX5CrvLN9zfYTtwL/v8xF75enjr2SoNVdyjgPYlJqjPd0tsBQ8C8vvIsLtgbe6vG2UYhgZXaSQ/r4I6l3xF608e0PS9X9v6TNi1VoOqNNTomi1U1MNbp69e0rKjP2nOvm9sfUp4FlR0tWYq6llAZ65d0sfHf9bcfRvv3hMH/qGWjaXzF9ICj7Pn0paazXv1f8vRTp5OW752U79uab+CZryddl8e38JpQc+Q3v/rc+ly2n19Tp2RfApKzR5O2+5m922od+e0AGvMVOniZek/1dKO65Hxqm4AeYjFMDJYU3SXjB49WrNmzVJMTIyaNGliu8YnISFB8fHxmjBhgp599lm99NJL2Rq34+Z+d2C2gPntOhlw+04A0tkb/p6zpwDkOS7+B5w9hUxN3dfcacd+vvIXTju22Tn1Gp9x48bpxRdf1KuvvqqaNWsqICBAAQEBqlmzpl599VW9+OKL2Q56AAAAgH/Carg47ZETs2fPVnBwsDw9PRUWFqatW7fesv/06dNVsWJFeXl5KTAwUEOHDtW1a9ds21NTUxUTE6OyZcvKy8tL5cuX1/jx42WfL0lISFCPHj0UEBCg/Pnz69FHH9XBgwcdjtOwYUNZLBaHR79+zktQOL2c9YsvvqgXX3xRR48edShnXbZs2dvsCQAAAPy7LVu2TFFRUYqLi1NYWJimT5+u5s2ba//+/SpRokS6/kuWLFF0dLTmz5+v8PBwHThwQD169JDFYlFsbKwkacqUKZo7d64WLlyokJAQbdu2TT179pSPj48GDRokwzDUtm1bubm56eOPP1ahQoUUGxurpk2bau/evfL2/l810z59+mjcuHG2n/Pnz3/nT0omnB743FS2bNl0wc7vv/+uMWPGaP78+U6aFQAAAP5t8lJxg9jYWPXp00c9e/aUJMXFxWn16tWaP3++oqOj0/X//vvvVa9ePXXp0kWSFBwcrM6dO2vLli0Ofdq0aaNWrVrZ+rz//vu2TNLBgwf1ww8/6JdfflFISFrJw7lz58rf31/vv/++evf+38V1+fPnl7+//5158tl0TxcpP3funBYuXOjsaQAAAAB3RXJysi5evOjwSE5OzrBvSkqKtm/frqZNm9raXFxc1LRpU23evDnDfcLDw7V9+3ZbEHPkyBGtWbNGLVu2dOgTHx+vAwfSrsPatWuXNm3apBYtWtjmKEmenp4Ox/Xw8NCmTZscjrd48WIVK1ZMVatW1fDhw3XlypXsnpJc49SMzyeffHLL7UeOUHYVAAAA/x6TJ0/W2LFjHdrGjBmT4XXvZ8+eVWpqqq1A2E1+fn769ddfMxy/S5cuOnv2rOrXry/DMHTjxg3169dPI0aMsPWJjo7WxYsXValSJbm6uio1NVUTJ05U165dJUmVKlVSmTJlNHz4cL3xxhvy9vbWtGnT9Mcff+jkyZMOxwoKClJAQIB+/vlnvfjii9q/f79WrVqV09Pzjzg18Gnbtq0sFotuVVjO8ve7kQEAAAB3UE6LDOSG4cOHKyoqyqHNIxfrqW/YsEGTJk3SnDlzFBYWpkOHDmnw4MEaP368YmJiJEnLly/X4sWLtWTJEoWEhGjnzp0aMmSIAgICFBkZKTc3N61atUpPP/20fH195erqqqZNm6pFixYO3+v79u1r+3e1atVUsmRJNWnSRIcPH1b58uVz7TlllVMDn5IlS2rOnDlq06ZNhtt37typ0NDQuzwrAAAAwDk8PDyyHOgUK1ZMrq6uSkhIcGhPSEjI9LqamJgYdevWzXYdTrVq1ZSUlKS+fftq5MiRcnFx0bBhwxQdHa1OnTrZ+hw7dkyTJ09WZGSkJCk0NFQ7d+5UYmKiUlJSVLx4cYWFhal27dqZzjcsLEySdOjQIacEPk69xic0NFTbt2/PdPvtskEAAABAbks1XJz2yA53d3eFhoYqPj7e1ma1WhUfH6+6detmuM+VK1fk4uJ4HFdXV0myfe/OrI/Vak03no+Pj4oXL66DBw9q27ZtmSY0pLSkhpSW/HAGp2Z8hg0bpqSkpEy3V6hQQevXr7+LMwIAAADyjqioKEVGRqp27dqqU6eOpk+frqSkJFuVt+7du6tUqVKaPHmyJCkiIkKxsbGqVauWbalbTEyMIiIibAFQRESEJk6cqDJlyigkJEQ7duxQbGysevXqZTvuihUrVLx4cZUpU0a7d+/W4MGD1bZtWzVr1kySdPjwYS1ZskQtW7ZU0aJF9fPPP2vo0KFq0KCBqlevfpfPUhqnBj4PPfTQLbd7e3vr4YcfvkuzAQAAACRrHipn3bFjR505c0ajR4/WqVOnVLNmTa1du9ZW8OD48eMO2ZtRo0bJYrFo1KhROnHihIoXL24LdG6aOXOmYmJi1L9/f50+fVoBAQF65plnNHr0aFufkydPKioqSgkJCSpZsqS6d+9uu0ZISstGffXVV7ZALDAwUO3atdOoUaPuwlnJmMUw4Vqyjpudd0dYIC/bdTLA2VMA8qS94e85ewpAnuPif8DZU8jUS79kvlzrjh+76sdOO7bZ3dP38QEAAACA3ODUpW4AAADAvSa7RQaQN/CqAgAAADA9Mj4AAACAHauRd4obIOvI+AAAAAAwPQIfAAAAAKbHUjcAAADATiq5AVPiVQUAAABgemR8AAAAADsUNzAnMj4AAAAATI/ABwAAAIDpsdQNAAAAsGMlN2BKvKoAAAAATI+MDwAAAGAnleIGpkTGBwAAAIDpkfEBAAAA7FDO2pzI+AAAAAAwPQIfAAAAAKbHUjcAAADAjtUgN2BGvKoAAAAATI+MDwAAAGAnVRQ3MCMyPgAAAABMj8AHAAAAgOmx1A0AAACww318zImMDwAAAADTI+MDAAAA2KGctTnxqgIAAAAwPTI+AAAAgB0r5axNiYwPAAAAANMj8AEAAABgeix1AwAAAOykUs7alMj4AAAAADA9Mj4AAACAHcpZmxOvKgAAAADTI/ABAAAAYHosdQMAAADsWCluYEpkfAAAAACYHhkfAAAAwI5VZHzMiIwPAAAAANMj4wMAAADY4RofcyLjAwAAAMD0CHwAAAAAmB5L3QAAAAA7VoPcgBnxqgIAAAAwPTI+AAAAgB2KG5gTGR8AAAAApkfgAwAAAMD0WOoGAAAA2LGKpW5mRMYHAAAAgOmR8QEAAADsUNzAnMj4AAAAADA9Mj4AAACAHTI+5kTGBwAAAIDpEfgAAAAAMD2WugEAAAB2WOpmTmR8AAAAAJgeGR8AAADADhkfcyLjAwAAAMD0CHwAAAAAmB5L3QAAAAA7VrHUzYzI+AAAAAAwPTI+AAAAgB2KG5gTGR8AAAAApkfGBwAAALBDxsecyPgAAAAAedjs2bMVHBwsT09PhYWFaevWrbfsP336dFWsWFFeXl4KDAzU0KFDde3aNdv21NRUxcTEqGzZsvLy8lL58uU1fvx4GYZh65OQkKAePXooICBA+fPn16OPPqqDBw86HOfatWsaMGCAihYtqgIFCqhdu3ZKSEjI3SefDQQ+AAAAQB61bNkyRUVFacyYMfrpp59Uo0YNNW/eXKdPn86w/5IlSxQdHa0xY8Zo3759evvtt7Vs2TKNGDHC1mfKlCmaO3euZs2apX379mnKlCl65ZVXNHPmTEmSYRhq27atjhw5oo8//lg7duxQUFCQmjZtqqSkJNs4Q4cO1aeffqoVK1bom2++0Z9//qknnnjizp6QW7AY9qGbSXTc3M/ZUwDypF0nA5w9BSBP2hv+nrOnAOQ5Lv4HnD2FTDVZH+W0Y8c3is1W/7CwMD3wwAOaNWuWJMlqtSowMFDPPvusoqOj0/UfOHCg9u3bp/j4eFvbc889py1btmjTpk2SpMcee0x+fn56++23bX3atWsnLy8vvffeezpw4IAqVqyoX375RSEhIbbj+vv7a9KkSerdu7cSExNVvHhxLVmyRO3bt5ck/frrr6pcubI2b96sBx98MHsnJheQ8QEAAADuEcnJybp48aLDIzk5OcO+KSkp2r59u5o2bWprc3FxUdOmTbV58+YM9wkPD9f27dtty+GOHDmiNWvWqGXLlg594uPjdeBAWnC6a9cubdq0SS1atLDNUZI8PT0djuvh4WELnrZv367r1687zK1SpUoqU6ZMpnO70wh8AAAAADtWw+K0x+TJk+Xj4+PwmDx5cobzPHv2rFJTU+Xn5+fQ7ufnp1OnTmW4T5cuXTRu3DjVr19fbm5uKl++vBo2bOiw1C06OlqdOnVSpUqV5Obmplq1amnIkCHq2rWrpP8FMMOHD9f58+eVkpKiKVOm6I8//tDJkyclSadOnZK7u7sKFy6c5bndaQQ+AAAAwD1i+PDhSkxMdHgMHz4818bfsGGDJk2apDlz5uinn37SqlWrtHr1ao0fP97WZ/ny5Vq8eLGWLFmin376SQsXLtTUqVO1cOFCSZKbm5tWrVqlAwcOyNfXV/nz59f69evVokULubjcu+EF5awBAACAe4SHh4c8PDyy1LdYsWJydXVNVyktISFB/v7+Ge4TExOjbt26qXfv3pKkatWqKSkpSX379tXIkSPl4uKiYcOG2bI+N/scO3ZMkydPVmRkpCQpNDRUO3fuVGJiolJSUlS8eHGFhYWpdu3akiR/f3+lpKTowoULDlmfW83tTrt3QzIAAADACQzD4rRHdri7uys0NNShUIHValV8fLzq1q2b4T5XrlxJl5VxdXX9/+dt3LKP1WpNN56Pj4+KFy+ugwcPatu2bWrTpo2ktMDIzc3NYW779+/X8ePHM53bnUbGBwAAAMijoqKiFBkZqdq1a6tOnTqaPn26kpKS1LNnT0lS9+7dVapUKdt1QhEREYqNjVWtWrUUFhamQ4cOKSYmRhEREbYAKCIiQhMnTlSZMmUUEhKiHTt2KDY2Vr169bIdd8WKFSpevLjKlCmj3bt3a/DgwWrbtq2aNWsmKS0gevrppxUVFSVfX18VKlRIzz77rOrWreuUim4SgQ8AAADgwKrsZV6cqWPHjjpz5oxGjx6tU6dOqWbNmlq7dq2t4MHx48cdsjejRo2SxWLRqFGjdOLECRUvXtwW6Nw0c+ZMxcTEqH///jp9+rQCAgL0zDPPaPTo0bY+J0+eVFRUlBISElSyZEl1795dMTExDnObNm2aXFxc1K5dOyUnJ6t58+aaM2fOHT4jmeM+PgBsuI8PkDPcxwfIvnv5Pj4N4oc57dgbm7zqtGObHRkfAAAAwI41m9faIG+guAEAAAAA0yPwAQAAAGB6LHUDAAAA7GS3rDTyBjI+AAAAAEyPjA8AAABgh+IG5kTGBwAAAIDpEfgAAAAAMD2WugEAAAB2KG5gTmR8AAAAAJgeGR8AAADADsUNzMmUgc+Wg8HOngKQJ5X83M3ZUwDypObtazh7CkCes87q7Bng34albgAAAABMz5QZHwAAACCnDMPZM8CdQMYHAAAAgOmR8QEAAADsWEVxAzMi4wMAAADA9Mj4AAAAAHa4gak5kfEBAAAAYHoEPgAAAABMj6VuAAAAgB0rS91MiYwPAAAAANMj4wMAAADY4Qam5kTGBwAAAIDpEfgAAAAAMD2WugEAAAB2uI+POZHxAQAAAGB6ZHwAAAAAO2R8zImMDwAAAADTI+MDAAAA2OEGpuZExgcAAACA6RH4AAAAADA9lroBAAAAdgzD2TPAnUDGBwAAAIDpkfEBAAAA7FDO2pzI+AAAAAAwPQIfAAAAAKbHUjcAAADADkvdzImMDwAAAADTI+MDAAAA2KGatTmR8QEAAABgemR8AAAAADtc42NOZHwAAAAAmB6BDwAAAADTY6kbAAAAYI/qBqZExgcAAACA6ZHxAQAAAOxQ3MCcyPgAAAAAMD0CHwAAAACmx1I3AAAAwI5BcQNTIuMDAAAAwPTI+AAAAAB2KG5gTmR8AAAAAJgeGR8AAADAHhkfUyLjAwAAAMD0CHwAAAAAmB5L3QAAAAA7lLM2JzI+AAAAAEyPjA8AAABgj4yPKZHxAQAAAHDPunbtWq6MQ+ADAAAA4J5itVo1fvx4lSpVSgUKFNCRI0ckSTExMXr77bdzNCaBDwAAAGDHMCxOeyDNhAkTtGDBAr3yyityd3e3tVetWlVvvfVWjsYk8AEAAABwT3n33Xc1b948de3aVa6urrb2GjVq6Ndff83RmBQ3AAAAAOxR3MDpTpw4oQoVKqRrt1qtun79eo7GJOMDAAAA5GGzZ89WcHCwPD09FRYWpq1bt96y//Tp01WxYkV5eXkpMDBQQ4cOdSggkJqaqpiYGJUtW1ZeXl4qX768xo8fL8PuBkeXL1/WwIEDVbp0aXl5ealKlSqKi4tzOE7Dhg1lsVgcHv369cvSc6pSpYq+/fbbdO0ffPCBatWqlaUx/o6MDwAAAGAnL11rs2zZMkVFRSkuLk5hYWGaPn26mjdvrv3796tEiRLp+i9ZskTR0dGaP3++wsPDdeDAAfXo0UMWi0WxsbGSpClTpmju3LlauHChQkJCtG3bNvXs2VM+Pj4aNGiQJCkqKkpff/213nvvPQUHB+vLL79U//79FRAQoNatW9uO16dPH40bN872c/78+bP0vEaPHq3IyEidOHFCVqtVq1at0v79+/Xuu+/qs88+y9G5IuMDAAAA5FGxsbHq06ePevbsacu65M+fX/Pnz8+w//fff6969eqpS5cuCg4OVrNmzdS5c2eHLNH333+vNm3aqFWrVgoODlb79u3VrFmzdH0iIyPVsGFDBQcHq2/fvqpRo0a6bFP+/Pnl7+9vexQqVChLz6tNmzb69NNP9dVXX8nb21ujR4/Wvn379Omnn+qRRx7JwZki8AEAAADuGcnJybp48aLDIzk5OcO+KSkp2r59u5o2bWprc3FxUdOmTbV58+YM9wkPD9f27dttAcqRI0e0Zs0atWzZ0qFPfHy8Dhw4IEnatWuXNm3apBYtWjj0+eSTT3TixAkZhqH169frwIEDatasmcPxFi9erGLFiqlq1aoaPny4rly5cttzcOPGDY0bN05ly5bVunXrdPr0aV25ckWbNm1KN352sNQNAAAAsOfE4gaTJ0/W2LFjHdrGjBmjl156KV3fs2fPKjU1VX5+fg7tfn5+mVY+69Kli86ePav69evLMAzduHFD/fr104gRI2x9oqOjdfHiRVWqVEmurq5KTU3VxIkT1bVrV1ufmTNnqm/fvipdurTy5csnFxcXvfnmm2rQoIHDsYKCghQQEKCff/5ZL774ovbv369Vq1bd8hzky5dPr7zyirp3737LftlF4AMAAADcI4YPH66oqCiHNg8Pj1wbf8OGDZo0aZLmzJmjsLAwHTp0SIMHD9b48eMVExMjSVq+fLkWL16sJUuWKCQkRDt37tSQIUMUEBCgyMhISWmBzw8//KBPPvlEQUFB2rhxowYMGKCAgABbBqpv376241arVk0lS5ZUkyZNdPjwYZUvX/6W82zSpIm++eYbBQcH59pzJ/ABAAAAHDivuIGHh0eWA51ixYrJ1dVVCQkJDu0JCQny9/fPcJ+YmBh169ZNvXv3lpQWkCQlJalv374aOXKkXFxcNGzYMEVHR6tTp062PseOHdPkyZMVGRmpq1evasSIEfrwww/VqlUrSVL16tW1c+dOTZ061WHpnb2wsDBJ0qFDh24b+LRo0ULR0dHavXu3QkND5e3t7bDdvoBCVhH4AAAAAHmQu7u7QkNDFR8fr7Zt20pKu89NfHy8Bg4cmOE+V65ckYuL42X+N28QerNcdWZ9rFarJOn69eu6fv36LftkZOfOnZKkkiVL3va59e/fX5JslebsWSwWpaam3naMv8u1wOfChQsqXLhwbg0HAAAA4DaioqIUGRmp2rVrq06dOpo+fbqSkpLUs2dPSVL37t1VqlQpTZ48WZIUERGh2NhY1apVy7bULSYmRhEREbYAKCIiQhMnTlSZMmUUEhKiHTt2KDY2Vr169ZIkFSpUSA8//LCGDRsmLy8vBQUF6ZtvvtG7775rC1QOHz6sJUuWqGXLlipatKh+/vlnDR06VA0aNFD16tVv+7xuFUDlVI4CnylTpig4OFgdO3aUJHXo0EErV66Uv7+/1qxZoxo1auTqJAEAAIC7xonFDbKrY8eOOnPmjEaPHq1Tp06pZs2aWrt2ra3gwfHjxx0yM6NGjZLFYtGoUaN04sQJFS9e3Bbo3DRz5kzFxMSof//+On36tAICAvTMM89o9OjRtj5Lly7V8OHD1bVrV507d05BQUGaOHGi7Qal7u7u+uqrr2yBWGBgoNq1a6dRo0bdpTOTnsWwvwVrFpUtW1aLFy9WeHi41q1bpw4dOmjZsmVavny5jh8/ri+//PJOzDXLgt992anHB/Kqkp+7OXsKQJ5UYNkPzp4CkOess65w9hQyFbxwitOO/Vvki0479r3mm2++0dSpU7Vv3z5JUpUqVTRs2DA99NBDORovR/fxOXXqlAIDAyVJn332mTp06KBmzZrphRde0I8//pijiQAAAAD3BMOJD0iS3nvvPTVt2lT58+fXoEGDNGjQIHl5ealJkyZasmRJjsbM0VK3IkWK6Pfff1dgYKDWrl2rCRMmSEq7IConFxoBAAAAwE0TJ07UK6+8oqFDh9raBg0apNjYWI0fP15dunTJ9pg5yvg88cQT6tKlix555BH99ddftru47tixQxUqVMjJkAAAAMC9wbA47wFJ0pEjRxQREZGuvXXr1jp69GiOxsxRxmfatGkqW7asjh8/rldeeUUFChSQJJ08edJWeg4AAAAAciIwMFDx8fHpkipfffWV7ZKb7Mp24HP9+nU988wziomJUdmyZR222aeiAAAAACAnnnvuOQ0aNEg7d+5UeHi4JOm7777TggUL9Prrr+dozGwHPm5ublq5cqViYmJydEAAAADgXpb9msfIbf/973/l7++v1157TcuXL5ckVa5cWcuWLVObNm1yNGaOlrq1bdtWH330ERkeAAAAAHfE448/rscffzzXxstR4HPfffdp3Lhx+u677xQaGipvb2+H7YMGDcqVyQEAAAB3HRkfp/vxxx9ltVoVFhbm0L5lyxa5urqqdu3a2R4zR4HP22+/rcKFC2v79u3avn27wzaLxULgAwAAACDHBgwYoBdeeCFd4HPixAlNmTJFW7ZsyfaYOQp8clpCDgAAAABuZ+/evfrPf/6Trr1WrVrau3dvjsbM0X187BmGIYMrwAAAAGAW3MfH6Tw8PJSQkJCu/eTJk8qXL0e5m5wHPu+++66qVasmLy8veXl5qXr16lq0aFFOhwMAAAAASVKzZs00fPhwJSYm2touXLigESNG6JFHHsnRmDkKl2JjYxUTE6OBAweqXr16kqRNmzapX79+Onv2LNXeAAAAkGdZWMzkdFOnTlWDBg0UFBSkWrVqSZJ27twpPz+/HCdbchT4zJw5U3PnzlX37t1tba1bt1ZISIheeuklAh8AAAAAOVaqVCn9/PPPWrx4sXbt2iUvLy/17NlTnTt3lpubW47GzFHgc/LkSdsdVO2Fh4fr5MmTOZoIAAAAANzk7e2tvn375tp4ObrGp0KFCrY7qNpbtmyZ7rvvvn88KQAAAMBpDCc+/uUOHDigrVu3OrTFx8erUaNGqlOnjiZNmpTjsXOU8Rk7dqw6duyojRs32q7x+e677xQfH59hQAQAAAAAt/Piiy+qWrVqqlOnjqS02+hERETooYceUvXq1TV58mTlz59fQ4YMyfbYOQp82rVrpy1btmjatGn66KOPJEmVK1fW1q1bbRcfAQAAAHkSZaWdZtu2bXrhhRdsPy9evFj333+/vvjiC0lS9erVNXPmzLsX+EhSaGio3nvvvZzuDgAAAAAOzp49q9KlS9t+Xr9+vSIiImw/N2zYUM8991yOxs7RNT6urq46ffp0uva//vpLrq6uOZoIAAAAcE/gGh+n8fX1tRVLs1qt2rZtmx588EHb9pSUFBlGzk5UjgKfzA6WnJwsd3f3HE0EAAAAwL9bw4YNNX78eP3++++aPn26rFarGjZsaNu+d+9eBQcH52jsbC11mzFjhiTJYrHorbfeUoECBWzbUlNTtXHjRlWqVClHEwEAAADw7zZx4kQ98sgjCgoKkqurq2bMmCFvb2/b9kWLFqlx48Y5Gjtbgc+0adMkpWV84uLiHJa1ubu7Kzg4WHFxcTmaCAAAAHBPYMmZ0wQHB2vfvn3as2ePihcvroCAAIftY8eOdbgGKDuyFfgcPXpUktSoUSOtWrVKRYoUydFBAQAAACAj+fLlU40aNTLclll7lsbNyU7r16/P8QEBAACAexoZH1PKcTnrP/74Q5988omOHz+ulJQUh22xsbH/eGIAAAAAkFtyFPjEx8erdevWKleunH799VdVrVpVv/32mwzD0H/+85/cniMAAAAA/CM5Kmc9fPhwPf/889q9e7c8PT21cuVK/f7773r44Yf15JNP5vYcAQAAgLvHsDjvAUnS8ePHM7yFjmEYOn78eI7GzFHGZ9++fXr//ffTBsiXT1evXlWBAgU0btw4tWnTRv/973+zNd6NGze0Z88enTp1SpLk7++vKlWqyM3NLSfTAwAAAJCHlS1bVidPnlSJEiUc2s+dO6eyZcsqNTU122PmKPDx9va2XddTsmRJHT58WCEhIZKks2fPZnkcq9Wq0aNHa/bs2UpMTHTY5uPjo4EDB2rs2LFycclRYgoAAADINgvFDZzOMAxZLOkzYJcvX5anp2eOxsxR4PPggw9q06ZNqly5slq2bKnnnntOu3fv1qpVq/Tggw9meZzo6GgtWLBAL7/8spo3by4/Pz9JUkJCgr788kvFxMQoJSVFU6ZMyck0AQAAAOQhUVFRkiSLxaKYmBjlz5/fti01NVVbtmxRzZo1czR2jgKf2NhYXb58WVLaTYQuX76sZcuW6b777stWRbd3331XixYtUvPmzR3ag4OD1bdvXwUFBal79+4EPgAAALh7yPg4zY4dOySlZXx2794td3d32zZ3d3fVqFFDzz//fI7GzlHgU65cOdu/vb29FRcXl6ODX7p0Kd3dWO2VLFlSSUlJORobAAAAQN5y836hPXv21Ouvv65ChQrl2tj/+OKZy5cv6+LFiw6PrGrYsKGef/75DK8LOnv2rF588UU1bNjwn04RAAAAQB7yzjvvOAQ9Fy9e1EcffaRff/01x2PmKONz9OhRDRw4UBs2bNC1a9ds7TcvQspqlYW4uDi1bNlSJUuWVLVq1Ryu8dm9e7eqVKmizz77LCdTBAAAAJBHdejQQQ0aNNDAgQN19epV1a5d23bf0KVLl6pdu3bZHjNHgc9TTz0lwzA0f/58+fn5ZVhxISsCAwO1a9cuffHFF/rhhx9s5azr1KmjSZMmqVmzZlR0AwAAAP5lNm7cqJEjR0qSPvzwQxmGoQsXLmjhwoWaMGHC3Qt8du3ape3bt6tixYo52d2Bi4uLWrRooRYtWvzjsQAAAIB/inLWzpeYmChfX19J0tq1a9WuXTvlz59frVq10rBhw3I0Zo4CnwceeEC///57rgQ+krR161Zt3rzZ4Qam4eHheuCBB3JlfAAAAAB5R2BgoDZv3ixfX1+tXbtWS5culSSdP3/+7t7H56233lK/fv104sQJVa1aVW5ubg7bq1evnqVxTp8+rXbt2um7775TmTJlHK7xGTp0qOrVq6eVK1emu2OrveTkZCUnJzu0GddvyOKWo6cGAAAAwMmGDBmirl27qkCBAipTpoyt4NnGjRtVrVq1HI2Zo+jgzJkzOnz4sHr27Glrs1gs2S5u0L9/f6Wmpmrfvn3pskf79+9Xr169NGDAAK1YsSLTMSZPnqyxY8c6tPm0baLCjzfNxjMCAAAA/p+Rs+vXkXv69++vOnXq6Pfff9cjjzxiu+6/XLlymjBhQo7GtBiGke1VjFWqVFHlypX1wgsvZFjcICgoKEvjFCxYUBs3blStWrUy3L59+3Y1bNhQly5dynSMjDI+1VbMIOMD5EDJz91u3wlAOgWW/eDsKQB5zjpr5n/YdrZyr8c67dhHBkc57dj3opSUFB09elTly5dXvnz/7Pt9jvY+duyYPvnkE1WoUOEfHdzDw+OW9/25dOmSPDw8bjvG3/sQ9AAAACDHKG7gdFeuXNGzzz6rhQsXSpIOHDigcuXK6dlnn1WpUqUUHR2d7TFzVCu6cePG2rVrV052ddCxY0dFRkbqww8/dAiALl68qA8//FA9e/ZU586d//FxAAAAAOQdw4cP165du7RhwwaHYgZNmzbVsmXLcjRmjlIjERERGjp0qHbv3q1q1aqlK27QunXrLI0TGxsrq9WqTp066caNG3J3d5eUltLKly+fnn76aU2dOjUnUwQAAAByhoyP03300UdatmyZHnzwQYfLakJCQnT48OEcjZmjwKdfv36SpHHjxqXblp3iBh4eHpo7d66mTJmi7du3O5SzDg0NVaFChXIyPQAAAAB52JkzZzKs7JyUlJSuvkBW5SjwsVqtOTpYZgoVKqRGjRrl6pgAAAAA8qbatWtr9erVevbZZyXJFuy89dZbqlu3bo7GdHoVgKtXr2r79u3y9fVVlSpVHLZdu3ZNy5cvV/fu3Z00OwAAAPzbWFjq5jSNGzfWqlWrNGnSJLVo0UJ79+7VjRs39Prrr2vv3r36/vvv9c033+Ro7CwHPjNmzFDfvn3l6empGTNm3LLvoEGDsjTmgQMH1KxZMx0/flwWi0X169fX+++/r4CAAElSYmKievbsSeADAAAA/Ats2LBBKSkpql+/vnbu3KmXX35Z1apV05dffqn//Oc/2rx5852/gem0adPUtWtXeXp6atq0aZn2s1gsWQ58XnzxRVWtWlXbtm3ThQsXNGTIENWvX18bNmxQmTJlsjo1AAAAIPeQ8bknlC9fXm+++WaujZflwOfo0aMZ/vuf+P777/XVV1+pWLFiKlasmD799FP1799fDz30kNavXy9vb+9cOQ4AAACAvGHv3r22omeZqV69erbHzdE1PuPGjdPzzz+v/PnzO7RfvXpVr776qkaPHp2lca5evepwB1aLxaK5c+dq4MCBevjhh7VkyZKcTA8AAABAHtWkSRMZRuZpt+xUkbaXo8Bn7Nix6tevX7rA58qVKxo7dmyWA59KlSpp27Ztqly5skP7rFmzJGX9fkAAAABArmGpm1Nt2bJFxYsXz/VxcxT4GIaRYf3sXbt2ydfXN8vjPP7443r//ffVrVu3dNtmzZolq9WquLi4nEwRAAAAQB5UpkyZDO/h80+5ZKdzkSJF5OvrK4vFovvvv1++vr62h4+Pjx555BF16NAhy+MNHz5ca9asyXT7nDlzcv2eQQAAAMCtWAznPXDnZCvjM336dBmGoV69emns2LHy8fGxbXN3d1dwcHCObygEAAAA4N/t4Ycflru7+x0ZO1uBT2RkpCSpbNmyqlevnkNhAgAAAMAUjPSXdODuWL9+/R0bO1tL3W4qWLCg9u3bZ/v5448/Vtu2bTVixAilpKTk2uQAAAAAIDfkKPB55plndODAAUnSkSNH1LFjR+XPn18rVqzQCy+8kKsTBAAAAIB/KkeBz4EDB1SzZk1J0ooVK2z33FmwYIFWrlyZm/MDAAAA7i7DiQ/cMTkKfAzDsFVb++qrr9SyZUtJUmBgoM6ePZt7swMAAACAXJCj6gS1a9fWhAkT1LRpU33zzTeaO3euJOno0aPy8/PL1QkCAAAAdxNlpZ0vNTVVCxYsUHx8vE6fPp3uFjdff/11tsfMUeAzffp0de3aVR999JFGjhypChUqSJI++OADhYeH52RIAAAAAJAkDR48WAsWLFCrVq1UtWpVWSz/vNJejgKf6tWra/fu3enaX331Vbm6uv7jSQEAAAD491q6dKmWL19uu6QmN+ToGh9JunDhgt566y0NHz5c586dkyTt3btXp0+fzrXJAQAAAHcdxQ2czt3d3baqLLfkKPD5+eefdd9992nKlCmaOnWqLly4IElatWqVhg8fnpvzAwAAAHALs2fPVnBwsDw9PRUWFqatW7fesv/06dNVsWJFeXl5KTAwUEOHDtW1a9ds21NTUxUTE6OyZcvKy8tL5cuX1/jx42UY/4vMLl++rIEDB6p06dLy8vJSlSpVFBcX53Cca9euacCAASpatKgKFCigdu3aKSEhIUvP6bnnntPrr7/ucMx/KkdL3aKiotSzZ0+98sorKliwoK29ZcuW6tKlS65NDgAAALjb8lJxg2XLlikqKkpxcXEKCwvT9OnT1bx5c+3fv18lSpRI13/JkiWKjo7W/PnzFR4ergMHDqhHjx6yWCyKjY2VJE2ZMkVz587VwoULFRISom3btqlnz57y8fHRoEGDJKXFA19//bXee+89BQcH68svv1T//v0VEBCg1q1bS5KGDh2q1atXa8WKFfLx8dHAgQP1xBNP6Lvvvrvt89q0aZPWr1+vzz//XCEhIXJzc3PYvmrVqmyfqxwFPj/++KPeeOONdO2lSpXSqVOncjIkAAAAgGyKjY1Vnz591LNnT0lSXFycVq9erfnz5ys6Ojpd/++//1716tWzJSuCg4PVuXNnbdmyxaFPmzZt1KpVK1uf999/3yGT9P333ysyMlINGzaUJPXt21dvvPGGtm7dqtatWysxMVFvv/22lixZosaNG0uS3nnnHVWuXFk//PCDHnzwwVs+r8KFC+vxxx/P+YnJQI4CHw8PD128eDFd+4EDB1S8ePF/PCkAAADAaZyY8UlOTlZycrJDm4eHhzw8PNL1TUlJ0fbt2x0uNXFxcVHTpk21efPmDMcPDw/Xe++9p61bt6pOnTo6cuSI1qxZo27dujn0mTdvng4cOKD7779fu3bt0qZNm2wZoZt9PvnkE/Xq1UsBAQHasGGDDhw4oGnTpkmStm/fruvXr6tp06a2fSpVqqQyZcpo8+bNtw183nnnnVtuz4kcXePTunVrjRs3TtevX5ckWSwWHT9+XC+++KLatWuXqxMEAAAA/i0mT54sHx8fh8fkyZMz7Hv27Fmlpqamu4+mn59fpquwunTponHjxql+/fpyc3NT+fLl1bBhQ40YMcLWJzo6Wp06dVKlSpXk5uamWrVqaciQIeratautz8yZM1WlShWVLl1a7u7uevTRRzV79mw1aNBAknTq1Cm5u7urcOHCWZ7bnZajjM9rr72m9u3bq0SJErp69aoefvhhnTp1SnXr1tXEiRNze44AAADAv8Lw4cMVFRXl0JZRtienNmzYoEmTJmnOnDkKCwvToUOHNHjwYI0fP14xMTGSpOXLl2vx4sVasmSJQkJCtHPnTg0ZMkQBAQGKjIyUlBb4/PDDD/rkk08UFBSkjRs3asCAAQoICHDI8vwTH3zwgZYvX67jx48rJSXFYdtPP/2U7fFyFPj4+Pho3bp1+u6777Rr1y5dvnxZ//nPf3LtSQIAAABO48Slbpkta8tIsWLF5Orqmq5SWkJCgvz9/TPcJyYmRt26dVPv3r0lSdWqVVNSUpL69u2rkSNHysXFRcOGDbNlfW72OXbsmCZPnqzIyEhdvXpVI0aM0Icffmi7Dqh69erauXOnpk6dqqZNm8rf318pKSm6cOGCQ9bnVnOzN2PGDI0cOVI9evTQxx9/rJ49e+rw4cP68ccfNWDAgCydn7/L8X18JKlevXrq37+/XnjhhQyDnmrVqun333//J4cAAAAAkAF3d3eFhoYqPj7e1ma1WhUfH6+6detmuM+VK1fk4uIYAri6ukqSrXR0Zn2sVqsk6fr167p+/fot+4SGhsrNzc1hbvv379fx48cznZu9OXPmaN68eZo5c6bc3d31wgsvaN26dRo0aJASExNvu39GcpTxyarffvvNdh0QAAAAkBfkpXLWUVFRioyMVO3atVWnTh1Nnz5dSUlJtipv3bt3V6lSpWzXCUVERCg2Nla1atWyLXWLiYlRRESELQCKiIjQxIkTVaZMGYWEhGjHjh2KjY1Vr169JEmFChXSww8/rGHDhsnLy0tBQUH65ptv9O6779oKIPj4+Ojpp59WVFSUfH19VahQIT377LOqW7fubQsbSNLx48cVHh4uSfLy8tKlS5ckSd26ddODDz6oWbNmZftc3dHABwAAAMCd07FjR505c0ajR4/WqVOnVLNmTa1du9ZW8OD48eMOmZlRo0bJYrFo1KhROnHihIoXL24LdG6aOXOmYmJi1L9/f50+fVoBAQF65plnNHr0aFufpUuXavjw4eratavOnTunoKAgTZw4Uf369bP1mTZtmlxcXNSuXTslJyerefPmmjNnTpael7+/v23cMmXK6IcfflCNGjV09OjRHN/U1GLk5u1Q/6ZgwYLatWuXypUrd6cOkaHgd1++q8cDzKLk52637wQgnQLLfnD2FIA8Z511hbOnkKmK46c57dj7Y4Y67dj3kt69eyswMFBjxozR7NmzNWzYMNWrV0/btm3TE088obfffjvbY5LxAQAAAHBPmTdvnu16oQEDBqho0aL6/vvv1bp1az3zzDM5GpPABwAAAMA9xcXFxWGJXqdOnWxV5nI85j+dFAAAAGAqhhMfsPn222/11FNPqW7dujpx4oQkadGiRdq0aVOOxstxxic+Pl7x8fE6ffq0LQ110/z58yVJb7zxRro7yQIAAADAraxcuVLdunVT165dtWPHDiUnJ0uSEhMTNWnSJK1ZsybbY+Yo4zN27Fg1a9ZM8fHxOnv2rM6fP+/wuKlLly7y9vbOySEAAAAAp7AYznsgzYQJExQXF6c333xTbm7/K75Ur149/fTTTzkaM0cZn7i4OC1YsEDdunXL0UEBAAAAIDP79+9XgwYN0rX7+PjowoULORozRxmflJQU2w2FAAAAACA3+fv769ChQ+naN23alONb5eQo8Ondu7eWLFmSowMCAAAA9zSKGzhdnz59NHjwYG3ZskUWi0V//vmnFi9erOeff17//e9/czRmjpa6Xbt2TfPmzdNXX32l6tWrO6y7k6TY2NgcTQYAAAAAoqOjZbVa1aRJE125ckUNGjSQh4eHnn/+eT377LM5GjNHgc/PP/+smjVrSpJ++eUXh20WiyVHEwEAAADuCWRenM5isWjkyJEaNmyYDh06pMuXL6tKlSoqUKBAjsfMUeCzfv36HB8QAAAAALLC3d1dVapUyZWxcnwfHwAAAADITb169cpSv5v3Dc0OAh8AAADADvfTcZ4FCxYoKChItWrVkmHk7gtB4AMAAADgnvDf//5X77//vo4ePaqePXvqqaeekq+vb66MnaNy1gAAAIBpUc7aaWbPnq2TJ0/qhRde0KeffqrAwEB16NBBX3zxxT/OABH4AAAAALhneHh4qHPnzlq3bp327t2rkJAQ9e/fX8HBwbp8+XKOxyXwAQAAAHBPcnFxkcVikWEYSk1N/Wdj5dKcAAAAAFOwGM57QEpOTtb777+vRx55RPfff792796tWbNm6fjx43f/Pj4AAAAAkNv69++vpUuXKjAwUL169dL777+vYsWK5crYBD4AAACAPTIvThMXF6cyZcqoXLly+uabb/TNN99k2G/VqlXZHpvABwAAAMA9oXv37rJYLHdkbAIfAAAAwB4ZH6dZsGDBHRub4gYAAAAATI/ABwAAAIDpsdQNAAAAsENZaXMi4wMAAADA9Mj4AAAAAPbI+JgSGR8AAAAApkfgAwAAAMD0WOoGAAAA2GOpmymR8QEAAABgemR8AAAAADuUszYnMj4AAAAATI+MDwAAAGCPjI8pkfEBAAAAYHoEPgAAAABMj6VuAAAAgB2KG5gTGR8AAAAApkfGBwAAALBHxseUyPgAAAAAMD0CHwAAAACmx1I3AAAAwB5L3UyJjA8AAAAA0yPjAwAAANixOHsCuCPI+AAAAAAwPTI+AAAAgD2u8TElMj4AAAAATI/ABwAAAIDpsdQNAAAAsGNhqZspkfEBAAAAYHpkfAAAAAB7ZHxMiYwPAAAAANMj8AEAAABgeix1AwAAAOyx1M2UyPgAAAAAMD0yPgAAAIAdylmbExkfAAAAAKZHxgcAAACwR8bHlMj4AAAAADA9Ah8AAAAApsdSNwAAAMAOxQ3MiYwPAAAAANMj4wMAAADYI+NjSmR8AAAAAJgegQ8AAACQh82ePVvBwcHy9PRUWFiYtm7desv+06dPV8WKFeXl5aXAwEANHTpU165ds21PTU1VTEyMypYtKy8vL5UvX17jx4+XYfwvFWaxWDJ8vPrqq7Y+wcHB6ba//PLLuX8CsoilbgAAAICdvFTcYNmyZYqKilJcXJzCwsI0ffp0NW/eXPv371eJEiXS9V+yZImio6M1f/58hYeH68CBA+rRo4csFotiY2MlSVOmTNHcuXO1cOFChYSEaNu2berZs6d8fHw0aNAgSdLJkycdxv3888/19NNPq127dg7t48aNU58+fWw/FyxYMLdPQZaZMvApEe/u7CkAeVLclGnOngKQJz1VMsrZUwDwLxUbG6s+ffqoZ8+ekqS4uDitXr1a8+fPV3R0dLr+33//verVq6cuXbpISsvKdO7cWVu2bHHo06ZNG7Vq1crW5/3333fIJPn7+zuM+/HHH6tRo0YqV66cQ3vBggXT9XUWlroBAAAA9gznPZKTk3Xx4kWHR3JycobTTElJ0fbt29W0aVNbm4uLi5o2barNmzdnuE94eLi2b99uC2KOHDmiNWvWqGXLlg594uPjdeDAAUnSrl27tGnTJrVo0SLDMRMSErR69Wo9/fTT6ba9/PLLKlq0qGrVqqVXX31VN27cyHCMu8GUGR8AAAAgL5o8ebLGjh3r0DZmzBi99NJL6fqePXtWqamp8vPzc2j38/PTr7/+muH4Xbp00dmzZ1W/fn0ZhqEbN26oX79+GjFihK1PdHS0Ll68qEqVKsnV1VWpqamaOHGiunbtmuGYCxcuVMGCBfXEE084tA8aNEj/+c9/5Ovrq++//17Dhw/XyZMnbUvq7jYCHwAAAMCeE6/xGT58uKKiHJfPenh45Nr4GzZs0KRJkzRnzhyFhYXp0KFDGjx4sMaPH6+YmBhJ0vLly7V48WItWbJEISEh2rlzp4YMGaKAgABFRkamG3P+/Pnq2rWrPD09Hdrtn0f16tXl7u6uZ555RpMnT87V55RVBD4AAADAPcLDwyPLQUGxYsXk6uqqhIQEh/aEhIRMr6uJiYlRt27d1Lt3b0lStWrVlJSUpL59+2rkyJFycXHRsGHDFB0drU6dOtn6HDt2TJMnT04X+Hz77bfav3+/li1bdtv5hoWF6caNG/rtt99UsWLFLD3H3MQ1PgAAAEAe5O7urtDQUMXHx9varFar4uPjVbdu3Qz3uXLlilxcHEMAV1dXSbKVq86sj9VqTTfe22+/rdDQUNWoUeO28925c6dcXFwyrDZ3N5DxAQAAAOzkpXLWUVFRioyMVO3atVWnTh1Nnz5dSUlJtipv3bt3V6lSpTR58mRJUkREhGJjY1WrVi3bUreYmBhFRETYAqCIiAhNnDhRZcqUUUhIiHbs2KHY2Fj16tXL4dgXL17UihUr9Nprr6Wb1+bNm7VlyxY1atRIBQsW1ObNmzV06FA99dRTKlKkyB0+Kxkj8AEAAADyqI4dO+rMmTMaPXq0Tp06pZo1a2rt2rW2ggfHjx93yN6MGjVKFotFo0aN0okTJ1S8eHFboHPTzJkzFRMTo/79++v06dMKCAjQM888o9GjRzsce+nSpTIMQ507d043Lw8PDy1dulQvvfSSkpOTVbZsWQ0dOjTd9Ut3k8WwvwWrSdSJdE6lCCCve3M89/EBcuKp6dzHB8iu3bFDnT2FTIX2cd7vw+1v3rvnJa/jGh8AAAAApkfgAwAAAMD0uMYHAAAAsGMx35UgEBkfAAAAAP8CZHwAAAAAeyR8TImMDwAAAADTI+MDAAAA2MlLNzBF1pHxAQAAAGB6BD4AAAAATI+lbgAAAIA9lrqZEhkfAAAAAKZHxgcAAACwQ3EDcyLjAwAAAMD0CHwAAAAAmB5L3QAAAAB7LHUzJTI+AAAAAEyPjA8AAABgh+IG5kTGBwAAAIDpEfgAAAAAMD2WugEAAAD2WOpmSmR8AAAAAJgeGR8AAADADsUNzImMDwAAAADTI+MDAAAA2DNI+ZgRGR8AAAAApkfgAwAAAMD0WOoGAAAA2KG4gTmR8QEAAABgemR8AAAAAHtkfEyJjA8AAAAA0yPwAQAAAGB6LHUDAAAA7Fiszp4B7gQyPgAAAABMj4wPAAAAYI/iBqZExgcAAACA6ZHxAQAAAOxwA1NzIuMDAAAAwPQIfAAAAACYHkvdAAAAAHsGa93MiIwPAAAAANMj4wMAAADYobiBOZHxAQAAAGB6BD4AAAAATI+lbgAAAIA9lrqZEhkfAAAAAKZHxgcAAACwQ3EDcyLjAwAAAMD0yPgAAAAA9riBqSmR8QEAAABgegQ+AAAAAEyPpW4AAACAHYobmBMZHwAAAACmR8YHAAAAsEfGx5TI+AAAAAAwPQIfAAAAAKbHUjcAAADADsUNzImMDwAAAADTI+MDAAAA2LOS8jEjMj4AAAAATI+MDwAAAGCPhI8pkfEBAAAAYHoEPgAAAABMj6VuAAAAgB3KWZsTGR8AAAAApkfgAwAAANgzDOc9cmD27NkKDg6Wp6enwsLCtHXr1lv2nz59uipWrCgvLy8FBgZq6NChunbtmm17amqqYmJiVLZsWXl5eal8+fIaP368DLv5WSyWDB+vvvqqrc+5c+fUtWtXFSpUSIULF9bTTz+ty5cv5+g55gaWugEAAAB51LJlyxQVFaW4uDiFhYVp+vTpat68ufbv368SJUqk679kyRJFR0dr/vz5Cg8P14EDB9SjRw9ZLBbFxsZKkqZMmaK5c+dq4cKFCgkJ0bZt29SzZ0/5+Pho0KBBkqSTJ086jPv555/r6aefVrt27WxtXbt21cmTJ7Vu3Tpdv35dPXv2VN++fbVkyZI7eEYyR+ADAAAA5FGxsbHq06ePevbsKUmKi4vT6tWrNX/+fEVHR6fr//3336tevXrq0qWLJCk4OFidO3fWli1bHPq0adNGrVq1svV5//33HTJJ/v7+DuN+/PHHatSokcqVKydJ2rdvn9auXasff/xRtWvXliTNnDlTLVu21NSpUxUQEJCLZyFrWOoGAAAA2LEYznskJyfr4sWLDo/k5OQM55mSkqLt27eradOmtjYXFxc1bdpUmzdvznCf8PBwbd++3RbEHDlyRGvWrFHLli0d+sTHx+vAgQOSpF27dmnTpk1q0aJFhmMmJCRo9erVevrpp21tmzdvVuHChW1BjyQ1bdpULi4uDkHW3UTgAwAAANwjJk+eLB8fH4fH5MmTM+x79uxZpaamys/Pz6Hdz89Pp06dynCfLl26aNy4capfv77c3NxUvnx5NWzYUCNGjLD1iY6OVqdOnVSpUiW5ubmpVq1aGjJkiLp27ZrhmAsXLlTBggX1xBNP2NpOnTqVbqldvnz55Ovrm+nc7jQCHwAAAMCe4bzH8OHDlZiY6PAYPnx4rj21DRs2aNKkSZozZ45++uknrVq1SqtXr9b48eNtfZYvX67FixdryZIl+umnn7Rw4UJNnTpVCxcuzHDM+fPnq2vXrvL09My1ed4JXOMDAAAA3CM8PDzk4eGRpb7FihWTq6urEhISHNoTEhLSXYNzU0xMjLp166bevXtLkqpVq6akpCT17dtXI0eOlIuLi4YNG2bL+tzsc+zYMU2ePFmRkZEO43377bfav3+/li1b5tDu7++v06dPO7TduHFD586dy3RudxoZHwAAAMCOxTCc9sgOd3d3hYaGKj4+3tZmtVoVHx+vunXrZrjPlStX5OLiGAK4urpKkq1cdWZ9rFZruvHefvtthYaGqkaNGg7tdevW1YULF7R9+3Zb29dffy2r1aqwsLBsPMvcQ8YHAAAAyKOioqIUGRmp2rVrq06dOpo+fbqSkpJsVd66d++uUqVK2a4TioiIUGxsrGrVqqWwsDAdOnRIMTExioiIsAVAERERmjhxosqUKaOQkBDt2LFDsbGx6tWrl8OxL168qBUrVui1115LN6/KlSvr0UcfVZ8+fRQXF6fr169r4MCB6tSpk1MqukkEPgAAAECe1bFjR505c0ajR4/WqVOnVLNmTa1du9ZW8OD48eMO2ZtRo0bJYrFo1KhROnHihIoXL24LdG6aOXOmYmJi1L9/f50+fVoBAQF65plnNHr0aIdjL126VIZhqHPnzhnObfHixRo4cKCaNGkiFxcXtWvXTjNmzLgDZyFrLIaRzZxaHlAnMtbZUwDypDfHT3P2FIA86anpUc6eApDn7I4d6uwpZKpxk5edduyv49Pfewe5g2t8AAAAAJgeS90AAAAAO9ktMoC8gYwPAAAAANMj8AEAAABgeix1AwAAAOyx0s2UyPgAAAAAMD0yPgAAAIA9ihuYEhkfAAAAAKZHxgcAAACwYyHhY0pkfAAAAACY3j2R8blx44b27NmjU6dOSZL8/f1VpUoVubm5OXlmAAAAAMzAqYGP1WrV6NGjNXv2bCUmJjps8/Hx0cCBAzV27Fi5uJCYAgAAwF1CcQNTcmrgEx0drQULFujll19W8+bN5efnJ0lKSEjQl19+qZiYGKWkpGjKlCnOnCYAAACAPM6pgc+7776rRYsWqXnz5g7twcHB6tu3r4KCgtS9e3cCHwAAANw1FquzZ4A7walryC5duqSAgIBMt5csWVJJSUl3cUYAAAAAzMipgU/Dhg31/PPP6+zZs+m2nT17Vi+++KIaNmx49ycGAAAAwFScutQtLi5OLVu2VMmSJVWtWjWHa3x2796tKlWq6LPPPnPmFAEAAPBvQ3EDU3Jq4BMYGKhdu3bpiy++0A8//GArZ12nTh1NmjRJzZo1o6IbAAAAgH/M6ffxcXFxUYsWLdSiRYsc7Z+cnKzk5GSHNmvqDbm4Ov2pAQAAIC8i4WNK90R0sHXrVm3evNnhBqbh4eF64IEHbrvv5MmTNXbsWIe2gOrNVKpm80z2AAAAAPBv49TA5/Tp02rXrp2+++47lSlTxuEan6FDh6pevXpauXKlSpQokekYw4cPV1RUlENb4/5xd3TeAAAAAPIWpwY+/fv3V2pqqvbt26eKFSs6bNu/f7969eqlAQMGaMWKFZmO4eHhIQ8PD4c2lrkBAAAgpywUNzAlp0YIX3zxhTZu3Jgu6JGkihUrasaMGZSzBgAAAPCPOTXw8fDw0MWLFzPdfunSpXTZHAAAAOCOIuNjSk6tFd2xY0dFRkbqww8/dAiALl68qA8//FA9e/ZU586dnThDAAAAAGbg1IxPbGysrFarOnXqpBs3bsjd3V2SlJKSonz58unpp5/W1KlTnTlFAAAA/NtYnT0B3AlOX+o2d+5cTZkyRdu3b3coZx0aGqpChQo5c3oAAAAATMKpS90kad++fVq5cqVKliypzp07q1atWlq+fLmGDBmir7/+2tnTAwAAAGACTs34rF27Vm3atFGBAgV05coVffjhh+revbtq1Kghq9WqZs2a6csvv1Tjxo2dOU0AAAD8i1DO2pycmvEZN26chg0bpr/++kvvvPOOunTpoj59+mjdunWKj4/XsGHD9PLLLztzigAAAABMwKmBz549e9SjRw9JUocOHXTp0iW1b9/etr1r1676+eefnTQ7AAAA/CsZhvMeuGOcfo2PxWKRJLm4uMjT01M+Pj62bQULFlRiYqKzpgYAAADAJJwa+AQHB+vgwYO2nzdv3qwyZcrYfj5+/LhKlizpjKkBAAAAMBGnFjf473//q9TUVNvPVatWddj++eefU9gAAAAAdxdLzkzJqYFPv379brl90qRJd2kmAAAAAMzMqYEPAAAAcM+xOnsCuBOcXtwAAAAAAO40Mj4AAACAHW5gak5kfAAAAACYHoEPAAAAANNjqRsAAABgj6VupkTGBwAAAIDpkfEBAAAA7JHxMSUyPgAAAABMj8AHAAAAgOmx1A0AAACwx1I3UyLjAwAAAMD0yPgAAAAA9qzOngDuBDI+AAAAAEyPjA8AAABgx8I1PqZExgcAAACA6RH4AAAAADA9lroBAAAA9ljqZkpkfAAAAACYHhkfAAAAwJ6VjI8ZkfEBAAAAYHoEPgAAAABMj6VuAAAAgD2KG5gSGR8AAAAApkfGBwAAALBHxseUyPgAAAAAMD0yPgAAAIA9Mj6mRMYHAAAAgOkR+AAAAAAwPQIfAAAAwJ7VcN4jB2bPnq3g4GB5enoqLCxMW7duvWX/6dOnq2LFivLy8lJgYKCGDh2qa9eu2banpqYqJiZGZcuWlZeXl8qXL6/x48fL+NsSwH379ql169by8fGRt7e3HnjgAR0/fty2vWHDhrJYLA6Pfv365eg55gau8QEAAADyqGXLlikqKkpxcXEKCwvT9OnT1bx5c+3fv18lSpRI13/JkiWKjo7W/PnzFR4ergMHDqhHjx6yWCyKjY2VJE2ZMkVz587VwoULFRISom3btqlnz57y8fHRoEGDJEmHDx9W/fr19fTTT2vs2LEqVKiQ9uzZI09PT4fj9enTR+PGjfu/9u49qKrq7+P454BcNBUVlEuKUZapeSXFo04/S8q0HBQrTU1K00osL2UjJTh2w9GizLyUZWiZlJU5ZZJFSFmARaCWhkUXnymRbEYt8BZnPX/4tJ9zEpRQOLJ/79fMmWGvvfbaa++Z7x/f+a69sI6bNGlSh2/j9Eh8AAAAAHfG5e0Z1FhaWpomTZqkO+64Q5K0fPlybdy4UStXrtTs2bNP6f/555+rf//+GjNmjCTpoosu0q233qr8/HyPPnFxcbrhhhusPmvXrvWoJD388MMaOnSoFixYYLVdcsklp9yvSZMmCgsLOzcPe5ZY6gYAAACcJ44dO6bDhw97/I4dO1Zl3+PHj6ugoECxsbFWm4+Pj2JjY5Wbm1vlNf369VNBQYGVxPzwww96//33NXToUI8+WVlZ2rNnjyRp+/bt2rp1q4YMGSJJcrlc2rhxoy677DINHjxYbdq0UUxMjN55551T7rdmzRqFhIToiiuuUFJSkioqKmr1Xs4FEh8AAADgPJGamqqgoCCPX2pqapV9Dxw4oMrKSoWGhnq0h4aGqrS0tMprxowZo0ceeUQDBgyQn5+fLrnkEg0cOFAPPfSQ1Wf27NkaPXq0Lr/8cvn5+alnz56aPn26xo4dK0kqKyvTn3/+qfnz5+v666/X5s2bNWLECMXHxysnJ8fjXq+++qqys7OVlJSkV155RePGjTvbV1RrLHUDAAAA3Hnx//gkJSVp5syZHm0BAQHnbPwtW7boiSee0NKlSxUTE6Pvv/9e06ZN06OPPqrk5GRJ0htvvKE1a9botddeU5cuXVRUVKTp06crIiJCCQkJcrlOLgWMi4vTjBkzJEk9evTQ559/ruXLl+s///mPJGny5MnWfbt27arw8HANGjRIJSUlVS6Lq2skPgAAAMB5IiAgoMaJTkhIiHx9fbV//36P9v3791f7XU1ycrJuu+023XnnnZJOJiTl5eWaPHmyHn74Yfn4+GjWrFlW1efvPj///LNSU1OVkJCgkJAQNWrUSJ07d/YYu1OnTtq6dWu1842JiZEkff/9915JfFjqBgAAALhrINtZ+/v7Kzo6WllZWf8/dZdLWVlZcjqdVV5TUVEhHx/PFMDX11eSrO2qq+vzd6XH399fvXv3VnFxsUefPXv2qH379tXOt6ioSJIUHh5eg6c796j4AAAAAA3UzJkzlZCQoCuvvFJ9+vTRM888o/LycmuXt/Hjx+vCCy+0vhMaNmyY0tLS1LNnT2upW3JysoYNG2YlQMOGDdPjjz+uyMhIdenSRYWFhUpLS9OECROs+86aNUujRo3SVVddpauvvlqZmZl69913tWXLFkknt7t+7bXXNHToUAUHB2vHjh2aMWOGrrrqKnXr1q1+X9L/IfEBAAAA3HnxG59/a9SoUfrtt9+UkpKi0tJS9ejRQ5mZmdaGB3v37vWo3syZM0cOh0Nz5szRL7/8otatW1uJzt8WL16s5ORkTZkyRWVlZYqIiNBdd92llJQUq8+IESO0fPlypaam6r777lPHjh311ltvacCAAZJOVoU++ugjKxFr166dRo4cqTlz5tTTmzmVw/zzX7DaQJ+ENG9PAWiQVjz6tLenADRI456ZeeZOADzsTJvh7SlUa0i7aV6796b/WeS1e9sd3/gAAAAAsD2WugEAAADu7LcgCqLiAwAAAOC/ABUfAAAAwB0VH1ui4gMAAADA9kh8AAAAANgeS90AAAAAdy6Xt2eAOkDFBwAAAIDtUfEBAAAA3LG5gS1R8QEAAABge1R8AAAAAHdUfGyJig8AAAAA2yPxAQAAAGB7LHUDAAAA3LlY6mZHVHwAAAAA2B4VHwAAAMCNMfwDUzui4gMAAADA9kh8AAAAANgeS90AAAAAd2xuYEtUfAAAAADYHhUfAAAAwJ2h4mNHVHwAAAAA2B6JDwAAAADbY6kbAAAA4M7F//GxIyo+AAAAAGyPig8AAADgjs0NbImKDwAAAADbo+IDAAAAuDF842NLVHwAAAAA2B6JDwAAAADbY6kbAAAA4I7NDWyJig8AAAAA26PiAwAAALhzUfGxIyo+AAAAAGyPxAcAAACA7bHUDQAAAHBn+D8+dkTFBwAAAIDtUfEBAAAA3Bg2N7AlKj4AAAAAbI+KDwAAAOCOb3xsiYoPAAAAANsj8QEAAABgeyx1AwAAANywuYE9UfEBAAAAYHtUfAAAAAB3bG5gS1R8AAAAANgeiQ8AAAAA23MYY/h6C/Xm2LFjSk1NVVJSkgICArw9HaBBIG6A2iF2ALgj8UG9Onz4sIKCgnTo0CE1b97c29MBGgTiBqgdYgeAO5a6AQAAALA9Eh8AAAAAtkfiAwAAAMD2SHxQrwICAjR37lw+MgX+BeIGqB1iB4A7NjcAAAAAYHtUfAAAAADYHokPAAAAANsj8QEAAABgeyQ+AAAAAGyPxAe19sknn2jYsGGKiIiQw+HQO++843HeGKOUlBSFh4ercePGio2N1XfffXfGcZcsWaKLLrpIgYGBiomJ0bZt2+roCYD6l5qaqt69e6tZs2Zq06aNhg8fruLiYo8+R48eVWJiooKDg9W0aVONHDlS+/fvP+24tY03oKFYtmyZunXrpubNm6t58+ZyOp3atGmTdZ64AXAmJD6otfLycnXv3l1Lliyp8vyCBQv07LPPavny5crPz9cFF1ygwYMH6+jRo9WO+frrr2vmzJmaO3euvvrqK3Xv3l2DBw9WWVlZXT0GUK9ycnKUmJiovLw8ffjhhzpx4oSuu+46lZeXW31mzJihd999V+vWrVNOTo5+/fVXxcfHn3bc2sQb0JC0bdtW8+fPV0FBgb788ktdc801iouL0zfffCOJuAFQAwY4BySZ9evXW8cul8uEhYWZhQsXWm0HDx40AQEBZu3atdWO06dPH5OYmGgdV1ZWmoiICJOamlon8wa8rayszEgyOTk5xpiTceLn52fWrVtn9dm9e7eRZHJzc6sco7bxBjR0LVu2NC+++CJxA6BGqPigTvz4448qLS1VbGys1RYUFKSYmBjl5uZWec3x48dVUFDgcY2Pj49iY2OrvQZo6A4dOiRJatWqlSSpoKBAJ06c8IiDyy+/XJGRkdXGQW3iDWjIKisrlZGRofLycjmdTuIGQI008vYEYE+lpaWSpNDQUI/20NBQ69w/HThwQJWVlVVe8+2339bNRAEvcrlcmj59uvr3768rrrhC0snY8ff3V4sWLTz6ni52ahNvQEO0c+dOOZ1OHT16VE2bNtX69evVuXNnFRUVETcAzojEBwC8JDExUV9//bW2bt3q7akADULHjh1VVFSkQ4cO6c0331RCQoJycnK8PS0ADQRL3VAnwsLCJOmUHXX2799vnfunkJAQ+fr6/qtrgIZq6tSpeu+995Sdna22bdta7WFhYTp+/LgOHjzo0f90cVCbeAMaIn9/f3Xo0EHR0dFKTU1V9+7dtWjRIuIGQI2Q+KBOREVFKSwsTFlZWVbb4cOHlZ+fL6fTWeU1/v7+io6O9rjG5XIpKyur2muAhsYYo6lTp2r9+vX6+OOPFRUV5XE+Ojpafn5+HnFQXFysvXv3VhsHtYk3wA5cLpeOHTtG3ACoGW/vroCG648//jCFhYWmsLDQSDJpaWmmsLDQ/Pzzz8YYY+bPn29atGhhNmzYYHbs2GHi4uJMVFSUOXLkiDXGNddcYxYvXmwdZ2RkmICAAJOenm527dplJk+ebFq0aGFKS0vr/fmAunDPPfeYoKAgs2XLFrNv3z7rV1FRYfW5++67TWRkpPn444/Nl19+aZxOp3E6nR7jdOzY0bz99tvWcU3iDWjIZs+ebXJycsyPP/5oduzYYWbPnm0cDofZvHmzMYa4AXBmJD6otezsbCPplF9CQoIx5uRWocnJySY0NNQEBASYQYMGmeLiYo8x2rdvb+bOnevRtnjxYhMZGWn8/f1Nnz59TF5eXj09EVD3qooZSebll1+2+hw5csRMmTLFtGzZ0jRp0sSMGDHC7Nu375Rx3K+pSbwBDdmECRNM+/btjb+/v2ndurUZNGiQlfQYQ9wAODOHMcZ4o9IEAAAAAPWFb3wAAAAA2B6JDwAAAADbI/EBAAAAYHskPgAAAABsj8QHAAAAgO2R+AAAAACwPRIfAAAAALZH4gMAAADA9kh8AKABSk9PV4sWLerlXrfffruGDx9eL/cCAKCukPgAACRJP/30kxwOh4qKirw9FQAAzjkSHwAAAAC2R+IDAP8wcOBA3XvvvZo+fbpatmyp0NBQrVixQuXl5brjjjvUrFkzdejQQZs2bZIkVVZWauLEiYqKilLjxo3VsWNHLVq0yBrv6NGj6tKliyZPnmy1lZSUqFmzZlq5cmWN5pSenq7IyEg1adJEI0aM0O+//35Knw0bNqhXr14KDAzUxRdfrHnz5umvv/6yzjscDi1btkxDhgxR48aNdfHFF+vNN9+0zkdFRUmSevbsKYfDoYEDB3qM/+STTyo8PFzBwcFKTEzUiRMnajR3AADOByQ+AFCFVatWKSQkRNu2bdO9996re+65RzfffLP69eunr776Stddd51uu+02VVRUyOVyqW3btlq3bp127dqllJQUPfTQQ3rjjTckSYGBgVqzZo1WrVqlDRs2qLKyUuPGjdO1116rCRMmnHEu+fn5mjhxoqZOnaqioiJdffXVeuyxxzz6fPrppxo/frymTZumXbt26fnnn1d6eroef/xxj37JyckaOXKktm/frrFjx2r06NHavXu3JGnbtm2SpI8++kj79u3T22+/bV2XnZ2tkpISZWdna9WqVUpPT1d6evrZvGIAAOqVwxhjvD0JADifDBw4UJWVlfr0008lnazoBAUFKT4+XqtXr5YklZaWKjw8XLm5uerbt+8pY0ydOlWlpaUeFZWFCxdqwYIFGj16tN566y3t3LlTwcHBZ5zPmDFjdOjQIW3cuNFqGz16tDIzM3Xw4EFJUmxsrAYNGqSkpCSrz6uvvqoHH3xQv/76q6STFZ+7775by5Yts/r07dtXvXr10tKlS/XTTz8pKipKhYWF6tGjh9Xn9ttv15YtW1RSUiJfX19J0i233CIfHx9lZGSccf4AAJwPqPgAQBW6detm/e3r66vg4GB17drVagsNDZUklZWVSZKWLFmi6OhotW7dWk2bNtULL7ygvXv3eox5//3367LLLtNzzz2nlStX1ijpkaTdu3crJibGo83pdHocb9++XY888oiaNm1q/SZNmqR9+/apoqKi2uucTqdV8TmdLl26WEmPJIWHh1vPDgBAQ9DI2xMAgPORn5+fx7HD4fBoczgckiSXy6WMjAw98MADeuqpp+R0OtWsWTMtXLhQ+fn5HmOUlZVpz5498vX11Xfffafrr7/+nM33zz//1Lx58xQfH3/KucDAwLMev6r34XK5znpcAADqC4kPAJylzz77TP369dOUKVOstpKSklP6TZgwQV27dtXEiRM1adIkxcbGqlOnTmccv1OnTqckUXl5eR7HvXr1UnFxsTp06HDasfLy8jR+/HiP4549e0qS/P39JZ1c2gcAgN2Q+ADAWbr00ku1evVqffDBB4qKitIrr7yiL774wtolTTq5FC43N1c7duxQu3bttHHjRo0dO1Z5eXlWwlGd++67T/3799eTTz6puLg4ffDBB8rMzPTok5KSohtvvFGRkZG66aab5OPjo+3bt+vrr7/22Ahh3bp1uvLKKzVgwACtWbNG27Zt00svvSRJatOmjRo3bqzMzEy1bdtWgYGBCgoKOodvCgAA7+EbHwA4S3fddZfi4+M1atQoxcTE6Pfff/eo/nz77beaNWuWli5dqnbt2kmSli5dqgMHDig5OfmM4/ft21crVqzQokWL1L17d23evFlz5szx6DN48GC999572rx5s3r37q2+ffvq6aefVvv27T36zZs3TxkZGerWrZtWr16ttWvXqnPnzpKkRo0a6dlnn9Xzzz+viIgIxcXFne2rAQDgvMGubgDwX8LhcGj9+vUaPny4t6cCAEC9o+IDAAAAwPZIfADAy4YMGeKxDbX774knnvD29AAAsAWWugGAl/3yyy86cuRIledatWqlVq1a1fOMAACwHxIfAAAAALbHUjcAAAAAtkfiAwAAAMD2SHwAAAAA2B6JDwAAAADbI/EBAAAAYHskPgAAAABsj8QHAAAAgO39L5xYJvf91f+oAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_sets = ['vegas', 'taiwan', 'money', 'diabetes']\n",
    "\n",
    "for dataset in data_sets:\n",
    "    # initialize a list to collect results for each data set\n",
    "    dataset_results = []\n",
    "    \n",
    "    # get the n_estimators, max_depth and mean test score for each random forest classifier across all data sets\n",
    "    for j in range(len(results_summary[dataset + ' random_forest'])):\n",
    "        cv_results = results_summary[dataset + ' random_forest'][j]['cv_results']\n",
    "        # Collect the parameters and mean test scores\n",
    "        df = pd.DataFrame({\n",
    "            'n_estimators': cv_results['param_classifier__n_estimators'],\n",
    "            'max_depth': cv_results['param_classifier__max_depth'],\n",
    "            'mean_test_score': cv_results['mean_test_score']\n",
    "        })\n",
    "        dataset_results.append(df)\n",
    "    \n",
    "    # concatenate the resutls to dataset results\n",
    "    dataset_results = pd.concat(dataset_results)\n",
    "    heatmap_data = dataset_results.groupby(['n_estimators', 'max_depth'])['mean_test_score'].mean().unstack()\n",
    "    \n",
    "  \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(heatmap_data, annot=True, fmt=\".3f\", cmap='viridis', cbar_kws={'label': 'Mean Test Score'})\n",
    "    plt.title(f'Average Heatmap of n_estimators and max_depth for {dataset}')\n",
    "    plt.xlabel('max_depth')\n",
    "    plt.ylabel('n_estimators')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary['vegas log_reg'][0]['cv_results']['param_classifier__max_iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize accumulators for averaging across all classifiers and datasets\n",
    "all_split_ratios = {}\n",
    "\n",
    "for classifier, results in results_summary.items():\n",
    "    for result in results:\n",
    "        split_ratio = result['split_ratio']\n",
    "        if split_ratio not in all_split_ratios:\n",
    "            all_split_ratios[split_ratio] = {\n",
    "                'train_accuracies': [],\n",
    "                'validation_accuracies': [],\n",
    "                'test_accuracies': []\n",
    "            }\n",
    "        all_split_ratios[split_ratio]['train_accuracies'].append(result['train_accuracy'])\n",
    "        all_split_ratios[split_ratio]['validation_accuracies'].append(result['best_validation_accuracy'])\n",
    "        all_split_ratios[split_ratio]['test_accuracies'].append(result['test_accuracy'])\n",
    "\n",
    "# Compute the averages for each split ratio\n",
    "split_ratios = sorted(all_split_ratios.keys())\n",
    "average_train_accuracies = [\n",
    "    sum(all_split_ratios[ratio]['train_accuracies']) / len(all_split_ratios[ratio]['train_accuracies'])\n",
    "    for ratio in split_ratios\n",
    "]\n",
    "average_validation_accuracies = [\n",
    "    sum(all_split_ratios[ratio]['validation_accuracies']) / len(all_split_ratios[ratio]['validation_accuracies'])\n",
    "    for ratio in split_ratios\n",
    "]\n",
    "average_test_accuracies = [\n",
    "    sum(all_split_ratios[ratio]['test_accuracies']) / len(all_split_ratios[ratio]['test_accuracies'])\n",
    "    for ratio in split_ratios\n",
    "]\n",
    "\n",
    "# Create a single averaged line plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(split_ratios, average_train_accuracies, marker='o', color = '#2ecc71',  label='Average Training Accuracy')\n",
    "plt.plot(split_ratios, average_validation_accuracies, marker='o', color = '#3498db', label='Average Validation Accuracy')\n",
    "plt.plot(split_ratios, average_test_accuracies, marker='o', color = '#9b59b6', label='Average Test Accuracy')\n",
    "\n",
    "plt.xticks(split_ratios, [f\"Split {ratio}\" for ratio in split_ratios])\n",
    "plt.xlabel('Dataset Split Ratios')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Averaged Performance Metrics Across All Classifiers and Datasets')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vegas random_forest': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__max_depth': None,\n",
       "    'classifier__min_samples_leaf': 1,\n",
       "    'classifier__min_samples_split': 10,\n",
       "    'classifier__n_estimators': 300},\n",
       "   'best_validation_accuracy': 0.7902554961378492,\n",
       "   'train_accuracy': 0.86,\n",
       "   'test_accuracy': 0.7722772277227723,\n",
       "   'cv_results': {'mean_fit_time': [0.22405322392781576,\n",
       "     0.4889212449391683,\n",
       "     0.782522996266683,\n",
       "     0.3042000929514567,\n",
       "     0.5971498489379883,\n",
       "     0.7883925437927246,\n",
       "     0.2560574213663737,\n",
       "     0.5661787986755371,\n",
       "     0.7186117966969808,\n",
       "     0.22861901919047037,\n",
       "     0.5213337739308676,\n",
       "     0.6870508988698324,\n",
       "     0.25809383392333984,\n",
       "     0.40688490867614746,\n",
       "     0.6349324385325114,\n",
       "     0.2256192366282145,\n",
       "     0.3967307408650716,\n",
       "     0.5843359629313151,\n",
       "     0.21860726674397787,\n",
       "     0.37280774116516113,\n",
       "     0.5845090548197428,\n",
       "     0.2126945654551188,\n",
       "     0.3978671232859294,\n",
       "     0.5941394170125326,\n",
       "     0.21021596590677896,\n",
       "     0.40277568499247235,\n",
       "     0.5708474318186442,\n",
       "     0.21811302502950033,\n",
       "     0.3969842592875163,\n",
       "     0.6109654903411865,\n",
       "     0.2178971767425537,\n",
       "     0.39219196637471515,\n",
       "     0.5910411675771078,\n",
       "     0.20399880409240723,\n",
       "     0.3853265444437663,\n",
       "     0.581070343653361,\n",
       "     0.20287219683329263,\n",
       "     0.420332670211792,\n",
       "     0.5845709641774496,\n",
       "     0.20121145248413086,\n",
       "     0.3920904000600179,\n",
       "     0.5850013891855875,\n",
       "     0.2130893071492513,\n",
       "     0.3896325429280599,\n",
       "     0.5917754173278809,\n",
       "     0.1993406613667806,\n",
       "     0.3847213586171468,\n",
       "     0.6105794906616211,\n",
       "     0.2099486986796061,\n",
       "     0.3831659158070882,\n",
       "     0.5951231320699056,\n",
       "     0.20054523150126138,\n",
       "     0.3809088071187337,\n",
       "     0.6020089785257975,\n",
       "     0.2182297706604004,\n",
       "     0.4084923267364502,\n",
       "     0.6121548016866049,\n",
       "     0.1996182600657145,\n",
       "     0.4104321002960205,\n",
       "     0.5812430381774902,\n",
       "     0.2054747740427653,\n",
       "     0.3920580546061198,\n",
       "     0.5779008070627848,\n",
       "     0.203173557917277,\n",
       "     0.40562065442403156,\n",
       "     0.5659089883168539,\n",
       "     0.20334776242574057,\n",
       "     0.3897858460744222,\n",
       "     0.5932415326436361,\n",
       "     0.21026611328125,\n",
       "     0.39833545684814453,\n",
       "     0.5912040074666342,\n",
       "     0.2032341162363688,\n",
       "     0.3627306620279948,\n",
       "     0.571644147237142,\n",
       "     0.21030394236246744,\n",
       "     0.38422807057698566,\n",
       "     0.6005181471506754,\n",
       "     0.20734556516011557,\n",
       "     0.37879157066345215,\n",
       "     0.581184466679891,\n",
       "     0.21254142125447592,\n",
       "     0.3923235734303792,\n",
       "     0.6453280448913574,\n",
       "     0.21062064170837402,\n",
       "     0.3993012110392253,\n",
       "     0.6277528603871664,\n",
       "     0.21676174799601236,\n",
       "     0.3997189203898112,\n",
       "     0.5922793547312418,\n",
       "     0.2055678367614746,\n",
       "     0.39997442563374835,\n",
       "     0.5847623348236084,\n",
       "     0.20850610733032227,\n",
       "     0.38296953837076825,\n",
       "     0.5832961400349935,\n",
       "     0.19833811124165854,\n",
       "     0.3936620553334554,\n",
       "     0.6077659924825033,\n",
       "     0.20031269391377768,\n",
       "     0.3915213743845622,\n",
       "     0.573890765508016,\n",
       "     0.194838285446167,\n",
       "     0.37946001688639325,\n",
       "     0.5888199011484782,\n",
       "     0.1989738941192627,\n",
       "     0.3543907006581624,\n",
       "     0.44367138544718426],\n",
       "    'std_fit_time': [0.007470883151373532,\n",
       "     0.06989002348056142,\n",
       "     0.15126879249403646,\n",
       "     0.06114237463115696,\n",
       "     0.12596658120763812,\n",
       "     0.09137033452190932,\n",
       "     0.01952463078987667,\n",
       "     0.06409140444195688,\n",
       "     0.09947409272264386,\n",
       "     0.0062530167034213924,\n",
       "     0.07523875569611156,\n",
       "     0.07936047351593128,\n",
       "     0.022102145254876422,\n",
       "     0.026751065456349907,\n",
       "     0.04744903967518066,\n",
       "     0.01087614988347848,\n",
       "     0.0066812371446010885,\n",
       "     0.02678896859727788,\n",
       "     0.011895299332085576,\n",
       "     0.009805544600262797,\n",
       "     0.02788610182411745,\n",
       "     0.007603185880679727,\n",
       "     0.01717883819213046,\n",
       "     0.023419935997341535,\n",
       "     0.005558972247493286,\n",
       "     0.01702033233593626,\n",
       "     0.014823074475431425,\n",
       "     0.010985692410538322,\n",
       "     0.013332585785166037,\n",
       "     0.02320866582862532,\n",
       "     0.00735850257521401,\n",
       "     0.012767103222424645,\n",
       "     0.02061453921416014,\n",
       "     0.007633828196116937,\n",
       "     0.012608950033793764,\n",
       "     0.01803238706790428,\n",
       "     0.010937413210947622,\n",
       "     0.009638232331233051,\n",
       "     0.01873500112724579,\n",
       "     0.001322865924796173,\n",
       "     0.02132078452563527,\n",
       "     0.018932823039693434,\n",
       "     0.0035519116093060913,\n",
       "     0.01053381397229536,\n",
       "     0.010368525344413812,\n",
       "     0.006608344988659611,\n",
       "     0.012933548707370405,\n",
       "     0.022875139416936235,\n",
       "     0.016635999493598713,\n",
       "     0.012394597575304903,\n",
       "     0.024044683152221993,\n",
       "     0.006382823607754673,\n",
       "     0.007679717756665038,\n",
       "     0.014616595003081287,\n",
       "     0.015073452814360217,\n",
       "     0.03596252581622479,\n",
       "     0.0158544935585535,\n",
       "     0.0011327948963768025,\n",
       "     0.02887800530188088,\n",
       "     0.015807643836453496,\n",
       "     0.007826145575358052,\n",
       "     0.005750816028043789,\n",
       "     0.03398924393189509,\n",
       "     0.009983331322681048,\n",
       "     0.007856284954026677,\n",
       "     0.011869829046314884,\n",
       "     0.0121649392278366,\n",
       "     0.010040272322277109,\n",
       "     0.021064236469732874,\n",
       "     0.002132135785430732,\n",
       "     0.01489087233800525,\n",
       "     0.006301681673605599,\n",
       "     0.009840638448612203,\n",
       "     0.0070934670802314205,\n",
       "     0.025485931540242323,\n",
       "     0.007806499632324887,\n",
       "     0.001199347773114336,\n",
       "     0.027938323310231807,\n",
       "     0.007758457673081451,\n",
       "     0.003834169341001586,\n",
       "     0.013273040064290668,\n",
       "     0.009058851691715957,\n",
       "     0.008100744078393058,\n",
       "     0.00973096301452547,\n",
       "     0.023333281797999088,\n",
       "     0.013600524624224078,\n",
       "     0.034472589838333116,\n",
       "     0.013471148982871852,\n",
       "     0.012420563254738202,\n",
       "     0.030014642108651436,\n",
       "     0.00782870227150322,\n",
       "     0.01359454092490509,\n",
       "     0.020802011952584958,\n",
       "     0.007284132108323647,\n",
       "     0.018812721598837328,\n",
       "     0.013594548582333098,\n",
       "     0.0023331371419670647,\n",
       "     0.020578938615827814,\n",
       "     0.007222807151341059,\n",
       "     0.0004847640674248396,\n",
       "     0.006844387517600022,\n",
       "     0.030756148415773704,\n",
       "     0.007325796713881755,\n",
       "     0.009276655436916696,\n",
       "     0.019534116938243803,\n",
       "     0.0013216162281106765,\n",
       "     0.008788667641258985,\n",
       "     0.016176052411217626],\n",
       "    'mean_score_time': [0.020974397659301758,\n",
       "     0.049747467041015625,\n",
       "     0.05007290840148926,\n",
       "     0.031853834788004555,\n",
       "     0.057535012563069664,\n",
       "     0.05269304911295573,\n",
       "     0.02012189229329427,\n",
       "     0.04341276486714681,\n",
       "     0.06917945543924968,\n",
       "     0.022986729939778645,\n",
       "     0.03661553064982096,\n",
       "     0.04715704917907715,\n",
       "     0.02097495396931966,\n",
       "     0.036469618479410805,\n",
       "     0.04409639040629069,\n",
       "     0.020831902821858723,\n",
       "     0.03308399518330892,\n",
       "     0.04212657610575358,\n",
       "     0.015406211217244467,\n",
       "     0.03138653437296549,\n",
       "     0.0420218308766683,\n",
       "     0.01816733678181966,\n",
       "     0.034253438313802086,\n",
       "     0.05200997988382975,\n",
       "     0.022301514943440754,\n",
       "     0.026405811309814453,\n",
       "     0.04785633087158203,\n",
       "     0.02498594919840495,\n",
       "     0.0314027468363444,\n",
       "     0.05021198590596517,\n",
       "     0.015625158945719402,\n",
       "     0.03845437367757162,\n",
       "     0.045839786529541016,\n",
       "     0.017630894978841145,\n",
       "     0.03561663627624512,\n",
       "     0.03811319669087728,\n",
       "     0.026068687438964844,\n",
       "     0.03018983205159505,\n",
       "     0.03585513432820638,\n",
       "     0.020977179209391277,\n",
       "     0.02633515993754069,\n",
       "     0.043819586435953774,\n",
       "     0.017496506373087566,\n",
       "     0.034651597340901695,\n",
       "     0.042648633321126304,\n",
       "     0.015095154444376627,\n",
       "     0.026179154713948567,\n",
       "     0.03962349891662598,\n",
       "     0.01576821009318034,\n",
       "     0.03093091646830241,\n",
       "     0.04632488886515299,\n",
       "     0.018316030502319336,\n",
       "     0.03381792704264323,\n",
       "     0.04246274630228678,\n",
       "     0.021835168202718098,\n",
       "     0.02732237180074056,\n",
       "     0.04116384188334147,\n",
       "     0.028037468592325848,\n",
       "     0.03675222396850586,\n",
       "     0.041337172190348305,\n",
       "     0.0182799498240153,\n",
       "     0.03281935056050619,\n",
       "     0.03928414980570475,\n",
       "     0.026311397552490234,\n",
       "     0.03499690691630045,\n",
       "     0.0404206911722819,\n",
       "     0.026136477788289387,\n",
       "     0.027953704198201496,\n",
       "     0.03440443674723307,\n",
       "     0.017346779505411785,\n",
       "     0.029955228169759113,\n",
       "     0.041843255360921226,\n",
       "     0.016642967859903973,\n",
       "     0.033249219258626304,\n",
       "     0.03995108604431152,\n",
       "     0.022528727849324543,\n",
       "     0.03336787223815918,\n",
       "     0.043984572092692055,\n",
       "     0.019867579142252605,\n",
       "     0.030586957931518555,\n",
       "     0.04163201649983724,\n",
       "     0.020847082138061523,\n",
       "     0.029118696848551433,\n",
       "     0.04503639539082845,\n",
       "     0.013472954432169596,\n",
       "     0.028653303782145183,\n",
       "     0.03855578104654948,\n",
       "     0.01716891924540202,\n",
       "     0.033968051274617515,\n",
       "     0.043311754862467446,\n",
       "     0.01975695292154948,\n",
       "     0.033381382624308266,\n",
       "     0.03886620203653971,\n",
       "     0.02105991045633952,\n",
       "     0.023084004720052082,\n",
       "     0.05748446782430013,\n",
       "     0.021370331446329754,\n",
       "     0.028514385223388672,\n",
       "     0.04017829895019531,\n",
       "     0.016706466674804688,\n",
       "     0.0370629628499349,\n",
       "     0.04525629679361979,\n",
       "     0.02853981653849284,\n",
       "     0.033370256423950195,\n",
       "     0.027309497197469074,\n",
       "     0.015841007232666016,\n",
       "     0.01670670509338379,\n",
       "     0.020298560460408527],\n",
       "    'std_score_time': [0.007554572875350747,\n",
       "     0.00553239508603285,\n",
       "     0.013270602609586171,\n",
       "     0.010737487406697605,\n",
       "     0.019555961746946966,\n",
       "     0.008228301146093877,\n",
       "     0.006335963834541707,\n",
       "     0.009165866402455125,\n",
       "     0.018411506506137407,\n",
       "     0.010385938805755371,\n",
       "     0.007563569324795396,\n",
       "     0.0001869664856551972,\n",
       "     0.007270441482608627,\n",
       "     0.0073703645321219645,\n",
       "     0.0070251572278680965,\n",
       "     0.007364515634304548,\n",
       "     0.0018198276787536485,\n",
       "     0.007327089357509819,\n",
       "     0.005727533812629506,\n",
       "     0.0001944374611302578,\n",
       "     0.01312549557321992,\n",
       "     0.003582768688497036,\n",
       "     0.004250369585155898,\n",
       "     0.008019910480463074,\n",
       "     0.005558972247493287,\n",
       "     0.003479110385834889,\n",
       "     0.0010988385292953892,\n",
       "     0.007096441651244932,\n",
       "     0.0002015893902718203,\n",
       "     0.004065315093179608,\n",
       "     1.1239159602905073e-06,\n",
       "     0.006576875768735252,\n",
       "     0.005746031204717607,\n",
       "     0.010409546297748226,\n",
       "     0.006393478805285818,\n",
       "     0.00643158494086481,\n",
       "     0.0073665947701281025,\n",
       "     0.00075302369339464,\n",
       "     0.0029511785285308146,\n",
       "     0.007277942214381963,\n",
       "     0.007573395306821556,\n",
       "     0.0032834525806829788,\n",
       "     0.002598156525403566,\n",
       "     0.011096573534562094,\n",
       "     0.009536876489449073,\n",
       "     0.0007625063604042474,\n",
       "     0.007173618399746222,\n",
       "     0.006611489775214279,\n",
       "     0.00018821737076115148,\n",
       "     0.01244703917313986,\n",
       "     0.0022446018508641983,\n",
       "     0.009657413907774465,\n",
       "     0.001344428271699505,\n",
       "     0.00711693177959801,\n",
       "     0.007155053689459293,\n",
       "     0.008458860305158132,\n",
       "     0.007016570696160993,\n",
       "     0.008105095316982808,\n",
       "     0.004592082802816108,\n",
       "     0.006510592563961255,\n",
       "     0.001981694195498679,\n",
       "     0.01138352919393349,\n",
       "     0.007694213812411188,\n",
       "     0.007091464858984252,\n",
       "     0.0026255794782608995,\n",
       "     0.007796073509464568,\n",
       "     0.006008052044095761,\n",
       "     0.010233267722794375,\n",
       "     0.000904844511429294,\n",
       "     0.0004998054275411887,\n",
       "     0.00434649671104626,\n",
       "     0.007806979236312854,\n",
       "     4.9376763385457816e-05,\n",
       "     3.821314264987726e-05,\n",
       "     0.007862848408474373,\n",
       "     0.007991399145463339,\n",
       "     6.00171122795131e-05,\n",
       "     0.008734971868237013,\n",
       "     0.002457277332097405,\n",
       "     0.010365615961210894,\n",
       "     0.00611637073744982,\n",
       "     0.009059357871238809,\n",
       "     0.005784345881231125,\n",
       "     0.007002304827095108,\n",
       "     0.0028320789162761175,\n",
       "     0.006500171326046677,\n",
       "     0.007347096133811492,\n",
       "     0.0010319796347387441,\n",
       "     0.0008971709892770791,\n",
       "     0.011052856124313207,\n",
       "     0.004444898140319921,\n",
       "     5.776928035893209e-05,\n",
       "     0.007125192280652512,\n",
       "     0.003283582920803877,\n",
       "     0.0072631523548105795,\n",
       "     0.005953149405444903,\n",
       "     0.008786220325920305,\n",
       "     0.006777047606305741,\n",
       "     0.004153995035879743,\n",
       "     5.630818961055443e-05,\n",
       "     0.009981731584319422,\n",
       "     0.0069793696933843595,\n",
       "     0.008448161379037662,\n",
       "     0.003578935129304151,\n",
       "     0.006605871475805705,\n",
       "     0.001044227234011118,\n",
       "     5.866841312716449e-05,\n",
       "     0.004453239917829532],\n",
       "    'param_classifier__max_depth': [None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30],\n",
       "    'param_classifier__min_samples_leaf': [1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10],\n",
       "    'param_classifier__n_estimators': [100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300],\n",
       "    'params': [{'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300}],\n",
       "    'split0_test_score': [0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411],\n",
       "    'split1_test_score': [0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878],\n",
       "    'split2_test_score': [0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878],\n",
       "    'mean_test_score': [0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368391,\n",
       "     0.7801544860368389,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7902554961378492,\n",
       "     0.7700534759358288,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7902554961378492,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7902554961378492,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7801544860368389,\n",
       "     0.7902554961378492,\n",
       "     0.7801544860368391,\n",
       "     0.7902554961378492,\n",
       "     0.7801544860368391,\n",
       "     0.7801544860368389,\n",
       "     0.7902554961378492,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7700534759358288,\n",
       "     0.7801544860368391,\n",
       "     0.7801544860368389,\n",
       "     0.7902554961378492,\n",
       "     0.7801544860368389,\n",
       "     0.7700534759358288,\n",
       "     0.7902554961378492,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7902554961378492,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7700534759358288,\n",
       "     0.7801544860368389,\n",
       "     0.7700534759358288,\n",
       "     0.7902554961378492,\n",
       "     0.7902554961378492,\n",
       "     0.7902554961378492,\n",
       "     0.7902554961378492,\n",
       "     0.7902554961378492,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389],\n",
       "    'std_test_score': [0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.02704648051513026,\n",
       "     0.010923812424747622,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.02189604964074666,\n",
       "     0.012936150360711367,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.02189604964074666,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.02189604964074666,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.010923812424747622,\n",
       "     0.02189604964074666,\n",
       "     0.02704648051513026,\n",
       "     0.02189604964074666,\n",
       "     0.02704648051513026,\n",
       "     0.010923812424747622,\n",
       "     0.02189604964074666,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.012936150360711367,\n",
       "     0.02704648051513026,\n",
       "     0.010923812424747622,\n",
       "     0.02189604964074666,\n",
       "     0.010923812424747622,\n",
       "     0.012936150360711367,\n",
       "     0.02189604964074666,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.02189604964074666,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.012936150360711367,\n",
       "     0.010923812424747622,\n",
       "     0.012936150360711367,\n",
       "     0.02189604964074666,\n",
       "     0.02189604964074666,\n",
       "     0.02189604964074666,\n",
       "     0.02189604964074666,\n",
       "     0.02189604964074666,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622],\n",
       "    'rank_test_score': [19,\n",
       "     19,\n",
       "     19,\n",
       "     15,\n",
       "     19,\n",
       "     90,\n",
       "     90,\n",
       "     90,\n",
       "     1,\n",
       "     90,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     1,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     90,\n",
       "     90,\n",
       "     90,\n",
       "     1,\n",
       "     90,\n",
       "     90,\n",
       "     90,\n",
       "     90,\n",
       "     19,\n",
       "     1,\n",
       "     15,\n",
       "     1,\n",
       "     15,\n",
       "     19,\n",
       "     1,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     90,\n",
       "     90,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     90,\n",
       "     15,\n",
       "     19,\n",
       "     1,\n",
       "     19,\n",
       "     90,\n",
       "     1,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     1,\n",
       "     19,\n",
       "     19,\n",
       "     90,\n",
       "     90,\n",
       "     19,\n",
       "     19,\n",
       "     90,\n",
       "     19,\n",
       "     90,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19,\n",
       "     19]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__max_depth': 10,\n",
       "    'classifier__min_samples_leaf': 1,\n",
       "    'classifier__min_samples_split': 5,\n",
       "    'classifier__n_estimators': 100},\n",
       "   'best_validation_accuracy': 0.7857142857142857,\n",
       "   'train_accuracy': 0.873015873015873,\n",
       "   'test_accuracy': 0.7738095238095238,\n",
       "   'cv_results': {'mean_fit_time': [0.2172714869181315,\n",
       "     0.43515880902608234,\n",
       "     0.646894613901774,\n",
       "     0.2050189971923828,\n",
       "     0.4667486349741618,\n",
       "     0.6622885862986246,\n",
       "     0.2514139811197917,\n",
       "     0.42413942019144696,\n",
       "     0.6633943716684977,\n",
       "     0.22270099322001138,\n",
       "     0.41746719678243,\n",
       "     0.6497408548990885,\n",
       "     0.2315373420715332,\n",
       "     0.4331629276275635,\n",
       "     0.637131929397583,\n",
       "     0.23811841011047363,\n",
       "     0.4321463902791341,\n",
       "     0.6576247215270996,\n",
       "     0.218354860941569,\n",
       "     0.4078257878621419,\n",
       "     0.6138131618499756,\n",
       "     0.21484136581420898,\n",
       "     0.4214643637339274,\n",
       "     0.628819465637207,\n",
       "     0.2082509994506836,\n",
       "     0.4152352015177409,\n",
       "     0.6077573299407959,\n",
       "     0.22861305872599283,\n",
       "     0.4291369915008545,\n",
       "     0.6574675242106119,\n",
       "     0.22317941983540854,\n",
       "     0.41819365819295246,\n",
       "     0.6118013064066569,\n",
       "     0.2324387232462565,\n",
       "     0.43378011385599774,\n",
       "     0.6158639589945475,\n",
       "     0.21206863721211752,\n",
       "     0.4172827402750651,\n",
       "     0.6161172389984131,\n",
       "     0.21584486961364746,\n",
       "     0.42887481053670246,\n",
       "     0.6070644855499268,\n",
       "     0.22476832071940103,\n",
       "     0.39898475011189777,\n",
       "     0.623390277226766,\n",
       "     0.22655399640401205,\n",
       "     0.4129384358723958,\n",
       "     0.5963734785715739,\n",
       "     0.2046047846476237,\n",
       "     0.4253944555918376,\n",
       "     0.6222821076711019,\n",
       "     0.21669689814249674,\n",
       "     0.394370158513387,\n",
       "     0.6300985018412272,\n",
       "     0.2474994659423828,\n",
       "     0.4440193176269531,\n",
       "     0.6946554978688558,\n",
       "     0.21860035260518393,\n",
       "     0.4164375464121501,\n",
       "     0.6349494457244873,\n",
       "     0.21985610326131186,\n",
       "     0.42222754160563153,\n",
       "     0.6350372632344564,\n",
       "     0.21430309613545737,\n",
       "     0.4302676518758138,\n",
       "     0.629835844039917,\n",
       "     0.22302023569742838,\n",
       "     0.42993640899658203,\n",
       "     0.65464981396993,\n",
       "     0.22039206822713217,\n",
       "     0.4244693120320638,\n",
       "     0.6584270795186361,\n",
       "     0.219494899113973,\n",
       "     0.41865118344624835,\n",
       "     0.6203529834747314,\n",
       "     0.2138361930847168,\n",
       "     0.42959753672281903,\n",
       "     0.608167807261149,\n",
       "     0.21477063496907553,\n",
       "     0.42846107482910156,\n",
       "     0.6506945292154948,\n",
       "     0.22432327270507812,\n",
       "     0.41419458389282227,\n",
       "     0.6437277793884277,\n",
       "     0.23047137260437012,\n",
       "     0.45029664039611816,\n",
       "     0.6605374018351237,\n",
       "     0.22438200314839682,\n",
       "     0.44101373354593915,\n",
       "     0.6055976549784342,\n",
       "     0.22873846689860025,\n",
       "     0.42572609583536786,\n",
       "     0.6462821960449219,\n",
       "     0.21643845240275064,\n",
       "     0.420102596282959,\n",
       "     0.6240551471710205,\n",
       "     0.2166255315144857,\n",
       "     0.4176374276479085,\n",
       "     0.6133622328440348,\n",
       "     0.22116454442342123,\n",
       "     0.41510430971781415,\n",
       "     0.6367972691853842,\n",
       "     0.2094259262084961,\n",
       "     0.39182154337565106,\n",
       "     0.6241183280944824,\n",
       "     0.2221809228261312,\n",
       "     0.40841253598531085,\n",
       "     0.5680727958679199],\n",
       "    'std_fit_time': [0.004339512556227868,\n",
       "     0.012077695751999998,\n",
       "     0.047168416012883914,\n",
       "     0.005561688208775554,\n",
       "     0.023621566520617653,\n",
       "     0.023134894494589792,\n",
       "     0.003606002847929624,\n",
       "     0.019804075747487552,\n",
       "     0.014324806057529452,\n",
       "     0.007986054720862652,\n",
       "     0.012327888232814624,\n",
       "     0.03086658637449477,\n",
       "     0.015899338891534814,\n",
       "     0.01019496434882007,\n",
       "     0.032879510427474834,\n",
       "     0.007395676310329195,\n",
       "     0.012231092984460365,\n",
       "     0.014485077056309165,\n",
       "     0.0053063762353330315,\n",
       "     0.010792542886600585,\n",
       "     0.010274057615284138,\n",
       "     0.011193527560336166,\n",
       "     0.016007476847096688,\n",
       "     0.006685501698192055,\n",
       "     0.006412322996567248,\n",
       "     0.024733423336324698,\n",
       "     0.012810812999949048,\n",
       "     0.008414036350824338,\n",
       "     0.021622939274746154,\n",
       "     0.022210918339983385,\n",
       "     0.007977097036231012,\n",
       "     0.0011078181699563285,\n",
       "     0.015070843585954211,\n",
       "     0.010809269920219081,\n",
       "     0.014090705373221738,\n",
       "     0.013676695924832954,\n",
       "     0.009073976134594517,\n",
       "     0.02315970717617729,\n",
       "     0.02217841883574836,\n",
       "     0.005366007731800767,\n",
       "     0.015007048658818531,\n",
       "     0.021984907428826025,\n",
       "     0.010522021057186737,\n",
       "     0.02360237621900538,\n",
       "     0.007104793294065248,\n",
       "     0.009503712981754713,\n",
       "     0.021896747136629473,\n",
       "     0.007681924044691604,\n",
       "     0.010298412592635538,\n",
       "     0.020451942712908733,\n",
       "     0.028346266785199623,\n",
       "     0.013572138004856531,\n",
       "     0.007798967037902551,\n",
       "     0.02645374695637528,\n",
       "     0.024728328627645704,\n",
       "     0.02192316506311582,\n",
       "     0.020781971092779013,\n",
       "     0.008041804873426048,\n",
       "     0.006108033677794792,\n",
       "     0.022326032458110247,\n",
       "     0.002951875569020307,\n",
       "     0.020710522841887943,\n",
       "     0.011771409917644488,\n",
       "     0.014074734024357397,\n",
       "     0.023838381134154457,\n",
       "     0.012641167607388041,\n",
       "     0.019911046155286136,\n",
       "     0.0186574560789583,\n",
       "     0.021739501510921293,\n",
       "     0.014082464132536368,\n",
       "     0.017409471858815122,\n",
       "     0.02161581836214276,\n",
       "     0.016291081210704255,\n",
       "     0.015952497774016212,\n",
       "     0.01459385812273927,\n",
       "     0.01628519951550069,\n",
       "     0.022754462560189995,\n",
       "     0.039173616141783926,\n",
       "     0.00526149871801071,\n",
       "     0.02723884385520768,\n",
       "     0.024841100382660065,\n",
       "     0.010327049331606003,\n",
       "     0.006052126548725,\n",
       "     0.015531321363870362,\n",
       "     0.007400069413456348,\n",
       "     0.011940619738186711,\n",
       "     0.01598305601569786,\n",
       "     0.012665858522897845,\n",
       "     0.02993615525223356,\n",
       "     0.02079414415229118,\n",
       "     0.00979716608072586,\n",
       "     0.011578690251766511,\n",
       "     0.03966784671236142,\n",
       "     0.01200366493569101,\n",
       "     0.004869478289554653,\n",
       "     0.014586774148600849,\n",
       "     0.008345015078093718,\n",
       "     0.02292513144722891,\n",
       "     0.01891931302405398,\n",
       "     0.007534725488646933,\n",
       "     0.01443678567354822,\n",
       "     0.010560531956686828,\n",
       "     0.003438979998732824,\n",
       "     0.00701890318888725,\n",
       "     0.006090685104025027,\n",
       "     0.015723543612552154,\n",
       "     0.006275756119604727,\n",
       "     0.01559718391032097],\n",
       "    'mean_score_time': [0.01706687609354655,\n",
       "     0.03953202565511068,\n",
       "     0.05172999699910482,\n",
       "     0.02113517125447591,\n",
       "     0.04394984245300293,\n",
       "     0.045764525731404625,\n",
       "     0.02514195442199707,\n",
       "     0.03733539581298828,\n",
       "     0.042445103327433266,\n",
       "     0.018673419952392578,\n",
       "     0.041435798009236656,\n",
       "     0.05288958549499512,\n",
       "     0.02623780568440755,\n",
       "     0.03962953885396322,\n",
       "     0.04775094985961914,\n",
       "     0.022455612818400066,\n",
       "     0.03330834706624349,\n",
       "     0.03642908732096354,\n",
       "     0.017584800720214844,\n",
       "     0.0370786984761556,\n",
       "     0.05282139778137207,\n",
       "     0.026268641153971355,\n",
       "     0.03624320030212402,\n",
       "     0.04867736498514811,\n",
       "     0.015887896219889324,\n",
       "     0.03643051783243815,\n",
       "     0.04735922813415527,\n",
       "     0.017506202061971027,\n",
       "     0.035552978515625,\n",
       "     0.04248762130737305,\n",
       "     0.026431878407796223,\n",
       "     0.036478281021118164,\n",
       "     0.043578783671061196,\n",
       "     0.018795013427734375,\n",
       "     0.03732689221700033,\n",
       "     0.05591646830240885,\n",
       "     0.025980234146118164,\n",
       "     0.028651078542073567,\n",
       "     0.05461947123209635,\n",
       "     0.016654411951700848,\n",
       "     0.030849377314249676,\n",
       "     0.05158440272013346,\n",
       "     0.027474006017049152,\n",
       "     0.034482717514038086,\n",
       "     0.03776319821675619,\n",
       "     0.029219627380371094,\n",
       "     0.03049151102701823,\n",
       "     0.05041368802388509,\n",
       "     0.026239315668741863,\n",
       "     0.02786850929260254,\n",
       "     0.05515782038370768,\n",
       "     0.017870346705118816,\n",
       "     0.0439767042795817,\n",
       "     0.04358482360839844,\n",
       "     0.02644626299540202,\n",
       "     0.03105894724527995,\n",
       "     0.04316385587056478,\n",
       "     0.02182793617248535,\n",
       "     0.03459811210632324,\n",
       "     0.04675006866455078,\n",
       "     0.01814548174540202,\n",
       "     0.03526941935221354,\n",
       "     0.04264704386393229,\n",
       "     0.017695109049479168,\n",
       "     0.038851658503214516,\n",
       "     0.04370967547098795,\n",
       "     0.022234121958414715,\n",
       "     0.0316923459370931,\n",
       "     0.0453635056813558,\n",
       "     0.02750118573506673,\n",
       "     0.03791586558024088,\n",
       "     0.037465174992879234,\n",
       "     0.0157167911529541,\n",
       "     0.04512667655944824,\n",
       "     0.03922263781229655,\n",
       "     0.0221097469329834,\n",
       "     0.03154706954956055,\n",
       "     0.045474608739217125,\n",
       "     0.014204819997151693,\n",
       "     0.021897236506144207,\n",
       "     0.04132843017578125,\n",
       "     0.020351727803548176,\n",
       "     0.031724135080973305,\n",
       "     0.04655702908833822,\n",
       "     0.021831432978312176,\n",
       "     0.033400376637776695,\n",
       "     0.04181098937988281,\n",
       "     0.02257696787516276,\n",
       "     0.0396273136138916,\n",
       "     0.050036112467447914,\n",
       "     0.0174405574798584,\n",
       "     0.03662919998168945,\n",
       "     0.04285740852355957,\n",
       "     0.01685198148091634,\n",
       "     0.0316926638285319,\n",
       "     0.05076138178507487,\n",
       "     0.02406175931294759,\n",
       "     0.03450584411621094,\n",
       "     0.044696648915608726,\n",
       "     0.021580060323079426,\n",
       "     0.031094074249267578,\n",
       "     0.046006361643473305,\n",
       "     0.021819273630777996,\n",
       "     0.033885796864827476,\n",
       "     0.037238121032714844,\n",
       "     0.02370444933573405,\n",
       "     0.029755671819051106,\n",
       "     0.05323219299316406],\n",
       "    'std_score_time': [0.00496178252328851,\n",
       "     0.011748185964215733,\n",
       "     0.00028401356316541123,\n",
       "     0.008812468137205366,\n",
       "     0.00744144757308345,\n",
       "     0.00632578644413565,\n",
       "     0.006780268772808784,\n",
       "     0.009345580964228458,\n",
       "     0.006588009283162139,\n",
       "     0.004631417870592832,\n",
       "     0.007271670002981054,\n",
       "     0.00408146205516887,\n",
       "     0.0019767596476705997,\n",
       "     0.0070126574658196245,\n",
       "     0.0026087592057629986,\n",
       "     0.007512078441015292,\n",
       "     3.293073763651187e-05,\n",
       "     0.004503081686499947,\n",
       "     0.0019441712303465907,\n",
       "     0.009832178317333476,\n",
       "     0.007567007326854763,\n",
       "     0.008555248289731343,\n",
       "     0.004140332699627953,\n",
       "     0.0016660930195346484,\n",
       "     0.0066587583573198845,\n",
       "     0.0027984389318203733,\n",
       "     0.003920943755657474,\n",
       "     0.0011775207012935096,\n",
       "     0.002516359704781882,\n",
       "     0.007378381419519569,\n",
       "     0.006998158743152119,\n",
       "     0.002786523022534973,\n",
       "     0.007415145625377066,\n",
       "     0.0007913492276405464,\n",
       "     0.0028007551201855254,\n",
       "     0.006918650531712322,\n",
       "     0.006862646297697372,\n",
       "     0.007333838847043123,\n",
       "     0.00403835404172409,\n",
       "     1.2925033543340835e-05,\n",
       "     0.003513162936314552,\n",
       "     0.005813266509730133,\n",
       "     0.0037832736742284654,\n",
       "     0.0016531679859913076,\n",
       "     0.006289109704931092,\n",
       "     0.005595328660760619,\n",
       "     0.0026386350070960224,\n",
       "     0.014721033475706519,\n",
       "     0.009201820510740784,\n",
       "     0.00406207113981714,\n",
       "     0.00825249810791236,\n",
       "     0.0016507744456209898,\n",
       "     0.007196355513208117,\n",
       "     0.002419660281718045,\n",
       "     0.006307626886592063,\n",
       "     0.010068218305302646,\n",
       "     0.007100474070521863,\n",
       "     0.007358888785017531,\n",
       "     0.006568217718276661,\n",
       "     0.010481752637265302,\n",
       "     0.0018408322458133997,\n",
       "     0.004455670127727825,\n",
       "     0.007168708223638013,\n",
       "     0.00160315372575838,\n",
       "     0.007170655985922908,\n",
       "     0.00543527106234068,\n",
       "     0.007789299562793363,\n",
       "     0.003332476823714661,\n",
       "     0.006655929647533648,\n",
       "     0.012079077796313405,\n",
       "     0.003236508090298362,\n",
       "     0.004786991150478341,\n",
       "     0.004395339149810627,\n",
       "     0.004574689176921036,\n",
       "     0.005061174823910244,\n",
       "     0.007899668110093891,\n",
       "     0.002548317447169666,\n",
       "     0.006685491133366123,\n",
       "     0.00344903577199889,\n",
       "     0.004858611153835357,\n",
       "     0.001298960258807248,\n",
       "     0.009469989243937181,\n",
       "     0.004236173035198496,\n",
       "     0.00889814765590687,\n",
       "     0.005697516762790691,\n",
       "     4.8440777888520874e-05,\n",
       "     0.007115156380791639,\n",
       "     0.004202891529830185,\n",
       "     0.008981834769935932,\n",
       "     0.004479826658708073,\n",
       "     0.005853213632544968,\n",
       "     0.0015696836233777944,\n",
       "     0.00655966716570949,\n",
       "     0.005465929574745739,\n",
       "     0.006559074514301947,\n",
       "     0.0007778907191759026,\n",
       "     0.006921950346057179,\n",
       "     0.0027255679387242974,\n",
       "     0.0055690900299652435,\n",
       "     0.009204999011447652,\n",
       "     0.007525072512912835,\n",
       "     0.0028520491408331916,\n",
       "     0.0042457506320863125,\n",
       "     0.0004176920373610123,\n",
       "     0.004763606229462302,\n",
       "     0.007072744725670235,\n",
       "     0.0066258427889322215,\n",
       "     0.008968901563792398],\n",
       "    'param_classifier__max_depth': [None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30],\n",
       "    'param_classifier__min_samples_leaf': [1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10],\n",
       "    'param_classifier__n_estimators': [100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300],\n",
       "    'params': [{'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300}],\n",
       "    'split0_test_score': [0.7738095238095238,\n",
       "     0.7380952380952381,\n",
       "     0.75,\n",
       "     0.7619047619047619,\n",
       "     0.7857142857142857,\n",
       "     0.7738095238095238,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7976190476190477,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7738095238095238,\n",
       "     0.7976190476190477,\n",
       "     0.7857142857142857,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7857142857142857,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7857142857142857,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7857142857142857,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7857142857142857,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.75,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7857142857142857,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7857142857142857,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7857142857142857,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7857142857142857,\n",
       "     0.7976190476190477,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857],\n",
       "    'split1_test_score': [0.7738095238095238,\n",
       "     0.7857142857142857,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7857142857142857,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.75,\n",
       "     0.7619047619047619,\n",
       "     0.7857142857142857,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.75,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.75,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619],\n",
       "    'split2_test_score': [0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7857142857142857,\n",
       "     0.7738095238095238,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.75,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.75,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7857142857142857,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7857142857142857,\n",
       "     0.7619047619047619,\n",
       "     0.75,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7857142857142857,\n",
       "     0.75,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7976190476190477,\n",
       "     0.7738095238095238,\n",
       "     0.7857142857142857,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7857142857142857,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7857142857142857,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7857142857142857,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238],\n",
       "    'mean_test_score': [0.7698412698412698,\n",
       "     0.7658730158730158,\n",
       "     0.7658730158730158,\n",
       "     0.7698412698412698,\n",
       "     0.7817460317460317,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7738095238095237,\n",
       "     0.7777777777777778,\n",
       "     0.7817460317460317,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7698412698412698,\n",
       "     0.7738095238095237,\n",
       "     0.7777777777777778,\n",
       "     0.7738095238095237,\n",
       "     0.7698412698412698,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7777777777777778,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7698412698412698,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7857142857142857,\n",
       "     0.7817460317460317,\n",
       "     0.7777777777777778,\n",
       "     0.7698412698412698,\n",
       "     0.7698412698412698,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7698412698412698,\n",
       "     0.7698412698412698,\n",
       "     0.7698412698412698,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7698412698412698,\n",
       "     0.7777777777777778,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7619047619047619,\n",
       "     0.7698412698412698,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7817460317460317,\n",
       "     0.7738095238095237,\n",
       "     0.7698412698412698,\n",
       "     0.7738095238095237,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7738095238095237,\n",
       "     0.7817460317460317,\n",
       "     0.7698412698412698,\n",
       "     0.7698412698412698,\n",
       "     0.7698412698412698,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7738095238095237,\n",
       "     0.7658730158730158,\n",
       "     0.7698412698412698,\n",
       "     0.7698412698412698,\n",
       "     0.7738095238095238,\n",
       "     0.7777777777777778,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7777777777777777,\n",
       "     0.7777777777777778,\n",
       "     0.7738095238095237,\n",
       "     0.7777777777777778,\n",
       "     0.7738095238095237,\n",
       "     0.7698412698412698,\n",
       "     0.7817460317460317,\n",
       "     0.7738095238095237,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777777,\n",
       "     0.7777777777777778,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7777777777777778,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237],\n",
       "    'std_test_score': [0.005611958580845648,\n",
       "     0.020234204419018968,\n",
       "     0.014847846772912463,\n",
       "     0.005611958580845648,\n",
       "     0.005611958580845595,\n",
       "     0.005611958580845596,\n",
       "     0.014847846772912503,\n",
       "     0.01683587574253689,\n",
       "     0.014847846772912503,\n",
       "     0.011223917161691244,\n",
       "     0.01683587574253689,\n",
       "     0.01683587574253689,\n",
       "     0.020234204419019016,\n",
       "     0.01683587574253689,\n",
       "     0.014847846772912503,\n",
       "     0.00972019739199675,\n",
       "     0.011223917161691244,\n",
       "     0.01683587574253689,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.005611958580845595,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.005611958580845648,\n",
       "     0.014847846772912503,\n",
       "     0.005611958580845595,\n",
       "     0.00972019739199675,\n",
       "     0.011223917161691244,\n",
       "     0.014847846772912503,\n",
       "     0.020234204419019016,\n",
       "     0.011223917161691244,\n",
       "     0.014847846772912503,\n",
       "     0.014847846772912503,\n",
       "     0.011223917161691244,\n",
       "     0.011223917161691244,\n",
       "     0.011223917161691244,\n",
       "     0.014847846772912503,\n",
       "     0.014847846772912503,\n",
       "     0.011223917161691244,\n",
       "     0.014847846772912503,\n",
       "     0.01683587574253689,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.011223917161691244,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.014847846772912503,\n",
       "     0.014847846772912503,\n",
       "     0.014847846772912503,\n",
       "     0.00972019739199675,\n",
       "     0.020234204419019016,\n",
       "     0.01683587574253689,\n",
       "     0.014847846772912503,\n",
       "     0.014847846772912503,\n",
       "     0.00972019739199675,\n",
       "     0.014847846772912503,\n",
       "     0.020234204419019016,\n",
       "     0.011223917161691244,\n",
       "     0.011223917161691244,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.005611958580845595,\n",
       "     0.005611958580845595,\n",
       "     0.00972019739199675,\n",
       "     0.022447834323382487,\n",
       "     0.005611958580845648,\n",
       "     0.011223917161691244,\n",
       "     0.0,\n",
       "     0.005611958580845595,\n",
       "     0.01683587574253689,\n",
       "     0.01683587574253689,\n",
       "     0.011223917161691244,\n",
       "     0.014847846772912503,\n",
       "     0.01683587574253689,\n",
       "     0.005611958580845595,\n",
       "     0.01683587574253689,\n",
       "     0.020234204419019016,\n",
       "     0.014847846772912503,\n",
       "     0.01683587574253689,\n",
       "     0.014847846772912503,\n",
       "     0.011223917161691244,\n",
       "     0.014847846772912503,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.005611958580845595,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675],\n",
       "    'rank_test_score': [86,\n",
       "     105,\n",
       "     105,\n",
       "     86,\n",
       "     2,\n",
       "     8,\n",
       "     8,\n",
       "     36,\n",
       "     8,\n",
       "     2,\n",
       "     36,\n",
       "     36,\n",
       "     86,\n",
       "     36,\n",
       "     8,\n",
       "     36,\n",
       "     86,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     8,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     86,\n",
       "     8,\n",
       "     8,\n",
       "     1,\n",
       "     2,\n",
       "     8,\n",
       "     86,\n",
       "     86,\n",
       "     8,\n",
       "     8,\n",
       "     86,\n",
       "     86,\n",
       "     86,\n",
       "     8,\n",
       "     8,\n",
       "     86,\n",
       "     8,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     108,\n",
       "     86,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     8,\n",
       "     8,\n",
       "     2,\n",
       "     36,\n",
       "     86,\n",
       "     36,\n",
       "     8,\n",
       "     8,\n",
       "     36,\n",
       "     2,\n",
       "     86,\n",
       "     86,\n",
       "     86,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     8,\n",
       "     8,\n",
       "     36,\n",
       "     105,\n",
       "     86,\n",
       "     86,\n",
       "     35,\n",
       "     8,\n",
       "     36,\n",
       "     36,\n",
       "     33,\n",
       "     8,\n",
       "     36,\n",
       "     8,\n",
       "     36,\n",
       "     86,\n",
       "     2,\n",
       "     36,\n",
       "     8,\n",
       "     33,\n",
       "     8,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     36,\n",
       "     8,\n",
       "     36,\n",
       "     36]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__max_depth': 30,\n",
       "    'classifier__min_samples_leaf': 1,\n",
       "    'classifier__min_samples_split': 2,\n",
       "    'classifier__n_estimators': 300},\n",
       "   'best_validation_accuracy': 0.7766906209692279,\n",
       "   'train_accuracy': 1.0,\n",
       "   'test_accuracy': 0.7524752475247525,\n",
       "   'cv_results': {'mean_fit_time': [0.409976323445638,\n",
       "     0.5183039506276449,\n",
       "     0.9991449515024821,\n",
       "     0.4436883131663005,\n",
       "     0.5331003665924072,\n",
       "     0.7485474745432535,\n",
       "     0.281086524327596,\n",
       "     0.5024701754252116,\n",
       "     0.7375500996907552,\n",
       "     0.2697457472483317,\n",
       "     0.4553195635477702,\n",
       "     0.6642102400461832,\n",
       "     0.24069897333780924,\n",
       "     0.4519971211751302,\n",
       "     0.6787366072336832,\n",
       "     0.23627853393554688,\n",
       "     0.4385048548380534,\n",
       "     0.6713011264801025,\n",
       "     0.23335742950439453,\n",
       "     0.45462902386983234,\n",
       "     0.6586001714070638,\n",
       "     0.22725486755371094,\n",
       "     0.4497083028157552,\n",
       "     0.6444560686747233,\n",
       "     0.223768949508667,\n",
       "     0.4532178243001302,\n",
       "     0.6682222684224447,\n",
       "     0.24446233113606772,\n",
       "     0.4603664080301921,\n",
       "     0.6723598639170328,\n",
       "     0.23502937952677408,\n",
       "     0.4554723898569743,\n",
       "     0.6695104440053304,\n",
       "     0.23058629035949707,\n",
       "     0.4306604067484538,\n",
       "     0.6750361124674479,\n",
       "     0.23225553830464682,\n",
       "     0.45397408803304035,\n",
       "     0.6573125521341959,\n",
       "     0.23174333572387695,\n",
       "     0.44582541783650714,\n",
       "     0.6533627510070801,\n",
       "     0.2406484285990397,\n",
       "     0.42620301246643066,\n",
       "     0.7021691799163818,\n",
       "     0.23185094197591147,\n",
       "     0.43967461585998535,\n",
       "     0.6220138867696127,\n",
       "     0.22311226526896158,\n",
       "     0.44630734125773114,\n",
       "     0.643714427947998,\n",
       "     0.22545234362284342,\n",
       "     0.4186583360036214,\n",
       "     0.6691038608551025,\n",
       "     0.25233912467956543,\n",
       "     0.4623246192932129,\n",
       "     0.7113507588704427,\n",
       "     0.2487640380859375,\n",
       "     0.46434593200683594,\n",
       "     0.7111028035481771,\n",
       "     0.23238476117451987,\n",
       "     0.44588589668273926,\n",
       "     0.6596866448720297,\n",
       "     0.22696526845296225,\n",
       "     0.4701235294342041,\n",
       "     0.6884117921193441,\n",
       "     0.2340857187906901,\n",
       "     0.44233012199401855,\n",
       "     0.6689213116963705,\n",
       "     0.2300405502319336,\n",
       "     0.4445192813873291,\n",
       "     0.6497504711151123,\n",
       "     0.23615137736002603,\n",
       "     0.42971356709798175,\n",
       "     0.670072873433431,\n",
       "     0.2450695037841797,\n",
       "     0.45733102162679035,\n",
       "     0.6681241194407145,\n",
       "     0.24233229955037436,\n",
       "     0.44240697224934894,\n",
       "     0.6656617323557535,\n",
       "     0.2586201826731364,\n",
       "     0.47784606615702313,\n",
       "     0.729976495107015,\n",
       "     0.2404474417368571,\n",
       "     0.48024622599283856,\n",
       "     0.6978599230448405,\n",
       "     0.24628790219624838,\n",
       "     0.44597673416137695,\n",
       "     0.6945338249206543,\n",
       "     0.24676712354024252,\n",
       "     0.46262431144714355,\n",
       "     0.6551667849222819,\n",
       "     0.23781283696492514,\n",
       "     0.4640039602915446,\n",
       "     0.6683634916941324,\n",
       "     0.23812222480773926,\n",
       "     0.459971825281779,\n",
       "     0.6710524559020996,\n",
       "     0.2218963305155436,\n",
       "     0.42785247166951496,\n",
       "     0.6563507715861002,\n",
       "     0.22463154792785645,\n",
       "     0.43896063168843585,\n",
       "     0.6545116901397705,\n",
       "     0.2330176830291748,\n",
       "     0.4393761952718099,\n",
       "     0.5804073015848795],\n",
       "    'std_fit_time': [0.08966134667478619,\n",
       "     0.03460915541955655,\n",
       "     0.06282521630629893,\n",
       "     0.007356967220544056,\n",
       "     0.046761995919842314,\n",
       "     0.014478837758151116,\n",
       "     0.06308690904190146,\n",
       "     0.0035631328056357223,\n",
       "     0.020938578702871188,\n",
       "     0.010126356181253342,\n",
       "     0.016480455397928303,\n",
       "     0.013915377976214846,\n",
       "     0.010380487809243126,\n",
       "     0.013940197897561183,\n",
       "     0.025957869659125565,\n",
       "     0.004151230789233204,\n",
       "     0.007331764291639293,\n",
       "     0.02068168446696335,\n",
       "     0.01370471486060965,\n",
       "     0.02522968379154824,\n",
       "     0.018278479075381004,\n",
       "     0.009171384809389806,\n",
       "     0.01722653734989768,\n",
       "     0.007865234555328953,\n",
       "     0.01122246557591857,\n",
       "     0.027626972032898597,\n",
       "     0.021898664183206136,\n",
       "     0.01573032778022594,\n",
       "     0.010632323140178845,\n",
       "     0.02543058158069969,\n",
       "     0.0032721857021016138,\n",
       "     0.026731666765933547,\n",
       "     0.011024926771187259,\n",
       "     0.014676223598877061,\n",
       "     0.0317235386566221,\n",
       "     0.023722803500589484,\n",
       "     0.0024724278126134307,\n",
       "     0.021210910622632827,\n",
       "     0.030344504854581827,\n",
       "     0.0022991046385724867,\n",
       "     0.0296198701717991,\n",
       "     0.019729110501665727,\n",
       "     0.006848347269297176,\n",
       "     0.007999881003897912,\n",
       "     0.018274761668791002,\n",
       "     0.014905124953888819,\n",
       "     0.019706100080897623,\n",
       "     0.02429262029821598,\n",
       "     0.010072243498521425,\n",
       "     0.01836630703056578,\n",
       "     0.027970221037546827,\n",
       "     0.007119634188880407,\n",
       "     0.027801566885226506,\n",
       "     0.009885887501857845,\n",
       "     0.002597762252198059,\n",
       "     0.010097722861234362,\n",
       "     0.03314401616838822,\n",
       "     0.022790656469621334,\n",
       "     0.022124498341208897,\n",
       "     0.01569060067019069,\n",
       "     0.012430968788082308,\n",
       "     0.014779223360734065,\n",
       "     0.034592227119526586,\n",
       "     0.007961158748794564,\n",
       "     0.019032884316947864,\n",
       "     0.01280965072517574,\n",
       "     0.011354806885740507,\n",
       "     0.036131211305490796,\n",
       "     0.012314037730804788,\n",
       "     0.010312061147146518,\n",
       "     0.020769993573472166,\n",
       "     0.01770136010929178,\n",
       "     0.0005348257636369874,\n",
       "     0.005505404458033481,\n",
       "     0.037460821018187956,\n",
       "     0.013091417984350838,\n",
       "     0.01243259217828102,\n",
       "     0.024945878247136198,\n",
       "     0.006695767471002481,\n",
       "     0.01860940551179108,\n",
       "     0.0314749294703353,\n",
       "     0.018349829989707692,\n",
       "     0.028262851769301062,\n",
       "     0.03931063402991348,\n",
       "     0.006826825582379519,\n",
       "     0.013694121637373697,\n",
       "     0.02557475092997466,\n",
       "     0.00946149991725388,\n",
       "     0.01782293560650497,\n",
       "     0.028317369898349248,\n",
       "     0.0023663847245302457,\n",
       "     0.01637625679291375,\n",
       "     0.02107956917147193,\n",
       "     0.008692071120201353,\n",
       "     0.01617880626245052,\n",
       "     0.024749755123146564,\n",
       "     0.006750576432292875,\n",
       "     0.007183917165159934,\n",
       "     0.02710445069633897,\n",
       "     0.005664594004584756,\n",
       "     0.007861117792655926,\n",
       "     0.027325068583808773,\n",
       "     0.0041571607808352585,\n",
       "     0.021767653998771324,\n",
       "     0.008708498118861574,\n",
       "     0.013183698507563952,\n",
       "     0.008239741362016745,\n",
       "     0.010227834345828352],\n",
       "    'mean_score_time': [0.023293415705362957,\n",
       "     0.0339965025583903,\n",
       "     0.049578189849853516,\n",
       "     0.03963971138000488,\n",
       "     0.03919426600138346,\n",
       "     0.051150878270467125,\n",
       "     0.018439213434855144,\n",
       "     0.03790529568990072,\n",
       "     0.05081892013549805,\n",
       "     0.02219080924987793,\n",
       "     0.03746533393859863,\n",
       "     0.04535301526387533,\n",
       "     0.02038272221883138,\n",
       "     0.03176077206929525,\n",
       "     0.04721371332804362,\n",
       "     0.02866808573404948,\n",
       "     0.03893669446309408,\n",
       "     0.05004183451334635,\n",
       "     0.024578650792439777,\n",
       "     0.031683921813964844,\n",
       "     0.04884600639343262,\n",
       "     0.022199312845865887,\n",
       "     0.030486663182576496,\n",
       "     0.05002411206563314,\n",
       "     0.02213891347249349,\n",
       "     0.034836769104003906,\n",
       "     0.04241657257080078,\n",
       "     0.016689459482828777,\n",
       "     0.03481928507486979,\n",
       "     0.04626774787902832,\n",
       "     0.016928990681966145,\n",
       "     0.03966546058654785,\n",
       "     0.058348655700683594,\n",
       "     0.019838889439900715,\n",
       "     0.03612836201985677,\n",
       "     0.04684591293334961,\n",
       "     0.021040995915730793,\n",
       "     0.03184819221496582,\n",
       "     0.04821856816609701,\n",
       "     0.024426062901814777,\n",
       "     0.035886526107788086,\n",
       "     0.05712231000264486,\n",
       "     0.021602869033813477,\n",
       "     0.03503878911336263,\n",
       "     0.041505893071492515,\n",
       "     0.020541826883951824,\n",
       "     0.040872812271118164,\n",
       "     0.05005017916361491,\n",
       "     0.023655176162719727,\n",
       "     0.03152767817179362,\n",
       "     0.04815904299418131,\n",
       "     0.019695043563842773,\n",
       "     0.04335665702819824,\n",
       "     0.036525726318359375,\n",
       "     0.024010976155598957,\n",
       "     0.042005062103271484,\n",
       "     0.04804452260335287,\n",
       "     0.01973549524943034,\n",
       "     0.03340601921081543,\n",
       "     0.049663941065470375,\n",
       "     0.024188518524169922,\n",
       "     0.03743577003479004,\n",
       "     0.047456582387288414,\n",
       "     0.02594335873921712,\n",
       "     0.02834479014078776,\n",
       "     0.04423300425211588,\n",
       "     0.02817694346110026,\n",
       "     0.031295379002889,\n",
       "     0.04472796122233073,\n",
       "     0.01645215352376302,\n",
       "     0.04069844881693522,\n",
       "     0.04169106483459473,\n",
       "     0.022330284118652344,\n",
       "     0.03679951032002767,\n",
       "     0.05010541280110677,\n",
       "     0.021293481190999348,\n",
       "     0.03503680229187012,\n",
       "     0.04909062385559082,\n",
       "     0.01904408137003581,\n",
       "     0.031558593114217125,\n",
       "     0.04517078399658203,\n",
       "     0.023999373118082683,\n",
       "     0.03569348653157552,\n",
       "     0.04441293080647787,\n",
       "     0.027780612309773762,\n",
       "     0.035970608393351235,\n",
       "     0.04645744959513346,\n",
       "     0.02108136812845866,\n",
       "     0.03576064109802246,\n",
       "     0.04785784085591634,\n",
       "     0.023705482482910156,\n",
       "     0.03155597050984701,\n",
       "     0.04889591534932455,\n",
       "     0.018394867579142254,\n",
       "     0.04000314076741537,\n",
       "     0.04170743624369303,\n",
       "     0.023109277089436848,\n",
       "     0.04283658663431803,\n",
       "     0.0451507568359375,\n",
       "     0.014351924260457357,\n",
       "     0.046899000803629555,\n",
       "     0.044445435206095375,\n",
       "     0.02436089515686035,\n",
       "     0.032750209172566734,\n",
       "     0.0511483351389567,\n",
       "     0.01845828692118327,\n",
       "     0.023343801498413086,\n",
       "     0.024103641510009766],\n",
       "    'std_score_time': [0.007091218555606486,\n",
       "     0.004935188171288591,\n",
       "     0.013193687625843203,\n",
       "     0.00891085529956726,\n",
       "     0.007589462015604799,\n",
       "     0.002366544788437576,\n",
       "     0.0025138430352830334,\n",
       "     0.0032805053350149563,\n",
       "     0.0015917618930541182,\n",
       "     0.007934734288054954,\n",
       "     0.0032181936575157613,\n",
       "     0.004815305540268651,\n",
       "     0.009316010467683577,\n",
       "     0.0003680824769951412,\n",
       "     0.01032204223533952,\n",
       "     0.007543075622317271,\n",
       "     0.007074015395382722,\n",
       "     2.438897633830401e-05,\n",
       "     0.006454734146257309,\n",
       "     0.002599394988167953,\n",
       "     0.005157664991356423,\n",
       "     0.008575695058879465,\n",
       "     0.003174757940259937,\n",
       "     7.914259953104092e-05,\n",
       "     0.006553800324090833,\n",
       "     0.009126979987391188,\n",
       "     0.006811770636179661,\n",
       "     1.9331354516996727e-05,\n",
       "     0.002071536759004591,\n",
       "     0.0024573311818243153,\n",
       "     0.0003051545049615127,\n",
       "     0.008929982532481902,\n",
       "     0.01045322440689477,\n",
       "     0.0022785290297385455,\n",
       "     0.01045234754459833,\n",
       "     0.010153387222043017,\n",
       "     0.006264723327506578,\n",
       "     0.002030422854141775,\n",
       "     0.0025932269996557468,\n",
       "     0.007073323264539408,\n",
       "     0.0019130636168647821,\n",
       "     0.010754560137616536,\n",
       "     0.005265639842431948,\n",
       "     0.0024075403785382963,\n",
       "     0.00681679516482658,\n",
       "     0.002878066730429956,\n",
       "     0.009280763906189692,\n",
       "     0.0077229472183613975,\n",
       "     0.006994161632074113,\n",
       "     0.002642233371662788,\n",
       "     0.004383989185805567,\n",
       "     0.005993689558728156,\n",
       "     0.005446626315899476,\n",
       "     0.00369342341742226,\n",
       "     0.011775039834692653,\n",
       "     0.003551970911088166,\n",
       "     0.0014534604913877436,\n",
       "     0.003203586247192478,\n",
       "     0.006912651184244257,\n",
       "     0.009657902843082522,\n",
       "     0.00690914812787864,\n",
       "     0.009059517916933657,\n",
       "     0.004126569839802628,\n",
       "     0.0076212030392525795,\n",
       "     0.003438408793836827,\n",
       "     0.004211841307585315,\n",
       "     0.0033541159243176025,\n",
       "     0.0030774753130587184,\n",
       "     0.01084638047688228,\n",
       "     0.00656602058972202,\n",
       "     0.006984394070643116,\n",
       "     0.0068474144683560445,\n",
       "     0.004885254577683419,\n",
       "     0.004923052137722568,\n",
       "     0.000104074617922901,\n",
       "     0.004401175014489592,\n",
       "     0.007014913535802025,\n",
       "     0.0028490088725591617,\n",
       "     0.0035875064149280596,\n",
       "     0.0062265448225672804,\n",
       "     0.004220241797926952,\n",
       "     0.007022099509517731,\n",
       "     0.0032948294584295465,\n",
       "     0.00785152978021573,\n",
       "     0.007809857018102486,\n",
       "     0.0016908303657055155,\n",
       "     0.003306495903976566,\n",
       "     0.005458470430956994,\n",
       "     0.0033319612558772387,\n",
       "     0.01056120999538051,\n",
       "     0.007122691244640291,\n",
       "     0.012307720575452593,\n",
       "     0.0015450609812296965,\n",
       "     0.002314102161927802,\n",
       "     0.0037917758332739653,\n",
       "     0.005954351374952735,\n",
       "     0.007542003175803124,\n",
       "     0.007812330367291007,\n",
       "     0.0056477600745115245,\n",
       "     0.0032847260821064375,\n",
       "     0.004289987220428867,\n",
       "     0.007888654511900612,\n",
       "     0.0068166857505369445,\n",
       "     0.0008300689142903767,\n",
       "     0.0015789117389753743,\n",
       "     0.002557042809044017,\n",
       "     0.007126252464924993,\n",
       "     0.007711561296805961],\n",
       "    'param_classifier__max_depth': [None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30],\n",
       "    'param_classifier__min_samples_leaf': [1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10],\n",
       "    'param_classifier__n_estimators': [100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300],\n",
       "    'params': [{'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300}],\n",
       "    'split0_test_score': [0.7555555555555555,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.762962962962963,\n",
       "     0.7703703703703704,\n",
       "     0.762962962962963,\n",
       "     0.762962962962963,\n",
       "     0.7703703703703704,\n",
       "     0.762962962962963,\n",
       "     0.762962962962963,\n",
       "     0.762962962962963,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.762962962962963,\n",
       "     0.7777777777777778,\n",
       "     0.7703703703703704,\n",
       "     0.762962962962963,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7703703703703704,\n",
       "     0.7777777777777778,\n",
       "     0.7703703703703704,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.762962962962963,\n",
       "     0.7555555555555555,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.762962962962963,\n",
       "     0.762962962962963,\n",
       "     0.762962962962963,\n",
       "     0.762962962962963,\n",
       "     0.762962962962963,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.762962962962963,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.7777777777777778,\n",
       "     0.7703703703703704,\n",
       "     0.7777777777777778,\n",
       "     0.762962962962963,\n",
       "     0.7703703703703704,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7703703703703704,\n",
       "     0.762962962962963,\n",
       "     0.762962962962963,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.762962962962963,\n",
       "     0.7703703703703704,\n",
       "     0.7555555555555555,\n",
       "     0.762962962962963,\n",
       "     0.7703703703703704,\n",
       "     0.762962962962963,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.762962962962963,\n",
       "     0.762962962962963,\n",
       "     0.7703703703703704,\n",
       "     0.7777777777777778,\n",
       "     0.7703703703703704,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.7777777777777778,\n",
       "     0.7703703703703704,\n",
       "     0.7777777777777778,\n",
       "     0.762962962962963,\n",
       "     0.7703703703703704,\n",
       "     0.762962962962963,\n",
       "     0.762962962962963,\n",
       "     0.762962962962963,\n",
       "     0.7555555555555555,\n",
       "     0.762962962962963,\n",
       "     0.7703703703703704,\n",
       "     0.762962962962963,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.762962962962963,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.762962962962963,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.7777777777777778],\n",
       "    'split1_test_score': [0.7761194029850746,\n",
       "     0.753731343283582,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.753731343283582,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.753731343283582,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7686567164179104,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7686567164179104,\n",
       "     0.7761194029850746,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.7686567164179104,\n",
       "     0.7761194029850746,\n",
       "     0.746268656716418,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.753731343283582,\n",
       "     0.7686567164179104,\n",
       "     0.753731343283582,\n",
       "     0.7611940298507462,\n",
       "     0.7686567164179104,\n",
       "     0.753731343283582,\n",
       "     0.753731343283582,\n",
       "     0.7686567164179104,\n",
       "     0.753731343283582,\n",
       "     0.753731343283582,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7611940298507462,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.753731343283582,\n",
       "     0.7611940298507462,\n",
       "     0.753731343283582,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.753731343283582,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7686567164179104,\n",
       "     0.7761194029850746,\n",
       "     0.7611940298507462,\n",
       "     0.7686567164179104,\n",
       "     0.7761194029850746,\n",
       "     0.753731343283582,\n",
       "     0.7761194029850746,\n",
       "     0.7835820895522388,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.753731343283582,\n",
       "     0.7686567164179104,\n",
       "     0.746268656716418,\n",
       "     0.7611940298507462,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.753731343283582,\n",
       "     0.7611940298507462,\n",
       "     0.753731343283582,\n",
       "     0.753731343283582,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.753731343283582,\n",
       "     0.746268656716418,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7686567164179104,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746],\n",
       "    'split2_test_score': [0.753731343283582,\n",
       "     0.7611940298507462,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.753731343283582,\n",
       "     0.7761194029850746,\n",
       "     0.753731343283582,\n",
       "     0.753731343283582,\n",
       "     0.753731343283582,\n",
       "     0.7686567164179104,\n",
       "     0.753731343283582,\n",
       "     0.7761194029850746,\n",
       "     0.7835820895522388,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.753731343283582,\n",
       "     0.746268656716418,\n",
       "     0.746268656716418,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.7761194029850746,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.753731343283582,\n",
       "     0.7388059701492538,\n",
       "     0.7388059701492538,\n",
       "     0.7611940298507462,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7686567164179104,\n",
       "     0.746268656716418,\n",
       "     0.7761194029850746,\n",
       "     0.746268656716418,\n",
       "     0.7388059701492538,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7686567164179104,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7611940298507462,\n",
       "     0.7761194029850746,\n",
       "     0.746268656716418,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.753731343283582,\n",
       "     0.753731343283582,\n",
       "     0.753731343283582,\n",
       "     0.753731343283582,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7611940298507462,\n",
       "     0.753731343283582,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.753731343283582,\n",
       "     0.7761194029850746,\n",
       "     0.7686567164179104,\n",
       "     0.7761194029850746,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.7761194029850746,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.7761194029850746,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.7761194029850746,\n",
       "     0.753731343283582,\n",
       "     0.7611940298507462,\n",
       "     0.7835820895522388,\n",
       "     0.746268656716418,\n",
       "     0.753731343283582,\n",
       "     0.753731343283582,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7686567164179104,\n",
       "     0.7761194029850746,\n",
       "     0.7686567164179104,\n",
       "     0.7761194029850746],\n",
       "    'mean_test_score': [0.7618021006080707,\n",
       "     0.7617652478348994,\n",
       "     0.7692279344020637,\n",
       "     0.766740372213009,\n",
       "     0.7617652478348996,\n",
       "     0.7667587985995946,\n",
       "     0.7617652478348996,\n",
       "     0.7592961120324304,\n",
       "     0.7568085498433756,\n",
       "     0.7692279344020637,\n",
       "     0.7617836742214852,\n",
       "     0.76427123641054,\n",
       "     0.7717339229777042,\n",
       "     0.7642528100239542,\n",
       "     0.7642528100239542,\n",
       "     0.7592961120324304,\n",
       "     0.761746821448314,\n",
       "     0.7617652478348996,\n",
       "     0.7692463607886494,\n",
       "     0.7716970702045328,\n",
       "     0.7766721945826424,\n",
       "     0.7741846323935876,\n",
       "     0.7692279344020637,\n",
       "     0.7716970702045328,\n",
       "     0.7692279344020637,\n",
       "     0.7741846323935876,\n",
       "     0.7692095080154782,\n",
       "     0.7617836742214852,\n",
       "     0.7667772249861802,\n",
       "     0.7692279344020637,\n",
       "     0.766740372213009,\n",
       "     0.7692279344020637,\n",
       "     0.7567901234567902,\n",
       "     0.7543209876543209,\n",
       "     0.7543209876543209,\n",
       "     0.7592961120324304,\n",
       "     0.7667587985995946,\n",
       "     0.7592961120324304,\n",
       "     0.7642528100239542,\n",
       "     0.7692279344020637,\n",
       "     0.7567901234567901,\n",
       "     0.766740372213009,\n",
       "     0.7592961120324304,\n",
       "     0.7543025612677354,\n",
       "     0.7642528100239542,\n",
       "     0.7741846323935876,\n",
       "     0.7717154965911185,\n",
       "     0.7766721945826424,\n",
       "     0.7667587985995946,\n",
       "     0.7717154965911185,\n",
       "     0.7766721945826424,\n",
       "     0.7766721945826424,\n",
       "     0.7667219458264235,\n",
       "     0.7692279344020637,\n",
       "     0.7592961120324304,\n",
       "     0.7667587985995946,\n",
       "     0.7692279344020637,\n",
       "     0.7692279344020637,\n",
       "     0.7667587985995946,\n",
       "     0.7642528100239542,\n",
       "     0.7568269762299612,\n",
       "     0.7568085498433756,\n",
       "     0.7617652478348996,\n",
       "     0.7568085498433756,\n",
       "     0.766740372213009,\n",
       "     0.766740372213009,\n",
       "     0.766740372213009,\n",
       "     0.7642528100239542,\n",
       "     0.766740372213009,\n",
       "     0.7692463607886494,\n",
       "     0.7617836742214852,\n",
       "     0.7617652478348996,\n",
       "     0.7741846323935876,\n",
       "     0.7717154965911185,\n",
       "     0.7716970702045328,\n",
       "     0.7741846323935876,\n",
       "     0.7716970702045329,\n",
       "     0.766740372213009,\n",
       "     0.7692279344020637,\n",
       "     0.7716970702045329,\n",
       "     0.7742030587801733,\n",
       "     0.7667219458264234,\n",
       "     0.7692463607886494,\n",
       "     0.7766906209692279,\n",
       "     0.7642712364105398,\n",
       "     0.7617836742214852,\n",
       "     0.76427123641054,\n",
       "     0.7618021006080706,\n",
       "     0.7568085498433756,\n",
       "     0.7642528100239542,\n",
       "     0.7667587985995946,\n",
       "     0.766740372213009,\n",
       "     0.766740372213009,\n",
       "     0.7592961120324304,\n",
       "     0.7617652478348994,\n",
       "     0.7692279344020637,\n",
       "     0.7592961120324304,\n",
       "     0.7617652478348996,\n",
       "     0.7592776856458449,\n",
       "     0.7642343836373687,\n",
       "     0.7741846323935876,\n",
       "     0.7716970702045328,\n",
       "     0.7692095080154782,\n",
       "     0.7716970702045328,\n",
       "     0.7741846323935876,\n",
       "     0.7742030587801733,\n",
       "     0.7717154965911185,\n",
       "     0.7766721945826424],\n",
       "    'std_test_score': [0.010151216614088708,\n",
       "     0.006804852341664441,\n",
       "     0.0008078242202610288,\n",
       "     0.003983766029505946,\n",
       "     0.006804852341664441,\n",
       "     0.006658226337144909,\n",
       "     0.006804852341664441,\n",
       "     0.0040006057466333575,\n",
       "     0.004351827251083615,\n",
       "     0.0008078242202610288,\n",
       "     0.006150053238336789,\n",
       "     0.009186584017273064,\n",
       "     0.008694404157651202,\n",
       "     0.0043257684052687385,\n",
       "     0.0043257684052687385,\n",
       "     0.0040006057466333575,\n",
       "     0.012869482285044559,\n",
       "     0.010980054786968608,\n",
       "     0.005387252786397017,\n",
       "     0.007457566369945868,\n",
       "     0.0007817653744461518,\n",
       "     0.003967026007298881,\n",
       "     0.006146574154545685,\n",
       "     0.007457566369945868,\n",
       "     0.0008078242202610288,\n",
       "     0.003967026007298881,\n",
       "     0.006781561164392108,\n",
       "     0.0008338830660759058,\n",
       "     0.008499698869473571,\n",
       "     0.006146574154545685,\n",
       "     0.003983766029505946,\n",
       "     0.006146574154545685,\n",
       "     0.010074398323648157,\n",
       "     0.010994517034285198,\n",
       "     0.010994517034285198,\n",
       "     0.0040006057466333575,\n",
       "     0.0026840611189318034,\n",
       "     0.0040006057466333575,\n",
       "     0.0043257684052687385,\n",
       "     0.0008078242202610288,\n",
       "     0.010074398323648157,\n",
       "     0.009493470361823589,\n",
       "     0.009500549145863738,\n",
       "     0.0128924411399024,\n",
       "     0.007472621103903898,\n",
       "     0.003967026007298881,\n",
       "     0.0031916501596343893,\n",
       "     0.0007817653744461518,\n",
       "     0.006658226337144909,\n",
       "     0.0031916501596343893,\n",
       "     0.0007817653744461518,\n",
       "     0.0007817653744461518,\n",
       "     0.00781765374446157,\n",
       "     0.006146574154545685,\n",
       "     0.009500549145863738,\n",
       "     0.0026840611189318034,\n",
       "     0.006146574154545685,\n",
       "     0.006146574154545685,\n",
       "     0.0026840611189318034,\n",
       "     0.0043257684052687385,\n",
       "     0.0031765081036061187,\n",
       "     0.004351827251083615,\n",
       "     0.006804852341664441,\n",
       "     0.004351827251083615,\n",
       "     0.003983766029505946,\n",
       "     0.003983766029505946,\n",
       "     0.003983766029505946,\n",
       "     0.0043257684052687385,\n",
       "     0.009493470361823589,\n",
       "     0.0053872527863970164,\n",
       "     0.0008338830660759058,\n",
       "     0.006804852341664441,\n",
       "     0.003967026007298881,\n",
       "     0.0031916501596343893,\n",
       "     0.007457566369945868,\n",
       "     0.003967026007298881,\n",
       "     0.0042997095594538605,\n",
       "     0.009493470361823589,\n",
       "     0.006146574154545685,\n",
       "     0.0042997095594538605,\n",
       "     0.0027101199647466805,\n",
       "     0.009911786112239442,\n",
       "     0.005387252786397017,\n",
       "     0.005408764395201734,\n",
       "     0.0031839814970315984,\n",
       "     0.0008338830660759058,\n",
       "     0.009186584017273064,\n",
       "     0.0053657814913741384,\n",
       "     0.007487736259361828,\n",
       "     0.0043257684052687385,\n",
       "     0.0026840611189318034,\n",
       "     0.003983766029505946,\n",
       "     0.009493470361823589,\n",
       "     0.0040006057466333575,\n",
       "     0.006804852341664441,\n",
       "     0.012213261457808681,\n",
       "     0.009500549145863738,\n",
       "     0.006804852341664441,\n",
       "     0.007843712590276447,\n",
       "     0.013238175804121649,\n",
       "     0.003967026007298881,\n",
       "     0.007457566369945868,\n",
       "     0.006781561164392108,\n",
       "     0.007457566369945868,\n",
       "     0.003967026007298881,\n",
       "     0.0027101199647466805,\n",
       "     0.0031916501596343893,\n",
       "     0.0007817653744461518],\n",
       "    'rank_test_score': [75,\n",
       "     87,\n",
       "     31,\n",
       "     52,\n",
       "     81,\n",
       "     46,\n",
       "     81,\n",
       "     90,\n",
       "     100,\n",
       "     31,\n",
       "     77,\n",
       "     64,\n",
       "     16,\n",
       "     67,\n",
       "     67,\n",
       "     90,\n",
       "     89,\n",
       "     81,\n",
       "     28,\n",
       "     23,\n",
       "     2,\n",
       "     9,\n",
       "     31,\n",
       "     23,\n",
       "     31,\n",
       "     9,\n",
       "     43,\n",
       "     77,\n",
       "     45,\n",
       "     31,\n",
       "     52,\n",
       "     31,\n",
       "     104,\n",
       "     106,\n",
       "     106,\n",
       "     90,\n",
       "     46,\n",
       "     90,\n",
       "     67,\n",
       "     31,\n",
       "     105,\n",
       "     52,\n",
       "     90,\n",
       "     108,\n",
       "     67,\n",
       "     9,\n",
       "     17,\n",
       "     2,\n",
       "     46,\n",
       "     17,\n",
       "     2,\n",
       "     2,\n",
       "     62,\n",
       "     31,\n",
       "     90,\n",
       "     46,\n",
       "     31,\n",
       "     31,\n",
       "     46,\n",
       "     67,\n",
       "     99,\n",
       "     100,\n",
       "     81,\n",
       "     100,\n",
       "     52,\n",
       "     52,\n",
       "     52,\n",
       "     67,\n",
       "     52,\n",
       "     28,\n",
       "     77,\n",
       "     81,\n",
       "     9,\n",
       "     17,\n",
       "     23,\n",
       "     9,\n",
       "     21,\n",
       "     52,\n",
       "     31,\n",
       "     21,\n",
       "     7,\n",
       "     63,\n",
       "     28,\n",
       "     1,\n",
       "     66,\n",
       "     77,\n",
       "     64,\n",
       "     76,\n",
       "     100,\n",
       "     67,\n",
       "     46,\n",
       "     52,\n",
       "     52,\n",
       "     90,\n",
       "     87,\n",
       "     31,\n",
       "     90,\n",
       "     81,\n",
       "     98,\n",
       "     74,\n",
       "     9,\n",
       "     23,\n",
       "     43,\n",
       "     23,\n",
       "     9,\n",
       "     7,\n",
       "     17,\n",
       "     2]}}],\n",
       " 'vegas SVM': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__C': 1e-07},\n",
       "   'best_validation_accuracy': 0.7801544860368389,\n",
       "   'train_accuracy': 0.78,\n",
       "   'test_accuracy': 0.7747524752475248,\n",
       "   'cv_results': {'mean_fit_time': [0.01838541030883789,\n",
       "     0.01838541030883789,\n",
       "     0.01838541030883789,\n",
       "     0.006918032964070638,\n",
       "     0.011393864949544271,\n",
       "     0.008312463760375977,\n",
       "     0.017852147420247395,\n",
       "     0.023154497146606445,\n",
       "     0.0189364751180013,\n",
       "     0.01426537831624349,\n",
       "     0.013070027033487955],\n",
       "    'std_fit_time': [0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.008166118162942642,\n",
       "     0.008128255784312376,\n",
       "     0.007157714671907524,\n",
       "     0.004011042471619368,\n",
       "     0.0012464915657095141,\n",
       "     0.0053423097482358465,\n",
       "     0.001260247342148554,\n",
       "     0.0012481057742871502],\n",
       "    'mean_score_time': [0.014974276224772135,\n",
       "     0.014644940694173178,\n",
       "     0.014974276224772135,\n",
       "     0.015303611755371094,\n",
       "     0.012510935465494791,\n",
       "     0.019821723302205402,\n",
       "     0.011562665303548178,\n",
       "     0.01015631357828776,\n",
       "     0.007936954498291016,\n",
       "     0.008490959803263346,\n",
       "     0.0],\n",
       "    'std_score_time': [0.00046575077394438635,\n",
       "     0.00046575077394438635,\n",
       "     0.00046575077394438635,\n",
       "     0.0,\n",
       "     0.007026262292536444,\n",
       "     0.002054372248842948,\n",
       "     0.002837788822184559,\n",
       "     0.0014165311222277893,\n",
       "     0.0016204609090336457,\n",
       "     0.003092037854292065,\n",
       "     0.0],\n",
       "    'param_classifier__C': [1e-07,\n",
       "     1e-06,\n",
       "     1e-05,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     1000.0],\n",
       "    'params': [{'classifier__C': 1e-07},\n",
       "     {'classifier__C': 1e-06},\n",
       "     {'classifier__C': 1e-05},\n",
       "     {'classifier__C': 0.0001},\n",
       "     {'classifier__C': 0.001},\n",
       "     {'classifier__C': 0.01},\n",
       "     {'classifier__C': 0.1},\n",
       "     {'classifier__C': 1},\n",
       "     {'classifier__C': 10},\n",
       "     {'classifier__C': 100},\n",
       "     {'classifier__C': 1000}],\n",
       "    'split0_test_score': [0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7058823529411765,\n",
       "     0.7058823529411765,\n",
       "     0.7058823529411765],\n",
       "    'split1_test_score': [0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273],\n",
       "    'split2_test_score': [0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576],\n",
       "    'mean_test_score': [0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7302436125965537,\n",
       "     0.7302436125965537,\n",
       "     0.7302436125965537],\n",
       "    'std_test_score': [0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.02120804313437282,\n",
       "     0.02120804313437282,\n",
       "     0.02120804313437282],\n",
       "    'rank_test_score': [1, 1, 1, 1, 1, 1, 1, 1, 9, 9, 9]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__C': 1e-07},\n",
       "   'best_validation_accuracy': 0.7777777777777778,\n",
       "   'train_accuracy': 0.7777777777777778,\n",
       "   'test_accuracy': 0.7738095238095238,\n",
       "   'cv_results': {'mean_fit_time': [0.0,\n",
       "     0.019189914067586262,\n",
       "     0.02318882942199707,\n",
       "     0.013661940892537435,\n",
       "     0.011901060740152994,\n",
       "     0.016620874404907227,\n",
       "     0.02740176518758138,\n",
       "     0.027434031168619793,\n",
       "     0.02776312828063965,\n",
       "     0.016656160354614258,\n",
       "     0.01666998863220215],\n",
       "    'std_fit_time': [0.0,\n",
       "     0.0008151721550769067,\n",
       "     0.0016323888390026506,\n",
       "     0.008637483040847582,\n",
       "     0.0067205634450327265,\n",
       "     0.0,\n",
       "     0.007606613012352943,\n",
       "     0.007628818913275861,\n",
       "     0.007853812338914037,\n",
       "     0.0,\n",
       "     0.0],\n",
       "    'mean_score_time': [0.021189769109090168,\n",
       "     0.009665648142496744,\n",
       "     0.009242534637451172,\n",
       "     0.013880014419555664,\n",
       "     0.011429389317830404,\n",
       "     0.016660451889038086,\n",
       "     0.011443376541137695,\n",
       "     0.005882581075032552,\n",
       "     0.010776122411092123,\n",
       "     0.01666998863220215,\n",
       "     0.011710405349731445],\n",
       "    'std_score_time': [0.002161304421547673,\n",
       "     0.00047114657596417054,\n",
       "     0.0006567628566733905,\n",
       "     0.0038761613638499024,\n",
       "     0.015457119066154658,\n",
       "     0.0,\n",
       "     0.007371989566737497,\n",
       "     0.007628818913275861,\n",
       "     0.007631052761705561,\n",
       "     0.0,\n",
       "     0.008290520176610893],\n",
       "    'param_classifier__C': [1e-07,\n",
       "     1e-06,\n",
       "     1e-05,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     1000.0],\n",
       "    'params': [{'classifier__C': 1e-07},\n",
       "     {'classifier__C': 1e-06},\n",
       "     {'classifier__C': 1e-05},\n",
       "     {'classifier__C': 0.0001},\n",
       "     {'classifier__C': 0.001},\n",
       "     {'classifier__C': 0.01},\n",
       "     {'classifier__C': 0.1},\n",
       "     {'classifier__C': 1},\n",
       "     {'classifier__C': 10},\n",
       "     {'classifier__C': 100},\n",
       "     {'classifier__C': 1000}],\n",
       "    'split0_test_score': [0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7142857142857143,\n",
       "     0.7142857142857143,\n",
       "     0.7142857142857143],\n",
       "    'split1_test_score': [0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7023809523809523,\n",
       "     0.7142857142857143,\n",
       "     0.7142857142857143],\n",
       "    'split2_test_score': [0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7261904761904762,\n",
       "     0.7261904761904762,\n",
       "     0.7261904761904762],\n",
       "    'mean_test_score': [0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7142857142857143,\n",
       "     0.7182539682539683,\n",
       "     0.7182539682539683],\n",
       "    'std_test_score': [0.005611958580845595,\n",
       "     0.005611958580845595,\n",
       "     0.005611958580845595,\n",
       "     0.005611958580845595,\n",
       "     0.005611958580845595,\n",
       "     0.005611958580845595,\n",
       "     0.005611958580845595,\n",
       "     0.005611958580845595,\n",
       "     0.00972019739199675,\n",
       "     0.005611958580845596,\n",
       "     0.005611958580845596],\n",
       "    'rank_test_score': [1, 1, 1, 1, 1, 1, 1, 1, 11, 9, 9]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__C': 1},\n",
       "   'best_validation_accuracy': 0.7791597567716971,\n",
       "   'train_accuracy': 0.7791563275434243,\n",
       "   'test_accuracy': 0.7722772277227723,\n",
       "   'cv_results': {'mean_fit_time': [0.016781091690063477,\n",
       "     0.010876178741455078,\n",
       "     0.0167238712310791,\n",
       "     0.022336641947428387,\n",
       "     0.01878070831298828,\n",
       "     0.02700463930765788,\n",
       "     0.03852065404256185,\n",
       "     0.02209893862406413,\n",
       "     0.019538005193074543,\n",
       "     0.022598902384440105,\n",
       "     0.016722440719604492],\n",
       "    'std_fit_time': [0.0,\n",
       "     0.007697888140135979,\n",
       "     0.0,\n",
       "     0.007897230044944444,\n",
       "     0.001679980918575051,\n",
       "     0.0024898402191509935,\n",
       "     0.008103629632711952,\n",
       "     0.007984372055882902,\n",
       "     0.00947730705289983,\n",
       "     0.0076002802115608704,\n",
       "     0.0],\n",
       "    'mean_score_time': [0.0167238712310791,\n",
       "     0.01173837979634603,\n",
       "     0.005237023035685222,\n",
       "     0.005593697230021159,\n",
       "     0.016605456670125324,\n",
       "     0.006349643071492513,\n",
       "     0.016342322031656902,\n",
       "     0.016608715057373047,\n",
       "     0.011444330215454102,\n",
       "     0.018198410669962566,\n",
       "     0.0303342342376709],\n",
       "    'std_score_time': [0.0,\n",
       "     0.008331590210627444,\n",
       "     0.007406269003526357,\n",
       "     0.007910682486504736,\n",
       "     0.003612667525382101,\n",
       "     0.0024898402191509935,\n",
       "     0.00044111631096668645,\n",
       "     0.0,\n",
       "     0.007384105234491733,\n",
       "     0.0008093318830051945,\n",
       "     0.017581288981786847],\n",
       "    'param_classifier__C': [1e-07,\n",
       "     1e-06,\n",
       "     1e-05,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     1000.0],\n",
       "    'params': [{'classifier__C': 1e-07},\n",
       "     {'classifier__C': 1e-06},\n",
       "     {'classifier__C': 1e-05},\n",
       "     {'classifier__C': 0.0001},\n",
       "     {'classifier__C': 0.001},\n",
       "     {'classifier__C': 0.01},\n",
       "     {'classifier__C': 0.1},\n",
       "     {'classifier__C': 1},\n",
       "     {'classifier__C': 10},\n",
       "     {'classifier__C': 100},\n",
       "     {'classifier__C': 1000}],\n",
       "    'split0_test_score': [0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.6962962962962963,\n",
       "     0.6814814814814815,\n",
       "     0.6814814814814815],\n",
       "    'split1_test_score': [0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7313432835820896,\n",
       "     0.7089552238805971,\n",
       "     0.7089552238805971],\n",
       "    'split2_test_score': [0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7835820895522388,\n",
       "     0.7014925373134329,\n",
       "     0.6865671641791045,\n",
       "     0.6865671641791045],\n",
       "    'mean_test_score': [0.7766721945826424,\n",
       "     0.7766721945826424,\n",
       "     0.7766721945826424,\n",
       "     0.7766721945826424,\n",
       "     0.7766721945826424,\n",
       "     0.7766721945826424,\n",
       "     0.7766721945826424,\n",
       "     0.7791597567716971,\n",
       "     0.7097107057306062,\n",
       "     0.6923346231803943,\n",
       "     0.6923346231803943],\n",
       "    'std_test_score': [0.0007817653744461518,\n",
       "     0.0007817653744461518,\n",
       "     0.0007817653744461518,\n",
       "     0.0007817653744461518,\n",
       "     0.0007817653744461518,\n",
       "     0.0007817653744461518,\n",
       "     0.0007817653744461518,\n",
       "     0.003199512687338382,\n",
       "     0.015442939024084931,\n",
       "     0.01193452464775787,\n",
       "     0.01193452464775787],\n",
       "    'rank_test_score': [2, 2, 2, 2, 2, 2, 2, 1, 9, 10, 10]}}],\n",
       " 'vegas KNN': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__n_neighbors': 7},\n",
       "   'best_validation_accuracy': 0.8101604278074866,\n",
       "   'train_accuracy': 0.8,\n",
       "   'test_accuracy': 0.7599009900990099,\n",
       "   'cv_results': {'mean_fit_time': [0.010560035705566406,\n",
       "     0.01666545867919922,\n",
       "     0.01666545867919922,\n",
       "     0.016436100006103516,\n",
       "     0.011141141255696615],\n",
       "    'std_fit_time': [0.007497424410673877,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.00042356199643241263,\n",
       "     0.007877976532060283],\n",
       "    'mean_score_time': [0.2894706726074219,\n",
       "     0.28336524963378906,\n",
       "     0.28336524963378906,\n",
       "     0.27248430252075195,\n",
       "     0.005570570627848308],\n",
       "    'std_score_time': [0.007497424410673877,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007703934520925979,\n",
       "     0.007877976532060283],\n",
       "    'param_classifier__n_neighbors': [3, 5, 7, 9, 11],\n",
       "    'params': [{'classifier__n_neighbors': 3},\n",
       "     {'classifier__n_neighbors': 5},\n",
       "     {'classifier__n_neighbors': 7},\n",
       "     {'classifier__n_neighbors': 9},\n",
       "     {'classifier__n_neighbors': 11}],\n",
       "    'split0_test_score': [0.6764705882352942,\n",
       "     0.7647058823529411,\n",
       "     0.7941176470588235,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411],\n",
       "    'split1_test_score': [0.696969696969697,\n",
       "     0.7575757575757576,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878],\n",
       "    'split2_test_score': [0.696969696969697,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878],\n",
       "    'mean_test_score': [0.690136660724896,\n",
       "     0.7801544860368389,\n",
       "     0.8101604278074866,\n",
       "     0.8003565062388592,\n",
       "     0.7801544860368389],\n",
       "    'std_test_score': [0.009663372529584432,\n",
       "     0.02704648051513026,\n",
       "     0.011343959056468724,\n",
       "     0.025208797903263774,\n",
       "     0.010923812424747622],\n",
       "    'rank_test_score': [5, 3, 1, 2, 3]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__n_neighbors': 7},\n",
       "   'best_validation_accuracy': 0.7777777777777778,\n",
       "   'train_accuracy': 0.7738095238095238,\n",
       "   'test_accuracy': 0.7738095238095238,\n",
       "   'cv_results': {'mean_fit_time': [0.01651302973429362,\n",
       "     0.011199156443277994,\n",
       "     0.0055695374806722,\n",
       "     0.0167086124420166,\n",
       "     0.006433645884195964],\n",
       "    'std_fit_time': [0.0004040477877244374,\n",
       "     0.007918999464610887,\n",
       "     0.007876515441311906,\n",
       "     0.0,\n",
       "     0.007272772459744661],\n",
       "    'mean_score_time': [0.0002857049306233724,\n",
       "     0.01584450403849284,\n",
       "     0.0111390749613444,\n",
       "     0.0050160884857177734,\n",
       "     0.0050160884857177734],\n",
       "    'std_score_time': [0.0004040477877244375,\n",
       "     0.0006921647459776945,\n",
       "     0.007876515441311906,\n",
       "     0.007093820366565596,\n",
       "     0.007093820366565596],\n",
       "    'param_classifier__n_neighbors': [3, 5, 7, 9, 11],\n",
       "    'params': [{'classifier__n_neighbors': 3},\n",
       "     {'classifier__n_neighbors': 5},\n",
       "     {'classifier__n_neighbors': 7},\n",
       "     {'classifier__n_neighbors': 9},\n",
       "     {'classifier__n_neighbors': 11}],\n",
       "    'split0_test_score': [0.7261904761904762,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7857142857142857],\n",
       "    'split1_test_score': [0.7023809523809523,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238],\n",
       "    'split2_test_score': [0.7261904761904762,\n",
       "     0.7380952380952381,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238],\n",
       "    'mean_test_score': [0.7182539682539683,\n",
       "     0.7619047619047619,\n",
       "     0.7777777777777778,\n",
       "     0.7738095238095238,\n",
       "     0.7777777777777778],\n",
       "    'std_test_score': [0.011223917161691244,\n",
       "     0.019440394783993453,\n",
       "     0.005611958580845595,\n",
       "     0.0,\n",
       "     0.005611958580845595],\n",
       "    'rank_test_score': [5, 4, 1, 3, 1]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__n_neighbors': 7},\n",
       "   'best_validation_accuracy': 0.7692647871752349,\n",
       "   'train_accuracy': 0.8138957816377171,\n",
       "   'test_accuracy': 0.7425742574257426,\n",
       "   'cv_results': {'mean_fit_time': [0.0,\n",
       "     0.0112457275390625,\n",
       "     0.01686859130859375,\n",
       "     0.022662639617919922,\n",
       "     0.01743912696838379],\n",
       "    'std_fit_time': [0.0,\n",
       "     0.007951930202247399,\n",
       "     0.0,\n",
       "     0.008194021700093973,\n",
       "     0.0007545971757390468],\n",
       "    'mean_score_time': [0.01686859130859375,\n",
       "     0.00562286376953125,\n",
       "     0.005457321802775065,\n",
       "     0.011645078659057617,\n",
       "     0.0005335807800292969],\n",
       "    'std_score_time': [0.0,\n",
       "     0.007951930202247399,\n",
       "     0.007717818507718885,\n",
       "     0.007843992789798375,\n",
       "     0.0007545971757390468],\n",
       "    'param_classifier__n_neighbors': [3, 5, 7, 9, 11],\n",
       "    'params': [{'classifier__n_neighbors': 3},\n",
       "     {'classifier__n_neighbors': 5},\n",
       "     {'classifier__n_neighbors': 7},\n",
       "     {'classifier__n_neighbors': 9},\n",
       "     {'classifier__n_neighbors': 11}],\n",
       "    'split0_test_score': [0.7185185185185186,\n",
       "     0.762962962962963,\n",
       "     0.7555555555555555,\n",
       "     0.7555555555555555,\n",
       "     0.7777777777777778],\n",
       "    'split1_test_score': [0.7238805970149254,\n",
       "     0.7761194029850746,\n",
       "     0.7835820895522388,\n",
       "     0.7835820895522388,\n",
       "     0.7761194029850746],\n",
       "    'split2_test_score': [0.746268656716418,\n",
       "     0.746268656716418,\n",
       "     0.7686567164179104,\n",
       "     0.746268656716418,\n",
       "     0.753731343283582],\n",
       "    'mean_test_score': [0.7295559240832873,\n",
       "     0.7617836742214852,\n",
       "     0.7692647871752349,\n",
       "     0.7618021006080707,\n",
       "     0.7692095080154782],\n",
       "    'std_test_score': [0.01201872276908796,\n",
       "     0.012215012748001604,\n",
       "     0.011449860683322636,\n",
       "     0.015860591861973628,\n",
       "     0.010965635392414276],\n",
       "    'rank_test_score': [5, 4, 1, 3, 2]}}],\n",
       " 'vegas log_reg': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__C': 0.1,\n",
       "    'classifier__max_iter': 500,\n",
       "    'classifier__penalty': 'l2'},\n",
       "   'best_validation_accuracy': 0.7902554961378492,\n",
       "   'train_accuracy': 0.78,\n",
       "   'test_accuracy': 0.7722772277227723,\n",
       "   'cv_results': {'mean_fit_time': [0.02282579739888509,\n",
       "     0.01763153076171875,\n",
       "     0.011870940526326498,\n",
       "     0.015582799911499023,\n",
       "     0.01729098955790202,\n",
       "     0.01950812339782715,\n",
       "     0.01950812339782715,\n",
       "     0.02397616704305013,\n",
       "     0.022899945576985676,\n",
       "     0.026816050211588543,\n",
       "     0.02675175666809082,\n",
       "     0.021785497665405273,\n",
       "     0.018938302993774414,\n",
       "     0.025719563166300457,\n",
       "     0.02010480562845866,\n",
       "     0.023015737533569336],\n",
       "    'std_fit_time': [0.007345802324862728,\n",
       "     0.0,\n",
       "     0.007494905975968188,\n",
       "     0.0,\n",
       "     0.0016211103089305448,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.006318767920349262,\n",
       "     0.005945294225775815,\n",
       "     0.007294020480801911,\n",
       "     0.007384231528081163,\n",
       "     0.008214670914060414,\n",
       "     0.0057378829106044206,\n",
       "     0.010836910080717103,\n",
       "     0.002621076379567664,\n",
       "     0.0073786856718584615],\n",
       "    'mean_score_time': [0.01561427116394043,\n",
       "     0.015582799911499023,\n",
       "     0.010711272557576498,\n",
       "     0.0,\n",
       "     0.0003368059794108073,\n",
       "     0.004446824391682942,\n",
       "     0.016413370768229168,\n",
       "     0.015281200408935547,\n",
       "     0.008621851603190104,\n",
       "     0.0055998961130778,\n",
       "     0.005491336186726888,\n",
       "     0.011091232299804688,\n",
       "     0.01143320401509603,\n",
       "     0.005491336186726888,\n",
       "     0.0055998961130778,\n",
       "     0.010930776596069336],\n",
       "    'std_score_time': [4.45070720275041e-05,\n",
       "     0.0,\n",
       "     0.006889380053388753,\n",
       "     0.0,\n",
       "     0.00047631558397111706,\n",
       "     0.006288759364209506,\n",
       "     0.0035623677456358004,\n",
       "     0.004724062923673722,\n",
       "     0.006747471718923943,\n",
       "     0.007919449030995004,\n",
       "     0.0077659221108193205,\n",
       "     0.007843812520103305,\n",
       "     0.007360265531224406,\n",
       "     0.0077659221108193205,\n",
       "     0.007919449030995004,\n",
       "     0.007730727146718809],\n",
       "    'param_classifier__C': [0.0001,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     100.0,\n",
       "     1000.0,\n",
       "     1000.0],\n",
       "    'param_classifier__max_iter': [500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000],\n",
       "    'param_classifier__penalty': ['l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2'],\n",
       "    'params': [{'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'}],\n",
       "    'split0_test_score': [0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.6470588235294118,\n",
       "     0.6470588235294118,\n",
       "     0.6470588235294118,\n",
       "     0.6470588235294118,\n",
       "     0.6470588235294118,\n",
       "     0.6470588235294118],\n",
       "    'split1_test_score': [0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.6060606060606061,\n",
       "     0.6060606060606061,\n",
       "     0.5757575757575758,\n",
       "     0.5757575757575758,\n",
       "     0.6666666666666666,\n",
       "     0.6666666666666666],\n",
       "    'split2_test_score': [0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.5454545454545454,\n",
       "     0.5454545454545454,\n",
       "     0.48484848484848486,\n",
       "     0.48484848484848486,\n",
       "     0.48484848484848486,\n",
       "     0.48484848484848486],\n",
       "    'mean_test_score': [0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7801544860368389,\n",
       "     0.7902554961378492,\n",
       "     0.7902554961378492,\n",
       "     0.7299465240641712,\n",
       "     0.7299465240641712,\n",
       "     0.5995246583481878,\n",
       "     0.5995246583481878,\n",
       "     0.5692216280451575,\n",
       "     0.5692216280451575,\n",
       "     0.5995246583481878,\n",
       "     0.5995246583481878],\n",
       "    'std_test_score': [0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.010923812424747622,\n",
       "     0.02189604964074666,\n",
       "     0.02189604964074666,\n",
       "     0.003781319685489574,\n",
       "     0.003781319685489574,\n",
       "     0.04173644522599158,\n",
       "     0.04173644522599158,\n",
       "     0.06638316781192782,\n",
       "     0.06638316781192782,\n",
       "     0.08148245395799135,\n",
       "     0.08148245395799135],\n",
       "    'rank_test_score': [3,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     1,\n",
       "     1,\n",
       "     9,\n",
       "     9,\n",
       "     11,\n",
       "     11,\n",
       "     15,\n",
       "     15,\n",
       "     11,\n",
       "     11]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__C': 0.0001,\n",
       "    'classifier__max_iter': 500,\n",
       "    'classifier__penalty': 'l2'},\n",
       "   'best_validation_accuracy': 0.7777777777777778,\n",
       "   'train_accuracy': 0.7777777777777778,\n",
       "   'test_accuracy': 0.7738095238095238,\n",
       "   'cv_results': {'mean_fit_time': [0.005006551742553711,\n",
       "     0.0063889821370442705,\n",
       "     0.016646862030029297,\n",
       "     0.016335010528564453,\n",
       "     0.020329634348551433,\n",
       "     0.025625228881835938,\n",
       "     0.024849812189737957,\n",
       "     0.02308940887451172,\n",
       "     0.02037334442138672,\n",
       "     0.019190073013305664,\n",
       "     0.029603004455566406,\n",
       "     0.027271032333374023,\n",
       "     0.03132295608520508,\n",
       "     0.026012182235717773,\n",
       "     0.031217336654663086,\n",
       "     0.027523517608642578],\n",
       "    'std_fit_time': [0.0070803333750421105,\n",
       "     0.007312972167391654,\n",
       "     0.0,\n",
       "     0.00044102462281799513,\n",
       "     0.006168382484840444,\n",
       "     0.011479115660427098,\n",
       "     0.0024842819134225256,\n",
       "     0.0030141698707586858,\n",
       "     0.0006154931892597109,\n",
       "     0.0018784829432377836,\n",
       "     0.0028917871985342757,\n",
       "     0.00791300233300679,\n",
       "     0.0019486674444257883,\n",
       "     0.006906974684604987,\n",
       "     0.007781882775808622,\n",
       "     0.015237708322843567],\n",
       "    'mean_score_time': [0.006137927373250325,\n",
       "     0.005548954010009766,\n",
       "     0.011672178904215494,\n",
       "     0.012503941853841146,\n",
       "     0.004296064376831055,\n",
       "     0.01264190673828125,\n",
       "     0.012103557586669922,\n",
       "     0.00910655657450358,\n",
       "     0.006332874298095703,\n",
       "     0.0030047098795572915,\n",
       "     0.0,\n",
       "     0.011510610580444336,\n",
       "     0.005559841791788737,\n",
       "     0.01630560557047526,\n",
       "     0.0055493513743082685,\n",
       "     0.005911032358805339],\n",
       "    'std_score_time': [0.007512350946671037,\n",
       "     0.007847406017940381,\n",
       "     0.008253476854393342,\n",
       "     0.007077186410353297,\n",
       "     0.0040329786486576445,\n",
       "     0.0018814607061734304,\n",
       "     0.003590446230375128,\n",
       "     7.327957918010767e-05,\n",
       "     0.00449656891965751,\n",
       "     0.004249301462666351,\n",
       "     0.0,\n",
       "     0.0073945255472264585,\n",
       "     0.007862803666596361,\n",
       "     0.0005067118362419919,\n",
       "     0.007847967975920526,\n",
       "     0.007626612822570863],\n",
       "    'param_classifier__C': [0.0001,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     100.0,\n",
       "     1000.0,\n",
       "     1000.0],\n",
       "    'param_classifier__max_iter': [500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000],\n",
       "    'param_classifier__penalty': ['l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2'],\n",
       "    'params': [{'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'}],\n",
       "    'split0_test_score': [0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7261904761904762,\n",
       "     0.7261904761904762,\n",
       "     0.6547619047619048,\n",
       "     0.6547619047619048,\n",
       "     0.6428571428571429,\n",
       "     0.6428571428571429],\n",
       "    'split1_test_score': [0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.75,\n",
       "     0.75,\n",
       "     0.7023809523809523,\n",
       "     0.7023809523809523,\n",
       "     0.6785714285714286,\n",
       "     0.6785714285714286,\n",
       "     0.6547619047619048,\n",
       "     0.6547619047619048],\n",
       "    'split2_test_score': [0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.6904761904761905,\n",
       "     0.6904761904761905,\n",
       "     0.6547619047619048,\n",
       "     0.6547619047619048,\n",
       "     0.6666666666666666,\n",
       "     0.6666666666666666],\n",
       "    'mean_test_score': [0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7738095238095237,\n",
       "     0.7658730158730158,\n",
       "     0.7658730158730158,\n",
       "     0.7063492063492062,\n",
       "     0.7063492063492062,\n",
       "     0.6626984126984127,\n",
       "     0.6626984126984127,\n",
       "     0.6547619047619048,\n",
       "     0.6547619047619048],\n",
       "    'std_test_score': [0.005611958580845595,\n",
       "     0.005611958580845595,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.011223917161691244,\n",
       "     0.011223917161691244,\n",
       "     0.014847846772912463,\n",
       "     0.014847846772912463,\n",
       "     0.011223917161691244,\n",
       "     0.011223917161691244,\n",
       "     0.009720197391996704,\n",
       "     0.009720197391996704],\n",
       "    'rank_test_score': [1,\n",
       "     1,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     9,\n",
       "     9,\n",
       "     11,\n",
       "     11,\n",
       "     13,\n",
       "     13,\n",
       "     15,\n",
       "     15]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__C': 0.0001,\n",
       "    'classifier__max_iter': 500,\n",
       "    'classifier__penalty': 'l2'},\n",
       "   'best_validation_accuracy': 0.7766721945826424,\n",
       "   'train_accuracy': 0.7766749379652605,\n",
       "   'test_accuracy': 0.7722772277227723,\n",
       "   'cv_results': {'mean_fit_time': [0.005648454030354817,\n",
       "     0.016945362091064453,\n",
       "     0.016945362091064453,\n",
       "     0.016573190689086914,\n",
       "     0.01812903086344401,\n",
       "     0.02387269337972005,\n",
       "     0.02696506182352702,\n",
       "     0.020962317784627277,\n",
       "     0.024265607198079426,\n",
       "     0.02189040184020996,\n",
       "     0.03156582514444987,\n",
       "     0.031479994455973305,\n",
       "     0.03791308403015137,\n",
       "     0.03585966428120931,\n",
       "     0.0505673885345459,\n",
       "     0.04399394989013672],\n",
       "    'std_fit_time': [0.007988120296168754,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0005263298442040446,\n",
       "     0.0024991277649533726,\n",
       "     0.0002881720522184861,\n",
       "     0.004085097340867908,\n",
       "     0.00047313646244675,\n",
       "     0.0015209874879330008,\n",
       "     0.006974620087453143,\n",
       "     0.0034747488162358677,\n",
       "     0.004866564004015352,\n",
       "     0.012159276500818545,\n",
       "     0.0008844912488610894,\n",
       "     0.0031040310991303235,\n",
       "     0.007919295703499122],\n",
       "    'mean_score_time': [0.005648454030354817,\n",
       "     0.0,\n",
       "     0.010292847951253256,\n",
       "     0.011691013971964518,\n",
       "     0.005947430928548177,\n",
       "     0.01288445790608724,\n",
       "     0.013792673746744791,\n",
       "     0.010391553243001303,\n",
       "     0.011838833491007486,\n",
       "     0.013480822245279947,\n",
       "     0.0050309499104817705,\n",
       "     0.00986631711324056,\n",
       "     0.01404277483622233,\n",
       "     0.01044917106628418,\n",
       "     0.0050267378489176435,\n",
       "     0.0003543694814046224],\n",
       "    'std_score_time': [0.007988120296168754,\n",
       "     0.0,\n",
       "     0.007285090191066577,\n",
       "     0.007461790451964709,\n",
       "     0.0024991277649533726,\n",
       "     0.0022058314311388365,\n",
       "     0.002114372754359651,\n",
       "     0.0005520709518378161,\n",
       "     0.004236686613562948,\n",
       "     0.006516564932803176,\n",
       "     0.006410404034355104,\n",
       "     0.0071525341519226085,\n",
       "     0.005815903163842718,\n",
       "     0.004948517930180907,\n",
       "     0.006413044881616485,\n",
       "     0.0005011541266935374],\n",
       "    'param_classifier__C': [0.0001,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     100.0,\n",
       "     1000.0,\n",
       "     1000.0],\n",
       "    'param_classifier__max_iter': [500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000],\n",
       "    'param_classifier__penalty': ['l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2'],\n",
       "    'params': [{'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'}],\n",
       "    'split0_test_score': [0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7703703703703704,\n",
       "     0.7703703703703704,\n",
       "     0.7333333333333333,\n",
       "     0.7333333333333333,\n",
       "     0.6888888888888889,\n",
       "     0.6888888888888889,\n",
       "     0.674074074074074,\n",
       "     0.674074074074074,\n",
       "     0.6666666666666666,\n",
       "     0.6666666666666666],\n",
       "    'split1_test_score': [0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.7238805970149254,\n",
       "     0.7238805970149254,\n",
       "     0.7089552238805971,\n",
       "     0.7089552238805971,\n",
       "     0.7164179104477612,\n",
       "     0.7164179104477612,\n",
       "     0.7238805970149254,\n",
       "     0.7238805970149254],\n",
       "    'split2_test_score': [0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.753731343283582,\n",
       "     0.753731343283582,\n",
       "     0.7313432835820896,\n",
       "     0.7313432835820896,\n",
       "     0.7238805970149254,\n",
       "     0.7238805970149254,\n",
       "     0.7164179104477612,\n",
       "     0.7164179104477612,\n",
       "     0.7089552238805971,\n",
       "     0.7089552238805971],\n",
       "    'mean_test_score': [0.7766721945826424,\n",
       "     0.7766721945826424,\n",
       "     0.7741846323935876,\n",
       "     0.7741846323935876,\n",
       "     0.7741846323935876,\n",
       "     0.7741846323935876,\n",
       "     0.7642528100239544,\n",
       "     0.7642528100239544,\n",
       "     0.7295190713101162,\n",
       "     0.7295190713101162,\n",
       "     0.707241569928137,\n",
       "     0.707241569928137,\n",
       "     0.7023032983231987,\n",
       "     0.7023032983231987,\n",
       "     0.6998341625207297,\n",
       "     0.6998341625207297],\n",
       "    'std_test_score': [0.0007817653744461518,\n",
       "     0.0007817653744461518,\n",
       "     0.003967026007298881,\n",
       "     0.003967026007298881,\n",
       "     0.003967026007298881,\n",
       "     0.003967026007298881,\n",
       "     0.007472621103903898,\n",
       "     0.007472621103903898,\n",
       "     0.00406893669863525,\n",
       "     0.00406893669863525,\n",
       "     0.014336605055963514,\n",
       "     0.014336605055963514,\n",
       "     0.019961075894191826,\n",
       "     0.019961075894191826,\n",
       "     0.024231574123055502,\n",
       "     0.024231574123055502],\n",
       "    'rank_test_score': [1,\n",
       "     1,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     7,\n",
       "     7,\n",
       "     9,\n",
       "     9,\n",
       "     11,\n",
       "     11,\n",
       "     13,\n",
       "     13,\n",
       "     15,\n",
       "     15]}}],\n",
       " 'vegas decision_tree': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__criterion': 'entropy',\n",
       "    'classifier__max_depth': 3,\n",
       "    'classifier__min_samples_split': 5},\n",
       "   'best_validation_accuracy': 0.7599524658348188,\n",
       "   'train_accuracy': 0.84,\n",
       "   'test_accuracy': 0.7178217821782178,\n",
       "   'cv_results': {'mean_fit_time': [0.011546452840169271,\n",
       "     0.0003062884012858073,\n",
       "     0.01632404327392578,\n",
       "     0.01816105842590332,\n",
       "     0.020673274993896484,\n",
       "     0.015278339385986328,\n",
       "     0.013065735499064127,\n",
       "     0.008730649948120117,\n",
       "     0.017429431279500324,\n",
       "     0.012259642283121744,\n",
       "     0.01756604512532552,\n",
       "     0.016833146413167317,\n",
       "     0.020525455474853516,\n",
       "     0.019057194391886394,\n",
       "     0.020720958709716797,\n",
       "     0.015749216079711914,\n",
       "     0.016939640045166016,\n",
       "     0.01713705062866211,\n",
       "     0.017201662063598633,\n",
       "     0.011207103729248047,\n",
       "     0.015249808629353842,\n",
       "     0.01532745361328125,\n",
       "     0.019887447357177734,\n",
       "     0.013518810272216797],\n",
       "    'std_fit_time': [0.00751483928529042,\n",
       "     0.00043315721109596155,\n",
       "     0.0013369986023279296,\n",
       "     0.0,\n",
       "     0.0019474305962161565,\n",
       "     0.005409385711043202,\n",
       "     0.0008161240658926607,\n",
       "     0.0012327374166996733,\n",
       "     0.004426419626824671,\n",
       "     0.008671373598408375,\n",
       "     0.0017283396921470662,\n",
       "     0.0019871275093921136,\n",
       "     0.003896997912348408,\n",
       "     0.005369905746069721,\n",
       "     0.00765800004234897,\n",
       "     0.00045296430481727774,\n",
       "     0.002738970035187354,\n",
       "     0.010545878632956904,\n",
       "     0.0013688094362505098,\n",
       "     0.005942975348238896,\n",
       "     0.000505172319259522,\n",
       "     0.0007097529289234555,\n",
       "     0.007478460534744129,\n",
       "     0.00320400544779246],\n",
       "    'mean_score_time': [0.011636495590209961,\n",
       "     0.012107372283935547,\n",
       "     0.001837015151977539,\n",
       "     0.0,\n",
       "     0.00646201769510905,\n",
       "     0.006757020950317383,\n",
       "     0.0,\n",
       "     0.0094453493754069,\n",
       "     0.005601088205973308,\n",
       "     0.013794898986816406,\n",
       "     0.008889357248942057,\n",
       "     0.010673840840657553,\n",
       "     0.009397347768147787,\n",
       "     0.012430906295776367,\n",
       "     0.009898900985717773,\n",
       "     0.009038686752319336,\n",
       "     0.011917829513549805,\n",
       "     0.008275747299194336,\n",
       "     0.0061414241790771484,\n",
       "     0.013851404190063477,\n",
       "     0.005071401596069336,\n",
       "     0.006483713785807292,\n",
       "     0.00033354759216308594,\n",
       "     0.0104827880859375],\n",
       "    'std_score_time': [0.00824843028106129,\n",
       "     0.008561205044320883,\n",
       "     0.0013369986023279296,\n",
       "     0.0,\n",
       "     0.004608594881165013,\n",
       "     0.0017156886658896873,\n",
       "     0.0,\n",
       "     0.006691596955391148,\n",
       "     0.006040256883927051,\n",
       "     0.005628797874837075,\n",
       "     0.0009133328010413853,\n",
       "     0.0027553745325115645,\n",
       "     0.0006983891961345507,\n",
       "     0.004455153419969071,\n",
       "     0.0003509251525419774,\n",
       "     7.980222796796945e-05,\n",
       "     0.0023946726004065552,\n",
       "     0.006174331465306446,\n",
       "     0.004345978158351292,\n",
       "     0.0027482567699107677,\n",
       "     0.003789655132530861,\n",
       "     0.007261791741847455,\n",
       "     0.000471707528533926,\n",
       "     0.00744867396818149],\n",
       "    'param_classifier__criterion': ['gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy'],\n",
       "    'param_classifier__max_depth': [3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10],\n",
       "    'params': [{'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10}],\n",
       "    'split0_test_score': [0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7058823529411765,\n",
       "     0.6176470588235294,\n",
       "     0.6470588235294118,\n",
       "     0.5588235294117647,\n",
       "     0.6470588235294118,\n",
       "     0.5882352941176471,\n",
       "     0.5588235294117647,\n",
       "     0.6764705882352942,\n",
       "     0.6176470588235294,\n",
       "     0.5588235294117647,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7058823529411765,\n",
       "     0.6470588235294118,\n",
       "     0.6176470588235294,\n",
       "     0.5588235294117647,\n",
       "     0.7352941176470589,\n",
       "     0.6764705882352942,\n",
       "     0.5588235294117647,\n",
       "     0.6470588235294118,\n",
       "     0.6470588235294118,\n",
       "     0.5588235294117647],\n",
       "    'split1_test_score': [0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.7878787878787878,\n",
       "     0.7272727272727273,\n",
       "     0.7575757575757576,\n",
       "     0.7272727272727273,\n",
       "     0.6666666666666666,\n",
       "     0.696969696969697,\n",
       "     0.7272727272727273,\n",
       "     0.6666666666666666,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.8181818181818182,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.6363636363636364,\n",
       "     0.7272727272727273,\n",
       "     0.5757575757575758,\n",
       "     0.696969696969697,\n",
       "     0.6363636363636364,\n",
       "     0.5757575757575758],\n",
       "    'split2_test_score': [0.6363636363636364,\n",
       "     0.6666666666666666,\n",
       "     0.6666666666666666,\n",
       "     0.7272727272727273,\n",
       "     0.6666666666666666,\n",
       "     0.7575757575757576,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.7575757575757576,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7272727272727273,\n",
       "     0.696969696969697,\n",
       "     0.7272727272727273,\n",
       "     0.6666666666666666,\n",
       "     0.696969696969697],\n",
       "    'mean_test_score': [0.7094474153297683,\n",
       "     0.7195484254307783,\n",
       "     0.6999405822935234,\n",
       "     0.6907308377896614,\n",
       "     0.7005347593582888,\n",
       "     0.6812240047534166,\n",
       "     0.7106357694592988,\n",
       "     0.680926916221034,\n",
       "     0.6610219845513964,\n",
       "     0.700237670825906,\n",
       "     0.6907308377896614,\n",
       "     0.6509209744503862,\n",
       "     0.7397504456327986,\n",
       "     0.7599524658348188,\n",
       "     0.7302436125965537,\n",
       "     0.7510398098633392,\n",
       "     0.7109328579916815,\n",
       "     0.6913250148544267,\n",
       "     0.7097445038621508,\n",
       "     0.7103386809269162,\n",
       "     0.6105169340463459,\n",
       "     0.6904337492572786,\n",
       "     0.6500297088532383,\n",
       "     0.6105169340463459],\n",
       "    'std_test_score': [0.053890254751625566,\n",
       "     0.040395301560982845,\n",
       "     0.02509650871294462,\n",
       "     0.05167803570169064,\n",
       "     0.06227814687227035,\n",
       "     0.08742987927203273,\n",
       "     0.046626812398843594,\n",
       "     0.06554287454848569,\n",
       "     0.08123836892000728,\n",
       "     0.020868222612995764,\n",
       "     0.05167803570169064,\n",
       "     0.06966456862484116,\n",
       "     0.017646158532284576,\n",
       "     0.024969579785443462,\n",
       "     0.02120804313437282,\n",
       "     0.07455916018222893,\n",
       "     0.06596302118020674,\n",
       "     0.09369269887379685,\n",
       "     0.05267941821751616,\n",
       "     0.023948358008100534,\n",
       "     0.06152100261548296,\n",
       "     0.03307170540719131,\n",
       "     0.012548254356472282,\n",
       "     0.06152100261548296],\n",
       "    'rank_test_score': [10,\n",
       "     5,\n",
       "     13,\n",
       "     15,\n",
       "     11,\n",
       "     18,\n",
       "     7,\n",
       "     19,\n",
       "     20,\n",
       "     12,\n",
       "     15,\n",
       "     21,\n",
       "     3,\n",
       "     1,\n",
       "     4,\n",
       "     2,\n",
       "     6,\n",
       "     14,\n",
       "     9,\n",
       "     8,\n",
       "     23,\n",
       "     17,\n",
       "     22,\n",
       "     23]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__criterion': 'entropy',\n",
       "    'classifier__max_depth': 3,\n",
       "    'classifier__min_samples_split': 2},\n",
       "   'best_validation_accuracy': 0.746031746031746,\n",
       "   'train_accuracy': 0.7896825396825397,\n",
       "   'test_accuracy': 0.7777777777777778,\n",
       "   'cv_results': {'mean_fit_time': [0.018160263697306316,\n",
       "     0.02216339111328125,\n",
       "     0.02199689547220866,\n",
       "     0.014297803243001303,\n",
       "     0.009645700454711914,\n",
       "     0.009267568588256836,\n",
       "     0.020207722981770832,\n",
       "     0.018169879913330078,\n",
       "     0.01079400380452474,\n",
       "     0.012109994888305664,\n",
       "     0.011320273081461588,\n",
       "     0.01786939303080241,\n",
       "     0.016921202341715496,\n",
       "     0.015846411387125652,\n",
       "     0.016292730967203777,\n",
       "     0.016548713048299152,\n",
       "     0.0168761412302653,\n",
       "     0.01660776138305664,\n",
       "     0.011012395222981771,\n",
       "     0.022264639536539715,\n",
       "     0.017008304595947266,\n",
       "     0.016758441925048828,\n",
       "     0.016730785369873047,\n",
       "     0.016768614451090496],\n",
       "    'std_fit_time': [0.0017026304820252412,\n",
       "     0.00124789342619456,\n",
       "     0.0064172088123142556,\n",
       "     0.0015457459403183061,\n",
       "     0.0021691803194151178,\n",
       "     0.0,\n",
       "     0.0028819453053769194,\n",
       "     0.0,\n",
       "     0.007801659298909516,\n",
       "     0.007862530071301641,\n",
       "     0.008076084204270252,\n",
       "     0.0005992719900268986,\n",
       "     0.0001424001521688073,\n",
       "     0.000900489442214936,\n",
       "     0.0010311928935665406,\n",
       "     0.0014121846253638375,\n",
       "     0.0010421408970691453,\n",
       "     0.00012610337074459493,\n",
       "     0.007786939339276752,\n",
       "     0.007747827063858643,\n",
       "     0.0005151117131471503,\n",
       "     3.911227541810966e-05,\n",
       "     3.911227541810966e-05,\n",
       "     1.2363075563195581e-05],\n",
       "    'mean_score_time': [0.007669846216837565,\n",
       "     0.00799997647603353,\n",
       "     0.008461793263753256,\n",
       "     0.005573352177937825,\n",
       "     0.009768406550089518,\n",
       "     0.018169879913330078,\n",
       "     0.0010513464609781902,\n",
       "     0.0,\n",
       "     0.011087973912556967,\n",
       "     0.01572251319885254,\n",
       "     0.011070171991984049,\n",
       "     0.009889602661132812,\n",
       "     0.0055684248606363935,\n",
       "     0.006475528081258138,\n",
       "     0.012195428212483725,\n",
       "     0.01601870854695638,\n",
       "     0.010512510935465494,\n",
       "     0.011135419209798178,\n",
       "     0.016730785369873047,\n",
       "     0.0055866241455078125,\n",
       "     0.010932683944702148,\n",
       "     0.011173248291015625,\n",
       "     0.011181990305582682,\n",
       "     0.005013863245646159],\n",
       "    'std_score_time': [0.0004649115151929825,\n",
       "     1.0721474936192862e-06,\n",
       "     2.1212853074799114e-05,\n",
       "     0.001687315154980516,\n",
       "     0.005570984658419174,\n",
       "     0.0,\n",
       "     0.0014868284238683121,\n",
       "     0.0,\n",
       "     0.007160294695876112,\n",
       "     0.0009391972300483253,\n",
       "     0.006928015924369113,\n",
       "     0.006993005104927538,\n",
       "     0.006912678411786932,\n",
       "     0.008369116932650246,\n",
       "     0.008623469988520977,\n",
       "     0.0008408116482310457,\n",
       "     0.007472513978674713,\n",
       "     0.007873930434603238,\n",
       "     3.911227541810966e-05,\n",
       "     0.007900679634458152,\n",
       "     0.007734561493642959,\n",
       "     0.007900679634458152,\n",
       "     0.007906868421271508,\n",
       "     0.0070906734018767814],\n",
       "    'param_classifier__criterion': ['gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy'],\n",
       "    'param_classifier__max_depth': [3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10],\n",
       "    'params': [{'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10}],\n",
       "    'split0_test_score': [0.7261904761904762,\n",
       "     0.7261904761904762,\n",
       "     0.7261904761904762,\n",
       "     0.7142857142857143,\n",
       "     0.7142857142857143,\n",
       "     0.7142857142857143,\n",
       "     0.7142857142857143,\n",
       "     0.7142857142857143,\n",
       "     0.7261904761904762,\n",
       "     0.6785714285714286,\n",
       "     0.6666666666666666,\n",
       "     0.7023809523809523,\n",
       "     0.75,\n",
       "     0.75,\n",
       "     0.75,\n",
       "     0.7261904761904762,\n",
       "     0.7023809523809523,\n",
       "     0.6904761904761905,\n",
       "     0.6666666666666666,\n",
       "     0.6547619047619048,\n",
       "     0.6666666666666666,\n",
       "     0.6428571428571429,\n",
       "     0.6190476190476191,\n",
       "     0.6428571428571429],\n",
       "    'split1_test_score': [0.7380952380952381,\n",
       "     0.7380952380952381,\n",
       "     0.7261904761904762,\n",
       "     0.6666666666666666,\n",
       "     0.7142857142857143,\n",
       "     0.6547619047619048,\n",
       "     0.6785714285714286,\n",
       "     0.7142857142857143,\n",
       "     0.6666666666666666,\n",
       "     0.7142857142857143,\n",
       "     0.7380952380952381,\n",
       "     0.6309523809523809,\n",
       "     0.7261904761904762,\n",
       "     0.7380952380952381,\n",
       "     0.7261904761904762,\n",
       "     0.7380952380952381,\n",
       "     0.7261904761904762,\n",
       "     0.7142857142857143,\n",
       "     0.6666666666666666,\n",
       "     0.6428571428571429,\n",
       "     0.6309523809523809,\n",
       "     0.7261904761904762,\n",
       "     0.7023809523809523,\n",
       "     0.6190476190476191],\n",
       "    'split2_test_score': [0.75,\n",
       "     0.7380952380952381,\n",
       "     0.7380952380952381,\n",
       "     0.7023809523809523,\n",
       "     0.6904761904761905,\n",
       "     0.6666666666666666,\n",
       "     0.5833333333333334,\n",
       "     0.5952380952380952,\n",
       "     0.5595238095238095,\n",
       "     0.6428571428571429,\n",
       "     0.5952380952380952,\n",
       "     0.5714285714285714,\n",
       "     0.7619047619047619,\n",
       "     0.75,\n",
       "     0.75,\n",
       "     0.7142857142857143,\n",
       "     0.7142857142857143,\n",
       "     0.7142857142857143,\n",
       "     0.7023809523809523,\n",
       "     0.6904761904761905,\n",
       "     0.6904761904761905,\n",
       "     0.6785714285714286,\n",
       "     0.6904761904761905,\n",
       "     0.6785714285714286],\n",
       "    'mean_test_score': [0.7380952380952381,\n",
       "     0.7341269841269842,\n",
       "     0.7301587301587302,\n",
       "     0.6944444444444443,\n",
       "     0.7063492063492064,\n",
       "     0.6785714285714285,\n",
       "     0.6587301587301587,\n",
       "     0.6746031746031745,\n",
       "     0.6507936507936508,\n",
       "     0.6785714285714285,\n",
       "     0.6666666666666666,\n",
       "     0.6349206349206349,\n",
       "     0.746031746031746,\n",
       "     0.746031746031746,\n",
       "     0.7420634920634921,\n",
       "     0.7261904761904763,\n",
       "     0.7142857142857143,\n",
       "     0.7063492063492064,\n",
       "     0.6785714285714285,\n",
       "     0.6626984126984127,\n",
       "     0.6626984126984127,\n",
       "     0.6825396825396824,\n",
       "     0.6706349206349206,\n",
       "     0.6468253968253969],\n",
       "    'std_test_score': [0.00972019739199675,\n",
       "     0.005611958580845648,\n",
       "     0.005611958580845648,\n",
       "     0.020234204419019002,\n",
       "     0.011223917161691244,\n",
       "     0.025717224993681995,\n",
       "     0.05527138205231793,\n",
       "     0.05611958580845616,\n",
       "     0.06896090157532843,\n",
       "     0.0291605921759902,\n",
       "     0.05832118435198045,\n",
       "     0.05353467286996841,\n",
       "     0.014847846772912463,\n",
       "     0.005611958580845595,\n",
       "     0.011223917161691244,\n",
       "     0.00972019739199675,\n",
       "     0.00972019739199675,\n",
       "     0.011223917161691244,\n",
       "     0.016835875742536838,\n",
       "     0.020234204419018968,\n",
       "     0.024461960329241975,\n",
       "     0.034136211377153246,\n",
       "     0.0368000733948242,\n",
       "     0.024461960329241975],\n",
       "    'rank_test_score': [4,\n",
       "     5,\n",
       "     6,\n",
       "     11,\n",
       "     9,\n",
       "     13,\n",
       "     21,\n",
       "     16,\n",
       "     22,\n",
       "     13,\n",
       "     18,\n",
       "     24,\n",
       "     1,\n",
       "     1,\n",
       "     3,\n",
       "     7,\n",
       "     8,\n",
       "     9,\n",
       "     13,\n",
       "     19,\n",
       "     19,\n",
       "     12,\n",
       "     17,\n",
       "     23]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__criterion': 'gini',\n",
       "    'classifier__max_depth': 3,\n",
       "    'classifier__min_samples_split': 2},\n",
       "   'best_validation_accuracy': 0.7692095080154782,\n",
       "   'train_accuracy': 0.8163771712158809,\n",
       "   'test_accuracy': 0.7623762376237624,\n",
       "   'cv_results': {'mean_fit_time': [0.01664113998413086,\n",
       "     0.0005321502685546875,\n",
       "     0.016177574793497723,\n",
       "     0.018427133560180664,\n",
       "     0.010419368743896484,\n",
       "     0.005890687306722005,\n",
       "     0.016665935516357422,\n",
       "     0.016665935516357422,\n",
       "     0.015211025873819986,\n",
       "     0.014626105626424154,\n",
       "     0.018329699834187824,\n",
       "     0.014673709869384766,\n",
       "     0.010911146799723307,\n",
       "     0.013007005055745443,\n",
       "     0.012312173843383789,\n",
       "     0.020401636759440105,\n",
       "     0.021402597427368164,\n",
       "     0.02056272824605306,\n",
       "     0.02546072006225586,\n",
       "     0.02346460024515788,\n",
       "     0.019951502482096355,\n",
       "     0.01368403434753418,\n",
       "     0.0162659486134847,\n",
       "     0.017738501230875652],\n",
       "    'std_fit_time': [0.0,\n",
       "     0.0007525741270105238,\n",
       "     0.0008218073501644191,\n",
       "     0.0,\n",
       "     0.005566557816736936,\n",
       "     0.007630314675448567,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0013128295490045828,\n",
       "     0.0010370372565600514,\n",
       "     0.00905745557291822,\n",
       "     0.002963092037709894,\n",
       "     0.004162280941602242,\n",
       "     0.005320168589631146,\n",
       "     0.006243223458569385,\n",
       "     0.006161040242648616,\n",
       "     0.003855055708035004,\n",
       "     0.004709938645281864,\n",
       "     0.0051135928361297515,\n",
       "     0.007397840135831534,\n",
       "     0.0030618142685898794,\n",
       "     0.005958639879701197,\n",
       "     0.007628404201201929,\n",
       "     0.00176297457531169],\n",
       "    'mean_score_time': [0.00558622678120931,\n",
       "     0.018427133560180664,\n",
       "     0.002249558766682943,\n",
       "     0.005046923955281575,\n",
       "     0.011144479115804037,\n",
       "     0.011110623677571615,\n",
       "     0.005364735921223958,\n",
       "     0.01783100763956706,\n",
       "     0.011506795883178711,\n",
       "     0.01162099838256836,\n",
       "     0.005158821741739909,\n",
       "     0.005119800567626953,\n",
       "     0.010239601135253906,\n",
       "     0.014811992645263672,\n",
       "     0.01068441073099772,\n",
       "     0.014436960220336914,\n",
       "     0.012803157170613607,\n",
       "     0.010225534439086914,\n",
       "     0.01006174087524414,\n",
       "     0.0066576798756917315,\n",
       "     0.008572260538736979,\n",
       "     0.008496999740600586,\n",
       "     0.010660330454508463,\n",
       "     0.0018296241760253906],\n",
       "    'std_score_time': [0.007900117676478007,\n",
       "     0.0,\n",
       "     0.0008218073501644191,\n",
       "     0.007137428305824868,\n",
       "     0.006758806241264651,\n",
       "     0.007856397345622707,\n",
       "     0.007586882298345043,\n",
       "     0.00047957494025595954,\n",
       "     0.008472005807933046,\n",
       "     0.007280278024377792,\n",
       "     0.006528423199750743,\n",
       "     0.007240491399383507,\n",
       "     0.007240491399383507,\n",
       "     0.01187677183593617,\n",
       "     0.007574635284885227,\n",
       "     0.0032449464243958894,\n",
       "     0.003142330108140117,\n",
       "     0.0017972781616177453,\n",
       "     0.0013787619791752652,\n",
       "     0.002661642210674338,\n",
       "     0.002931278079777027,\n",
       "     0.006742140809554661,\n",
       "     0.004249048962009781,\n",
       "     0.0025874793237808066],\n",
       "    'param_classifier__criterion': ['gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy'],\n",
       "    'param_classifier__max_depth': [3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10],\n",
       "    'params': [{'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10}],\n",
       "    'split0_test_score': [0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7777777777777778,\n",
       "     0.7703703703703704,\n",
       "     0.7481481481481481,\n",
       "     0.7555555555555555,\n",
       "     0.7777777777777778,\n",
       "     0.7555555555555555,\n",
       "     0.725925925925926,\n",
       "     0.6962962962962963,\n",
       "     0.6814814814814815,\n",
       "     0.6888888888888889,\n",
       "     0.7555555555555555,\n",
       "     0.7555555555555555,\n",
       "     0.7555555555555555,\n",
       "     0.7925925925925926,\n",
       "     0.7925925925925926,\n",
       "     0.8,\n",
       "     0.7703703703703704,\n",
       "     0.7555555555555555,\n",
       "     0.7925925925925926,\n",
       "     0.6962962962962963,\n",
       "     0.6518518518518519,\n",
       "     0.6666666666666666],\n",
       "    'split1_test_score': [0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.6940298507462687,\n",
       "     0.7164179104477612,\n",
       "     0.7164179104477612,\n",
       "     0.6268656716417911,\n",
       "     0.6567164179104478,\n",
       "     0.7014925373134329,\n",
       "     0.6567164179104478,\n",
       "     0.6194029850746269,\n",
       "     0.6940298507462687,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.7089552238805971,\n",
       "     0.7089552238805971,\n",
       "     0.7388059701492538,\n",
       "     0.664179104477612,\n",
       "     0.6791044776119403,\n",
       "     0.7014925373134329,\n",
       "     0.6343283582089553,\n",
       "     0.6194029850746269,\n",
       "     0.6343283582089553],\n",
       "    'split2_test_score': [0.7686567164179104,\n",
       "     0.7686567164179104,\n",
       "     0.7611940298507462,\n",
       "     0.6791044776119403,\n",
       "     0.6791044776119403,\n",
       "     0.6716417910447762,\n",
       "     0.6268656716417911,\n",
       "     0.5970149253731343,\n",
       "     0.6119402985074627,\n",
       "     0.6044776119402985,\n",
       "     0.6044776119402985,\n",
       "     0.6194029850746269,\n",
       "     0.7313432835820896,\n",
       "     0.7313432835820896,\n",
       "     0.7313432835820896,\n",
       "     0.7611940298507462,\n",
       "     0.7611940298507462,\n",
       "     0.753731343283582,\n",
       "     0.7164179104477612,\n",
       "     0.7164179104477612,\n",
       "     0.7014925373134329,\n",
       "     0.6940298507462687,\n",
       "     0.7014925373134329,\n",
       "     0.7089552238805971],\n",
       "    'mean_test_score': [0.7692095080154782,\n",
       "     0.7692095080154782,\n",
       "     0.7667219458264235,\n",
       "     0.7145015662428599,\n",
       "     0.7145568454026164,\n",
       "     0.7145384190160309,\n",
       "     0.6771697070204533,\n",
       "     0.6697622996130459,\n",
       "     0.6797862539156071,\n",
       "     0.6524967753823475,\n",
       "     0.6351206928321357,\n",
       "     0.6674405749032615,\n",
       "     0.7493642896627971,\n",
       "     0.7493642896627971,\n",
       "     0.7493642896627971,\n",
       "     0.7542472821079786,\n",
       "     0.7542472821079786,\n",
       "     0.764179104477612,\n",
       "     0.7169891284319144,\n",
       "     0.7170259812050856,\n",
       "     0.7318592224064862,\n",
       "     0.67488483508384,\n",
       "     0.6575824580799705,\n",
       "     0.669983416252073],\n",
       "    'std_test_score': [0.006781561164392108,\n",
       "     0.006781561164392108,\n",
       "     0.00781765374446157,\n",
       "     0.03997235833905177,\n",
       "     0.028217663293343985,\n",
       "     0.034283420041608975,\n",
       "     0.07114064907460013,\n",
       "     0.06537802447667183,\n",
       "     0.04900035964973607,\n",
       "     0.03760338403668216,\n",
       "     0.033343502454918364,\n",
       "     0.03403248349849363,\n",
       "     0.012949017806126086,\n",
       "     0.012949017806126086,\n",
       "     0.012949017806126086,\n",
       "     0.03449633158678189,\n",
       "     0.03449633158678189,\n",
       "     0.026051795943454838,\n",
       "     0.04335428433627365,\n",
       "     0.031213983428581272,\n",
       "     0.042944977902908806,\n",
       "     0.028692682647150178,\n",
       "     0.03375700946962204,\n",
       "     0.03055642748372849],\n",
       "    'rank_test_score': [1,\n",
       "     1,\n",
       "     3,\n",
       "     15,\n",
       "     13,\n",
       "     14,\n",
       "     17,\n",
       "     20,\n",
       "     16,\n",
       "     23,\n",
       "     24,\n",
       "     21,\n",
       "     7,\n",
       "     7,\n",
       "     7,\n",
       "     5,\n",
       "     5,\n",
       "     4,\n",
       "     12,\n",
       "     11,\n",
       "     10,\n",
       "     18,\n",
       "     22,\n",
       "     19]}}],\n",
       " 'taiwan random_forest': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__max_depth': None,\n",
       "    'classifier__min_samples_leaf': 1,\n",
       "    'classifier__min_samples_split': 2,\n",
       "    'classifier__n_estimators': 100},\n",
       "   'best_validation_accuracy': 0.960190136660725,\n",
       "   'train_accuracy': 1.0,\n",
       "   'test_accuracy': 0.9375,\n",
       "   'cv_results': {'mean_fit_time': [0.22742446263631186,\n",
       "     0.3988990783691406,\n",
       "     0.6307458082834879,\n",
       "     0.207564115524292,\n",
       "     0.4069508711496989,\n",
       "     0.6010130246480306,\n",
       "     0.20560383796691895,\n",
       "     0.3840533097585042,\n",
       "     0.6447114944458008,\n",
       "     0.20799771944681802,\n",
       "     0.42122530937194824,\n",
       "     0.6590799490610758,\n",
       "     0.20716706911722818,\n",
       "     0.3911173343658447,\n",
       "     0.5652259190877279,\n",
       "     0.20074725151062012,\n",
       "     0.39073769251505536,\n",
       "     0.6123517354329427,\n",
       "     0.2242740790049235,\n",
       "     0.3936859766642253,\n",
       "     0.5722176233927408,\n",
       "     0.21309757232666016,\n",
       "     0.40603144963582355,\n",
       "     0.5759681860605875,\n",
       "     0.1872717539469401,\n",
       "     0.376331090927124,\n",
       "     0.5865607261657715,\n",
       "     0.21183069547017416,\n",
       "     0.402130921681722,\n",
       "     0.5625789165496826,\n",
       "     0.20347309112548828,\n",
       "     0.3802746931711833,\n",
       "     0.6100920041402181,\n",
       "     0.21123099327087402,\n",
       "     0.43902587890625,\n",
       "     0.7436625162760416,\n",
       "     0.21174860000610352,\n",
       "     0.5371111234029134,\n",
       "     0.8002587954203287,\n",
       "     0.30803990364074707,\n",
       "     0.48643310864766437,\n",
       "     0.6389591693878174,\n",
       "     0.22124433517456055,\n",
       "     0.405742883682251,\n",
       "     0.6981699466705322,\n",
       "     0.2503972848256429,\n",
       "     0.4905702273050944,\n",
       "     0.7620827356974283,\n",
       "     0.22888477643330893,\n",
       "     0.5592896938323975,\n",
       "     0.7653238773345947,\n",
       "     0.27222196261088055,\n",
       "     0.42862582206726074,\n",
       "     0.6154032548268636,\n",
       "     0.23432143529256186,\n",
       "     0.3838740984598796,\n",
       "     0.6824758052825928,\n",
       "     0.2117295265197754,\n",
       "     0.4657694498697917,\n",
       "     0.6467662652333578,\n",
       "     0.25472529729207355,\n",
       "     0.39566389719645184,\n",
       "     0.5764763355255127,\n",
       "     0.2061140537261963,\n",
       "     0.4024949868520101,\n",
       "     0.6649657885233561,\n",
       "     0.19492602348327637,\n",
       "     0.47864294052124023,\n",
       "     0.6907398700714111,\n",
       "     0.2395454247792562,\n",
       "     0.4688815275828044,\n",
       "     0.6544873714447021,\n",
       "     0.2364042599995931,\n",
       "     0.44155414899190265,\n",
       "     0.6380808353424072,\n",
       "     0.21250351270039877,\n",
       "     0.43234848976135254,\n",
       "     0.7060418923695883,\n",
       "     0.24029946327209473,\n",
       "     0.561573346455892,\n",
       "     0.9262656370798746,\n",
       "     0.3483277956644694,\n",
       "     0.6056624253590902,\n",
       "     0.8683675130208334,\n",
       "     0.2564270496368408,\n",
       "     0.6691976388295492,\n",
       "     0.9003682136535645,\n",
       "     0.30137427647908527,\n",
       "     0.49518410364786786,\n",
       "     0.8511989116668701,\n",
       "     0.2961932023366292,\n",
       "     0.515524705251058,\n",
       "     0.8237105210622152,\n",
       "     0.32807143529256183,\n",
       "     0.5654698212941488,\n",
       "     0.860226551691691,\n",
       "     0.2985090414683024,\n",
       "     0.5364674727121989,\n",
       "     0.8383824030558268,\n",
       "     0.32042455673217773,\n",
       "     0.5595044294993082,\n",
       "     0.8067757288614908,\n",
       "     0.34834758440653485,\n",
       "     0.7161585489908854,\n",
       "     0.8237923781077067,\n",
       "     0.25734663009643555,\n",
       "     0.5528788566589355,\n",
       "     0.6064498424530029],\n",
       "    'std_fit_time': [0.010067034441276396,\n",
       "     0.014937180287048933,\n",
       "     0.013180161520864911,\n",
       "     0.015711238220391794,\n",
       "     0.0095300206020913,\n",
       "     0.006906764801755946,\n",
       "     0.014054793866624855,\n",
       "     0.0028212538435212317,\n",
       "     0.0300702591259765,\n",
       "     0.014470535186293777,\n",
       "     0.028292054545709034,\n",
       "     0.019742847974574963,\n",
       "     0.008865569039359993,\n",
       "     0.022973988137653233,\n",
       "     0.007475872556543916,\n",
       "     0.0092719694976086,\n",
       "     0.018652308706408837,\n",
       "     0.023475514165607465,\n",
       "     0.012443601477923158,\n",
       "     0.010372013101608566,\n",
       "     0.014444751283985618,\n",
       "     0.007375024139830281,\n",
       "     0.008952103034359105,\n",
       "     0.016172657484941073,\n",
       "     0.011866638495276726,\n",
       "     0.01477670646218253,\n",
       "     0.03469795568316723,\n",
       "     0.0017224573783587967,\n",
       "     0.02479750449969722,\n",
       "     0.021520587439259126,\n",
       "     0.010537139726810781,\n",
       "     0.0017949563770142609,\n",
       "     0.031052036228346968,\n",
       "     0.007959665926245524,\n",
       "     0.05921507932697434,\n",
       "     0.027922592158997426,\n",
       "     0.018269218302099228,\n",
       "     0.02251549997174253,\n",
       "     0.028895130180573173,\n",
       "     0.014113427152300042,\n",
       "     0.03338544094664024,\n",
       "     0.013499215845572506,\n",
       "     0.005726009039523968,\n",
       "     0.009226293465797054,\n",
       "     0.05288308796560402,\n",
       "     0.019619375322794546,\n",
       "     0.08640284098674081,\n",
       "     0.024626295853080748,\n",
       "     0.02099538901065198,\n",
       "     0.013902753065177706,\n",
       "     0.043188276836586534,\n",
       "     0.006274768489501377,\n",
       "     0.04864192452673768,\n",
       "     0.02274994446404837,\n",
       "     0.024069650863257946,\n",
       "     0.010628562433566118,\n",
       "     0.027964730199347088,\n",
       "     0.006519097500505128,\n",
       "     0.0026857164150416715,\n",
       "     0.036424783239386804,\n",
       "     0.006828854521489045,\n",
       "     0.003195777269092289,\n",
       "     0.022022585266823158,\n",
       "     0.0016962795451436815,\n",
       "     0.008879021640784274,\n",
       "     0.004185013896835435,\n",
       "     0.014746340513415892,\n",
       "     0.028080139568035175,\n",
       "     0.03613984414656162,\n",
       "     0.01592540154680442,\n",
       "     0.025498692905405525,\n",
       "     0.021623885639286466,\n",
       "     0.027520410070927512,\n",
       "     0.011672009796844256,\n",
       "     0.019580130560635824,\n",
       "     0.003490299332500776,\n",
       "     0.014211235837823648,\n",
       "     0.08433853675001801,\n",
       "     0.0038443397345811372,\n",
       "     0.059718798499663245,\n",
       "     0.07790356715775958,\n",
       "     0.027925618132081033,\n",
       "     0.03114798318660204,\n",
       "     0.12541365534378263,\n",
       "     0.03917368267913236,\n",
       "     0.06910505366738441,\n",
       "     0.2498152295867814,\n",
       "     0.04716560600329115,\n",
       "     0.11176228526354091,\n",
       "     0.05938214146594909,\n",
       "     0.0733781018855871,\n",
       "     0.11455860378079585,\n",
       "     0.1115674019970049,\n",
       "     0.031011527220016974,\n",
       "     0.027698530881736495,\n",
       "     0.14491990510115504,\n",
       "     0.08015052350385245,\n",
       "     0.12185837481428993,\n",
       "     0.15891654970121005,\n",
       "     0.08313085688473242,\n",
       "     0.09707073854004375,\n",
       "     0.07869128315010111,\n",
       "     0.11350561526891216,\n",
       "     0.03195560375101287,\n",
       "     0.0349091304855642,\n",
       "     0.028383595898732728,\n",
       "     0.05504003677171816,\n",
       "     0.04351652297534783],\n",
       "    'mean_score_time': [0.01478266716003418,\n",
       "     0.025001128514607746,\n",
       "     0.044417222340901695,\n",
       "     0.015625794728597004,\n",
       "     0.02559216817220052,\n",
       "     0.04066618283589681,\n",
       "     0.01401519775390625,\n",
       "     0.02275538444519043,\n",
       "     0.029910961786905926,\n",
       "     0.01957416534423828,\n",
       "     0.029285987218221027,\n",
       "     0.03666106859842936,\n",
       "     0.02116243044535319,\n",
       "     0.020846843719482422,\n",
       "     0.04766996701558431,\n",
       "     0.014440059661865234,\n",
       "     0.024374643961588543,\n",
       "     0.03188920021057129,\n",
       "     0.010893821716308594,\n",
       "     0.020232677459716797,\n",
       "     0.041043599446614586,\n",
       "     0.015630006790161133,\n",
       "     0.021699269612630207,\n",
       "     0.03907958666483561,\n",
       "     0.015623092651367188,\n",
       "     0.026285489400227863,\n",
       "     0.031775871912638344,\n",
       "     0.018911282221476238,\n",
       "     0.026832183202107746,\n",
       "     0.04178174336751302,\n",
       "     0.012653112411499023,\n",
       "     0.025133530298868816,\n",
       "     0.04667377471923828,\n",
       "     0.013225555419921875,\n",
       "     0.0330344041188558,\n",
       "     0.04462043444315592,\n",
       "     0.023437102635701496,\n",
       "     0.039603630701700844,\n",
       "     0.051910718282063804,\n",
       "     0.01638650894165039,\n",
       "     0.03789973258972168,\n",
       "     0.03499007225036621,\n",
       "     0.01947816212972005,\n",
       "     0.024829546610514324,\n",
       "     0.0438840389251709,\n",
       "     0.022546132405598957,\n",
       "     0.031264940897623696,\n",
       "     0.03957017262776693,\n",
       "     0.025209665298461914,\n",
       "     0.029179811477661133,\n",
       "     0.05221255620320638,\n",
       "     0.014909664789835611,\n",
       "     0.033365329106648765,\n",
       "     0.04047314325968424,\n",
       "     0.01912403106689453,\n",
       "     0.03693540891011556,\n",
       "     0.03675389289855957,\n",
       "     0.021817763646443684,\n",
       "     0.02726268768310547,\n",
       "     0.03917876879374186,\n",
       "     0.02017498016357422,\n",
       "     0.02958067258199056,\n",
       "     0.03784815470377604,\n",
       "     0.017455577850341797,\n",
       "     0.03804492950439453,\n",
       "     0.04683828353881836,\n",
       "     0.015631675720214844,\n",
       "     0.030689557393391926,\n",
       "     0.051016012827555336,\n",
       "     0.02230493227640788,\n",
       "     0.030212879180908203,\n",
       "     0.037200371424357094,\n",
       "     0.020209232966105144,\n",
       "     0.02906958262125651,\n",
       "     0.050965309143066406,\n",
       "     0.0165712833404541,\n",
       "     0.027303536732991535,\n",
       "     0.06625548998514812,\n",
       "     0.01959840456644694,\n",
       "     0.053322156270345054,\n",
       "     0.05363138516743978,\n",
       "     0.01651310920715332,\n",
       "     0.026949564615885418,\n",
       "     0.0504606564839681,\n",
       "     0.016548871994018555,\n",
       "     0.02770407994588216,\n",
       "     0.07016173998514812,\n",
       "     0.039800008138020836,\n",
       "     0.026958624521891277,\n",
       "     0.05008037885030111,\n",
       "     0.016092777252197266,\n",
       "     0.02715190251668294,\n",
       "     0.049084742863972984,\n",
       "     0.015793641408284504,\n",
       "     0.0350645383199056,\n",
       "     0.05523975690205892,\n",
       "     0.016376972198486328,\n",
       "     0.027079184850056965,\n",
       "     0.03811176617940267,\n",
       "     0.01607068379720052,\n",
       "     0.030341307322184246,\n",
       "     0.05745530128479004,\n",
       "     0.016194264094034832,\n",
       "     0.028682549794514973,\n",
       "     0.04741970698038737,\n",
       "     0.017714659372965496,\n",
       "     0.033622026443481445,\n",
       "     0.033495028813680015],\n",
       "    'std_score_time': [0.006247849126524206,\n",
       "     0.006814082908955141,\n",
       "     0.009827897623498142,\n",
       "     3.0233339331814655e-05,\n",
       "     0.0066285532964092475,\n",
       "     0.005386476873441799,\n",
       "     0.0007057068314664097,\n",
       "     0.0007347038632419048,\n",
       "     0.004576922965091034,\n",
       "     0.005739445884022009,\n",
       "     0.004205247707312814,\n",
       "     0.00753507026544035,\n",
       "     0.0015208244220736857,\n",
       "     0.0074172593662957895,\n",
       "     0.00048075726896787066,\n",
       "     0.0017091390008137748,\n",
       "     0.005899996833545019,\n",
       "     0.007290791672399285,\n",
       "     0.006284417309786248,\n",
       "     0.004992517658996696,\n",
       "     0.008258651935915892,\n",
       "     0.0,\n",
       "     0.00636109044631862,\n",
       "     0.007767115411085749,\n",
       "     0.0,\n",
       "     0.006611782715283444,\n",
       "     0.006383681939370276,\n",
       "     0.0037385472725570447,\n",
       "     0.010354047221726633,\n",
       "     0.00751071399596802,\n",
       "     0.005464111315616706,\n",
       "     0.009275655431925593,\n",
       "     0.0028180830839330652,\n",
       "     0.0017108248747542106,\n",
       "     0.004432566912804748,\n",
       "     0.0036523751703339247,\n",
       "     0.00884123604297112,\n",
       "     0.003463124663112619,\n",
       "     0.008857255027630495,\n",
       "     0.0019475547619737122,\n",
       "     0.004678662909967315,\n",
       "     0.0065909377802976735,\n",
       "     0.004940614512408185,\n",
       "     0.00519240739228937,\n",
       "     0.00202195067370973,\n",
       "     0.005123500230735566,\n",
       "     0.007441386631669537,\n",
       "     0.0059895916073778996,\n",
       "     0.004057818130025255,\n",
       "     0.0034728014767574688,\n",
       "     0.007716396459920634,\n",
       "     0.004852959221140538,\n",
       "     0.002825658922539759,\n",
       "     0.008601779487645634,\n",
       "     0.011115798385530912,\n",
       "     0.0015863517465186776,\n",
       "     0.0009577559110860914,\n",
       "     0.006790691293012515,\n",
       "     0.0011176228051306665,\n",
       "     0.007344203344743318,\n",
       "     0.0008232783988246994,\n",
       "     0.002451822667373742,\n",
       "     0.008656883572641303,\n",
       "     0.001491237294884018,\n",
       "     0.008383360112123813,\n",
       "     0.002344905628375368,\n",
       "     9.562536961536576e-06,\n",
       "     0.002900112569888283,\n",
       "     0.008948189883117985,\n",
       "     0.004801713391581554,\n",
       "     0.003356908267324812,\n",
       "     0.0028933014298619425,\n",
       "     0.008777606402502967,\n",
       "     0.0015104289278733362,\n",
       "     0.004792229180286425,\n",
       "     0.0032031808592187785,\n",
       "     0.0006176239107770565,\n",
       "     0.035943274334784246,\n",
       "     0.004215648765542623,\n",
       "     0.03648511326602356,\n",
       "     0.022354071733331527,\n",
       "     0.00034878304921267075,\n",
       "     0.0015261837825248001,\n",
       "     0.01788235307696863,\n",
       "     0.0010433797954115804,\n",
       "     0.0023606788299198726,\n",
       "     0.0231802587408853,\n",
       "     0.016313166713633153,\n",
       "     0.0011461540393248209,\n",
       "     0.018796591396917296,\n",
       "     0.0003950654608597149,\n",
       "     0.0008883996320799312,\n",
       "     0.01325120354102485,\n",
       "     0.0008663760108305942,\n",
       "     0.011811751204843573,\n",
       "     0.024424926743126955,\n",
       "     0.0010491514329211034,\n",
       "     0.0014315576480748674,\n",
       "     0.0009110439965774501,\n",
       "     0.0008158014972865055,\n",
       "     0.00683467575560463,\n",
       "     0.02787665410112262,\n",
       "     0.00118071900371991,\n",
       "     0.0024298782106858957,\n",
       "     0.009578557600228127,\n",
       "     0.0024966913817816225,\n",
       "     0.007383548883691941,\n",
       "     0.0022754262273226296],\n",
       "    'param_classifier__max_depth': [None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30],\n",
       "    'param_classifier__min_samples_leaf': [1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10],\n",
       "    'param_classifier__n_estimators': [100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300],\n",
       "    'params': [{'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300}],\n",
       "    'split0_test_score': [0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353],\n",
       "    'split1_test_score': [0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9090909090909091,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9090909090909091,\n",
       "     0.9696969696969697,\n",
       "     0.9090909090909091,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9090909090909091,\n",
       "     0.9090909090909091,\n",
       "     0.9393939393939394,\n",
       "     0.9090909090909091,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9090909090909091,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9090909090909091,\n",
       "     0.9393939393939394,\n",
       "     0.9090909090909091,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9090909090909091,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9090909090909091,\n",
       "     0.9696969696969697,\n",
       "     0.9090909090909091,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9090909090909091,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394],\n",
       "    'split2_test_score': [0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394],\n",
       "    'mean_test_score': [0.960190136660725,\n",
       "     0.9500891265597149,\n",
       "     0.9500891265597149,\n",
       "     0.9500891265597149,\n",
       "     0.9399881164587048,\n",
       "     0.9500891265597149,\n",
       "     0.9399881164587048,\n",
       "     0.9500891265597149,\n",
       "     0.9500891265597149,\n",
       "     0.9399881164587046,\n",
       "     0.9399881164587048,\n",
       "     0.9500891265597149,\n",
       "     0.9399881164587046,\n",
       "     0.9500891265597149,\n",
       "     0.9298871063576946,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9500891265597149,\n",
       "     0.9500891265597149,\n",
       "     0.9500891265597149,\n",
       "     0.9500891265597149,\n",
       "     0.9500891265597149,\n",
       "     0.9500891265597149,\n",
       "     0.9399881164587048,\n",
       "     0.960190136660725,\n",
       "     0.9500891265597149,\n",
       "     0.9500891265597149,\n",
       "     0.9298871063576946,\n",
       "     0.9298871063576946,\n",
       "     0.9399881164587048,\n",
       "     0.9298871063576946,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9500891265597149,\n",
       "     0.9399881164587048,\n",
       "     0.9500891265597149,\n",
       "     0.9500891265597149,\n",
       "     0.9500891265597149,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9500891265597149,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587046,\n",
       "     0.960190136660725,\n",
       "     0.9399881164587048,\n",
       "     0.9500891265597149,\n",
       "     0.9500891265597149,\n",
       "     0.9298871063576946,\n",
       "     0.9399881164587048,\n",
       "     0.9298871063576946,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587046,\n",
       "     0.9500891265597149,\n",
       "     0.9500891265597149,\n",
       "     0.960190136660725,\n",
       "     0.9500891265597149,\n",
       "     0.9500891265597149,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9500891265597149,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9500891265597149,\n",
       "     0.9298871063576946,\n",
       "     0.9500891265597149,\n",
       "     0.9298871063576946,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9298871063576946,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048],\n",
       "    'std_test_score': [0.013444692215074007,\n",
       "     0.013883923286450295,\n",
       "     0.013883923286450295,\n",
       "     0.013883923286450295,\n",
       "     0.0008402932634420928,\n",
       "     0.013883923286450295,\n",
       "     0.0008402932634420928,\n",
       "     0.013883923286450295,\n",
       "     0.013883923286450295,\n",
       "     0.024756585449791656,\n",
       "     0.0008402932634420928,\n",
       "     0.013883923286450295,\n",
       "     0.024756585449791656,\n",
       "     0.013883923286450295,\n",
       "     0.014723127383676631,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.013883923286450295,\n",
       "     0.013883923286450295,\n",
       "     0.013883923286450295,\n",
       "     0.013883923286450295,\n",
       "     0.013883923286450295,\n",
       "     0.013883923286450295,\n",
       "     0.0008402932634420928,\n",
       "     0.013444692215074007,\n",
       "     0.013883923286450295,\n",
       "     0.013883923286450295,\n",
       "     0.014723127383676631,\n",
       "     0.014723127383676631,\n",
       "     0.0008402932634420928,\n",
       "     0.014723127383676631,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.013883923286450295,\n",
       "     0.0008402932634420928,\n",
       "     0.013883923286450295,\n",
       "     0.013883923286450295,\n",
       "     0.013883923286450295,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.013883923286450295,\n",
       "     0.0008402932634420928,\n",
       "     0.024756585449791656,\n",
       "     0.013444692215074007,\n",
       "     0.0008402932634420928,\n",
       "     0.013883923286450295,\n",
       "     0.013883923286450295,\n",
       "     0.014723127383676631,\n",
       "     0.0008402932634420928,\n",
       "     0.014723127383676631,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.024756585449791656,\n",
       "     0.013883923286450295,\n",
       "     0.013883923286450295,\n",
       "     0.013444692215074007,\n",
       "     0.013883923286450295,\n",
       "     0.013883923286450295,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.013883923286450295,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.013883923286450295,\n",
       "     0.014723127383676631,\n",
       "     0.013883923286450295,\n",
       "     0.014723127383676631,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.014723127383676631,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928],\n",
       "    'rank_test_score': [1,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     35,\n",
       "     5,\n",
       "     35,\n",
       "     5,\n",
       "     5,\n",
       "     96,\n",
       "     35,\n",
       "     5,\n",
       "     96,\n",
       "     5,\n",
       "     100,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     35,\n",
       "     1,\n",
       "     5,\n",
       "     5,\n",
       "     100,\n",
       "     100,\n",
       "     35,\n",
       "     100,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     5,\n",
       "     35,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     35,\n",
       "     35,\n",
       "     5,\n",
       "     35,\n",
       "     96,\n",
       "     1,\n",
       "     35,\n",
       "     5,\n",
       "     5,\n",
       "     100,\n",
       "     35,\n",
       "     100,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     96,\n",
       "     5,\n",
       "     5,\n",
       "     1,\n",
       "     5,\n",
       "     5,\n",
       "     35,\n",
       "     35,\n",
       "     5,\n",
       "     35,\n",
       "     35,\n",
       "     5,\n",
       "     100,\n",
       "     5,\n",
       "     100,\n",
       "     35,\n",
       "     35,\n",
       "     100,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35,\n",
       "     35]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__max_depth': 30,\n",
       "    'classifier__min_samples_leaf': 2,\n",
       "    'classifier__min_samples_split': 2,\n",
       "    'classifier__n_estimators': 200},\n",
       "   'best_validation_accuracy': 0.9599827882960413,\n",
       "   'train_accuracy': 0.996,\n",
       "   'test_accuracy': 0.956,\n",
       "   'cv_results': {'mean_fit_time': [0.4855857690175374,\n",
       "     0.8106266657511393,\n",
       "     1.4617300033569336,\n",
       "     0.3672693570454915,\n",
       "     0.9137511253356934,\n",
       "     1.201827605565389,\n",
       "     0.5668927033742269,\n",
       "     0.8752299944559733,\n",
       "     1.2080588340759277,\n",
       "     0.34506861368815106,\n",
       "     0.7624239126841227,\n",
       "     1.1961991786956787,\n",
       "     0.4009685516357422,\n",
       "     0.7121029694875082,\n",
       "     1.0859922568003337,\n",
       "     0.42324646313985187,\n",
       "     0.6724038124084473,\n",
       "     0.960140069325765,\n",
       "     0.31480153401692706,\n",
       "     0.5720518430074056,\n",
       "     0.9669426282246908,\n",
       "     0.335903803507487,\n",
       "     0.532336950302124,\n",
       "     0.8716142972310384,\n",
       "     0.25211437543233234,\n",
       "     0.5170734723409017,\n",
       "     0.7788116931915283,\n",
       "     0.25905513763427734,\n",
       "     0.5120362440745035,\n",
       "     0.7232585748036703,\n",
       "     0.22867139180501303,\n",
       "     0.44867610931396484,\n",
       "     0.7068183422088623,\n",
       "     0.21660629908243814,\n",
       "     0.4725338617960612,\n",
       "     0.6969597339630127,\n",
       "     0.24222715695699057,\n",
       "     0.48253146807352704,\n",
       "     0.6739303270975748,\n",
       "     0.24506473541259766,\n",
       "     0.4665686289469401,\n",
       "     0.6710100968678793,\n",
       "     0.22699666023254395,\n",
       "     0.46835867563883465,\n",
       "     0.7112928231557211,\n",
       "     0.2451647917429606,\n",
       "     0.4400218327840169,\n",
       "     0.66501784324646,\n",
       "     0.22758634885152182,\n",
       "     0.4354894161224365,\n",
       "     0.62174391746521,\n",
       "     0.21477087338765463,\n",
       "     0.41179076830546063,\n",
       "     0.6338505744934082,\n",
       "     0.22288751602172852,\n",
       "     0.42603015899658203,\n",
       "     0.6636234919230143,\n",
       "     0.2089103857676188,\n",
       "     0.42647139231363934,\n",
       "     0.6252779960632324,\n",
       "     0.23009602228800455,\n",
       "     0.4457465012868245,\n",
       "     0.6334953308105469,\n",
       "     0.21705126762390137,\n",
       "     0.4082290331522624,\n",
       "     0.645169734954834,\n",
       "     0.21574791272481283,\n",
       "     0.42006492614746094,\n",
       "     0.637425422668457,\n",
       "     0.20904000600179037,\n",
       "     0.4115804036458333,\n",
       "     0.6518393357594808,\n",
       "     0.20551395416259766,\n",
       "     0.44923098882039386,\n",
       "     0.6330916881561279,\n",
       "     0.21655543645222983,\n",
       "     0.4768558343251546,\n",
       "     0.6212472120920817,\n",
       "     0.22006074587504068,\n",
       "     0.4141562779744466,\n",
       "     0.6379737854003906,\n",
       "     0.22374296188354492,\n",
       "     0.41691215833028156,\n",
       "     0.6610715389251709,\n",
       "     0.22492877642313638,\n",
       "     0.4314088026682536,\n",
       "     0.6722312768300375,\n",
       "     0.21930336952209473,\n",
       "     0.4278699556986491,\n",
       "     0.6333801746368408,\n",
       "     0.22311155001322427,\n",
       "     0.4127153555552165,\n",
       "     0.6750479539235433,\n",
       "     0.22282489140828451,\n",
       "     0.4437355200449626,\n",
       "     0.6418600082397461,\n",
       "     0.23354649543762207,\n",
       "     0.430785338083903,\n",
       "     0.625018835067749,\n",
       "     0.21765891710917154,\n",
       "     0.39501794179280597,\n",
       "     0.6167960166931152,\n",
       "     0.21035432815551758,\n",
       "     0.41708803176879883,\n",
       "     0.6332801977793375,\n",
       "     0.22623666127522787,\n",
       "     0.43685412406921387,\n",
       "     0.5051898161570231],\n",
       "    'std_fit_time': [0.057649059105765496,\n",
       "     0.15564169867590102,\n",
       "     0.09078286571537658,\n",
       "     0.07929484971593999,\n",
       "     0.2094098880429327,\n",
       "     0.11496656668770722,\n",
       "     0.05723537089046676,\n",
       "     0.1152818716449795,\n",
       "     0.2410486106211743,\n",
       "     0.02970109171199366,\n",
       "     0.09156748773439434,\n",
       "     0.005745876738958494,\n",
       "     0.08618659807231793,\n",
       "     0.11003320317170877,\n",
       "     0.05577008278190675,\n",
       "     0.18739845095892305,\n",
       "     0.03123345276350421,\n",
       "     0.1317061470446289,\n",
       "     0.052927509203856214,\n",
       "     0.10795196939094756,\n",
       "     0.049739293346121836,\n",
       "     0.03035121129802546,\n",
       "     0.07522122456048827,\n",
       "     0.11740653498639483,\n",
       "     0.05297989406795793,\n",
       "     0.06601414571783848,\n",
       "     0.01035936429822202,\n",
       "     0.03170640863640003,\n",
       "     0.022992842311422262,\n",
       "     0.021197657680991862,\n",
       "     0.017520637178179452,\n",
       "     0.01376603266899865,\n",
       "     0.024126115369223183,\n",
       "     0.005278924513471159,\n",
       "     0.005209299947980155,\n",
       "     0.03904766641918679,\n",
       "     0.006417275857910306,\n",
       "     0.030996025987693836,\n",
       "     0.04023958309090732,\n",
       "     0.006176462546860369,\n",
       "     0.02357577979040905,\n",
       "     0.019458160173874705,\n",
       "     0.003852851088875009,\n",
       "     0.03358342707646584,\n",
       "     0.03626709495843432,\n",
       "     0.00799448943496884,\n",
       "     0.006355580266076971,\n",
       "     0.030909853458572792,\n",
       "     0.006379668101514433,\n",
       "     0.02578896761576137,\n",
       "     0.016191636207674272,\n",
       "     0.013916491648413461,\n",
       "     0.01904390018544733,\n",
       "     0.009795974662030275,\n",
       "     0.006473725278149054,\n",
       "     0.016295813195333124,\n",
       "     0.02288245503634695,\n",
       "     0.009012431280913108,\n",
       "     0.009882816750285163,\n",
       "     0.008806041936032691,\n",
       "     0.006127235351183138,\n",
       "     0.013987382393441628,\n",
       "     0.022285501737781516,\n",
       "     0.005233452876883225,\n",
       "     0.014673189277581072,\n",
       "     0.01515945091305859,\n",
       "     0.004376901068939278,\n",
       "     0.009203165096032117,\n",
       "     0.01859268122608608,\n",
       "     0.005311944659213475,\n",
       "     0.013924409340121527,\n",
       "     0.02754220888025286,\n",
       "     0.00790195353021348,\n",
       "     0.03459989914820109,\n",
       "     0.03164139255017883,\n",
       "     0.01354254172272268,\n",
       "     0.007262009506313616,\n",
       "     0.031102280305179256,\n",
       "     0.024428418377988946,\n",
       "     0.00356854556551839,\n",
       "     0.009943401975701692,\n",
       "     0.007702199592925023,\n",
       "     0.0002648017558096473,\n",
       "     0.03321865697988716,\n",
       "     0.02363325084530028,\n",
       "     0.016647141062923854,\n",
       "     0.051553092920644576,\n",
       "     0.013710800131998217,\n",
       "     0.013760561785106358,\n",
       "     0.02377250843408467,\n",
       "     0.006482439035992535,\n",
       "     0.005088487969218145,\n",
       "     0.0356413673484997,\n",
       "     0.008478372438047473,\n",
       "     0.02785530337449649,\n",
       "     0.034746050507803036,\n",
       "     0.0121595820282783,\n",
       "     0.015961658222344258,\n",
       "     0.018075082151907902,\n",
       "     0.01510892589488578,\n",
       "     0.014262165205811167,\n",
       "     0.01360828813708413,\n",
       "     0.009576143487727794,\n",
       "     0.0006846546688467491,\n",
       "     0.013546169631519214,\n",
       "     0.0067459897795731005,\n",
       "     0.012300697042330173,\n",
       "     0.017180708095092173],\n",
       "    'mean_score_time': [0.04454517364501953,\n",
       "     0.06369280815124512,\n",
       "     0.1118614673614502,\n",
       "     0.02422499656677246,\n",
       "     0.0676266352335612,\n",
       "     0.06245867411295573,\n",
       "     0.05131800969441732,\n",
       "     0.06158939997355143,\n",
       "     0.0568841298421224,\n",
       "     0.06039698918660482,\n",
       "     0.08032528559366862,\n",
       "     0.1626864274342855,\n",
       "     0.029969135920206707,\n",
       "     0.037978728612264,\n",
       "     0.053172032038370766,\n",
       "     0.017452160517374676,\n",
       "     0.05554771423339844,\n",
       "     0.039418538411458336,\n",
       "     0.01680763562520345,\n",
       "     0.04266961415608724,\n",
       "     0.04385622342427572,\n",
       "     0.017375469207763672,\n",
       "     0.030937910079956055,\n",
       "     0.04111957550048828,\n",
       "     0.03299609820048014,\n",
       "     0.027616500854492188,\n",
       "     0.04122471809387207,\n",
       "     0.022319952646891277,\n",
       "     0.030398050944010418,\n",
       "     0.04311561584472656,\n",
       "     0.017530520757039387,\n",
       "     0.02715587615966797,\n",
       "     0.04219500223795573,\n",
       "     0.016179958979288738,\n",
       "     0.028743823369344074,\n",
       "     0.050901571909586586,\n",
       "     0.017334699630737305,\n",
       "     0.030064185460408527,\n",
       "     0.04048562049865723,\n",
       "     0.018568754196166992,\n",
       "     0.02939748764038086,\n",
       "     0.044888973236083984,\n",
       "     0.015939076741536457,\n",
       "     0.028374512990315754,\n",
       "     0.04065640767415365,\n",
       "     0.016507784525553387,\n",
       "     0.026450157165527344,\n",
       "     0.043698390324910484,\n",
       "     0.016791661580403645,\n",
       "     0.02800615628560384,\n",
       "     0.03701432545979818,\n",
       "     0.015008370081583658,\n",
       "     0.02787160873413086,\n",
       "     0.0389245351155599,\n",
       "     0.017261346181233723,\n",
       "     0.03330254554748535,\n",
       "     0.04102389017740885,\n",
       "     0.01770782470703125,\n",
       "     0.025690476099650066,\n",
       "     0.037337541580200195,\n",
       "     0.01567697525024414,\n",
       "     0.02599819501241048,\n",
       "     0.03995450337727865,\n",
       "     0.017544905344645183,\n",
       "     0.028298695882161457,\n",
       "     0.03404672940572103,\n",
       "     0.018529733022054035,\n",
       "     0.018853425979614258,\n",
       "     0.038590192794799805,\n",
       "     0.01700107256571452,\n",
       "     0.022421598434448242,\n",
       "     0.04363568623860677,\n",
       "     0.01668262481689453,\n",
       "     0.025552988052368164,\n",
       "     0.03455503781636556,\n",
       "     0.017688830693562824,\n",
       "     0.02214813232421875,\n",
       "     0.03401676813761393,\n",
       "     0.02418406804402669,\n",
       "     0.029822746912638348,\n",
       "     0.03514965375264486,\n",
       "     0.017471790313720703,\n",
       "     0.03300158182779948,\n",
       "     0.047327915827433266,\n",
       "     0.015462954839070639,\n",
       "     0.02960975964864095,\n",
       "     0.047708988189697266,\n",
       "     0.01714038848876953,\n",
       "     0.026815017064412434,\n",
       "     0.03421481450398763,\n",
       "     0.016135215759277344,\n",
       "     0.024415016174316406,\n",
       "     0.03695241610209147,\n",
       "     0.022162596384684246,\n",
       "     0.033041795094807945,\n",
       "     0.04124013582865397,\n",
       "     0.01682766278584798,\n",
       "     0.018616994222005207,\n",
       "     0.033312479654947914,\n",
       "     0.018356482187906902,\n",
       "     0.029375871022542317,\n",
       "     0.050033171971639,\n",
       "     0.014537572860717773,\n",
       "     0.033232529958089195,\n",
       "     0.035396734873453774,\n",
       "     0.007222811381022136,\n",
       "     0.019695043563842773,\n",
       "     0.021675984064737957],\n",
       "    'std_score_time': [0.027669844423711606,\n",
       "     0.029555141158515034,\n",
       "     0.01112510048107418,\n",
       "     0.0010853434017279026,\n",
       "     0.013072367909883158,\n",
       "     0.016797617015292907,\n",
       "     0.01849565410389671,\n",
       "     0.024282097138336692,\n",
       "     0.024856963098440345,\n",
       "     0.06103150633560865,\n",
       "     0.023489936929390384,\n",
       "     0.0234935412386847,\n",
       "     0.02046608021347527,\n",
       "     0.01344878682851879,\n",
       "     0.008516780674498094,\n",
       "     0.0010560167652321202,\n",
       "     0.03679101218333712,\n",
       "     0.0012640286675514876,\n",
       "     0.0011265053962711655,\n",
       "     0.020216316217630922,\n",
       "     0.009029696714157424,\n",
       "     0.0010438752286308106,\n",
       "     0.0036061796616230057,\n",
       "     0.0008251469888162897,\n",
       "     0.0201529195326075,\n",
       "     0.0036555093895832467,\n",
       "     0.003003052173102259,\n",
       "     0.0018843314756908135,\n",
       "     0.002273873575877343,\n",
       "     0.003898351286595601,\n",
       "     0.0012524950776576969,\n",
       "     0.0009386476377307995,\n",
       "     0.005674949691492565,\n",
       "     0.0006166852929136036,\n",
       "     0.001237688236448666,\n",
       "     0.00818846640011625,\n",
       "     0.0009437522519330372,\n",
       "     0.0018107584158315285,\n",
       "     0.0026063861781723953,\n",
       "     0.002286626938936995,\n",
       "     0.0023590586033304644,\n",
       "     0.004927543476000047,\n",
       "     0.0009497401696136431,\n",
       "     0.0004915784983896583,\n",
       "     0.0011028405645272126,\n",
       "     0.00047000965471586444,\n",
       "     0.00048602362716777944,\n",
       "     0.005746952324742406,\n",
       "     0.0009034615976287913,\n",
       "     0.0008193744488700088,\n",
       "     0.002662089912492854,\n",
       "     0.0008210147316830639,\n",
       "     0.0018857139318642642,\n",
       "     0.007942282816077426,\n",
       "     0.0007852819474074106,\n",
       "     0.0,\n",
       "     0.0028741903379900986,\n",
       "     0.0008305642599471005,\n",
       "     0.0011876432875235906,\n",
       "     0.0020547331993630434,\n",
       "     0.0009483321889778701,\n",
       "     0.0014153478507397705,\n",
       "     0.001226756989058232,\n",
       "     0.0015340151077506041,\n",
       "     0.0005850501538191112,\n",
       "     0.001832612544827014,\n",
       "     0.0030656834136433297,\n",
       "     0.0033575191300966537,\n",
       "     0.0036557606389444027,\n",
       "     0.0014145048370334183,\n",
       "     0.00781745736335901,\n",
       "     0.006288421050459814,\n",
       "     5.301691594037921e-05,\n",
       "     0.006721051908891733,\n",
       "     0.0061384955352489015,\n",
       "     0.0014233271721118988,\n",
       "     0.007831406758003569,\n",
       "     0.0010914419993906027,\n",
       "     0.010717651676977264,\n",
       "     0.0024059668961938898,\n",
       "     0.004457754265924259,\n",
       "     0.001985295946631264,\n",
       "     0.0004843679186478895,\n",
       "     0.0016147569002942276,\n",
       "     0.005125328812359111,\n",
       "     0.00946442294314983,\n",
       "     0.003158316240012355,\n",
       "     0.00034155806033228523,\n",
       "     0.00784371998454371,\n",
       "     0.0008934007968349244,\n",
       "     0.0053672354716915475,\n",
       "     0.010242373006137877,\n",
       "     0.0019656217897840453,\n",
       "     0.007914342576663758,\n",
       "     0.00033395815754670694,\n",
       "     0.007609086053826185,\n",
       "     0.004500721837668752,\n",
       "     0.004416114657245859,\n",
       "     5.9330734732159095e-05,\n",
       "     0.0039918314087975465,\n",
       "     0.00562615871835174,\n",
       "     0.00017443186566295116,\n",
       "     0.0029887185642008757,\n",
       "     0.001904316820455352,\n",
       "     0.0027852885327919355,\n",
       "     0.006715102888981093,\n",
       "     0.005037599220332225,\n",
       "     0.004841919800238815],\n",
       "    'param_classifier__max_depth': [None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30],\n",
       "    'param_classifier__min_samples_leaf': [1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10],\n",
       "    'param_classifier__n_estimators': [100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300],\n",
       "    'params': [{'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300}],\n",
       "    'split0_test_score': [0.9642857142857143,\n",
       "     0.9523809523809523,\n",
       "     0.9642857142857143,\n",
       "     0.9642857142857143,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9642857142857143,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9523809523809523,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9642857142857143,\n",
       "     0.9523809523809523,\n",
       "     0.9642857142857143,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9642857142857143,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9523809523809523,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9642857142857143,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9642857142857143,\n",
       "     0.9642857142857143,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9285714285714286,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9642857142857143,\n",
       "     0.9642857142857143,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9642857142857143,\n",
       "     0.9523809523809523,\n",
       "     0.9404761904761905,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9523809523809523,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9523809523809523,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905],\n",
       "    'split1_test_score': [0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.927710843373494,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.927710843373494,\n",
       "     0.9518072289156626,\n",
       "     0.927710843373494,\n",
       "     0.927710843373494,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.927710843373494,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.963855421686747,\n",
       "     0.927710843373494,\n",
       "     0.927710843373494,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.927710843373494,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.927710843373494,\n",
       "     0.927710843373494,\n",
       "     0.927710843373494,\n",
       "     0.927710843373494,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.927710843373494,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.927710843373494,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.963855421686747,\n",
       "     0.9397590361445783,\n",
       "     0.963855421686747,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.927710843373494,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.927710843373494,\n",
       "     0.927710843373494,\n",
       "     0.927710843373494],\n",
       "    'split2_test_score': [0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.963855421686747,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626],\n",
       "    'mean_test_score': [0.9559667240390132,\n",
       "     0.9519984700707592,\n",
       "     0.9559667240390132,\n",
       "     0.9559667240390132,\n",
       "     0.947982405813731,\n",
       "     0.9519984700707592,\n",
       "     0.9519984700707592,\n",
       "     0.947982405813731,\n",
       "     0.947982405813731,\n",
       "     0.947982405813731,\n",
       "     0.9519984700707592,\n",
       "     0.947982405813731,\n",
       "     0.9559667240390132,\n",
       "     0.9519984700707592,\n",
       "     0.9519984700707592,\n",
       "     0.9560145343277874,\n",
       "     0.947982405813731,\n",
       "     0.943966341556703,\n",
       "     0.9440141518454771,\n",
       "     0.9440141518454771,\n",
       "     0.9440141518454771,\n",
       "     0.9440141518454771,\n",
       "     0.9440141518454771,\n",
       "     0.939998087588449,\n",
       "     0.9519984700707592,\n",
       "     0.939998087588449,\n",
       "     0.939998087588449,\n",
       "     0.9559667240390132,\n",
       "     0.9519984700707592,\n",
       "     0.9519506597819851,\n",
       "     0.9479824058137312,\n",
       "     0.947982405813731,\n",
       "     0.947982405813731,\n",
       "     0.943966341556703,\n",
       "     0.947982405813731,\n",
       "     0.9519984700707592,\n",
       "     0.947982405813731,\n",
       "     0.947982405813731,\n",
       "     0.9519984700707592,\n",
       "     0.947982405813731,\n",
       "     0.9519506597819851,\n",
       "     0.9519984700707592,\n",
       "     0.9560145343277874,\n",
       "     0.943966341556703,\n",
       "     0.943966341556703,\n",
       "     0.9480302161025053,\n",
       "     0.9440141518454771,\n",
       "     0.939998087588449,\n",
       "     0.947982405813731,\n",
       "     0.9440141518454771,\n",
       "     0.939998087588449,\n",
       "     0.939998087588449,\n",
       "     0.939998087588449,\n",
       "     0.939998087588449,\n",
       "     0.9519506597819851,\n",
       "     0.9519984700707592,\n",
       "     0.9519984700707592,\n",
       "     0.947982405813731,\n",
       "     0.9519506597819851,\n",
       "     0.9559667240390132,\n",
       "     0.9519984700707592,\n",
       "     0.947982405813731,\n",
       "     0.9519984700707592,\n",
       "     0.9519984700707592,\n",
       "     0.9519984700707592,\n",
       "     0.947982405813731,\n",
       "     0.9519984700707592,\n",
       "     0.9519984700707592,\n",
       "     0.9519984700707592,\n",
       "     0.947982405813731,\n",
       "     0.9519984700707592,\n",
       "     0.9519984700707592,\n",
       "     0.9440141518454771,\n",
       "     0.939998087588449,\n",
       "     0.9480302161025053,\n",
       "     0.9440141518454771,\n",
       "     0.9480302161025053,\n",
       "     0.9440141518454771,\n",
       "     0.9360298336201951,\n",
       "     0.9440141518454771,\n",
       "     0.9440141518454771,\n",
       "     0.9519984700707592,\n",
       "     0.947982405813731,\n",
       "     0.9559667240390132,\n",
       "     0.9519506597819851,\n",
       "     0.947982405813731,\n",
       "     0.947982405813731,\n",
       "     0.947982405813731,\n",
       "     0.9519984700707592,\n",
       "     0.9519984700707592,\n",
       "     0.947982405813731,\n",
       "     0.9599827882960413,\n",
       "     0.947982405813731,\n",
       "     0.9520462803595334,\n",
       "     0.947982405813731,\n",
       "     0.9519984700707592,\n",
       "     0.9519984700707592,\n",
       "     0.947982405813731,\n",
       "     0.9519984700707592,\n",
       "     0.939998087588449,\n",
       "     0.9440141518454771,\n",
       "     0.9440141518454771,\n",
       "     0.9440141518454771,\n",
       "     0.9440141518454771,\n",
       "     0.9440141518454771,\n",
       "     0.943966341556703,\n",
       "     0.939998087588449,\n",
       "     0.939998087588449],\n",
       "    'std_test_score': [0.005882414416067119,\n",
       "     0.0002704558352214713,\n",
       "     0.005882414416067119,\n",
       "     0.005882414416067119,\n",
       "     0.005819515798318166,\n",
       "     0.0002704558352214713,\n",
       "     0.0002704558352214713,\n",
       "     0.005819515798318166,\n",
       "     0.005819515798318166,\n",
       "     0.005819515798318166,\n",
       "     0.0002704558352214713,\n",
       "     0.005819515798318166,\n",
       "     0.005882414416067119,\n",
       "     0.0002704558352214713,\n",
       "     0.0002704558352214713,\n",
       "     0.00554928977951691,\n",
       "     0.005819515798318166,\n",
       "     0.011496759124260174,\n",
       "     0.0055183098408978695,\n",
       "     0.0055183098408978695,\n",
       "     0.0055183098408978695,\n",
       "     0.0055183098408978695,\n",
       "     0.0055183098408978695,\n",
       "     0.009843115557845781,\n",
       "     0.0002704558352214713,\n",
       "     0.009843115557845781,\n",
       "     0.009843115557845781,\n",
       "     0.005882414416067119,\n",
       "     0.0002704558352214713,\n",
       "     0.010013488052614488,\n",
       "     0.005819515798318166,\n",
       "     0.005819515798318166,\n",
       "     0.005819515798318166,\n",
       "     0.011496759124260174,\n",
       "     0.005819515798318166,\n",
       "     0.0002704558352214713,\n",
       "     0.005819515798318166,\n",
       "     0.005819515798318166,\n",
       "     0.0002704558352214713,\n",
       "     0.005819515798318166,\n",
       "     0.010013488052614488,\n",
       "     0.0002704558352214713,\n",
       "     0.00554928977951691,\n",
       "     0.011496759124260174,\n",
       "     0.011496759124260174,\n",
       "     0.005341502745624124,\n",
       "     0.0055183098408978695,\n",
       "     0.009843115557845781,\n",
       "     0.005819515798318166,\n",
       "     0.0055183098408978695,\n",
       "     0.009843115557845781,\n",
       "     0.009843115557845781,\n",
       "     0.009843115557845781,\n",
       "     0.009843115557845781,\n",
       "     0.010013488052614488,\n",
       "     0.0002704558352214713,\n",
       "     0.0002704558352214713,\n",
       "     0.005819515798318166,\n",
       "     0.010013488052614488,\n",
       "     0.005882414416067119,\n",
       "     0.0002704558352214713,\n",
       "     0.005819515798318166,\n",
       "     0.0002704558352214713,\n",
       "     0.0002704558352214713,\n",
       "     0.0002704558352214713,\n",
       "     0.005819515798318166,\n",
       "     0.0002704558352214713,\n",
       "     0.0002704558352214713,\n",
       "     0.0002704558352214713,\n",
       "     0.005819515798318166,\n",
       "     0.0002704558352214713,\n",
       "     0.0002704558352214713,\n",
       "     0.0055183098408978695,\n",
       "     0.009843115557845781,\n",
       "     0.005341502745624124,\n",
       "     0.0055183098408978695,\n",
       "     0.005341502745624124,\n",
       "     0.0055183098408978695,\n",
       "     0.011161833883157588,\n",
       "     0.0055183098408978695,\n",
       "     0.0055183098408978695,\n",
       "     0.0002704558352214713,\n",
       "     0.005819515798318166,\n",
       "     0.005882414416067119,\n",
       "     0.010013488052614488,\n",
       "     0.005819515798318166,\n",
       "     0.005819515798318166,\n",
       "     0.005819515798318166,\n",
       "     0.0002704558352214713,\n",
       "     0.0002704558352214713,\n",
       "     0.005819515798318166,\n",
       "     0.005783661834095248,\n",
       "     0.005819515798318166,\n",
       "     0.009546027871800134,\n",
       "     0.005819515798318166,\n",
       "     0.0002704558352214713,\n",
       "     0.0002704558352214713,\n",
       "     0.005819515798318166,\n",
       "     0.0002704558352214713,\n",
       "     0.009843115557845781,\n",
       "     0.0055183098408978695,\n",
       "     0.0055183098408978695,\n",
       "     0.0055183098408978695,\n",
       "     0.0055183098408978695,\n",
       "     0.0055183098408978695,\n",
       "     0.011496759124260174,\n",
       "     0.009843115557845781,\n",
       "     0.009843115557845781],\n",
       "    'rank_test_score': [4,\n",
       "     12,\n",
       "     4,\n",
       "     4,\n",
       "     49,\n",
       "     12,\n",
       "     12,\n",
       "     49,\n",
       "     49,\n",
       "     49,\n",
       "     12,\n",
       "     49,\n",
       "     4,\n",
       "     12,\n",
       "     12,\n",
       "     2,\n",
       "     49,\n",
       "     91,\n",
       "     74,\n",
       "     74,\n",
       "     74,\n",
       "     74,\n",
       "     74,\n",
       "     96,\n",
       "     12,\n",
       "     96,\n",
       "     96,\n",
       "     4,\n",
       "     12,\n",
       "     40,\n",
       "     48,\n",
       "     49,\n",
       "     49,\n",
       "     91,\n",
       "     49,\n",
       "     12,\n",
       "     49,\n",
       "     49,\n",
       "     12,\n",
       "     49,\n",
       "     40,\n",
       "     12,\n",
       "     2,\n",
       "     91,\n",
       "     91,\n",
       "     45,\n",
       "     74,\n",
       "     96,\n",
       "     49,\n",
       "     74,\n",
       "     96,\n",
       "     96,\n",
       "     96,\n",
       "     96,\n",
       "     40,\n",
       "     12,\n",
       "     12,\n",
       "     49,\n",
       "     40,\n",
       "     4,\n",
       "     12,\n",
       "     49,\n",
       "     12,\n",
       "     12,\n",
       "     12,\n",
       "     49,\n",
       "     12,\n",
       "     12,\n",
       "     12,\n",
       "     49,\n",
       "     12,\n",
       "     12,\n",
       "     74,\n",
       "     96,\n",
       "     45,\n",
       "     74,\n",
       "     45,\n",
       "     74,\n",
       "     108,\n",
       "     74,\n",
       "     74,\n",
       "     12,\n",
       "     49,\n",
       "     4,\n",
       "     40,\n",
       "     49,\n",
       "     49,\n",
       "     49,\n",
       "     12,\n",
       "     12,\n",
       "     49,\n",
       "     1,\n",
       "     49,\n",
       "     11,\n",
       "     49,\n",
       "     12,\n",
       "     12,\n",
       "     49,\n",
       "     12,\n",
       "     96,\n",
       "     74,\n",
       "     74,\n",
       "     74,\n",
       "     74,\n",
       "     74,\n",
       "     91,\n",
       "     96,\n",
       "     96]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__max_depth': None,\n",
       "    'classifier__min_samples_leaf': 1,\n",
       "    'classifier__min_samples_split': 5,\n",
       "    'classifier__n_estimators': 200},\n",
       "   'best_validation_accuracy': 0.9674933602663375,\n",
       "   'train_accuracy': 1.0,\n",
       "   'test_accuracy': 0.93,\n",
       "   'cv_results': {'mean_fit_time': [0.2365907828013102,\n",
       "     0.5697353680928549,\n",
       "     0.9670771757761637,\n",
       "     0.25371646881103516,\n",
       "     0.48729848861694336,\n",
       "     0.860724925994873,\n",
       "     0.30432558059692383,\n",
       "     0.5652145544687907,\n",
       "     0.8574317296346029,\n",
       "     0.3143637180328369,\n",
       "     0.5896353721618652,\n",
       "     0.8523268699645996,\n",
       "     0.27663469314575195,\n",
       "     0.6276811758677164,\n",
       "     0.8946544329325358,\n",
       "     0.27277660369873047,\n",
       "     0.6098033587137858,\n",
       "     0.8300762971242269,\n",
       "     0.2900984287261963,\n",
       "     0.5241758028666178,\n",
       "     0.7496607303619385,\n",
       "     0.24764553705851236,\n",
       "     0.4499785900115967,\n",
       "     0.6879040400187174,\n",
       "     0.23297921816507974,\n",
       "     0.45864200592041016,\n",
       "     0.7011250654856364,\n",
       "     0.2338414192199707,\n",
       "     0.4735097090403239,\n",
       "     0.7479456265767416,\n",
       "     0.2622681458791097,\n",
       "     0.5105802218119303,\n",
       "     0.7663125991821289,\n",
       "     0.26030882199605304,\n",
       "     0.4983650843302409,\n",
       "     0.7821707725524902,\n",
       "     0.24427111943562826,\n",
       "     0.5302481651306152,\n",
       "     0.7334619363149008,\n",
       "     0.26882346471150714,\n",
       "     0.47149984041849774,\n",
       "     0.919488271077474,\n",
       "     0.2576042016347249,\n",
       "     0.6273016134897867,\n",
       "     0.8685249487559,\n",
       "     0.27701743443806964,\n",
       "     0.5560894012451172,\n",
       "     0.7381963729858398,\n",
       "     0.2425541083017985,\n",
       "     0.49063563346862793,\n",
       "     0.7851228713989258,\n",
       "     0.24004030227661133,\n",
       "     0.5582546393076578,\n",
       "     0.7514826456705729,\n",
       "     0.28961602846781415,\n",
       "     0.4918758074442546,\n",
       "     0.7507739067077637,\n",
       "     0.2456364631652832,\n",
       "     0.47229615847269696,\n",
       "     0.7422738075256348,\n",
       "     0.23740744590759277,\n",
       "     0.4797906080881755,\n",
       "     0.7218955357869467,\n",
       "     0.24553672472635904,\n",
       "     0.49893919626871747,\n",
       "     0.7106866041819254,\n",
       "     0.2509698073069255,\n",
       "     0.4792020320892334,\n",
       "     0.7258752981821696,\n",
       "     0.2492232322692871,\n",
       "     0.46578526496887207,\n",
       "     0.6999218463897705,\n",
       "     0.24963577588399252,\n",
       "     0.4763595263163249,\n",
       "     0.6864206790924072,\n",
       "     0.24010078112284342,\n",
       "     0.4674701690673828,\n",
       "     0.7280295689900717,\n",
       "     0.23666111628214517,\n",
       "     0.47563862800598145,\n",
       "     0.6892146269480387,\n",
       "     0.25165295600891113,\n",
       "     0.47781944274902344,\n",
       "     0.7167453765869141,\n",
       "     0.2529326279958089,\n",
       "     0.46571095784505206,\n",
       "     0.7467857996622721,\n",
       "     0.23346646626790366,\n",
       "     0.47134892145792645,\n",
       "     0.7269404729207357,\n",
       "     0.23182050387064615,\n",
       "     0.46717635790507,\n",
       "     0.7260137399037679,\n",
       "     0.23960264523824057,\n",
       "     0.4618511199951172,\n",
       "     0.7090814908345541,\n",
       "     0.23405090967814127,\n",
       "     0.45844300587972003,\n",
       "     0.7194629510243734,\n",
       "     0.23066035906473795,\n",
       "     0.45675134658813477,\n",
       "     0.6863817373911539,\n",
       "     0.23267277081807455,\n",
       "     0.479900598526001,\n",
       "     0.7315288384755453,\n",
       "     0.2519034544626872,\n",
       "     0.448563814163208,\n",
       "     0.5757402578989664],\n",
       "    'std_fit_time': [0.010537498868895712,\n",
       "     0.0869990763145983,\n",
       "     0.052987218931556945,\n",
       "     0.03174910688655862,\n",
       "     0.016369569471001277,\n",
       "     0.050603528140135245,\n",
       "     0.040172115955198484,\n",
       "     0.018854634107699837,\n",
       "     0.0459700095164099,\n",
       "     0.02729593660180734,\n",
       "     0.031942444833463764,\n",
       "     0.03731880540735444,\n",
       "     0.01660097904468752,\n",
       "     0.033086002837123,\n",
       "     0.02665854477470771,\n",
       "     0.018726887625052355,\n",
       "     0.025998836653945378,\n",
       "     0.010088305770436942,\n",
       "     0.015316891445658638,\n",
       "     0.028113556698756665,\n",
       "     0.009243179366880532,\n",
       "     0.015751399400389568,\n",
       "     0.03600389876669859,\n",
       "     0.03217658928832224,\n",
       "     0.013152589092434205,\n",
       "     0.006829143970603403,\n",
       "     0.025979639583103214,\n",
       "     0.013679273953709045,\n",
       "     0.01948333508246248,\n",
       "     0.03490846149800559,\n",
       "     0.012877138706928496,\n",
       "     0.019977630455874692,\n",
       "     0.046057839353832265,\n",
       "     0.0211225542630402,\n",
       "     0.014878513411462426,\n",
       "     0.03341031405412708,\n",
       "     0.01084741976498009,\n",
       "     0.006402984816348183,\n",
       "     0.024746372196577868,\n",
       "     0.0026933719779393102,\n",
       "     0.0005158203208258177,\n",
       "     0.02455918081491235,\n",
       "     0.00539148029205152,\n",
       "     0.06250623436204872,\n",
       "     0.013371178831856206,\n",
       "     0.010456478575890788,\n",
       "     0.02058900160809127,\n",
       "     0.04458811778188449,\n",
       "     0.009255503515144124,\n",
       "     0.02780549125381737,\n",
       "     0.014502477786638704,\n",
       "     0.011534371333173303,\n",
       "     0.010368738268255115,\n",
       "     0.027458903808816045,\n",
       "     0.015042784646707042,\n",
       "     0.00021259749033558623,\n",
       "     0.0004120275910425001,\n",
       "     0.016050590812113227,\n",
       "     0.006452081344989459,\n",
       "     0.022618957398767358,\n",
       "     0.009826390666751346,\n",
       "     0.028013625297901096,\n",
       "     0.02949081117689395,\n",
       "     0.012437660458509836,\n",
       "     0.014457117826176995,\n",
       "     0.019226209247565816,\n",
       "     0.017653454109902173,\n",
       "     0.027961814143876555,\n",
       "     0.01666198786343661,\n",
       "     0.01172686152169238,\n",
       "     0.025735440338982615,\n",
       "     0.05284956498623898,\n",
       "     0.0018068683409729936,\n",
       "     0.013903305145739023,\n",
       "     0.03366230482487089,\n",
       "     0.02135019704339614,\n",
       "     0.02320787105702855,\n",
       "     0.039405480689430485,\n",
       "     0.01219184246314262,\n",
       "     0.012572910672981821,\n",
       "     0.022405280305391635,\n",
       "     0.01198191367372475,\n",
       "     0.02080992726678924,\n",
       "     0.01650371028345812,\n",
       "     0.010278646467649954,\n",
       "     0.008495108002441477,\n",
       "     0.026434049906662635,\n",
       "     0.013023191874103992,\n",
       "     0.012457606437092355,\n",
       "     0.017407405474539575,\n",
       "     0.014841664001521853,\n",
       "     0.01581511213671083,\n",
       "     0.007375473706214398,\n",
       "     0.010498035587821565,\n",
       "     0.00798101756226234,\n",
       "     0.0344713096799772,\n",
       "     0.010560433906273349,\n",
       "     0.00693798458544229,\n",
       "     0.027507522956226913,\n",
       "     0.0023534437133595066,\n",
       "     0.022549784405640042,\n",
       "     0.03814025715801961,\n",
       "     0.003775267282395057,\n",
       "     0.02898895336742484,\n",
       "     0.00977931334044156,\n",
       "     0.013131007864709375,\n",
       "     0.007201050011350309,\n",
       "     0.009711374241172134],\n",
       "    'mean_score_time': [0.015194098154703775,\n",
       "     0.033727010091145836,\n",
       "     0.04124283790588379,\n",
       "     0.022307554880777996,\n",
       "     0.03198846181233724,\n",
       "     0.0387880007425944,\n",
       "     0.023876269658406574,\n",
       "     0.03733968734741211,\n",
       "     0.059682210286458336,\n",
       "     0.025741736094156902,\n",
       "     0.04275202751159668,\n",
       "     0.05696463584899902,\n",
       "     0.01999807357788086,\n",
       "     0.036756038665771484,\n",
       "     0.042648871739705406,\n",
       "     0.0236051082611084,\n",
       "     0.03693747520446777,\n",
       "     0.033184448877970375,\n",
       "     0.012593428293863932,\n",
       "     0.027112404505411785,\n",
       "     0.042653163274129234,\n",
       "     0.01282962163289388,\n",
       "     0.04033986727396647,\n",
       "     0.03986485799153646,\n",
       "     0.01699964205423991,\n",
       "     0.03255931536356608,\n",
       "     0.03635756174723307,\n",
       "     0.0163571834564209,\n",
       "     0.030247211456298828,\n",
       "     0.045766989390055336,\n",
       "     0.014045397440592447,\n",
       "     0.02186886469523112,\n",
       "     0.05170234044392904,\n",
       "     0.02186862627665202,\n",
       "     0.03249343236287435,\n",
       "     0.04216917355855306,\n",
       "     0.020312388737996418,\n",
       "     0.03101181983947754,\n",
       "     0.04143222173055013,\n",
       "     0.0168764591217041,\n",
       "     0.02999107042948405,\n",
       "     0.0666506290435791,\n",
       "     0.017671744028727215,\n",
       "     0.03553255399068197,\n",
       "     0.030909220377604168,\n",
       "     0.016471703847249348,\n",
       "     0.020057280858357746,\n",
       "     0.05128041903177897,\n",
       "     0.016052802403767902,\n",
       "     0.039793809254964195,\n",
       "     0.04037181536356608,\n",
       "     0.01791071891784668,\n",
       "     0.03311610221862793,\n",
       "     0.03493817647298177,\n",
       "     0.01558534304300944,\n",
       "     0.02575516700744629,\n",
       "     0.036468823750813804,\n",
       "     0.015933513641357422,\n",
       "     0.027686913808186848,\n",
       "     0.046202500661214195,\n",
       "     0.01572426160176595,\n",
       "     0.030159155527750652,\n",
       "     0.03532020250956217,\n",
       "     0.017508745193481445,\n",
       "     0.038922627766927086,\n",
       "     0.04133756955464681,\n",
       "     0.016206105550130207,\n",
       "     0.027231693267822266,\n",
       "     0.03860155741373698,\n",
       "     0.016938527425130207,\n",
       "     0.02851708730061849,\n",
       "     0.05028096834818522,\n",
       "     0.015976508458455402,\n",
       "     0.02812504768371582,\n",
       "     0.0414430300394694,\n",
       "     0.01565074920654297,\n",
       "     0.02611430486043294,\n",
       "     0.04155500729878744,\n",
       "     0.014275550842285156,\n",
       "     0.02563174565633138,\n",
       "     0.035432656606038414,\n",
       "     0.01777497927347819,\n",
       "     0.03220860163370768,\n",
       "     0.044879913330078125,\n",
       "     0.01940457026163737,\n",
       "     0.02196502685546875,\n",
       "     0.04241506258646647,\n",
       "     0.01589679718017578,\n",
       "     0.025150299072265625,\n",
       "     0.03713059425354004,\n",
       "     0.019000768661499023,\n",
       "     0.026044607162475586,\n",
       "     0.03957962989807129,\n",
       "     0.020283301671346027,\n",
       "     0.02770121892293294,\n",
       "     0.0405875047047933,\n",
       "     0.01606639226277669,\n",
       "     0.02097773551940918,\n",
       "     0.03402813275655111,\n",
       "     0.022835969924926758,\n",
       "     0.03405372301737467,\n",
       "     0.0423585573832194,\n",
       "     0.017591555913289387,\n",
       "     0.02995610237121582,\n",
       "     0.03568561871846517,\n",
       "     0.017754395802815754,\n",
       "     0.03013189633687337,\n",
       "     0.013156652450561523],\n",
       "    'std_score_time': [0.002102397195319423,\n",
       "     0.0004915374078908213,\n",
       "     0.007429469689750847,\n",
       "     0.007923774767340233,\n",
       "     0.009744676937103458,\n",
       "     0.006421529841311541,\n",
       "     0.00355509368664601,\n",
       "     0.0043993431264263095,\n",
       "     0.02219287175103298,\n",
       "     0.012128800099538862,\n",
       "     0.007342432875427398,\n",
       "     0.010153349193441217,\n",
       "     0.000946788145801929,\n",
       "     0.0009847652104782955,\n",
       "     0.003778971584297011,\n",
       "     0.005106674676269798,\n",
       "     0.0033576347274075174,\n",
       "     0.0002707653042825291,\n",
       "     0.003964914620524378,\n",
       "     0.008052135718470809,\n",
       "     0.005388513148150143,\n",
       "     0.005351600735936743,\n",
       "     0.005710429083057673,\n",
       "     0.006507048492889363,\n",
       "     0.0005152705337086111,\n",
       "     0.0012166392761967402,\n",
       "     0.007060924785206159,\n",
       "     0.000644030324397496,\n",
       "     0.006462680248554424,\n",
       "     0.009677216623015381,\n",
       "     0.002246818085528458,\n",
       "     0.007577957833732475,\n",
       "     0.0008876551855067679,\n",
       "     0.006253104423672721,\n",
       "     0.0032820118411942315,\n",
       "     8.584400650590587e-05,\n",
       "     0.00398220792390788,\n",
       "     0.0021736796675357003,\n",
       "     0.002238956217281128,\n",
       "     0.00217037428471843,\n",
       "     0.002817550307520012,\n",
       "     0.013889548428226654,\n",
       "     0.0025039009410669595,\n",
       "     0.007639071626395121,\n",
       "     0.001816288533426781,\n",
       "     0.000505626894506713,\n",
       "     0.005866411761933119,\n",
       "     0.006906654308931556,\n",
       "     0.0012617688817756355,\n",
       "     0.009665966869659677,\n",
       "     0.007426162316023499,\n",
       "     0.001883893546701115,\n",
       "     0.012017952554786935,\n",
       "     0.0022559241154951064,\n",
       "     0.0006896600274677151,\n",
       "     0.009378031757358546,\n",
       "     0.007586302669626042,\n",
       "     0.00020807873641289794,\n",
       "     0.008713820376461625,\n",
       "     0.006292807235161124,\n",
       "     0.0006047440874760829,\n",
       "     0.0015450473809835504,\n",
       "     0.0028875876963126786,\n",
       "     0.002648527305158241,\n",
       "     0.009757128756541809,\n",
       "     0.009464326816471582,\n",
       "     0.0008090172158903455,\n",
       "     0.003001627853242908,\n",
       "     0.005823797120870375,\n",
       "     0.0021484439043618414,\n",
       "     0.00948784133932436,\n",
       "     0.0021205979414785575,\n",
       "     0.00047556470262729813,\n",
       "     0.00919969151795325,\n",
       "     0.00722161712133664,\n",
       "     0.00011038136514965301,\n",
       "     0.007438603197023354,\n",
       "     0.011483769413358567,\n",
       "     0.006169265503197256,\n",
       "     0.005336831887486739,\n",
       "     0.00881098953709925,\n",
       "     0.0033732762980564304,\n",
       "     0.008890467072068134,\n",
       "     0.0065545615679558755,\n",
       "     0.003944202850872094,\n",
       "     0.005437068157129234,\n",
       "     0.008296176459735679,\n",
       "     0.00019236533329311772,\n",
       "     0.007546901012445609,\n",
       "     0.004462583274325996,\n",
       "     0.004775912453481805,\n",
       "     0.007368617818856626,\n",
       "     0.007367269119704277,\n",
       "     0.005981101873745214,\n",
       "     0.003122290814715475,\n",
       "     0.004737602374493921,\n",
       "     0.00453646591669261,\n",
       "     0.004746723853808602,\n",
       "     0.003643917235589811,\n",
       "     0.006427762684670776,\n",
       "     0.003626360143605092,\n",
       "     0.011422837750510425,\n",
       "     0.003936717793364364,\n",
       "     0.0017093117146227627,\n",
       "     0.007912255968849145,\n",
       "     0.003200404016871836,\n",
       "     0.006566577536361324,\n",
       "     0.004117138691627272],\n",
       "    'param_classifier__max_depth': [None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30],\n",
       "    'param_classifier__min_samples_leaf': [1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10],\n",
       "    'param_classifier__n_estimators': [100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300],\n",
       "    'params': [{'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300}],\n",
       "    'split0_test_score': [0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9626865671641791,\n",
       "     0.9626865671641791,\n",
       "     0.9626865671641791,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9626865671641791,\n",
       "     0.9776119402985075,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9626865671641791,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9626865671641791,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9776119402985075,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9626865671641791,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9626865671641791,\n",
       "     0.9701492537313433,\n",
       "     0.9626865671641791,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9626865671641791,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9626865671641791,\n",
       "     0.9626865671641791,\n",
       "     0.9701492537313433,\n",
       "     0.9776119402985075,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9626865671641791,\n",
       "     0.9626865671641791,\n",
       "     0.9776119402985075,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9626865671641791,\n",
       "     0.9776119402985075,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9626865671641791,\n",
       "     0.9626865671641791,\n",
       "     0.9626865671641791,\n",
       "     0.9626865671641791,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9626865671641791,\n",
       "     0.9626865671641791,\n",
       "     0.9626865671641791,\n",
       "     0.9701492537313433],\n",
       "    'split1_test_score': [0.9774436090225563,\n",
       "     0.9849624060150376,\n",
       "     0.9849624060150376,\n",
       "     0.9699248120300752,\n",
       "     0.9924812030075187,\n",
       "     0.9774436090225563,\n",
       "     0.9624060150375939,\n",
       "     0.9699248120300752,\n",
       "     0.9624060150375939,\n",
       "     0.9699248120300752,\n",
       "     0.9924812030075187,\n",
       "     0.9624060150375939,\n",
       "     0.9774436090225563,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9624060150375939,\n",
       "     0.9624060150375939,\n",
       "     0.9774436090225563,\n",
       "     0.9624060150375939,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9548872180451128,\n",
       "     0.9624060150375939,\n",
       "     0.9624060150375939,\n",
       "     0.9624060150375939,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9849624060150376,\n",
       "     0.9774436090225563,\n",
       "     0.9774436090225563,\n",
       "     0.9774436090225563,\n",
       "     0.9774436090225563,\n",
       "     0.9774436090225563,\n",
       "     0.9774436090225563,\n",
       "     0.9774436090225563,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9849624060150376,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9624060150375939,\n",
       "     0.9774436090225563,\n",
       "     0.9774436090225563,\n",
       "     0.9774436090225563,\n",
       "     0.9624060150375939,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9624060150375939,\n",
       "     0.9624060150375939,\n",
       "     0.9548872180451128,\n",
       "     0.9699248120300752,\n",
       "     0.9774436090225563,\n",
       "     0.9624060150375939,\n",
       "     0.9699248120300752,\n",
       "     0.9849624060150376,\n",
       "     0.9774436090225563,\n",
       "     0.9774436090225563,\n",
       "     0.9849624060150376,\n",
       "     0.9624060150375939,\n",
       "     0.9699248120300752,\n",
       "     0.9624060150375939,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9774436090225563,\n",
       "     0.9699248120300752,\n",
       "     0.9774436090225563,\n",
       "     0.9624060150375939,\n",
       "     0.9774436090225563,\n",
       "     0.9849624060150376,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9624060150375939,\n",
       "     0.9774436090225563,\n",
       "     0.9774436090225563,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9624060150375939,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9774436090225563,\n",
       "     0.9849624060150376,\n",
       "     0.9849624060150376,\n",
       "     0.9774436090225563,\n",
       "     0.9699248120300752,\n",
       "     0.9774436090225563,\n",
       "     0.9699248120300752,\n",
       "     0.9624060150375939,\n",
       "     0.9624060150375939,\n",
       "     0.9849624060150376,\n",
       "     0.9548872180451128,\n",
       "     0.9774436090225563,\n",
       "     0.9774436090225563,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9774436090225563,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9774436090225563,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9624060150375939,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752],\n",
       "    'split2_test_score': [0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9323308270676691,\n",
       "     0.9398496240601504,\n",
       "     0.9473684210526315,\n",
       "     0.9323308270676691,\n",
       "     0.9323308270676691,\n",
       "     0.9398496240601504,\n",
       "     0.9473684210526315,\n",
       "     0.9323308270676691,\n",
       "     0.9473684210526315,\n",
       "     0.9473684210526315,\n",
       "     0.9473684210526315,\n",
       "     0.9323308270676691,\n",
       "     0.9323308270676691,\n",
       "     0.9323308270676691,\n",
       "     0.9323308270676691,\n",
       "     0.9323308270676691,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9323308270676691,\n",
       "     0.9473684210526315,\n",
       "     0.9473684210526315,\n",
       "     0.9398496240601504,\n",
       "     0.9473684210526315,\n",
       "     0.9323308270676691,\n",
       "     0.9398496240601504,\n",
       "     0.9473684210526315,\n",
       "     0.9323308270676691,\n",
       "     0.9398496240601504,\n",
       "     0.9473684210526315,\n",
       "     0.9398496240601504,\n",
       "     0.9323308270676691,\n",
       "     0.9323308270676691,\n",
       "     0.9323308270676691,\n",
       "     0.9323308270676691,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9323308270676691,\n",
       "     0.9398496240601504,\n",
       "     0.9323308270676691,\n",
       "     0.9323308270676691,\n",
       "     0.9323308270676691,\n",
       "     0.9323308270676691,\n",
       "     0.9473684210526315,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9323308270676691,\n",
       "     0.9398496240601504,\n",
       "     0.9323308270676691,\n",
       "     0.9473684210526315,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9473684210526315,\n",
       "     0.9473684210526315,\n",
       "     0.9473684210526315,\n",
       "     0.9323308270676691,\n",
       "     0.9323308270676691,\n",
       "     0.9323308270676691,\n",
       "     0.9398496240601504,\n",
       "     0.9323308270676691,\n",
       "     0.9473684210526315,\n",
       "     0.9398496240601504,\n",
       "     0.9473684210526315,\n",
       "     0.9473684210526315,\n",
       "     0.9323308270676691,\n",
       "     0.9398496240601504,\n",
       "     0.9473684210526315,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9473684210526315,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9473684210526315,\n",
       "     0.9473684210526315,\n",
       "     0.9323308270676691,\n",
       "     0.9398496240601504,\n",
       "     0.9323308270676691,\n",
       "     0.9473684210526315,\n",
       "     0.9398496240601504,\n",
       "     0.9473684210526315,\n",
       "     0.9323308270676691,\n",
       "     0.9473684210526315,\n",
       "     0.9398496240601504,\n",
       "     0.9473684210526315,\n",
       "     0.9398496240601504,\n",
       "     0.9323308270676691,\n",
       "     0.9398496240601504,\n",
       "     0.9473684210526315,\n",
       "     0.9473684210526315,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9473684210526315],\n",
       "    'mean_test_score': [0.9624808289380167,\n",
       "     0.9649870946021771,\n",
       "     0.9649870946021771,\n",
       "     0.9574682976096959,\n",
       "     0.9674933602663375,\n",
       "     0.964987094602177,\n",
       "     0.9549620319455355,\n",
       "     0.9574682976096959,\n",
       "     0.9574682976096959,\n",
       "     0.9624808289380167,\n",
       "     0.9649870946021771,\n",
       "     0.9599745632738562,\n",
       "     0.964987094602177,\n",
       "     0.9624808289380167,\n",
       "     0.9574682976096959,\n",
       "     0.9524744697564808,\n",
       "     0.9524744697564808,\n",
       "     0.9574870010848014,\n",
       "     0.9549620319455355,\n",
       "     0.9599745632738563,\n",
       "     0.9599745632738563,\n",
       "     0.9524557662813752,\n",
       "     0.9599745632738562,\n",
       "     0.9574870010848016,\n",
       "     0.9599558597987506,\n",
       "     0.9624808289380167,\n",
       "     0.9574682976096959,\n",
       "     0.9624995324131224,\n",
       "     0.964987094602177,\n",
       "     0.9599745632738562,\n",
       "     0.9599932667489619,\n",
       "     0.964987094602177,\n",
       "     0.9624808289380167,\n",
       "     0.9599745632738562,\n",
       "     0.9599745632738562,\n",
       "     0.9574682976096959,\n",
       "     0.9574682976096959,\n",
       "     0.9649870946021771,\n",
       "     0.9599745632738563,\n",
       "     0.9574682976096959,\n",
       "     0.9574682976096959,\n",
       "     0.9599745632738562,\n",
       "     0.9599745632738562,\n",
       "     0.9599745632738562,\n",
       "     0.9549620319455355,\n",
       "     0.9624808289380167,\n",
       "     0.962462125462911,\n",
       "     0.9574682976096959,\n",
       "     0.9574682976096959,\n",
       "     0.9499682040923204,\n",
       "     0.9599745632738563,\n",
       "     0.9599745632738562,\n",
       "     0.9599745632738562,\n",
       "     0.9599745632738563,\n",
       "     0.9649870946021771,\n",
       "     0.9624808289380167,\n",
       "     0.9624808289380167,\n",
       "     0.9649870946021771,\n",
       "     0.9599745632738562,\n",
       "     0.9624808289380167,\n",
       "     0.9599745632738562,\n",
       "     0.9549807354206411,\n",
       "     0.9574682976096959,\n",
       "     0.9574870010848014,\n",
       "     0.9599745632738563,\n",
       "     0.9599745632738562,\n",
       "     0.9599745632738562,\n",
       "     0.9624808289380167,\n",
       "     0.9674933602663375,\n",
       "     0.9599932667489619,\n",
       "     0.9574682976096959,\n",
       "     0.9574682976096959,\n",
       "     0.9624995324131222,\n",
       "     0.9599932667489619,\n",
       "     0.9599745632738563,\n",
       "     0.962462125462911,\n",
       "     0.9574682976096959,\n",
       "     0.9599745632738563,\n",
       "     0.9574870010848016,\n",
       "     0.9574870010848016,\n",
       "     0.962462125462911,\n",
       "     0.9624808289380167,\n",
       "     0.9674933602663375,\n",
       "     0.9649870946021771,\n",
       "     0.9624808289380167,\n",
       "     0.9624808289380167,\n",
       "     0.964987094602177,\n",
       "     0.9574682976096959,\n",
       "     0.9574682976096959,\n",
       "     0.9549620319455355,\n",
       "     0.9650057980772827,\n",
       "     0.9574495941345903,\n",
       "     0.964987094602177,\n",
       "     0.9599745632738562,\n",
       "     0.9624808289380167,\n",
       "     0.9599745632738563,\n",
       "     0.9599932667489619,\n",
       "     0.9574870010848016,\n",
       "     0.9574870010848014,\n",
       "     0.9574870010848016,\n",
       "     0.9624808289380167,\n",
       "     0.9624808289380167,\n",
       "     0.9624808289380167,\n",
       "     0.9599745632738563,\n",
       "     0.9574870010848016,\n",
       "     0.9549807354206411,\n",
       "     0.9574870010848016,\n",
       "     0.9624808289380167],\n",
       "    'std_test_score': [0.016277397016447506,\n",
       "     0.01877545719076591,\n",
       "     0.01877545719076591,\n",
       "     0.017775112047612417,\n",
       "     0.02156866713848838,\n",
       "     0.012809245307269365,\n",
       "     0.016311918179357184,\n",
       "     0.017775112047612417,\n",
       "     0.012853084703711787,\n",
       "     0.010686478920892058,\n",
       "     0.024826099795476477,\n",
       "     0.009457820490416134,\n",
       "     0.012809245307269365,\n",
       "     0.010686478920892058,\n",
       "     0.017775112047612417,\n",
       "     0.014244166828444024,\n",
       "     0.014244166828444024,\n",
       "     0.01878061748164243,\n",
       "     0.016311918179357184,\n",
       "     0.014230775975231418,\n",
       "     0.014230775975231418,\n",
       "     0.015534742076787395,\n",
       "     0.009457820490416134,\n",
       "     0.007155833227724305,\n",
       "     0.015513447444980245,\n",
       "     0.010686478920892058,\n",
       "     0.017775112047612417,\n",
       "     0.01841769095961591,\n",
       "     0.012809245307269365,\n",
       "     0.01977260762362176,\n",
       "     0.015465387734838897,\n",
       "     0.012809245307269365,\n",
       "     0.016277397016447506,\n",
       "     0.01977260762362176,\n",
       "     0.01977260762362176,\n",
       "     0.017775112047612417,\n",
       "     0.017775112047612417,\n",
       "     0.01877545719076591,\n",
       "     0.014230775975231418,\n",
       "     0.017775112047612417,\n",
       "     0.012853084703711787,\n",
       "     0.01977260762362176,\n",
       "     0.01977260762362176,\n",
       "     0.01977260762362176,\n",
       "     0.016311918179357184,\n",
       "     0.010686478920892058,\n",
       "     0.016294516460478803,\n",
       "     0.012853084703711787,\n",
       "     0.012853084703711787,\n",
       "     0.012871551652191253,\n",
       "     0.014230775975231418,\n",
       "     0.01977260762362176,\n",
       "     0.009457820490416134,\n",
       "     0.014230775975231418,\n",
       "     0.01877545719076591,\n",
       "     0.016277397016447506,\n",
       "     0.016277397016447506,\n",
       "     0.01877545719076591,\n",
       "     0.009457820490416134,\n",
       "     0.010686478920892058,\n",
       "     0.009457820490416134,\n",
       "     0.01628622748384232,\n",
       "     0.017775112047612417,\n",
       "     0.01878061748164243,\n",
       "     0.014230775975231418,\n",
       "     0.01977260762362176,\n",
       "     0.009457820490416134,\n",
       "     0.016277397016447506,\n",
       "     0.015462152802062609,\n",
       "     0.009403477861117207,\n",
       "     0.017775112047612417,\n",
       "     0.012853084703711787,\n",
       "     0.012278856335320339,\n",
       "     0.015465387734838897,\n",
       "     0.014230775975231418,\n",
       "     0.016294516460478803,\n",
       "     0.012853084703711787,\n",
       "     0.014230775975231418,\n",
       "     0.012816807933775548,\n",
       "     0.012816807933775548,\n",
       "     0.016294516460478803,\n",
       "     0.016277397016447506,\n",
       "     0.015462152802062609,\n",
       "     0.01877545719076591,\n",
       "     0.016277397016447506,\n",
       "     0.010686478920892058,\n",
       "     0.012809245307269365,\n",
       "     0.017775112047612417,\n",
       "     0.012853084703711787,\n",
       "     0.016311918179357184,\n",
       "     0.01543504778870963,\n",
       "     0.015522509684097841,\n",
       "     0.012809245307269365,\n",
       "     0.01977260762362176,\n",
       "     0.010686478920892058,\n",
       "     0.014230775975231418,\n",
       "     0.009403477861117207,\n",
       "     0.012816807933775548,\n",
       "     0.01878061748164243,\n",
       "     0.012816807933775548,\n",
       "     0.010686478920892058,\n",
       "     0.010686478920892058,\n",
       "     0.016277397016447506,\n",
       "     0.014230775975231418,\n",
       "     0.012816807933775548,\n",
       "     0.010699924474082741,\n",
       "     0.012816807933775548,\n",
       "     0.010686478920892058],\n",
       "    'rank_test_score': [20,\n",
       "     5,\n",
       "     5,\n",
       "     81,\n",
       "     1,\n",
       "     12,\n",
       "     101,\n",
       "     81,\n",
       "     81,\n",
       "     20,\n",
       "     5,\n",
       "     55,\n",
       "     12,\n",
       "     20,\n",
       "     81,\n",
       "     105,\n",
       "     105,\n",
       "     78,\n",
       "     101,\n",
       "     45,\n",
       "     45,\n",
       "     107,\n",
       "     55,\n",
       "     71,\n",
       "     70,\n",
       "     20,\n",
       "     81,\n",
       "     18,\n",
       "     12,\n",
       "     55,\n",
       "     41,\n",
       "     12,\n",
       "     20,\n",
       "     55,\n",
       "     55,\n",
       "     81,\n",
       "     81,\n",
       "     5,\n",
       "     45,\n",
       "     81,\n",
       "     81,\n",
       "     55,\n",
       "     55,\n",
       "     55,\n",
       "     101,\n",
       "     20,\n",
       "     38,\n",
       "     81,\n",
       "     81,\n",
       "     108,\n",
       "     45,\n",
       "     55,\n",
       "     55,\n",
       "     45,\n",
       "     5,\n",
       "     20,\n",
       "     20,\n",
       "     5,\n",
       "     55,\n",
       "     20,\n",
       "     55,\n",
       "     99,\n",
       "     81,\n",
       "     78,\n",
       "     45,\n",
       "     55,\n",
       "     55,\n",
       "     20,\n",
       "     1,\n",
       "     41,\n",
       "     81,\n",
       "     81,\n",
       "     19,\n",
       "     41,\n",
       "     45,\n",
       "     38,\n",
       "     81,\n",
       "     45,\n",
       "     71,\n",
       "     71,\n",
       "     38,\n",
       "     20,\n",
       "     1,\n",
       "     5,\n",
       "     20,\n",
       "     20,\n",
       "     12,\n",
       "     81,\n",
       "     81,\n",
       "     101,\n",
       "     4,\n",
       "     98,\n",
       "     12,\n",
       "     55,\n",
       "     20,\n",
       "     45,\n",
       "     41,\n",
       "     71,\n",
       "     78,\n",
       "     71,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     45,\n",
       "     71,\n",
       "     99,\n",
       "     71,\n",
       "     20]}}],\n",
       " 'taiwan SVM': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__C': 10},\n",
       "   'best_validation_accuracy': 0.9500891265597149,\n",
       "   'train_accuracy': 0.99,\n",
       "   'test_accuracy': 0.9375,\n",
       "   'cv_results': {'mean_fit_time': [0.0043417612711588545,\n",
       "     0.0043417612711588545,\n",
       "     0.009093046188354492,\n",
       "     0.0021076202392578125,\n",
       "     0.0036706924438476562,\n",
       "     0.011012077331542969,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.011198759078979492,\n",
       "     0.020447969436645508,\n",
       "     0.005437453587849935],\n",
       "    'std_fit_time': [0.0030700888371295505,\n",
       "     0.0030700888371295505,\n",
       "     0.002924291926505913,\n",
       "     0.0020281063503442207,\n",
       "     0.005191143037389796,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007974769633373988,\n",
       "     0.001459628021991833,\n",
       "     0.002720536396334649],\n",
       "    'mean_score_time': [0.003829479217529297,\n",
       "     0.005488077799479167,\n",
       "     0.00022451082865397135,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.005984703699747722,\n",
       "     0.010152101516723633,\n",
       "     0.0034978389739990234,\n",
       "     0.0002024968465169271],\n",
       "    'std_score_time': [0.0027795871802213314,\n",
       "     0.0007244762280032611,\n",
       "     0.00031750625878206837,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.008463649138967666,\n",
       "     0.00622941020994819,\n",
       "     0.001459628021991833,\n",
       "     0.0002863737866820213],\n",
       "    'param_classifier__C': [1e-07,\n",
       "     1e-06,\n",
       "     1e-05,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     1000.0],\n",
       "    'params': [{'classifier__C': 1e-07},\n",
       "     {'classifier__C': 1e-06},\n",
       "     {'classifier__C': 1e-05},\n",
       "     {'classifier__C': 0.0001},\n",
       "     {'classifier__C': 0.001},\n",
       "     {'classifier__C': 0.01},\n",
       "     {'classifier__C': 0.1},\n",
       "     {'classifier__C': 1},\n",
       "     {'classifier__C': 10},\n",
       "     {'classifier__C': 100},\n",
       "     {'classifier__C': 1000}],\n",
       "    'split0_test_score': [0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353],\n",
       "    'split1_test_score': [0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394],\n",
       "    'split2_test_score': [0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9090909090909091,\n",
       "     0.9090909090909091],\n",
       "    'mean_test_score': [0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9500891265597149,\n",
       "     0.9298871063576946,\n",
       "     0.9298871063576946],\n",
       "    'std_test_score': [0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.013883923286450295,\n",
       "     0.014723127383676633,\n",
       "     0.014723127383676633],\n",
       "    'rank_test_score': [2, 2, 2, 2, 2, 2, 2, 2, 1, 10, 10]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__C': 1e-07},\n",
       "   'best_validation_accuracy': 0.9360298336201951,\n",
       "   'train_accuracy': 0.936,\n",
       "   'test_accuracy': 0.94,\n",
       "   'cv_results': {'mean_fit_time': [0.004612366358439128,\n",
       "     0.006683190663655599,\n",
       "     0.006610472997029622,\n",
       "     0.0029357274373372397,\n",
       "     0.007010618845621745,\n",
       "     0.008515516916910807,\n",
       "     0.0045146942138671875,\n",
       "     0.0,\n",
       "     0.0052530765533447266,\n",
       "     0.01575922966003418,\n",
       "     0.0],\n",
       "    'std_fit_time': [0.0009588098205056203,\n",
       "     0.0004714266399769444,\n",
       "     0.0004978110785712558,\n",
       "     0.0021165364512836233,\n",
       "     0.0049572561260533415,\n",
       "     0.0028290088636472362,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007428972105924226,\n",
       "     0.0,\n",
       "     0.0],\n",
       "    'mean_score_time': [0.0033391316731770835,\n",
       "     0.00289765993754069,\n",
       "     0.00029929478963216144,\n",
       "     0.0035053094228108725,\n",
       "     0.006515105565388997,\n",
       "     0.003009796142578125,\n",
       "     0.0,\n",
       "     0.010506153106689453,\n",
       "     0.010506153106689453,\n",
       "     0.0,\n",
       "     0.0],\n",
       "    'std_score_time': [0.00047536249751825257,\n",
       "     0.0008166320775582997,\n",
       "     0.00042326675064540515,\n",
       "     0.0049572561260533415,\n",
       "     0.0028290088636472362,\n",
       "     0.002128247262406105,\n",
       "     0.0,\n",
       "     0.007428972105924226,\n",
       "     0.007428972105924226,\n",
       "     0.0,\n",
       "     0.0],\n",
       "    'param_classifier__C': [1e-07,\n",
       "     1e-06,\n",
       "     1e-05,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     1000.0],\n",
       "    'params': [{'classifier__C': 1e-07},\n",
       "     {'classifier__C': 1e-06},\n",
       "     {'classifier__C': 1e-05},\n",
       "     {'classifier__C': 0.0001},\n",
       "     {'classifier__C': 0.001},\n",
       "     {'classifier__C': 0.01},\n",
       "     {'classifier__C': 0.1},\n",
       "     {'classifier__C': 1},\n",
       "     {'classifier__C': 10},\n",
       "     {'classifier__C': 100},\n",
       "     {'classifier__C': 1000}],\n",
       "    'split0_test_score': [0.9285714285714286,\n",
       "     0.9285714285714286,\n",
       "     0.9285714285714286,\n",
       "     0.9285714285714286,\n",
       "     0.9285714285714286,\n",
       "     0.9285714285714286,\n",
       "     0.9285714285714286,\n",
       "     0.9285714285714286,\n",
       "     0.9285714285714286,\n",
       "     0.9166666666666666,\n",
       "     0.9166666666666666],\n",
       "    'split1_test_score': [0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9156626506024096,\n",
       "     0.9156626506024096,\n",
       "     0.9156626506024096],\n",
       "    'split2_test_score': [0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.927710843373494,\n",
       "     0.9156626506024096,\n",
       "     0.9156626506024096],\n",
       "    'mean_test_score': [0.9360298336201951,\n",
       "     0.9360298336201951,\n",
       "     0.9360298336201951,\n",
       "     0.9360298336201951,\n",
       "     0.9360298336201951,\n",
       "     0.9360298336201951,\n",
       "     0.9360298336201951,\n",
       "     0.9360298336201951,\n",
       "     0.9239816408491107,\n",
       "     0.9159973226238286,\n",
       "     0.9159973226238286],\n",
       "    'std_test_score': [0.005273888786818769,\n",
       "     0.005273888786818769,\n",
       "     0.005273888786818769,\n",
       "     0.005273888786818769,\n",
       "     0.005273888786818769,\n",
       "     0.005273888786818769,\n",
       "     0.005273888786818769,\n",
       "     0.005273888786818769,\n",
       "     0.005892896897353482,\n",
       "     0.0004732977116375879,\n",
       "     0.0004732977116375879],\n",
       "    'rank_test_score': [1, 1, 1, 1, 1, 1, 1, 1, 9, 10, 10]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__C': 10},\n",
       "   'best_validation_accuracy': 0.9550181423708525,\n",
       "   'train_accuracy': 0.9925,\n",
       "   'test_accuracy': 0.94,\n",
       "   'cv_results': {'mean_fit_time': [0.0008179346720377604,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.005225737889607747,\n",
       "     0.005225737889607747,\n",
       "     0.005194266637166341,\n",
       "     0.020155827204386394,\n",
       "     0.008354107538859049,\n",
       "     0.00509031613667806,\n",
       "     0.011450608571370443,\n",
       "     0.01033488909403483],\n",
       "    'std_fit_time': [0.0007640892130485108,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007390309396890233,\n",
       "     0.007390309396890233,\n",
       "     0.007345802324862728,\n",
       "     0.001025368660581274,\n",
       "     0.001364173307005019,\n",
       "     0.0019207685190424308,\n",
       "     0.0016827047817885602,\n",
       "     0.001958046062811576],\n",
       "    'mean_score_time': [0.0,\n",
       "     0.0,\n",
       "     0.015677213668823242,\n",
       "     0.010451475779215494,\n",
       "     0.005194266637166341,\n",
       "     0.013915936152140299,\n",
       "     0.004826704661051433,\n",
       "     0.0045929749806722,\n",
       "     0.0090788205464681,\n",
       "     0.005318800608317058,\n",
       "     0.00414125124613444],\n",
       "    'std_score_time': [0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007390309396890232,\n",
       "     0.007345802324862728,\n",
       "     0.006330527230658661,\n",
       "     0.0007595800989551231,\n",
       "     0.002874692357985118,\n",
       "     0.0022219918504683854,\n",
       "     0.0004572689481394358,\n",
       "     0.0008178060397482019],\n",
       "    'param_classifier__C': [1e-07,\n",
       "     1e-06,\n",
       "     1e-05,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     1000.0],\n",
       "    'params': [{'classifier__C': 1e-07},\n",
       "     {'classifier__C': 1e-06},\n",
       "     {'classifier__C': 1e-05},\n",
       "     {'classifier__C': 0.0001},\n",
       "     {'classifier__C': 0.001},\n",
       "     {'classifier__C': 0.01},\n",
       "     {'classifier__C': 0.1},\n",
       "     {'classifier__C': 1},\n",
       "     {'classifier__C': 10},\n",
       "     {'classifier__C': 100},\n",
       "     {'classifier__C': 1000}],\n",
       "    'split0_test_score': [0.9328358208955224,\n",
       "     0.9328358208955224,\n",
       "     0.9328358208955224,\n",
       "     0.9328358208955224,\n",
       "     0.9328358208955224,\n",
       "     0.9328358208955224,\n",
       "     0.9328358208955224,\n",
       "     0.9477611940298507,\n",
       "     0.9477611940298507,\n",
       "     0.9477611940298507,\n",
       "     0.9477611940298507],\n",
       "    'split1_test_score': [0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9699248120300752,\n",
       "     0.9548872180451128,\n",
       "     0.9548872180451128],\n",
       "    'split2_test_score': [0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9473684210526315,\n",
       "     0.9473684210526315,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504],\n",
       "    'mean_test_score': [0.9375116896719411,\n",
       "     0.9375116896719411,\n",
       "     0.9375116896719411,\n",
       "     0.9375116896719411,\n",
       "     0.9375116896719411,\n",
       "     0.9375116896719411,\n",
       "     0.9375116896719411,\n",
       "     0.9449930797142109,\n",
       "     0.9550181423708525,\n",
       "     0.9474993453783713,\n",
       "     0.9474993453783713],\n",
       "    'std_test_score': [0.0033063385197440666,\n",
       "     0.0033063385197440666,\n",
       "     0.0033063385197440666,\n",
       "     0.0033063385197440666,\n",
       "     0.0033063385197440666,\n",
       "     0.0033063385197440666,\n",
       "     0.0033063385197440666,\n",
       "     0.003640505432113654,\n",
       "     0.01054182678349446,\n",
       "     0.006141863547347584,\n",
       "     0.006141863547347584],\n",
       "    'rank_test_score': [5, 5, 5, 5, 5, 5, 5, 4, 1, 2, 2]}}],\n",
       " 'taiwan KNN': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__n_neighbors': 3},\n",
       "   'best_validation_accuracy': 0.9598930481283423,\n",
       "   'train_accuracy': 0.96,\n",
       "   'test_accuracy': 0.9325,\n",
       "   'cv_results': {'mean_fit_time': [0.004341284434000651,\n",
       "     0.006670157114664714,\n",
       "     0.007998069127400717,\n",
       "     0.006328741709391276,\n",
       "     0.005998373031616211],\n",
       "    'std_fit_time': [0.0012519931494606748,\n",
       "     0.0004703055444215425,\n",
       "     0.0008134255012909807,\n",
       "     0.00047227012844564464,\n",
       "     0.0008176056876945348],\n",
       "    'mean_score_time': [0.006999810536702474,\n",
       "     0.005998452504475911,\n",
       "     0.0060015519460042315,\n",
       "     0.005421638488769531,\n",
       "     0.0032581488291422525],\n",
       "    'std_score_time': [0.0021612011544928002,\n",
       "     0.0008146854212879391,\n",
       "     4.019472953924113e-06,\n",
       "     0.0008225441670072222,\n",
       "     0.0014133243200653133],\n",
       "    'param_classifier__n_neighbors': [3, 5, 7, 9, 11],\n",
       "    'params': [{'classifier__n_neighbors': 3},\n",
       "     {'classifier__n_neighbors': 5},\n",
       "     {'classifier__n_neighbors': 7},\n",
       "     {'classifier__n_neighbors': 9},\n",
       "     {'classifier__n_neighbors': 11}],\n",
       "    'split0_test_score': [0.9705882352941176,\n",
       "     0.9705882352941176,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353],\n",
       "    'split1_test_score': [0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394],\n",
       "    'split2_test_score': [0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394],\n",
       "    'mean_test_score': [0.9598930481283423,\n",
       "     0.9598930481283423,\n",
       "     0.9500891265597149,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048],\n",
       "    'std_test_score': [0.014499624886408095,\n",
       "     0.014499624886408095,\n",
       "     0.013883923286450295,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928],\n",
       "    'rank_test_score': [1, 1, 3, 4, 4]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__n_neighbors': 5},\n",
       "   'best_validation_accuracy': 0.9599827882960413,\n",
       "   'train_accuracy': 0.964,\n",
       "   'test_accuracy': 0.952,\n",
       "   'cv_results': {'mean_fit_time': [0.0,\n",
       "     0.0,\n",
       "     0.005237023035685222,\n",
       "     0.010474046071370443,\n",
       "     0.0],\n",
       "    'std_fit_time': [0.0,\n",
       "     0.0,\n",
       "     0.007406269003526356,\n",
       "     0.007406269003526357,\n",
       "     0.0],\n",
       "    'mean_score_time': [0.015711069107055664,\n",
       "     0.015711069107055664,\n",
       "     0.010474046071370443,\n",
       "     0.0,\n",
       "     0.010453065236409506],\n",
       "    'std_score_time': [0.0,\n",
       "     0.0,\n",
       "     0.007406269003526357,\n",
       "     0.0,\n",
       "     0.007391433312850523],\n",
       "    'param_classifier__n_neighbors': [3, 5, 7, 9, 11],\n",
       "    'params': [{'classifier__n_neighbors': 3},\n",
       "     {'classifier__n_neighbors': 5},\n",
       "     {'classifier__n_neighbors': 7},\n",
       "     {'classifier__n_neighbors': 9},\n",
       "     {'classifier__n_neighbors': 11}],\n",
       "    'split0_test_score': [0.9523809523809523,\n",
       "     0.9642857142857143,\n",
       "     0.9523809523809523,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905],\n",
       "    'split1_test_score': [0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783],\n",
       "    'split2_test_score': [0.963855421686747,\n",
       "     0.963855421686747,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783],\n",
       "    'mean_test_score': [0.9560145343277874,\n",
       "     0.9599827882960413,\n",
       "     0.9519984700707592,\n",
       "     0.939998087588449,\n",
       "     0.939998087588449],\n",
       "    'std_test_score': [0.00554928977951691,\n",
       "     0.005783661834095248,\n",
       "     0.0002704558352214713,\n",
       "     0.0003380697940268261,\n",
       "     0.0003380697940268261],\n",
       "    'rank_test_score': [2, 1, 3, 4, 4]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__n_neighbors': 5},\n",
       "   'best_validation_accuracy': 0.9524931732315864,\n",
       "   'train_accuracy': 0.9675,\n",
       "   'test_accuracy': 0.94,\n",
       "   'cv_results': {'mean_fit_time': [0.010427474975585938,\n",
       "     0.015641212463378906,\n",
       "     0.0,\n",
       "     0.005205551783243815,\n",
       "     0.015616655349731445],\n",
       "    'std_fit_time': [0.007373338265889846,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0073617619314988525,\n",
       "     0.0],\n",
       "    'mean_score_time': [0.005213737487792969,\n",
       "     0.0,\n",
       "     0.005205551783243815,\n",
       "     0.013085444768269857,\n",
       "     0.0026743412017822266],\n",
       "    'std_score_time': [0.007373338265889846,\n",
       "     0.0,\n",
       "     0.0073617619314988525,\n",
       "     0.0035796723335252663,\n",
       "     0.0037820895979735866],\n",
       "    'param_classifier__n_neighbors': [3, 5, 7, 9, 11],\n",
       "    'params': [{'classifier__n_neighbors': 3},\n",
       "     {'classifier__n_neighbors': 5},\n",
       "     {'classifier__n_neighbors': 7},\n",
       "     {'classifier__n_neighbors': 9},\n",
       "     {'classifier__n_neighbors': 11}],\n",
       "    'split0_test_score': [0.9626865671641791,\n",
       "     0.9552238805970149,\n",
       "     0.9477611940298507,\n",
       "     0.9552238805970149,\n",
       "     0.9477611940298507],\n",
       "    'split1_test_score': [0.9398496240601504,\n",
       "     0.9548872180451128,\n",
       "     0.9473684210526315,\n",
       "     0.9473684210526315,\n",
       "     0.9398496240601504],\n",
       "    'split2_test_score': [0.9323308270676691,\n",
       "     0.9473684210526315,\n",
       "     0.9473684210526315,\n",
       "     0.9473684210526315,\n",
       "     0.9473684210526315],\n",
       "    'mean_test_score': [0.9449556727639995,\n",
       "     0.9524931732315864,\n",
       "     0.9474993453783712,\n",
       "     0.949986907567426,\n",
       "     0.9449930797142109],\n",
       "    'std_test_score': [0.012907918479917041,\n",
       "     0.0036263525375819345,\n",
       "     0.00018515495710567443,\n",
       "     0.0037030991421133836,\n",
       "     0.003640505432113654],\n",
       "    'rank_test_score': [5, 1, 3, 2, 4]}}],\n",
       " 'taiwan log_reg': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__C': 0.1,\n",
       "    'classifier__max_iter': 500,\n",
       "    'classifier__penalty': 'l2'},\n",
       "   'best_validation_accuracy': 0.9500891265597149,\n",
       "   'train_accuracy': 0.96,\n",
       "   'test_accuracy': 0.9425,\n",
       "   'cv_results': {'mean_fit_time': [0.0,\n",
       "     0.017263412475585938,\n",
       "     0.019659042358398438,\n",
       "     0.016276121139526367,\n",
       "     0.00899052619934082,\n",
       "     0.018977562586466473,\n",
       "     0.017314672470092773,\n",
       "     0.010744412740071615,\n",
       "     0.01236271858215332,\n",
       "     0.009185711542765299,\n",
       "     0.010488351186116537,\n",
       "     0.007462501525878906,\n",
       "     0.010924736658732096,\n",
       "     0.010580857594807943,\n",
       "     0.00775297482808431,\n",
       "     0.011474370956420898],\n",
       "    'std_fit_time': [0.0,\n",
       "     0.0012465596031264758,\n",
       "     0.0008228658654932995,\n",
       "     0.007911353427177654,\n",
       "     0.010563522377582327,\n",
       "     0.0010819746725340817,\n",
       "     0.005854365845557224,\n",
       "     0.001112913995465698,\n",
       "     0.003371902235956402,\n",
       "     0.0015388068065575273,\n",
       "     0.0009640467816636544,\n",
       "     0.005277031913708882,\n",
       "     0.002944495747543616,\n",
       "     0.005447073197760302,\n",
       "     0.0054974382338217175,\n",
       "     0.006488400450045577],\n",
       "    'mean_score_time': [0.0052089691162109375,\n",
       "     0.004452069600423177,\n",
       "     0.0038846333821614585,\n",
       "     0.001325686772664388,\n",
       "     0.006176074345906575,\n",
       "     0.003960927327473958,\n",
       "     0.005670070648193359,\n",
       "     0.0038909117380777993,\n",
       "     0.00508570671081543,\n",
       "     0.005252440770467122,\n",
       "     0.0039980411529541016,\n",
       "     0.010593493779500326,\n",
       "     0.006792306900024414,\n",
       "     0.007564465204874675,\n",
       "     0.010095755259195963,\n",
       "     0.0020089149475097656],\n",
       "    'std_score_time': [0.0073665947701281025,\n",
       "     0.0005090705600333948,\n",
       "     0.000522885675661796,\n",
       "     0.0013353723707315213,\n",
       "     0.008734288102205622,\n",
       "     0.0010720085236939345,\n",
       "     0.0005709720622474843,\n",
       "     0.00014140042038961163,\n",
       "     0.003609027649108603,\n",
       "     0.0038245842893600487,\n",
       "     0.0032656530089232023,\n",
       "     0.007627493319288087,\n",
       "     0.004907554569989758,\n",
       "     0.004313544110706588,\n",
       "     0.0057382613875606,\n",
       "     0.0014205173822111725],\n",
       "    'param_classifier__C': [0.0001,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     100.0,\n",
       "     1000.0,\n",
       "     1000.0],\n",
       "    'param_classifier__max_iter': [500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000],\n",
       "    'param_classifier__penalty': ['l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2'],\n",
       "    'params': [{'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'}],\n",
       "    'split0_test_score': [0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9117647058823529,\n",
       "     0.9117647058823529,\n",
       "     0.8823529411764706,\n",
       "     0.8823529411764706,\n",
       "     0.8823529411764706,\n",
       "     0.8823529411764706],\n",
       "    'split1_test_score': [0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.8787878787878788,\n",
       "     0.8787878787878788,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8787878787878788,\n",
       "     0.8787878787878788],\n",
       "    'split2_test_score': [0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394,\n",
       "     0.9393939393939394],\n",
       "    'mean_test_score': [0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9500891265597149,\n",
       "     0.9500891265597149,\n",
       "     0.9399881164587048,\n",
       "     0.9399881164587048,\n",
       "     0.9099821746880571,\n",
       "     0.9099821746880571,\n",
       "     0.8900772430184195,\n",
       "     0.8900772430184195,\n",
       "     0.9001782531194297,\n",
       "     0.9001782531194297],\n",
       "    'std_test_score': [0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.013883923286450295,\n",
       "     0.013883923286450295,\n",
       "     0.0008402932634420928,\n",
       "     0.0008402932634420928,\n",
       "     0.02477440491906049,\n",
       "     0.02477440491906049,\n",
       "     0.037513236167949146,\n",
       "     0.037513236167949146,\n",
       "     0.02776784657290062,\n",
       "     0.02776784657290062],\n",
       "    'rank_test_score': [3,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     1,\n",
       "     1,\n",
       "     3,\n",
       "     3,\n",
       "     11,\n",
       "     11,\n",
       "     15,\n",
       "     15,\n",
       "     13,\n",
       "     13]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__C': 1,\n",
       "    'classifier__max_iter': 500,\n",
       "    'classifier__penalty': 'l2'},\n",
       "   'best_validation_accuracy': 0.9599827882960413,\n",
       "   'train_accuracy': 0.972,\n",
       "   'test_accuracy': 0.968,\n",
       "   'cv_results': {'mean_fit_time': [0.006512165069580078,\n",
       "     0.006547292073567708,\n",
       "     0.005014181137084961,\n",
       "     0.009158134460449219,\n",
       "     0.0030956268310546875,\n",
       "     0.0,\n",
       "     0.015015363693237305,\n",
       "     0.015015363693237305,\n",
       "     0.010221242904663086,\n",
       "     0.0,\n",
       "     0.0156401793162028,\n",
       "     0.015631993611653645,\n",
       "     0.020847797393798828,\n",
       "     0.015631675720214844,\n",
       "     0.010432243347167969,\n",
       "     0.01562349001566569],\n",
       "    'std_fit_time': [0.0006965248797626138,\n",
       "     0.0015595095196194184,\n",
       "     0.0037708737567659894,\n",
       "     0.003712791601516649,\n",
       "     0.0021889387242617925,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007232128665764225,\n",
       "     0.0,\n",
       "     1.1576334390992227e-05,\n",
       "     1.1576334390992227e-05,\n",
       "     0.007353107778604617,\n",
       "     1.1807538213331139e-05,\n",
       "     0.007376710013770717,\n",
       "     4.49566384116203e-07],\n",
       "    'mean_score_time': [0.0032334327697753906,\n",
       "     0.0013967355092366536,\n",
       "     0.0030312538146972656,\n",
       "     0.0015478134155273438,\n",
       "     0.0,\n",
       "     0.0050051212310791016,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.005216121673583984,\n",
       "     0.015631993611653645,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.01041555404663086,\n",
       "     0.01041555404663086,\n",
       "     0.005207618077596028],\n",
       "    'std_score_time': [0.0008732427556513847,\n",
       "     0.0009937143052744068,\n",
       "     0.004286840255740053,\n",
       "     0.0021889387242617925,\n",
       "     0.0,\n",
       "     0.007078310326313587,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007376710013770717,\n",
       "     1.1576334390992227e-05,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007364908906478524,\n",
       "     0.007364908906478524,\n",
       "     0.007364684112995609],\n",
       "    'param_classifier__C': [0.0001,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     100.0,\n",
       "     1000.0,\n",
       "     1000.0],\n",
       "    'param_classifier__max_iter': [500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000],\n",
       "    'param_classifier__penalty': ['l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2'],\n",
       "    'params': [{'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'}],\n",
       "    'split0_test_score': [0.9285714285714286,\n",
       "     0.9285714285714286,\n",
       "     0.9285714285714286,\n",
       "     0.9285714285714286,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9642857142857143,\n",
       "     0.9642857142857143,\n",
       "     0.9642857142857143,\n",
       "     0.9642857142857143,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9166666666666666,\n",
       "     0.9166666666666666,\n",
       "     0.9285714285714286,\n",
       "     0.9285714285714286],\n",
       "    'split1_test_score': [0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.963855421686747,\n",
       "     0.963855421686747,\n",
       "     0.963855421686747,\n",
       "     0.963855421686747,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783],\n",
       "    'split2_test_score': [0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.927710843373494,\n",
       "     0.927710843373494,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783],\n",
       "    'mean_test_score': [0.9360298336201951,\n",
       "     0.9360298336201951,\n",
       "     0.9360298336201951,\n",
       "     0.9360298336201951,\n",
       "     0.939998087588449,\n",
       "     0.939998087588449,\n",
       "     0.9559667240390132,\n",
       "     0.9559667240390132,\n",
       "     0.9599827882960413,\n",
       "     0.9599827882960413,\n",
       "     0.9480302161025053,\n",
       "     0.9480302161025053,\n",
       "     0.9360776439089692,\n",
       "     0.9360776439089692,\n",
       "     0.9360298336201951,\n",
       "     0.9360298336201951],\n",
       "    'std_test_score': [0.005273888786818769,\n",
       "     0.005273888786818769,\n",
       "     0.005273888786818769,\n",
       "     0.005273888786818769,\n",
       "     0.009843115557845781,\n",
       "     0.009843115557845781,\n",
       "     0.005882414416067119,\n",
       "     0.005882414416067119,\n",
       "     0.005783661834095248,\n",
       "     0.005783661834095248,\n",
       "     0.011193939622893391,\n",
       "     0.011193939622893391,\n",
       "     0.014580335281654599,\n",
       "     0.014580335281654599,\n",
       "     0.005273888786818769,\n",
       "     0.005273888786818769],\n",
       "    'rank_test_score': [11,\n",
       "     11,\n",
       "     11,\n",
       "     11,\n",
       "     7,\n",
       "     7,\n",
       "     3,\n",
       "     3,\n",
       "     1,\n",
       "     1,\n",
       "     5,\n",
       "     5,\n",
       "     9,\n",
       "     9,\n",
       "     11,\n",
       "     11]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__C': 1,\n",
       "    'classifier__max_iter': 500,\n",
       "    'classifier__penalty': 'l2'},\n",
       "   'best_validation_accuracy': 0.9650057980772827,\n",
       "   'train_accuracy': 0.9725,\n",
       "   'test_accuracy': 0.95,\n",
       "   'cv_results': {'mean_fit_time': [0.009905576705932617,\n",
       "     0.007067680358886719,\n",
       "     0.011296510696411133,\n",
       "     0.004169940948486328,\n",
       "     0.003901878992716471,\n",
       "     0.005214373270670573,\n",
       "     0.01564311981201172,\n",
       "     0.005214373270670573,\n",
       "     0.0,\n",
       "     0.010416189829508463,\n",
       "     0.015624205271402994,\n",
       "     0.011086463928222656,\n",
       "     0.02843014399210612,\n",
       "     0.020403703053792317,\n",
       "     0.02002994219462077,\n",
       "     0.015079418818155924],\n",
       "    'std_fit_time': [0.0040147402017537215,\n",
       "     0.0052795947521257465,\n",
       "     0.001965729014548098,\n",
       "     0.0,\n",
       "     0.005518090190238305,\n",
       "     0.0073742373986580775,\n",
       "     0.0,\n",
       "     0.0073742373986580775,\n",
       "     0.0,\n",
       "     0.00736535846514434,\n",
       "     2.247831920581015e-07,\n",
       "     0.007882199053341258,\n",
       "     0.003985855561574256,\n",
       "     0.003379390509401498,\n",
       "     0.00623020334267837,\n",
       "     0.004601866381010826],\n",
       "    'mean_score_time': [0.007067680358886719,\n",
       "     0.004228830337524414,\n",
       "     0.0013899803161621094,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.010428746541341146,\n",
       "     0.0,\n",
       "     0.005208015441894531,\n",
       "     0.015624205271402994,\n",
       "     0.005208174387613933,\n",
       "     0.005208174387613933,\n",
       "     0.007396697998046875,\n",
       "     0.002015829086303711,\n",
       "     0.002015829086303711,\n",
       "     0.008266448974609375,\n",
       "     0.00787210464477539],\n",
       "    'std_score_time': [0.002049011187205624,\n",
       "     0.003477116354934614,\n",
       "     0.001965729014548098,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0073742373986580775,\n",
       "     0.0,\n",
       "     0.007365246070975754,\n",
       "     2.247831920581015e-07,\n",
       "     0.007365470854167811,\n",
       "     0.007365470854167812,\n",
       "     0.007474795869081128,\n",
       "     0.0028508128332768723,\n",
       "     0.0028508128332768723,\n",
       "     0.006411023182298305,\n",
       "     0.008484318472929471],\n",
       "    'param_classifier__C': [0.0001,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     100.0,\n",
       "     1000.0,\n",
       "     1000.0],\n",
       "    'param_classifier__max_iter': [500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000],\n",
       "    'param_classifier__penalty': ['l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2'],\n",
       "    'params': [{'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'}],\n",
       "    'split0_test_score': [0.9328358208955224,\n",
       "     0.9328358208955224,\n",
       "     0.9328358208955224,\n",
       "     0.9328358208955224,\n",
       "     0.9402985074626866,\n",
       "     0.9402985074626866,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9626865671641791,\n",
       "     0.9626865671641791,\n",
       "     0.9552238805970149,\n",
       "     0.9552238805970149,\n",
       "     0.9552238805970149,\n",
       "     0.9552238805970149,\n",
       "     0.9552238805970149,\n",
       "     0.9552238805970149],\n",
       "    'split1_test_score': [0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9624060150375939,\n",
       "     0.9624060150375939,\n",
       "     0.9774436090225563,\n",
       "     0.9774436090225563,\n",
       "     0.9624060150375939,\n",
       "     0.9624060150375939,\n",
       "     0.9624060150375939,\n",
       "     0.9624060150375939,\n",
       "     0.9624060150375939,\n",
       "     0.9624060150375939],\n",
       "    'split2_test_score': [0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9398496240601504,\n",
       "     0.9548872180451128,\n",
       "     0.9548872180451128,\n",
       "     0.9624060150375939,\n",
       "     0.9624060150375939,\n",
       "     0.9548872180451128,\n",
       "     0.9548872180451128,\n",
       "     0.9548872180451128,\n",
       "     0.9548872180451128],\n",
       "    'mean_test_score': [0.9375116896719411,\n",
       "     0.9375116896719411,\n",
       "     0.9375116896719411,\n",
       "     0.9375116896719411,\n",
       "     0.9399992518609958,\n",
       "     0.9399992518609958,\n",
       "     0.9574682976096959,\n",
       "     0.9574682976096959,\n",
       "     0.9650057980772827,\n",
       "     0.9650057980772827,\n",
       "     0.9600119702240676,\n",
       "     0.9600119702240676,\n",
       "     0.9575057045599072,\n",
       "     0.9575057045599072,\n",
       "     0.9575057045599072,\n",
       "     0.9575057045599072],\n",
       "    'std_test_score': [0.0033063385197440666,\n",
       "     0.0033063385197440666,\n",
       "     0.0033063385197440666,\n",
       "     0.0033063385197440666,\n",
       "     0.00021160566526364286,\n",
       "     0.00021160566526364286,\n",
       "     0.012853084703711787,\n",
       "     0.012853084703711787,\n",
       "     0.009353495514264383,\n",
       "     0.009353495514264383,\n",
       "     0.0033856906442179193,\n",
       "     0.0033856906442179193,\n",
       "     0.0034677675337079165,\n",
       "     0.0034677675337079165,\n",
       "     0.0034677675337079165,\n",
       "     0.0034677675337079165],\n",
       "    'rank_test_score': [13,\n",
       "     13,\n",
       "     13,\n",
       "     13,\n",
       "     11,\n",
       "     11,\n",
       "     9,\n",
       "     9,\n",
       "     1,\n",
       "     1,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     5]}}],\n",
       " 'taiwan decision_tree': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__criterion': 'entropy',\n",
       "    'classifier__max_depth': None,\n",
       "    'classifier__min_samples_split': 5},\n",
       "   'best_validation_accuracy': 0.9595959595959597,\n",
       "   'train_accuracy': 1.0,\n",
       "   'test_accuracy': 0.9425,\n",
       "   'cv_results': {'mean_fit_time': [0.005321820576985677,\n",
       "     0.006336371103922526,\n",
       "     0.006999413172403972,\n",
       "     0.0073320865631103516,\n",
       "     0.004314343134562175,\n",
       "     0.00641934076944987,\n",
       "     0.003641843795776367,\n",
       "     0.0,\n",
       "     0.006953239440917969,\n",
       "     0.0020258426666259766,\n",
       "     0.006842454274495442,\n",
       "     0.010464827219645182,\n",
       "     0.01112826665242513,\n",
       "     0.007208506266276042,\n",
       "     0.0064004262288411455,\n",
       "     0.008417526880900065,\n",
       "     0.011617739995320639,\n",
       "     0.010434627532958984,\n",
       "     0.0,\n",
       "     0.005217313766479492,\n",
       "     0.015641450881958008,\n",
       "     0.010413646697998047,\n",
       "     0.0052068233489990234,\n",
       "     0.0052068233489990234],\n",
       "    'std_fit_time': [0.0012614326695603926,\n",
       "     0.00047243856521167216,\n",
       "     1.3810910540408108e-06,\n",
       "     0.0004713705145349331,\n",
       "     0.0005072351519315185,\n",
       "     0.0005621068568111046,\n",
       "     0.0008129340079997833,\n",
       "     0.0,\n",
       "     0.009833365519773709,\n",
       "     0.0016394991193862522,\n",
       "     0.007645537514626177,\n",
       "     0.00629662677593154,\n",
       "     0.00688420483250929,\n",
       "     0.0016914935202372138,\n",
       "     0.004525784788897816,\n",
       "     0.0064444101325212355,\n",
       "     0.0028526110988133374,\n",
       "     0.007378395887711153,\n",
       "     0.0,\n",
       "     0.007378395887711153,\n",
       "     1.4835690675834699e-05,\n",
       "     0.0073635601970353185,\n",
       "     0.0073635601970353185,\n",
       "     0.0073635601970353185],\n",
       "    'mean_score_time': [0.0026673475901285806,\n",
       "     0.004000504811604817,\n",
       "     0.003999233245849609,\n",
       "     0.0037016073862711587,\n",
       "     0.002987384796142578,\n",
       "     0.0002151330312093099,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.006061236063639323,\n",
       "     0.010497411092122396,\n",
       "     0.009514649709065756,\n",
       "     0.0007199446360270182,\n",
       "     0.003423452377319336,\n",
       "     0.0032002131144205728,\n",
       "     0.0,\n",
       "     0.005217313766479492,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.010434627532958984,\n",
       "     0.010413646697998047,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0052068233489990234,\n",
       "     0.0],\n",
       "    'std_score_time': [0.0004706406236293867,\n",
       "     1.9106571324938627e-06,\n",
       "     1.520405329840103e-06,\n",
       "     0.0004652452663028824,\n",
       "     1.2879017673558717e-05,\n",
       "     0.00030424405045064037,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.008102934321757018,\n",
       "     0.00634270733030345,\n",
       "     0.0064169611978547375,\n",
       "     0.0010181554684271707,\n",
       "     0.00437647952798292,\n",
       "     0.004525784788897816,\n",
       "     0.0,\n",
       "     0.007378395887711153,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007378395887711153,\n",
       "     0.0073635601970353185,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0073635601970353185,\n",
       "     0.0],\n",
       "    'param_classifier__criterion': ['gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy'],\n",
       "    'param_classifier__max_depth': [3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10],\n",
       "    'params': [{'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10}],\n",
       "    'split0_test_score': [0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9117647058823529,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9117647058823529,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     1.0,\n",
       "     0.9411764705882353,\n",
       "     0.9411764705882353,\n",
       "     1.0,\n",
       "     0.9411764705882353,\n",
       "     0.9705882352941176,\n",
       "     0.9117647058823529,\n",
       "     0.9705882352941176,\n",
       "     1.0,\n",
       "     1.0],\n",
       "    'split1_test_score': [0.8787878787878788,\n",
       "     0.9090909090909091,\n",
       "     0.8787878787878788,\n",
       "     0.9090909090909091,\n",
       "     0.9090909090909091,\n",
       "     0.8787878787878788,\n",
       "     0.9090909090909091,\n",
       "     0.9090909090909091,\n",
       "     0.8787878787878788,\n",
       "     0.8787878787878788,\n",
       "     0.9090909090909091,\n",
       "     0.8787878787878788,\n",
       "     0.8787878787878788,\n",
       "     0.9090909090909091,\n",
       "     0.8787878787878788,\n",
       "     0.9090909090909091,\n",
       "     0.9090909090909091,\n",
       "     0.8787878787878788,\n",
       "     0.8787878787878788,\n",
       "     0.9090909090909091,\n",
       "     0.8787878787878788,\n",
       "     0.9090909090909091,\n",
       "     0.9090909090909091,\n",
       "     0.8787878787878788],\n",
       "    'split2_test_score': [0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697,\n",
       "     0.9696969696969697],\n",
       "    'mean_test_score': [0.9298871063576946,\n",
       "     0.9399881164587046,\n",
       "     0.9298871063576946,\n",
       "     0.9301841948900772,\n",
       "     0.9399881164587046,\n",
       "     0.9298871063576946,\n",
       "     0.9399881164587046,\n",
       "     0.9399881164587046,\n",
       "     0.9298871063576946,\n",
       "     0.9200831847890671,\n",
       "     0.9399881164587046,\n",
       "     0.9298871063576946,\n",
       "     0.9298871063576946,\n",
       "     0.9399881164587046,\n",
       "     0.9494949494949495,\n",
       "     0.9399881164587046,\n",
       "     0.9399881164587046,\n",
       "     0.9494949494949495,\n",
       "     0.9298871063576946,\n",
       "     0.9497920380273323,\n",
       "     0.9200831847890671,\n",
       "     0.9497920380273323,\n",
       "     0.9595959595959597,\n",
       "     0.9494949494949495],\n",
       "    'std_test_score': [0.03796228840157645,\n",
       "     0.024756585449791656,\n",
       "     0.03796228840157645,\n",
       "     0.02796106611016626,\n",
       "     0.024756585449791656,\n",
       "     0.03796228840157645,\n",
       "     0.024756585449791656,\n",
       "     0.024756585449791656,\n",
       "     0.03796228840157645,\n",
       "     0.03757670839736079,\n",
       "     0.024756585449791656,\n",
       "     0.03796228840157645,\n",
       "     0.03796228840157645,\n",
       "     0.024756585449791656,\n",
       "     0.05150524761204834,\n",
       "     0.024756585449791656,\n",
       "     0.024756585449791656,\n",
       "     0.05150524761204834,\n",
       "     0.03796228840157645,\n",
       "     0.028782344253791736,\n",
       "     0.03757670839736079,\n",
       "     0.028782344253791736,\n",
       "     0.03779451905832266,\n",
       "     0.05150524761204834],\n",
       "    'rank_test_score': [16,\n",
       "     7,\n",
       "     16,\n",
       "     15,\n",
       "     7,\n",
       "     16,\n",
       "     7,\n",
       "     7,\n",
       "     16,\n",
       "     23,\n",
       "     7,\n",
       "     16,\n",
       "     16,\n",
       "     7,\n",
       "     4,\n",
       "     7,\n",
       "     7,\n",
       "     4,\n",
       "     16,\n",
       "     2,\n",
       "     23,\n",
       "     2,\n",
       "     1,\n",
       "     4]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__criterion': 'entropy',\n",
       "    'classifier__max_depth': 10,\n",
       "    'classifier__min_samples_split': 5},\n",
       "   'best_validation_accuracy': 0.9680149168100977,\n",
       "   'train_accuracy': 1.0,\n",
       "   'test_accuracy': 0.952,\n",
       "   'cv_results': {'mean_fit_time': [0.0,\n",
       "     0.010416825612386068,\n",
       "     0.0156252384185791,\n",
       "     0.0156252384185791,\n",
       "     0.004102865854899089,\n",
       "     0.00844264030456543,\n",
       "     0.0046910444895426435,\n",
       "     0.001149892807006836,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.010420799255371094,\n",
       "     0.01042016347249349,\n",
       "     0.01619402567545573,\n",
       "     0.014603535334269205,\n",
       "     0.010642608006795248,\n",
       "     0.010091702143351236,\n",
       "     0.007287740707397461,\n",
       "     0.00841379165649414,\n",
       "     0.008140484491984049,\n",
       "     0.00885311762491862,\n",
       "     0.008899688720703125,\n",
       "     0.008350054423014322,\n",
       "     0.009078582127888998,\n",
       "     0.007294257481892903],\n",
       "    'std_fit_time': [0.0,\n",
       "     0.0073658080289559,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.002930343241550164,\n",
       "     0.0006170298621994886,\n",
       "     0.001079093170796784,\n",
       "     0.0009136490503640584,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007368617818856626,\n",
       "     0.007368168293617729,\n",
       "     0.0007959572830777374,\n",
       "     0.010361971784126357,\n",
       "     0.008518519606435552,\n",
       "     0.005115302043749987,\n",
       "     0.001186482115978017,\n",
       "     0.0008213733781969018,\n",
       "     0.0004366506513484834,\n",
       "     0.00040156023082581346,\n",
       "     0.00041144171730222946,\n",
       "     0.0006207548813015116,\n",
       "     0.00039404883057557845,\n",
       "     0.0015684769590420728],\n",
       "    'mean_score_time': [0.010416825612386068,\n",
       "     0.005208412806193034,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.002852360407511393,\n",
       "     0.0007450580596923828,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.015630563100179035,\n",
       "     0.01042016347249349,\n",
       "     0.005773226420084636,\n",
       "     0.006336688995361328,\n",
       "     0.002245346705118815,\n",
       "     0.0014336109161376953,\n",
       "     0.008163928985595703,\n",
       "     0.0041964054107666016,\n",
       "     0.004621028900146484,\n",
       "     0.005113124847412109,\n",
       "     0.004222790400187175,\n",
       "     0.004841248194376628,\n",
       "     0.004343668619791667,\n",
       "     0.0034519036610921225,\n",
       "     0.0036689440409342446,\n",
       "     0.0035091241200764975],\n",
       "    'std_score_time': [0.0073658080289559,\n",
       "     0.007365808028955899,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.002077976079927445,\n",
       "     0.001053671212772351,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     8.99132768232406e-07,\n",
       "     0.007368168293617729,\n",
       "     0.008164575101934362,\n",
       "     0.0077967475712612845,\n",
       "     0.003175399762608771,\n",
       "     0.0013290813574949956,\n",
       "     0.006481637391442417,\n",
       "     0.0016691615420969855,\n",
       "     0.0016354337103996275,\n",
       "     0.0006846923611359902,\n",
       "     0.0001580790495065151,\n",
       "     0.00023380458796210893,\n",
       "     0.0006751094023250945,\n",
       "     0.0006311515868200768,\n",
       "     0.0004669308958475579,\n",
       "     0.0010912191045612855],\n",
       "    'param_classifier__criterion': ['gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy'],\n",
       "    'param_classifier__max_depth': [3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10],\n",
       "    'params': [{'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10}],\n",
       "    'split0_test_score': [0.9642857142857143,\n",
       "     0.9523809523809523,\n",
       "     0.9642857142857143,\n",
       "     0.9642857142857143,\n",
       "     0.9404761904761905,\n",
       "     0.9642857142857143,\n",
       "     0.9285714285714286,\n",
       "     0.9404761904761905,\n",
       "     0.9761904761904762,\n",
       "     0.9404761904761905,\n",
       "     0.9642857142857143,\n",
       "     0.9761904761904762,\n",
       "     0.9166666666666666,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9166666666666666,\n",
       "     0.9404761904761905,\n",
       "     0.9404761904761905,\n",
       "     0.9166666666666666,\n",
       "     0.9642857142857143,\n",
       "     0.9523809523809523,\n",
       "     0.9404761904761905,\n",
       "     0.9642857142857143,\n",
       "     0.9285714285714286],\n",
       "    'split1_test_score': [0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.963855421686747,\n",
       "     0.963855421686747,\n",
       "     0.9759036144578314,\n",
       "     0.963855421686747,\n",
       "     0.9759036144578314,\n",
       "     0.963855421686747,\n",
       "     0.9397590361445783,\n",
       "     0.963855421686747,\n",
       "     0.963855421686747,\n",
       "     0.9759036144578314,\n",
       "     0.9759036144578314,\n",
       "     0.9759036144578314,\n",
       "     0.963855421686747,\n",
       "     0.9759036144578314,\n",
       "     0.9759036144578314,\n",
       "     0.963855421686747,\n",
       "     0.9759036144578314,\n",
       "     0.9759036144578314,\n",
       "     0.963855421686747,\n",
       "     0.9759036144578314,\n",
       "     0.9759036144578314],\n",
       "    'split2_test_score': [0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.963855421686747,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.963855421686747,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9518072289156626,\n",
       "     0.9397590361445783],\n",
       "    'mean_test_score': [0.9519506597819851,\n",
       "     0.9479824058137312,\n",
       "     0.947934595524957,\n",
       "     0.9559667240390133,\n",
       "     0.9480302161025053,\n",
       "     0.9599827882960413,\n",
       "     0.9440619621342513,\n",
       "     0.9520462803595334,\n",
       "     0.9599349780072672,\n",
       "     0.939998087588449,\n",
       "     0.9559667240390133,\n",
       "     0.9599349780072672,\n",
       "     0.9481258366800535,\n",
       "     0.9600784088735895,\n",
       "     0.9560623446165614,\n",
       "     0.9400937081659974,\n",
       "     0.9560623446165614,\n",
       "     0.9560623446165614,\n",
       "     0.9441097724230253,\n",
       "     0.9680149168100977,\n",
       "     0.9600305985848153,\n",
       "     0.9520462803595334,\n",
       "     0.9639988525530695,\n",
       "     0.9480780263912795],\n",
       "    'std_test_score': [0.010013488052614488,\n",
       "     0.005819515798318166,\n",
       "     0.011561986955718067,\n",
       "     0.011461912234083207,\n",
       "     0.011193939622893391,\n",
       "     0.015066386746997932,\n",
       "     0.014722464050896531,\n",
       "     0.016872223135323054,\n",
       "     0.015129218198295241,\n",
       "     0.0003380697940268261,\n",
       "     0.011461912234083207,\n",
       "     0.015129218198295241,\n",
       "     0.02432308207577864,\n",
       "     0.01470770686492408,\n",
       "     0.014772837680796992,\n",
       "     0.019266182014222574,\n",
       "     0.014772837680796992,\n",
       "     0.014772837680796992,\n",
       "     0.02001887072120239,\n",
       "     0.00558091694157882,\n",
       "     0.011226360773715222,\n",
       "     0.009546027871800134,\n",
       "     0.00983939924620915,\n",
       "     0.020198814391605216],\n",
       "    'rank_test_score': [15,\n",
       "     19,\n",
       "     20,\n",
       "     11,\n",
       "     18,\n",
       "     5,\n",
       "     22,\n",
       "     13,\n",
       "     6,\n",
       "     24,\n",
       "     11,\n",
       "     6,\n",
       "     16,\n",
       "     3,\n",
       "     8,\n",
       "     23,\n",
       "     8,\n",
       "     8,\n",
       "     21,\n",
       "     1,\n",
       "     4,\n",
       "     13,\n",
       "     2,\n",
       "     17]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__criterion': 'entropy',\n",
       "    'classifier__max_depth': 5,\n",
       "    'classifier__min_samples_split': 2},\n",
       "   'best_validation_accuracy': 0.9674559533161261,\n",
       "   'train_accuracy': 0.9975,\n",
       "   'test_accuracy': 0.92,\n",
       "   'cv_results': {'mean_fit_time': [0.015628576278686523,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.005209287007649739,\n",
       "     0.005209287007649739,\n",
       "     0.015946388244628906,\n",
       "     0.015946388244628906,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.005213181177775065,\n",
       "     0.015772024790445965,\n",
       "     0.01590450604756673,\n",
       "     0.010558843612670898,\n",
       "     0.00033736228942871094,\n",
       "     0.0,\n",
       "     0.006626288096110026,\n",
       "     0.008528550465901693,\n",
       "     0.007432222366333008,\n",
       "     0.014959096908569336,\n",
       "     0.0034308433532714844,\n",
       "     0.01186664899190267,\n",
       "     0.013736963272094727,\n",
       "     0.005249977111816406,\n",
       "     0.0052119096120198565],\n",
       "    'std_fit_time': [0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007367044336512219,\n",
       "     0.007367044336512219,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0073725515247176415,\n",
       "     0.0001873567905804276,\n",
       "     0.0001873567905804276,\n",
       "     0.007467992778762775,\n",
       "     0.00047710232514332044,\n",
       "     0.0,\n",
       "     0.004685493246855097,\n",
       "     0.0064649818027589295,\n",
       "     0.008016319222330894,\n",
       "     0.009815373049508042,\n",
       "     0.0048519452005741205,\n",
       "     0.002665369702149663,\n",
       "     0.0026852600123260803,\n",
       "     0.007343983465437614,\n",
       "     0.007370753259181177],\n",
       "    'mean_score_time': [0.0,\n",
       "     0.0,\n",
       "     0.010418574015299479,\n",
       "     0.010418574015299479,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.005213181177775065,\n",
       "     0.015772024790445965,\n",
       "     0.010691324869791666,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.005345662434895833,\n",
       "     0.017045338948567707,\n",
       "     0.0058498382568359375,\n",
       "     0.010472456614176432,\n",
       "     0.007280190785725911,\n",
       "     0.0037037531534830728,\n",
       "     0.011278072992960611,\n",
       "     0.0003090699513753255,\n",
       "     0.0,\n",
       "     0.0052119096120198565,\n",
       "     0.0],\n",
       "    'std_score_time': [0.0,\n",
       "     0.0,\n",
       "     0.007367044336512219,\n",
       "     0.007367044336512219,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0073725515247176415,\n",
       "     0.0001873567905804276,\n",
       "     0.00755990831529807,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.00755990831529807,\n",
       "     0.0007130122852082979,\n",
       "     0.008272920600506368,\n",
       "     0.0077629940714386714,\n",
       "     0.006428389267580733,\n",
       "     0.003011592190241231,\n",
       "     0.0061626559934649106,\n",
       "     0.0004370909169569784,\n",
       "     0.0,\n",
       "     0.007370753259181177,\n",
       "     0.0],\n",
       "    'param_classifier__criterion': ['gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy'],\n",
       "    'param_classifier__max_depth': [3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10],\n",
       "    'params': [{'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10}],\n",
       "    'split0_test_score': [0.9776119402985075,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9626865671641791,\n",
       "     0.9626865671641791,\n",
       "     0.9701492537313433,\n",
       "     0.9776119402985075,\n",
       "     0.9701492537313433,\n",
       "     0.9701492537313433,\n",
       "     0.9776119402985075,\n",
       "     0.9626865671641791,\n",
       "     0.9626865671641791,\n",
       "     0.9626865671641791,\n",
       "     0.9626865671641791,\n",
       "     0.9850746268656716,\n",
       "     0.9850746268656716,\n",
       "     0.9850746268656716,\n",
       "     0.9850746268656716,\n",
       "     0.9776119402985075,\n",
       "     0.9850746268656716,\n",
       "     0.9776119402985075,\n",
       "     0.9701492537313433,\n",
       "     0.9776119402985075],\n",
       "    'split1_test_score': [0.9624060150375939,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9548872180451128,\n",
       "     0.9548872180451128,\n",
       "     0.9548872180451128,\n",
       "     0.9548872180451128,\n",
       "     0.9473684210526315,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9548872180451128,\n",
       "     0.9699248120300752,\n",
       "     0.9774436090225563,\n",
       "     0.9624060150375939,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9699248120300752,\n",
       "     0.9624060150375939,\n",
       "     0.9548872180451128,\n",
       "     0.9624060150375939,\n",
       "     0.9548872180451128,\n",
       "     0.9699248120300752],\n",
       "    'split2_test_score': [0.9398496240601504,\n",
       "     0.924812030075188,\n",
       "     0.9473684210526315,\n",
       "     0.924812030075188,\n",
       "     0.9323308270676691,\n",
       "     0.9323308270676691,\n",
       "     0.924812030075188,\n",
       "     0.9323308270676691,\n",
       "     0.9323308270676691,\n",
       "     0.9398496240601504,\n",
       "     0.9323308270676691,\n",
       "     0.9398496240601504,\n",
       "     0.9323308270676691,\n",
       "     0.9473684210526315,\n",
       "     0.9323308270676691,\n",
       "     0.9473684210526315,\n",
       "     0.9323308270676691,\n",
       "     0.9323308270676691,\n",
       "     0.9473684210526315,\n",
       "     0.9323308270676691,\n",
       "     0.9473684210526315,\n",
       "     0.9398496240601504,\n",
       "     0.9473684210526315,\n",
       "     0.9473684210526315],\n",
       "    'mean_test_score': [0.9599558597987506,\n",
       "     0.9549620319455355,\n",
       "     0.9624808289380167,\n",
       "     0.9499495006172146,\n",
       "     0.9499682040923204,\n",
       "     0.9499682040923204,\n",
       "     0.9499495006172146,\n",
       "     0.9524370628062693,\n",
       "     0.9574682976096959,\n",
       "     0.9599745632738563,\n",
       "     0.95494332847043,\n",
       "     0.9574870010848016,\n",
       "     0.9574870010848014,\n",
       "     0.9574870010848016,\n",
       "     0.9549807354206411,\n",
       "     0.9674559533161261,\n",
       "     0.9624434219878054,\n",
       "     0.9624434219878054,\n",
       "     0.9674559533161261,\n",
       "     0.9574495941345903,\n",
       "     0.9624434219878052,\n",
       "     0.9599558597987506,\n",
       "     0.9574682976096959,\n",
       "     0.9649683911270714],\n",
       "    'std_test_score': [0.015513447444980245,\n",
       "     0.02131946767793521,\n",
       "     0.010686478920892058,\n",
       "     0.018835281650144215,\n",
       "     0.012871551652191253,\n",
       "     0.012871551652191253,\n",
       "     0.018835281650144215,\n",
       "     0.018830173494970646,\n",
       "     0.017775112047612417,\n",
       "     0.014230775975231418,\n",
       "     0.018485979644780777,\n",
       "     0.012816807933775548,\n",
       "     0.01878061748164243,\n",
       "     0.007155833227724305,\n",
       "     0.01628622748384232,\n",
       "     0.015492168703701363,\n",
       "     0.022172888881189613,\n",
       "     0.022172888881189613,\n",
       "     0.015492168703701363,\n",
       "     0.01881523115247859,\n",
       "     0.016294409117270987,\n",
       "     0.015513447444980245,\n",
       "     0.009477624989869454,\n",
       "     0.012834645696180251],\n",
       "    'rank_test_score': [9,\n",
       "     18,\n",
       "     4,\n",
       "     23,\n",
       "     21,\n",
       "     21,\n",
       "     23,\n",
       "     20,\n",
       "     14,\n",
       "     8,\n",
       "     19,\n",
       "     11,\n",
       "     13,\n",
       "     11,\n",
       "     17,\n",
       "     1,\n",
       "     5,\n",
       "     5,\n",
       "     1,\n",
       "     16,\n",
       "     7,\n",
       "     9,\n",
       "     14,\n",
       "     3]}}],\n",
       " 'money random_forest': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__max_depth': None,\n",
       "    'classifier__min_samples_leaf': 1,\n",
       "    'classifier__min_samples_split': 10,\n",
       "    'classifier__n_estimators': 100},\n",
       "   'best_validation_accuracy': 0.8009506833036245,\n",
       "   'train_accuracy': 0.94,\n",
       "   'test_accuracy': 0.815,\n",
       "   'cv_results': {'mean_fit_time': [0.18939606348673502,\n",
       "     0.3758373260498047,\n",
       "     0.6177838643391927,\n",
       "     0.2166601022084554,\n",
       "     0.4091488520304362,\n",
       "     0.6061315536499023,\n",
       "     0.19780937830607095,\n",
       "     0.37671661376953125,\n",
       "     0.6019220352172852,\n",
       "     0.20824527740478516,\n",
       "     0.4311588605244954,\n",
       "     0.6466321150461832,\n",
       "     0.21035480499267578,\n",
       "     0.42013096809387207,\n",
       "     0.6368435223897299,\n",
       "     0.21999120712280273,\n",
       "     0.4171437422434489,\n",
       "     0.5981677373250326,\n",
       "     0.1934326489766439,\n",
       "     0.37863413492838544,\n",
       "     0.5858431657155355,\n",
       "     0.21062548955281576,\n",
       "     0.4007405440012614,\n",
       "     0.6011455853780111,\n",
       "     0.20398577054341635,\n",
       "     0.4422272841135661,\n",
       "     0.7263592084248861,\n",
       "     0.2770686149597168,\n",
       "     0.4822712739308675,\n",
       "     0.7509764830271403,\n",
       "     0.2442761262257894,\n",
       "     0.537941058476766,\n",
       "     0.7481238842010498,\n",
       "     0.24881784121195474,\n",
       "     0.5353429317474365,\n",
       "     0.7662865320841471,\n",
       "     0.2669528325398763,\n",
       "     0.5044070879618326,\n",
       "     0.801532506942749,\n",
       "     0.25384950637817383,\n",
       "     0.5068003336588541,\n",
       "     0.7038447856903076,\n",
       "     0.2612450122833252,\n",
       "     0.5229481856028239,\n",
       "     0.7765103181203207,\n",
       "     0.2869112491607666,\n",
       "     0.5795353253682455,\n",
       "     0.7628789742787679,\n",
       "     0.26831261316935223,\n",
       "     0.520158847173055,\n",
       "     0.7738495667775472,\n",
       "     0.28591442108154297,\n",
       "     0.49360378583272296,\n",
       "     0.6555248896280924,\n",
       "     0.2563490072886149,\n",
       "     0.44736337661743164,\n",
       "     0.8126544952392578,\n",
       "     0.2852168877919515,\n",
       "     0.5217902660369873,\n",
       "     0.7467688719431559,\n",
       "     0.280478556950887,\n",
       "     0.5666439533233643,\n",
       "     0.7749698956807455,\n",
       "     0.3066989580790202,\n",
       "     0.4905231793721517,\n",
       "     0.7168397903442383,\n",
       "     0.2695298989613851,\n",
       "     0.4620644251505534,\n",
       "     0.6777182420094808,\n",
       "     0.268310546875,\n",
       "     0.4708809057871501,\n",
       "     0.6603283882141113,\n",
       "     0.2798817952473958,\n",
       "     0.4629228115081787,\n",
       "     0.680350144704183,\n",
       "     0.25441614786783856,\n",
       "     0.4518152077992757,\n",
       "     0.7388723691304525,\n",
       "     0.249662717183431,\n",
       "     0.4290970166524251,\n",
       "     0.6636601289113363,\n",
       "     0.26606082916259766,\n",
       "     0.4769304593404134,\n",
       "     0.6869642734527588,\n",
       "     0.28261717160542804,\n",
       "     0.4454824924468994,\n",
       "     0.6809564431508383,\n",
       "     0.2420677344004313,\n",
       "     0.4399445056915283,\n",
       "     0.6729059219360352,\n",
       "     0.24971604347229004,\n",
       "     0.44756555557250977,\n",
       "     0.7187469005584717,\n",
       "     0.2379159132639567,\n",
       "     0.4519735972086589,\n",
       "     0.6504043738047282,\n",
       "     0.24443427721659342,\n",
       "     0.44677027066548664,\n",
       "     0.6472967465718588,\n",
       "     0.2571895917256673,\n",
       "     0.4329124291737874,\n",
       "     0.703446626663208,\n",
       "     0.23742961883544922,\n",
       "     0.4452022711435954,\n",
       "     0.6260286172231039,\n",
       "     0.24332022666931152,\n",
       "     0.3950379689534505,\n",
       "     0.5088024139404297],\n",
       "    'std_fit_time': [0.013085296139957837,\n",
       "     0.0,\n",
       "     0.008191340411358902,\n",
       "     0.015133367747496013,\n",
       "     0.013741544944316599,\n",
       "     0.026415197916029608,\n",
       "     0.0073744621818501365,\n",
       "     0.01474094456038221,\n",
       "     0.0350918973018987,\n",
       "     0.005714140646713141,\n",
       "     0.03417859223952765,\n",
       "     0.02176942157356347,\n",
       "     0.016355231224021678,\n",
       "     0.0063023773232323095,\n",
       "     0.014277712118982943,\n",
       "     0.013080052857168675,\n",
       "     0.013522997749383654,\n",
       "     0.02250793738960369,\n",
       "     0.0029575759059985644,\n",
       "     0.009311359350151578,\n",
       "     0.027157932497061568,\n",
       "     0.007005409379201388,\n",
       "     0.02803260487637908,\n",
       "     0.04629038635704755,\n",
       "     0.012757953745445444,\n",
       "     0.056045117255724995,\n",
       "     0.05830725379780965,\n",
       "     0.012209766016098819,\n",
       "     0.05422134730428892,\n",
       "     0.04656511959588043,\n",
       "     0.025675495269511104,\n",
       "     0.047811807497434515,\n",
       "     0.02471937829964526,\n",
       "     0.012429440496602733,\n",
       "     0.010517468368217547,\n",
       "     0.048456159511992926,\n",
       "     0.007813903329384666,\n",
       "     0.045262872851990404,\n",
       "     0.04741447941143986,\n",
       "     0.005760414315197592,\n",
       "     0.02878606601607278,\n",
       "     0.049512072523204026,\n",
       "     0.01436021459679475,\n",
       "     0.009285923403753154,\n",
       "     0.02976820153442246,\n",
       "     0.017619084141774946,\n",
       "     0.047920498897680686,\n",
       "     0.015079425303337241,\n",
       "     0.04340690386629121,\n",
       "     0.026615626032638492,\n",
       "     0.05009412534408411,\n",
       "     0.02104905892368081,\n",
       "     0.047623962311133396,\n",
       "     0.07595782121373702,\n",
       "     0.021181480360559213,\n",
       "     0.01391438162300709,\n",
       "     0.05013783070785386,\n",
       "     0.0014888845737470954,\n",
       "     0.07879430865627171,\n",
       "     0.04071079925692148,\n",
       "     0.012579264776601524,\n",
       "     0.0338890238520034,\n",
       "     0.05220954415329774,\n",
       "     0.012067256416846221,\n",
       "     0.03546232281913126,\n",
       "     0.07863188313613834,\n",
       "     0.018457414686974705,\n",
       "     0.0555623162940858,\n",
       "     0.0409646204457296,\n",
       "     0.017492863815502028,\n",
       "     0.03071702412621524,\n",
       "     0.05472167447070608,\n",
       "     0.022051849898078412,\n",
       "     0.050886055884053705,\n",
       "     0.052221959322592666,\n",
       "     0.024638713388004146,\n",
       "     0.0157626199964877,\n",
       "     0.10989961603088945,\n",
       "     0.014109293659631948,\n",
       "     0.014239303897363999,\n",
       "     0.02847968234523666,\n",
       "     0.018444148726972667,\n",
       "     0.02958036457354672,\n",
       "     0.06945400564068999,\n",
       "     0.008612493009159524,\n",
       "     0.02966430315751848,\n",
       "     0.06030476851331816,\n",
       "     0.019260541445569695,\n",
       "     0.03180804289429957,\n",
       "     0.047049871560082744,\n",
       "     0.014976331193628163,\n",
       "     0.03429965636346432,\n",
       "     0.03896251947929673,\n",
       "     0.019362351315876474,\n",
       "     0.02698914403604417,\n",
       "     0.051203660247063944,\n",
       "     0.01667098387430067,\n",
       "     0.029219802799298544,\n",
       "     0.03685883558647137,\n",
       "     0.006692033194533818,\n",
       "     0.022996219680312013,\n",
       "     0.03187640486993481,\n",
       "     0.01540642752329968,\n",
       "     0.04192824485555871,\n",
       "     0.010441066879502785,\n",
       "     0.014197876248457624,\n",
       "     0.009646467217079333,\n",
       "     0.019110468227449152],\n",
       "    'mean_score_time': [0.027338504791259766,\n",
       "     0.03165602684020996,\n",
       "     0.0468743642171224,\n",
       "     0.02003177007039388,\n",
       "     0.032762765884399414,\n",
       "     0.04709132512410482,\n",
       "     0.026046355565388996,\n",
       "     0.031256675720214844,\n",
       "     0.05828118324279785,\n",
       "     0.018051306406656902,\n",
       "     0.022222439448038738,\n",
       "     0.0428315798441569,\n",
       "     0.02325574556986491,\n",
       "     0.03454748789469401,\n",
       "     0.04735008875528971,\n",
       "     0.020847479502360027,\n",
       "     0.03074955940246582,\n",
       "     0.04123624165852865,\n",
       "     0.0157622496287028,\n",
       "     0.02877155939737956,\n",
       "     0.03509982426961263,\n",
       "     0.021704991658528645,\n",
       "     0.03264005978902181,\n",
       "     0.050794760386149086,\n",
       "     0.01713101069132487,\n",
       "     0.03846057256062826,\n",
       "     0.06465466817220052,\n",
       "     0.03279272715250651,\n",
       "     0.031336704889933266,\n",
       "     0.06612491607666016,\n",
       "     0.01910885175069173,\n",
       "     0.03721165657043457,\n",
       "     0.05272404352823893,\n",
       "     0.03181958198547363,\n",
       "     0.03881502151489258,\n",
       "     0.05440934499104818,\n",
       "     0.022581179936726887,\n",
       "     0.03508353233337402,\n",
       "     0.04608591397603353,\n",
       "     0.033622423807779946,\n",
       "     0.03251870473225912,\n",
       "     0.06322360038757324,\n",
       "     0.01850589116414388,\n",
       "     0.047945102055867515,\n",
       "     0.051073153813680015,\n",
       "     0.020936965942382812,\n",
       "     0.041082302729288735,\n",
       "     0.05952159563700358,\n",
       "     0.01699995994567871,\n",
       "     0.03913164138793945,\n",
       "     0.051171461741129555,\n",
       "     0.03194014231363932,\n",
       "     0.03610785802205404,\n",
       "     0.04885419209798177,\n",
       "     0.02419598897298177,\n",
       "     0.03453826904296875,\n",
       "     0.074066956837972,\n",
       "     0.021308422088623047,\n",
       "     0.04602829615275065,\n",
       "     0.07156435648600261,\n",
       "     0.03293760617574056,\n",
       "     0.035459438959757485,\n",
       "     0.04784210522969564,\n",
       "     0.02807005246480306,\n",
       "     0.03840867678324381,\n",
       "     0.04782509803771973,\n",
       "     0.026153087615966797,\n",
       "     0.0345455010732015,\n",
       "     0.047353506088256836,\n",
       "     0.02556324005126953,\n",
       "     0.04155429204305013,\n",
       "     0.05037673314412435,\n",
       "     0.027533690134684246,\n",
       "     0.03536756833394369,\n",
       "     0.04974444707234701,\n",
       "     0.02736981709798177,\n",
       "     0.0383448600769043,\n",
       "     0.049933433532714844,\n",
       "     0.02143096923828125,\n",
       "     0.03603935241699219,\n",
       "     0.049844821294148765,\n",
       "     0.027924458185831707,\n",
       "     0.041458845138549805,\n",
       "     0.03867880503336588,\n",
       "     0.025013208389282227,\n",
       "     0.03642042477925619,\n",
       "     0.048113743464152016,\n",
       "     0.024836142857869465,\n",
       "     0.03514711062113444,\n",
       "     0.042638699213663735,\n",
       "     0.02299157778422038,\n",
       "     0.03414670626322428,\n",
       "     0.04641207059224447,\n",
       "     0.02584552764892578,\n",
       "     0.03474728266398112,\n",
       "     0.06231911977132162,\n",
       "     0.017886241277058918,\n",
       "     0.0342256228129069,\n",
       "     0.049075682957967125,\n",
       "     0.022371292114257812,\n",
       "     0.035042365392049156,\n",
       "     0.03977672259012858,\n",
       "     0.01634502410888672,\n",
       "     0.03336048126220703,\n",
       "     0.04531574249267578,\n",
       "     0.02217753728230794,\n",
       "     0.02783544858296712,\n",
       "     0.020835240681966145],\n",
       "    'std_score_time': [0.004067459004713551,\n",
       "     0.0,\n",
       "     0.012758051084992141,\n",
       "     0.000841175579549783,\n",
       "     0.012940390476005943,\n",
       "     0.0001684324847176104,\n",
       "     0.0073703633135579595,\n",
       "     7.755020126004502e-06,\n",
       "     0.015381480141941047,\n",
       "     0.008189519296548686,\n",
       "     0.006778232598536226,\n",
       "     0.0060440329293398945,\n",
       "     0.0039288257065170935,\n",
       "     0.004567266622213739,\n",
       "     0.0001930887619779092,\n",
       "     0.007370703110295506,\n",
       "     0.0019368357622040336,\n",
       "     0.0038982710022014834,\n",
       "     0.0001937635027077352,\n",
       "     0.0035060558435305463,\n",
       "     0.0054326778821220875,\n",
       "     0.007094196347686769,\n",
       "     0.0016826700996236189,\n",
       "     0.0077821275907823725,\n",
       "     0.002129989387742856,\n",
       "     0.005706584666249217,\n",
       "     0.005859599138324328,\n",
       "     0.0048725432463670995,\n",
       "     0.001201110198593972,\n",
       "     0.010230370934401881,\n",
       "     0.0010256578903423243,\n",
       "     0.006265438509997255,\n",
       "     0.0067642392678871075,\n",
       "     0.008067429365527973,\n",
       "     0.0047733643658791685,\n",
       "     0.007739053918656648,\n",
       "     0.002934804854288228,\n",
       "     0.005199467182392746,\n",
       "     0.004638119626387834,\n",
       "     0.00748003790880048,\n",
       "     0.0008339668406540956,\n",
       "     0.006397630382190048,\n",
       "     0.0074443334464541,\n",
       "     0.012444620155540227,\n",
       "     0.005152293453467589,\n",
       "     0.0016918408940857815,\n",
       "     0.007734970110701167,\n",
       "     0.013158121077436507,\n",
       "     0.004030924591581905,\n",
       "     0.005742941258527217,\n",
       "     0.006405288681138475,\n",
       "     0.0015726438081125349,\n",
       "     0.008932562474843165,\n",
       "     0.002582714428374484,\n",
       "     0.0024526042040812633,\n",
       "     0.008237458567551358,\n",
       "     0.010892743826382436,\n",
       "     0.0023991088500909144,\n",
       "     0.010053606668069018,\n",
       "     0.02427206274893431,\n",
       "     0.004139169936247515,\n",
       "     0.00034280061385646467,\n",
       "     0.0024213751793543898,\n",
       "     0.003755465531040001,\n",
       "     0.0054595517657284555,\n",
       "     0.003133634366371315,\n",
       "     0.004954069269951401,\n",
       "     0.0018832605874386063,\n",
       "     0.0028305168649130773,\n",
       "     0.0025581374733329226,\n",
       "     0.0015480562873382126,\n",
       "     0.0031463955043605067,\n",
       "     0.0015263994929918543,\n",
       "     0.00409922043727683,\n",
       "     0.0027285646510075623,\n",
       "     0.0029675284297586025,\n",
       "     0.0030418809176910957,\n",
       "     0.005265889604100253,\n",
       "     0.005686230909159896,\n",
       "     0.0010407737548578755,\n",
       "     0.005396169316828977,\n",
       "     0.003032344856429374,\n",
       "     0.0036350061265212202,\n",
       "     0.006601764247628948,\n",
       "     0.003373299809004776,\n",
       "     0.0056049541818512195,\n",
       "     0.003353545732678517,\n",
       "     0.010639898319802362,\n",
       "     0.0031857688200068956,\n",
       "     0.004819809636617132,\n",
       "     0.00977033178347705,\n",
       "     0.0024631798417358622,\n",
       "     0.0019948686996449807,\n",
       "     0.009592918946383507,\n",
       "     0.002076204778910386,\n",
       "     0.01179520894501404,\n",
       "     0.0031832137300373963,\n",
       "     0.0017141545784366012,\n",
       "     0.004626337908448164,\n",
       "     0.006875097795455142,\n",
       "     0.0076106682734774275,\n",
       "     0.006198806708224351,\n",
       "     0.000999271758852493,\n",
       "     0.0037748630193117144,\n",
       "     0.009707707073308954,\n",
       "     0.004028996571528189,\n",
       "     0.010203471045497374,\n",
       "     0.007370247549058774],\n",
       "    'param_classifier__max_depth': [None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30],\n",
       "    'param_classifier__min_samples_leaf': [1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10],\n",
       "    'param_classifier__n_estimators': [100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300],\n",
       "    'params': [{'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300}],\n",
       "    'split0_test_score': [0.6764705882352942,\n",
       "     0.6470588235294118,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942,\n",
       "     0.6470588235294118,\n",
       "     0.6764705882352942,\n",
       "     0.7058823529411765,\n",
       "     0.7058823529411765,\n",
       "     0.6764705882352942,\n",
       "     0.7058823529411765,\n",
       "     0.7058823529411765,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942,\n",
       "     0.7058823529411765,\n",
       "     0.7058823529411765,\n",
       "     0.6470588235294118,\n",
       "     0.7058823529411765,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942,\n",
       "     0.6470588235294118,\n",
       "     0.6470588235294118,\n",
       "     0.7058823529411765,\n",
       "     0.6764705882352942,\n",
       "     0.7058823529411765,\n",
       "     0.7058823529411765,\n",
       "     0.7058823529411765,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942,\n",
       "     0.7058823529411765,\n",
       "     0.6764705882352942,\n",
       "     0.7058823529411765,\n",
       "     0.7058823529411765,\n",
       "     0.6764705882352942,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.6764705882352942,\n",
       "     0.7058823529411765,\n",
       "     0.6470588235294118,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942,\n",
       "     0.7058823529411765,\n",
       "     0.7058823529411765,\n",
       "     0.6764705882352942,\n",
       "     0.7058823529411765,\n",
       "     0.7058823529411765,\n",
       "     0.6764705882352942,\n",
       "     0.7352941176470589,\n",
       "     0.6470588235294118,\n",
       "     0.7058823529411765,\n",
       "     0.7058823529411765,\n",
       "     0.6764705882352942,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.6764705882352942,\n",
       "     0.6470588235294118,\n",
       "     0.6470588235294118,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942,\n",
       "     0.6470588235294118,\n",
       "     0.6764705882352942,\n",
       "     0.7058823529411765,\n",
       "     0.7058823529411765,\n",
       "     0.6470588235294118,\n",
       "     0.7352941176470589,\n",
       "     0.7058823529411765,\n",
       "     0.7058823529411765,\n",
       "     0.6764705882352942,\n",
       "     0.7058823529411765,\n",
       "     0.7058823529411765,\n",
       "     0.6764705882352942,\n",
       "     0.7058823529411765,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589],\n",
       "    'split1_test_score': [0.8484848484848485,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.8484848484848485,\n",
       "     0.8181818181818182,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8181818181818182,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8787878787878788,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.8484848484848485,\n",
       "     0.8181818181818182,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8181818181818182,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8787878787878788,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8787878787878788,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.8484848484848485,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.8484848484848485,\n",
       "     0.8181818181818182,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8787878787878788,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8181818181818182,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8787878787878788,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878],\n",
       "    'split2_test_score': [0.7272727272727273,\n",
       "     0.696969696969697,\n",
       "     0.7272727272727273,\n",
       "     0.7878787878787878,\n",
       "     0.8484848484848485,\n",
       "     0.7878787878787878,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.696969696969697,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.8484848484848485,\n",
       "     0.7575757575757576,\n",
       "     0.8484848484848485,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7272727272727273,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7272727272727273,\n",
       "     0.8181818181818182,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.8484848484848485,\n",
       "     0.8181818181818182,\n",
       "     0.8484848484848485,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.7272727272727273,\n",
       "     0.8181818181818182,\n",
       "     0.7575757575757576,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576],\n",
       "    'mean_test_score': [0.7507427213309565,\n",
       "     0.7106357694592988,\n",
       "     0.7305407011289363,\n",
       "     0.7608437314319666,\n",
       "     0.7813428401663697,\n",
       "     0.7608437314319666,\n",
       "     0.8009506833036245,\n",
       "     0.8009506833036245,\n",
       "     0.7709447415329768,\n",
       "     0.7706476530005942,\n",
       "     0.7706476530005942,\n",
       "     0.7608437314319666,\n",
       "     0.7608437314319666,\n",
       "     0.7507427213309565,\n",
       "     0.7605466428995841,\n",
       "     0.7807486631016043,\n",
       "     0.7510398098633392,\n",
       "     0.7807486631016043,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7507427213309565,\n",
       "     0.7507427213309565,\n",
       "     0.7608437314319668,\n",
       "     0.7709447415329768,\n",
       "     0.7409387997623291,\n",
       "     0.7611408199643493,\n",
       "     0.7706476530005942,\n",
       "     0.7608437314319666,\n",
       "     0.7908496732026143,\n",
       "     0.7706476530005942,\n",
       "     0.7706476530005942,\n",
       "     0.7709447415329768,\n",
       "     0.7709447415329768,\n",
       "     0.7706476530005942,\n",
       "     0.7608437314319666,\n",
       "     0.7807486631016043,\n",
       "     0.7706476530005942,\n",
       "     0.7608437314319666,\n",
       "     0.7703505644682117,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7305407011289363,\n",
       "     0.7403446226975637,\n",
       "     0.7308377896613191,\n",
       "     0.7810457516339869,\n",
       "     0.7709447415329769,\n",
       "     0.7810457516339869,\n",
       "     0.7608437314319666,\n",
       "     0.7908496732026143,\n",
       "     0.7908496732026143,\n",
       "     0.7709447415329768,\n",
       "     0.7807486631016043,\n",
       "     0.7605466428995841,\n",
       "     0.7608437314319666,\n",
       "     0.7804515745692218,\n",
       "     0.7611408199643493,\n",
       "     0.7908496732026143,\n",
       "     0.7706476530005942,\n",
       "     0.7608437314319666,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7507427213309565,\n",
       "     0.7409387997623291,\n",
       "     0.7308377896613191,\n",
       "     0.7709447415329769,\n",
       "     0.7507427213309565,\n",
       "     0.7611408199643493,\n",
       "     0.7911467617349971,\n",
       "     0.7908496732026143,\n",
       "     0.8009506833036245,\n",
       "     0.7611408199643495,\n",
       "     0.7905525846702318,\n",
       "     0.7605466428995841,\n",
       "     0.7908496732026143,\n",
       "     0.7608437314319666,\n",
       "     0.7807486631016043,\n",
       "     0.7807486631016043,\n",
       "     0.7608437314319666,\n",
       "     0.7807486631016043,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014,\n",
       "     0.7602495543672014],\n",
       "    'std_test_score': [0.07215888440619697,\n",
       "     0.058296007540872385,\n",
       "     0.04554087158289637,\n",
       "     0.060929953668406575,\n",
       "     0.09495313876896003,\n",
       "     0.060929953668406575,\n",
       "     0.06722346107536993,\n",
       "     0.06722346107536993,\n",
       "     0.07123808848517255,\n",
       "     0.058946437671947266,\n",
       "     0.04743751314607741,\n",
       "     0.07026253706465964,\n",
       "     0.07026253706465964,\n",
       "     0.07215888440619697,\n",
       "     0.06279189453890864,\n",
       "     0.0724652462907267,\n",
       "     0.08236160044467183,\n",
       "     0.05843513180341887,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.05805477850835495,\n",
       "     0.05805477850835495,\n",
       "     0.060929953668406575,\n",
       "     0.07123808848517255,\n",
       "     0.07084424746661382,\n",
       "     0.08437732743844643,\n",
       "     0.058946437671947266,\n",
       "     0.060929953668406575,\n",
       "     0.06134140823127506,\n",
       "     0.058946437671947266,\n",
       "     0.058946437671947266,\n",
       "     0.07123808848517255,\n",
       "     0.0831349056781447,\n",
       "     0.058946437671947266,\n",
       "     0.07026253706465964,\n",
       "     0.0724652462907267,\n",
       "     0.058946437671947266,\n",
       "     0.07026253706465964,\n",
       "     0.035023701435262414,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.06253413688236695,\n",
       "     0.034727603556036706,\n",
       "     0.06990613743717497,\n",
       "     0.07497351537391529,\n",
       "     0.06680331444364888,\n",
       "     0.07497351537391529,\n",
       "     0.07026253706465964,\n",
       "     0.06134140823127506,\n",
       "     0.06134140823127506,\n",
       "     0.07123808848517255,\n",
       "     0.05843513180341887,\n",
       "     0.06279189453890864,\n",
       "     0.07026253706465964,\n",
       "     0.048959252712414365,\n",
       "     0.08437732743844643,\n",
       "     0.07061963766916703,\n",
       "     0.058946437671947266,\n",
       "     0.07026253706465964,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.05805477850835495,\n",
       "     0.06638316781192777,\n",
       "     0.06990613743717497,\n",
       "     0.06680331444364888,\n",
       "     0.05805477850835495,\n",
       "     0.08437732743844643,\n",
       "     0.08108829992216497,\n",
       "     0.06134140823127506,\n",
       "     0.06722346107536993,\n",
       "     0.08066815329044394,\n",
       "     0.04624858397010433,\n",
       "     0.06279189453890864,\n",
       "     0.06134140823127506,\n",
       "     0.07026253706465964,\n",
       "     0.05843513180341887,\n",
       "     0.05843513180341887,\n",
       "     0.07026253706465964,\n",
       "     0.0724652462907267,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075,\n",
       "     0.021550696474536075],\n",
       "    'rank_test_score': [95,\n",
       "     108,\n",
       "     106,\n",
       "     44,\n",
       "     12,\n",
       "     44,\n",
       "     1,\n",
       "     1,\n",
       "     25,\n",
       "     30,\n",
       "     30,\n",
       "     44,\n",
       "     44,\n",
       "     95,\n",
       "     56,\n",
       "     15,\n",
       "     94,\n",
       "     15,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     95,\n",
       "     95,\n",
       "     43,\n",
       "     25,\n",
       "     101,\n",
       "     40,\n",
       "     30,\n",
       "     44,\n",
       "     5,\n",
       "     30,\n",
       "     30,\n",
       "     25,\n",
       "     25,\n",
       "     30,\n",
       "     44,\n",
       "     15,\n",
       "     30,\n",
       "     44,\n",
       "     38,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     106,\n",
       "     103,\n",
       "     104,\n",
       "     13,\n",
       "     23,\n",
       "     13,\n",
       "     44,\n",
       "     5,\n",
       "     5,\n",
       "     25,\n",
       "     15,\n",
       "     56,\n",
       "     44,\n",
       "     22,\n",
       "     40,\n",
       "     5,\n",
       "     30,\n",
       "     44,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     95,\n",
       "     101,\n",
       "     104,\n",
       "     23,\n",
       "     95,\n",
       "     40,\n",
       "     4,\n",
       "     5,\n",
       "     1,\n",
       "     39,\n",
       "     11,\n",
       "     56,\n",
       "     5,\n",
       "     44,\n",
       "     15,\n",
       "     15,\n",
       "     44,\n",
       "     15,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59,\n",
       "     59]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__max_depth': 20,\n",
       "    'classifier__min_samples_leaf': 2,\n",
       "    'classifier__min_samples_split': 2,\n",
       "    'classifier__n_estimators': 100},\n",
       "   'best_validation_accuracy': 0.8202333142092177,\n",
       "   'train_accuracy': 0.936,\n",
       "   'test_accuracy': 0.824,\n",
       "   'cv_results': {'mean_fit_time': [0.20213675498962402,\n",
       "     0.443144957224528,\n",
       "     0.676770289738973,\n",
       "     0.2242258389790853,\n",
       "     0.4816630681355794,\n",
       "     0.7305400371551514,\n",
       "     0.25560537974039715,\n",
       "     0.4874173005421956,\n",
       "     0.6966848373413086,\n",
       "     0.25264207522074383,\n",
       "     0.46117281913757324,\n",
       "     0.7578421433766683,\n",
       "     0.2524920304616292,\n",
       "     0.4676540692647298,\n",
       "     0.7056051890055338,\n",
       "     0.24897154172261557,\n",
       "     0.44287109375,\n",
       "     0.6992190678914388,\n",
       "     0.2549898624420166,\n",
       "     0.450489600499471,\n",
       "     0.7152485847473145,\n",
       "     0.2320702075958252,\n",
       "     0.48302189509073895,\n",
       "     0.6976850827534994,\n",
       "     0.2436056931813558,\n",
       "     0.45037062962849933,\n",
       "     0.7270503838857015,\n",
       "     0.2628169854482015,\n",
       "     0.47170456250508624,\n",
       "     0.7227087815602621,\n",
       "     0.24110627174377441,\n",
       "     0.4949491818745931,\n",
       "     0.6859727700551351,\n",
       "     0.254292090733846,\n",
       "     0.47124361991882324,\n",
       "     0.6744483311971029,\n",
       "     0.25005078315734863,\n",
       "     0.4628032048543294,\n",
       "     0.6994682947794596,\n",
       "     0.2630119323730469,\n",
       "     0.4506382942199707,\n",
       "     0.7446973323822021,\n",
       "     0.2425065040588379,\n",
       "     0.44412867228190106,\n",
       "     0.716301679611206,\n",
       "     0.23773455619812012,\n",
       "     0.4439420700073242,\n",
       "     0.6429317792256674,\n",
       "     0.2593982219696045,\n",
       "     0.49721018473307294,\n",
       "     0.6670401096343994,\n",
       "     0.23720002174377441,\n",
       "     0.4332731564839681,\n",
       "     0.7001345157623291,\n",
       "     0.2764628728230794,\n",
       "     0.467818021774292,\n",
       "     0.7644492785135905,\n",
       "     0.2522374788920085,\n",
       "     0.4389001528422038,\n",
       "     0.7652797698974609,\n",
       "     0.2326799233754476,\n",
       "     0.4755595525105794,\n",
       "     0.6493247350056967,\n",
       "     0.2680453459421794,\n",
       "     0.5066428184509277,\n",
       "     0.7113604545593262,\n",
       "     0.2537059783935547,\n",
       "     0.4446412722269694,\n",
       "     0.702214241027832,\n",
       "     0.266043742497762,\n",
       "     0.4597291946411133,\n",
       "     0.6753585338592529,\n",
       "     0.2377166748046875,\n",
       "     0.4517567952473958,\n",
       "     0.6740438938140869,\n",
       "     0.2440925439198812,\n",
       "     0.45495303471883136,\n",
       "     0.6859947840372721,\n",
       "     0.24408721923828125,\n",
       "     0.4426114559173584,\n",
       "     0.6983997027079264,\n",
       "     0.25546471277872723,\n",
       "     0.4475711981455485,\n",
       "     0.7273553212483724,\n",
       "     0.2568972110748291,\n",
       "     0.4809736410776774,\n",
       "     0.7126153310139974,\n",
       "     0.22558228174845377,\n",
       "     0.44446221987406415,\n",
       "     0.6836523214975992,\n",
       "     0.2663486798604329,\n",
       "     0.4605303605397542,\n",
       "     0.7494969367980957,\n",
       "     0.2446300188700358,\n",
       "     0.4494566122690837,\n",
       "     0.7155531247456869,\n",
       "     0.26446986198425293,\n",
       "     0.46578089396158856,\n",
       "     0.7033224105834961,\n",
       "     0.2569931348164876,\n",
       "     0.4564652442932129,\n",
       "     0.7176234722137451,\n",
       "     0.23554245630900064,\n",
       "     0.44224023818969727,\n",
       "     0.6595247586568197,\n",
       "     0.254560391108195,\n",
       "     0.39859986305236816,\n",
       "     0.5195823510487875],\n",
       "    'std_fit_time': [0.013486654348698003,\n",
       "     0.023720556912412753,\n",
       "     0.0476296964720728,\n",
       "     0.021052270716944432,\n",
       "     0.029917625221210442,\n",
       "     0.06032958975285318,\n",
       "     0.005727508825768191,\n",
       "     0.0696046534030548,\n",
       "     0.03866060228287101,\n",
       "     0.01617387384664168,\n",
       "     0.007118111679697277,\n",
       "     0.029566012029396672,\n",
       "     0.016728718175818086,\n",
       "     0.01274100754455954,\n",
       "     0.03595381574017945,\n",
       "     0.03033168197834007,\n",
       "     0.0022905106794946484,\n",
       "     0.029016657733309408,\n",
       "     0.028291231638503445,\n",
       "     0.02597997923049253,\n",
       "     0.05611508177305313,\n",
       "     0.008699092192524734,\n",
       "     0.03635014020740991,\n",
       "     0.051014846004860066,\n",
       "     0.02543295380483456,\n",
       "     0.028156029987676703,\n",
       "     0.03421142891010055,\n",
       "     0.011891378152800999,\n",
       "     0.028359707369231355,\n",
       "     0.014734594551262664,\n",
       "     0.018622706628856112,\n",
       "     0.04669749791074398,\n",
       "     0.03460405861696122,\n",
       "     0.01301362281233131,\n",
       "     0.049989542819704996,\n",
       "     0.05593272261076283,\n",
       "     0.0008826087705844712,\n",
       "     0.010977849142137532,\n",
       "     0.03782064679578164,\n",
       "     0.022010692042151787,\n",
       "     0.01527515460972642,\n",
       "     0.009990537737779921,\n",
       "     0.017955748995472906,\n",
       "     0.03815044325514884,\n",
       "     0.046236274145429156,\n",
       "     0.017107037301999785,\n",
       "     0.013872914132627,\n",
       "     0.007629086819377335,\n",
       "     0.002903457136125379,\n",
       "     0.007363672588631348,\n",
       "     0.02309716397603455,\n",
       "     0.014941226384505978,\n",
       "     1.1477708010645551e-05,\n",
       "     0.048874286667842444,\n",
       "     0.009430931189799405,\n",
       "     0.013081402375815432,\n",
       "     0.04230749271010671,\n",
       "     0.026510021556650575,\n",
       "     0.00745152990863141,\n",
       "     0.024598116661569143,\n",
       "     0.013035077637778388,\n",
       "     0.035503504948900755,\n",
       "     0.0007411606598566291,\n",
       "     0.014796053136756854,\n",
       "     0.025902444687380535,\n",
       "     0.038464029524585934,\n",
       "     0.021697871002402325,\n",
       "     0.011300883473695131,\n",
       "     0.057156307971454615,\n",
       "     0.006173305704337134,\n",
       "     0.01893142584199197,\n",
       "     0.01864766325722745,\n",
       "     0.011789097414734894,\n",
       "     0.020005920341325714,\n",
       "     0.05859895512081854,\n",
       "     0.00693509130553139,\n",
       "     0.029469188872985014,\n",
       "     0.0522843032066521,\n",
       "     0.013556803612127397,\n",
       "     0.019889283761995436,\n",
       "     0.03618206895228219,\n",
       "     0.018872381946337263,\n",
       "     0.010769246979384412,\n",
       "     0.034773263197375434,\n",
       "     0.022058205947901827,\n",
       "     0.039937858897641836,\n",
       "     0.04910559349549443,\n",
       "     0.005973955036144129,\n",
       "     0.008902039470985904,\n",
       "     0.03494944783420216,\n",
       "     0.02415448901904889,\n",
       "     0.02977265612942705,\n",
       "     0.010149458201223493,\n",
       "     0.025688925058083508,\n",
       "     0.01006136945457837,\n",
       "     0.04067737500242159,\n",
       "     0.023593809207898768,\n",
       "     0.028103387251300394,\n",
       "     0.045789506827402446,\n",
       "     0.040343937667394185,\n",
       "     0.024341987789080085,\n",
       "     0.01268269067927748,\n",
       "     0.01326748279504019,\n",
       "     0.007367943469280451,\n",
       "     0.01919659924479567,\n",
       "     0.01581670073565066,\n",
       "     0.0124133913400266,\n",
       "     0.01474218086793853],\n",
       "    'mean_score_time': [0.026640812555948894,\n",
       "     0.033515612284342446,\n",
       "     0.04889996846516927,\n",
       "     0.032280286153157554,\n",
       "     0.03571271896362305,\n",
       "     0.048969268798828125,\n",
       "     0.024962186813354492,\n",
       "     0.03797475496927897,\n",
       "     0.048518101374308266,\n",
       "     0.02328801155090332,\n",
       "     0.031252145767211914,\n",
       "     0.04199719429016113,\n",
       "     0.025399128595987957,\n",
       "     0.03868873914082845,\n",
       "     0.05362637837727865,\n",
       "     0.02882726987202962,\n",
       "     0.031532843907674156,\n",
       "     0.05125967661539713,\n",
       "     0.02922813097635905,\n",
       "     0.03632275263468424,\n",
       "     0.0559694766998291,\n",
       "     0.031755526860555015,\n",
       "     0.031224568684895832,\n",
       "     0.05087780952453613,\n",
       "     0.017508188883463543,\n",
       "     0.03125802675882975,\n",
       "     0.046010891596476235,\n",
       "     0.01933598518371582,\n",
       "     0.04017178217569987,\n",
       "     0.05276759465535482,\n",
       "     0.02676113446553548,\n",
       "     0.0322573184967041,\n",
       "     0.052675326665242515,\n",
       "     0.025435765584309895,\n",
       "     0.03493809700012207,\n",
       "     0.048628648122151695,\n",
       "     0.015771865844726562,\n",
       "     0.033531745274861656,\n",
       "     0.04978807767232259,\n",
       "     0.020833174387613933,\n",
       "     0.038477579752604164,\n",
       "     0.05007235209147135,\n",
       "     0.01794608434041341,\n",
       "     0.03423579533894857,\n",
       "     0.04764199256896973,\n",
       "     0.02298728624979655,\n",
       "     0.035927136739095054,\n",
       "     0.045625925064086914,\n",
       "     0.020979960759480793,\n",
       "     0.04210662841796875,\n",
       "     0.0512701670328776,\n",
       "     0.026180267333984375,\n",
       "     0.03565843900044759,\n",
       "     0.05852039655049642,\n",
       "     0.030256907145182293,\n",
       "     0.03854044278462728,\n",
       "     0.04959424336751302,\n",
       "     0.034421284993489586,\n",
       "     0.0484009583791097,\n",
       "     0.059805870056152344,\n",
       "     0.021655559539794922,\n",
       "     0.03741097450256348,\n",
       "     0.04559969902038574,\n",
       "     0.022561391194661457,\n",
       "     0.031258185704549156,\n",
       "     0.04916954040527344,\n",
       "     0.027985811233520508,\n",
       "     0.03151559829711914,\n",
       "     0.051512956619262695,\n",
       "     0.019449313481648762,\n",
       "     0.03207047780354818,\n",
       "     0.050780137379964195,\n",
       "     0.027940750122070312,\n",
       "     0.043899218241373696,\n",
       "     0.052094459533691406,\n",
       "     0.026749610900878906,\n",
       "     0.038663228352864586,\n",
       "     0.05581784248352051,\n",
       "     0.022984663645426433,\n",
       "     0.03278160095214844,\n",
       "     0.04907035827636719,\n",
       "     0.020804166793823242,\n",
       "     0.03016201655069987,\n",
       "     0.04892539978027344,\n",
       "     0.02738038698832194,\n",
       "     0.041424194971720375,\n",
       "     0.05312530199686686,\n",
       "     0.02262703577677409,\n",
       "     0.043658177057902016,\n",
       "     0.052816549936930336,\n",
       "     0.022214492162068684,\n",
       "     0.03870407740275065,\n",
       "     0.05259434382120768,\n",
       "     0.018749316533406574,\n",
       "     0.03604475657145182,\n",
       "     0.04632902145385742,\n",
       "     0.030016104380289715,\n",
       "     0.03477684656778971,\n",
       "     0.04733745257059733,\n",
       "     0.02077762285868327,\n",
       "     0.030956745147705078,\n",
       "     0.0504756768544515,\n",
       "     0.022506157557169598,\n",
       "     0.03646691640218099,\n",
       "     0.041959683100382485,\n",
       "     0.018382787704467773,\n",
       "     0.028388023376464844,\n",
       "     0.020830949147542317],\n",
       "    'std_score_time': [0.0027950666016464632,\n",
       "     0.004875048644666758,\n",
       "     0.0014501050270979716,\n",
       "     0.005653287104678968,\n",
       "     0.005550423615985407,\n",
       "     0.0025355711530068038,\n",
       "     0.004501579758802628,\n",
       "     0.004425531485239903,\n",
       "     0.004353774641350158,\n",
       "     0.007422883868713728,\n",
       "     5.731971397481588e-06,\n",
       "     0.003746201181176424,\n",
       "     0.00982474636294884,\n",
       "     0.007299431984633151,\n",
       "     0.01636087735888695,\n",
       "     0.007016219689996461,\n",
       "     0.00019433735486690956,\n",
       "     0.003424871491118422,\n",
       "     0.012656002197283803,\n",
       "     0.006362599725577418,\n",
       "     0.00484365470467843,\n",
       "     0.008690042859243961,\n",
       "     3.175077507024043e-05,\n",
       "     0.004961605099725214,\n",
       "     0.00262850225633141,\n",
       "     9.850147210065964e-06,\n",
       "     0.00779775223047074,\n",
       "     0.005234317660106855,\n",
       "     0.0018209391394716507,\n",
       "     0.0029544530266659005,\n",
       "     0.007082920251674182,\n",
       "     0.004594519909177463,\n",
       "     0.0073049217877942645,\n",
       "     0.006090463508185611,\n",
       "     0.002299797634602442,\n",
       "     0.00411907255752664,\n",
       "     0.0001892950430438235,\n",
       "     0.006757323961199938,\n",
       "     0.004125783098630424,\n",
       "     0.0073654710188089615,\n",
       "     0.0064299549351565875,\n",
       "     0.006771489409980354,\n",
       "     0.0043132905210747415,\n",
       "     0.011086015815862093,\n",
       "     0.008830946438943678,\n",
       "     0.0052047424205093114,\n",
       "     0.0032917250644988382,\n",
       "     0.007030813393524022,\n",
       "     0.007273992318580234,\n",
       "     0.007376035664194543,\n",
       "     0.0034309055355723457,\n",
       "     0.007167324470368596,\n",
       "     0.0031259480745839006,\n",
       "     0.004271005876646217,\n",
       "     0.00613827871415532,\n",
       "     0.006430626273035378,\n",
       "     0.004102292460621049,\n",
       "     0.0022776159209185586,\n",
       "     0.004146877533144862,\n",
       "     0.002784915017257951,\n",
       "     0.008495118785855802,\n",
       "     0.0054785696111795,\n",
       "     0.006348112530917276,\n",
       "     0.0041268761426748795,\n",
       "     5.95675458953969e-06,\n",
       "     0.009803177585778713,\n",
       "     0.004584369877461431,\n",
       "     0.0022500748655390292,\n",
       "     0.004637835949923398,\n",
       "     0.00736620190434857,\n",
       "     0.0004789903557467283,\n",
       "     0.0027444926203101425,\n",
       "     0.00680194041586785,\n",
       "     0.009006487800901561,\n",
       "     0.007372671690584199,\n",
       "     0.00786679370373805,\n",
       "     0.003365798022443406,\n",
       "     0.01585174762920331,\n",
       "     0.008579956773834668,\n",
       "     0.0021187947875380563,\n",
       "     0.0014998618148640405,\n",
       "     0.007388287055129212,\n",
       "     0.0060060227078713654,\n",
       "     0.002580398653230976,\n",
       "     0.008489438377335236,\n",
       "     0.0070460465915263846,\n",
       "     0.0004171733057307227,\n",
       "     0.006478641919914623,\n",
       "     0.0045563573157528115,\n",
       "     0.003544931560590457,\n",
       "     0.006616918095133484,\n",
       "     0.00640549163661146,\n",
       "     0.004784216658757591,\n",
       "     0.009259604289814776,\n",
       "     0.0035532900050984566,\n",
       "     0.006934116640472149,\n",
       "     0.0030415122478803427,\n",
       "     0.007650905365879898,\n",
       "     0.004756502695895723,\n",
       "     0.007345438294597441,\n",
       "     0.007055397547104805,\n",
       "     0.010590262341996066,\n",
       "     0.009663580091971683,\n",
       "     0.007376822405366746,\n",
       "     0.005391171578513473,\n",
       "     0.0022205355305554954,\n",
       "     0.004648965978145655,\n",
       "     0.007364853169270393],\n",
       "    'param_classifier__max_depth': [None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30],\n",
       "    'param_classifier__min_samples_leaf': [1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10],\n",
       "    'param_classifier__n_estimators': [100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300],\n",
       "    'params': [{'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300}],\n",
       "    'split0_test_score': [0.75,\n",
       "     0.7738095238095238,\n",
       "     0.75,\n",
       "     0.7857142857142857,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7857142857142857,\n",
       "     0.7619047619047619,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7380952380952381,\n",
       "     0.7619047619047619,\n",
       "     0.7380952380952381,\n",
       "     0.75,\n",
       "     0.7380952380952381,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.75,\n",
       "     0.75,\n",
       "     0.75,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7380952380952381,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.75,\n",
       "     0.75,\n",
       "     0.7738095238095238,\n",
       "     0.7976190476190477,\n",
       "     0.7857142857142857,\n",
       "     0.7738095238095238,\n",
       "     0.7857142857142857,\n",
       "     0.7619047619047619,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7619047619047619,\n",
       "     0.7380952380952381,\n",
       "     0.7619047619047619,\n",
       "     0.75,\n",
       "     0.7619047619047619,\n",
       "     0.75,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.75,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.75,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7857142857142857,\n",
       "     0.7976190476190477,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7738095238095238,\n",
       "     0.7976190476190477,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7380952380952381,\n",
       "     0.7619047619047619,\n",
       "     0.75,\n",
       "     0.7380952380952381,\n",
       "     0.7619047619047619,\n",
       "     0.75,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.75,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.75,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7857142857142857,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477,\n",
       "     0.7857142857142857,\n",
       "     0.75,\n",
       "     0.75,\n",
       "     0.75,\n",
       "     0.75,\n",
       "     0.75,\n",
       "     0.75,\n",
       "     0.7738095238095238,\n",
       "     0.7261904761904762,\n",
       "     0.75,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.75,\n",
       "     0.7738095238095238,\n",
       "     0.75,\n",
       "     0.7738095238095238,\n",
       "     0.75,\n",
       "     0.7857142857142857,\n",
       "     0.7619047619047619],\n",
       "    'split1_test_score': [0.8192771084337349,\n",
       "     0.8072289156626506,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8072289156626506,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.8554216867469879,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8433734939759037,\n",
       "     0.7951807228915663,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8192771084337349,\n",
       "     0.7951807228915663,\n",
       "     0.8192771084337349,\n",
       "     0.8072289156626506,\n",
       "     0.8192771084337349,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.8072289156626506,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.8433734939759037,\n",
       "     0.8433734939759037,\n",
       "     0.8072289156626506,\n",
       "     0.8192771084337349,\n",
       "     0.8072289156626506,\n",
       "     0.7951807228915663,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8192771084337349,\n",
       "     0.7951807228915663,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8433734939759037,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.7951807228915663,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8072289156626506,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8072289156626506,\n",
       "     0.8192771084337349,\n",
       "     0.8072289156626506,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8433734939759037,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.7951807228915663,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8192771084337349,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506],\n",
       "    'split2_test_score': [0.8554216867469879,\n",
       "     0.8072289156626506,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8433734939759037,\n",
       "     0.8192771084337349,\n",
       "     0.8072289156626506,\n",
       "     0.8192771084337349,\n",
       "     0.8433734939759037,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8433734939759037,\n",
       "     0.8433734939759037,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.7831325301204819,\n",
       "     0.8192771084337349,\n",
       "     0.8433734939759037,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8433734939759037,\n",
       "     0.8554216867469879,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.8433734939759037,\n",
       "     0.8313253012048193,\n",
       "     0.8554216867469879,\n",
       "     0.8433734939759037,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8433734939759037,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.8433734939759037,\n",
       "     0.8433734939759037,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8072289156626506,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8554216867469879,\n",
       "     0.8554216867469879,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8433734939759037,\n",
       "     0.8313253012048193,\n",
       "     0.8433734939759037,\n",
       "     0.8192771084337349,\n",
       "     0.8554216867469879,\n",
       "     0.8313253012048193,\n",
       "     0.8072289156626506,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.8433734939759037,\n",
       "     0.8072289156626506,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8192771084337349,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8554216867469879,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.8433734939759037,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8554216867469879,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193],\n",
       "    'mean_test_score': [0.8082329317269076,\n",
       "     0.7960891183782751,\n",
       "     0.8002008032128515,\n",
       "     0.8121055651176133,\n",
       "     0.8041212468923312,\n",
       "     0.8161694396634157,\n",
       "     0.8121055651176133,\n",
       "     0.7961369286670491,\n",
       "     0.8040734366035571,\n",
       "     0.8161216293746415,\n",
       "     0.8002486135016257,\n",
       "     0.8122011856951615,\n",
       "     0.8002486135016257,\n",
       "     0.8042168674698796,\n",
       "     0.7962325492445975,\n",
       "     0.8121533754063875,\n",
       "     0.8121533754063875,\n",
       "     0.8122011856951615,\n",
       "     0.7921686746987953,\n",
       "     0.7921686746987951,\n",
       "     0.7921686746987951,\n",
       "     0.8041212468923313,\n",
       "     0.7961369286670491,\n",
       "     0.7882004207305412,\n",
       "     0.7961369286670491,\n",
       "     0.8041690571811054,\n",
       "     0.7921686746987953,\n",
       "     0.7841365461847389,\n",
       "     0.8001051826353032,\n",
       "     0.8200898833428955,\n",
       "     0.8080895008605853,\n",
       "     0.8041212468923313,\n",
       "     0.8121055651176133,\n",
       "     0.8001529929240773,\n",
       "     0.8080895008605852,\n",
       "     0.8161216293746415,\n",
       "     0.8162172499521897,\n",
       "     0.7882004207305412,\n",
       "     0.8041690571811054,\n",
       "     0.8042168674698796,\n",
       "     0.8081851214381336,\n",
       "     0.8082329317269076,\n",
       "     0.8122011856951618,\n",
       "     0.8122011856951615,\n",
       "     0.8122011856951615,\n",
       "     0.8041212468923313,\n",
       "     0.8002008032128515,\n",
       "     0.7961369286670491,\n",
       "     0.792120864410021,\n",
       "     0.8041212468923313,\n",
       "     0.8001529929240773,\n",
       "     0.8081373111493594,\n",
       "     0.7921686746987951,\n",
       "     0.8001051826353032,\n",
       "     0.8001529929240773,\n",
       "     0.8121533754063875,\n",
       "     0.8001529929240773,\n",
       "     0.8121055651176133,\n",
       "     0.8120577548288391,\n",
       "     0.8080895008605852,\n",
       "     0.8080895008605852,\n",
       "     0.8081373111493594,\n",
       "     0.8120577548288391,\n",
       "     0.8202333142092177,\n",
       "     0.8081851214381336,\n",
       "     0.7922164849875694,\n",
       "     0.8041690571811054,\n",
       "     0.8082329317269078,\n",
       "     0.7922164849875694,\n",
       "     0.8041690571811054,\n",
       "     0.8002008032128515,\n",
       "     0.8122011856951615,\n",
       "     0.8001529929240773,\n",
       "     0.7960891183782751,\n",
       "     0.7961369286670491,\n",
       "     0.7961369286670491,\n",
       "     0.7921686746987953,\n",
       "     0.8080895008605853,\n",
       "     0.8040734366035571,\n",
       "     0.7961369286670491,\n",
       "     0.8001529929240773,\n",
       "     0.8042168674698796,\n",
       "     0.7961369286670491,\n",
       "     0.8041212468923313,\n",
       "     0.8121055651176133,\n",
       "     0.8001529929240773,\n",
       "     0.8041212468923312,\n",
       "     0.8120577548288391,\n",
       "     0.804025626314783,\n",
       "     0.804073436603557,\n",
       "     0.7881526104417671,\n",
       "     0.8082329317269076,\n",
       "     0.7961847389558233,\n",
       "     0.8082329317269076,\n",
       "     0.8082329317269078,\n",
       "     0.8002008032128515,\n",
       "     0.8081373111493594,\n",
       "     0.7922642952763436,\n",
       "     0.8042168674698796,\n",
       "     0.7961369286670492,\n",
       "     0.7961369286670491,\n",
       "     0.7921686746987951,\n",
       "     0.8081373111493594,\n",
       "     0.7961847389558233,\n",
       "     0.8041212468923313,\n",
       "     0.8042168674698796,\n",
       "     0.8080895008605853,\n",
       "     0.8001529929240773],\n",
       "    'std_test_score': [0.04374100584496378,\n",
       "     0.015754052401650953,\n",
       "     0.03583648252525049,\n",
       "     0.019298781631157967,\n",
       "     0.021433624941301903,\n",
       "     0.030354149530982803,\n",
       "     0.019298781631157967,\n",
       "     0.024700481347443227,\n",
       "     0.013882448230135241,\n",
       "     0.023644786041302233,\n",
       "     0.04394907322348974,\n",
       "     0.03850459124085797,\n",
       "     0.04503658146332975,\n",
       "     0.03957912318158038,\n",
       "     0.041402495480509116,\n",
       "     0.027113197480952905,\n",
       "     0.027113197480952905,\n",
       "     0.03590345778928003,\n",
       "     0.033269159690323076,\n",
       "     0.03022071675359922,\n",
       "     0.03022071675359922,\n",
       "     0.023583318486249394,\n",
       "     0.024700481347443227,\n",
       "     0.03576950966442519,\n",
       "     0.024700481347443227,\n",
       "     0.030287431151846535,\n",
       "     0.033269159690323076,\n",
       "     0.028291170288364184,\n",
       "     0.019233408296912956,\n",
       "     0.018688013852829553,\n",
       "     0.01863055981770456,\n",
       "     0.023583318486249394,\n",
       "     0.019298781631157967,\n",
       "     0.027045583522147552,\n",
       "     0.01582166636045631,\n",
       "     0.023644786041302233,\n",
       "     0.0396446189494926,\n",
       "     0.03576950966442519,\n",
       "     0.030287431151846535,\n",
       "     0.03957912318158038,\n",
       "     0.03272515606179855,\n",
       "     0.04374100584496378,\n",
       "     0.03590345778928003,\n",
       "     0.03590345778928003,\n",
       "     0.03590345778928003,\n",
       "     0.023583318486249394,\n",
       "     0.03583648252525049,\n",
       "     0.024700481347443227,\n",
       "     0.023521884660962788,\n",
       "     0.023583318486249394,\n",
       "     0.0287790934664894,\n",
       "     0.028406635059406462,\n",
       "     0.03022071675359922,\n",
       "     0.019233408296912956,\n",
       "     0.0287790934664894,\n",
       "     0.028842643955445977,\n",
       "     0.03344479210357498,\n",
       "     0.019298781631157967,\n",
       "     0.010209707779610661,\n",
       "     0.01582166636045631,\n",
       "     0.018630559817704565,\n",
       "     0.024766744840599337,\n",
       "     0.010209707779610661,\n",
       "     0.04153676883366946,\n",
       "     0.03818411148720054,\n",
       "     0.039513634549226274,\n",
       "     0.030287431151846535,\n",
       "     0.041469631381653396,\n",
       "     0.039513634549226274,\n",
       "     0.033329772744151595,\n",
       "     0.03583648252525049,\n",
       "     0.03850459124085797,\n",
       "     0.0287790934664894,\n",
       "     0.015754052401650953,\n",
       "     0.024700481347443227,\n",
       "     0.024700481347443227,\n",
       "     0.033269159690323076,\n",
       "     0.01863055981770456,\n",
       "     0.013882448230135241,\n",
       "     0.024700481347443227,\n",
       "     0.0287790934664894,\n",
       "     0.03957912318158038,\n",
       "     0.024700481347443227,\n",
       "     0.023583318486249394,\n",
       "     0.019298781631157967,\n",
       "     0.0287790934664894,\n",
       "     0.023583318486249394,\n",
       "     0.010209707779610661,\n",
       "     0.00453013523995971,\n",
       "     0.013882448230135241,\n",
       "     0.026977969563342197,\n",
       "     0.04374100584496378,\n",
       "     0.032657542102993146,\n",
       "     0.041469631381653396,\n",
       "     0.041469631381653396,\n",
       "     0.03583648252525049,\n",
       "     0.024766744840599337,\n",
       "     0.04697944170028874,\n",
       "     0.03833711464264415,\n",
       "     0.028348880827897535,\n",
       "     0.024700481347443227,\n",
       "     0.03022071675359922,\n",
       "     0.024766744840599337,\n",
       "     0.03410700351699404,\n",
       "     0.023583318486249394,\n",
       "     0.043090891031877375,\n",
       "     0.01863055981770456,\n",
       "     0.0287790934664894],\n",
       "    'rank_test_score': [26,\n",
       "     92,\n",
       "     65,\n",
       "     16,\n",
       "     57,\n",
       "     4,\n",
       "     16,\n",
       "     83,\n",
       "     59,\n",
       "     5,\n",
       "     63,\n",
       "     8,\n",
       "     63,\n",
       "     42,\n",
       "     79,\n",
       "     13,\n",
       "     13,\n",
       "     8,\n",
       "     97,\n",
       "     100,\n",
       "     100,\n",
       "     51,\n",
       "     83,\n",
       "     105,\n",
       "     83,\n",
       "     47,\n",
       "     97,\n",
       "     108,\n",
       "     77,\n",
       "     2,\n",
       "     36,\n",
       "     51,\n",
       "     16,\n",
       "     69,\n",
       "     39,\n",
       "     5,\n",
       "     3,\n",
       "     105,\n",
       "     47,\n",
       "     42,\n",
       "     30,\n",
       "     26,\n",
       "     7,\n",
       "     8,\n",
       "     8,\n",
       "     51,\n",
       "     65,\n",
       "     83,\n",
       "     104,\n",
       "     51,\n",
       "     69,\n",
       "     32,\n",
       "     100,\n",
       "     77,\n",
       "     69,\n",
       "     13,\n",
       "     69,\n",
       "     16,\n",
       "     21,\n",
       "     39,\n",
       "     39,\n",
       "     32,\n",
       "     21,\n",
       "     1,\n",
       "     30,\n",
       "     95,\n",
       "     47,\n",
       "     24,\n",
       "     95,\n",
       "     47,\n",
       "     65,\n",
       "     8,\n",
       "     69,\n",
       "     92,\n",
       "     83,\n",
       "     83,\n",
       "     97,\n",
       "     36,\n",
       "     59,\n",
       "     83,\n",
       "     69,\n",
       "     42,\n",
       "     83,\n",
       "     51,\n",
       "     16,\n",
       "     69,\n",
       "     57,\n",
       "     21,\n",
       "     62,\n",
       "     61,\n",
       "     107,\n",
       "     26,\n",
       "     80,\n",
       "     26,\n",
       "     24,\n",
       "     65,\n",
       "     32,\n",
       "     94,\n",
       "     42,\n",
       "     82,\n",
       "     83,\n",
       "     100,\n",
       "     32,\n",
       "     80,\n",
       "     51,\n",
       "     42,\n",
       "     36,\n",
       "     69]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__max_depth': 20,\n",
       "    'classifier__min_samples_leaf': 1,\n",
       "    'classifier__min_samples_split': 2,\n",
       "    'classifier__n_estimators': 100},\n",
       "   'best_validation_accuracy': 0.8399917704709535,\n",
       "   'train_accuracy': 0.995,\n",
       "   'test_accuracy': 0.85,\n",
       "   'cv_results': {'mean_fit_time': [0.21507390340169272,\n",
       "     0.4669329325358073,\n",
       "     0.692590077718099,\n",
       "     0.2532164255777995,\n",
       "     0.5166800816853842,\n",
       "     0.755584716796875,\n",
       "     0.2803022861480713,\n",
       "     0.48697733879089355,\n",
       "     0.718412717183431,\n",
       "     0.2713727156321208,\n",
       "     0.5211548805236816,\n",
       "     0.793188730875651,\n",
       "     0.2420960267384847,\n",
       "     0.4686916669209798,\n",
       "     0.7280387878417969,\n",
       "     0.26662405331929523,\n",
       "     0.5118978023529053,\n",
       "     0.7496067682902018,\n",
       "     0.24674002329508463,\n",
       "     0.4601450761159261,\n",
       "     0.7197540601094564,\n",
       "     0.2545943260192871,\n",
       "     0.4680359363555908,\n",
       "     0.6847980817159017,\n",
       "     0.26468634605407715,\n",
       "     0.49475804964701336,\n",
       "     0.7478233973185221,\n",
       "     0.24775091807047525,\n",
       "     0.4745064576466878,\n",
       "     0.7163011233011881,\n",
       "     0.26268625259399414,\n",
       "     0.4967193603515625,\n",
       "     0.7841009298960367,\n",
       "     0.2549355824788411,\n",
       "     0.45203081766764325,\n",
       "     0.746737003326416,\n",
       "     0.2516183853149414,\n",
       "     0.48221707344055176,\n",
       "     0.7540350755055746,\n",
       "     0.27119604746500653,\n",
       "     0.48928189277648926,\n",
       "     0.7062716484069824,\n",
       "     0.25570329030354816,\n",
       "     0.4792579809824626,\n",
       "     0.722308874130249,\n",
       "     0.23863045374552408,\n",
       "     0.45658055941263836,\n",
       "     0.7423064708709717,\n",
       "     0.2574914296468099,\n",
       "     0.4842525323232015,\n",
       "     0.6669517358144125,\n",
       "     0.2644108136494954,\n",
       "     0.5273857911427816,\n",
       "     0.7165501117706299,\n",
       "     0.2665647665659587,\n",
       "     0.5345760981241862,\n",
       "     0.7662801742553711,\n",
       "     0.2573692003885905,\n",
       "     0.4648071924845378,\n",
       "     0.7690307299296061,\n",
       "     0.27315505345662433,\n",
       "     0.4674081802368164,\n",
       "     0.7214938799540201,\n",
       "     0.26867175102233887,\n",
       "     0.4995256265004476,\n",
       "     0.6941433747609457,\n",
       "     0.2645053068796794,\n",
       "     0.49495331446329754,\n",
       "     0.7448694705963135,\n",
       "     0.25602149963378906,\n",
       "     0.4988527297973633,\n",
       "     0.6772753397623698,\n",
       "     0.26892773310343426,\n",
       "     0.4592893123626709,\n",
       "     0.741479237874349,\n",
       "     0.27059610684712726,\n",
       "     0.4603722890218099,\n",
       "     0.7072757879892985,\n",
       "     0.24425164858500162,\n",
       "     0.4896994431813558,\n",
       "     0.7006243069966634,\n",
       "     0.2601870695749919,\n",
       "     0.4861751397450765,\n",
       "     0.795894463857015,\n",
       "     0.29380114873250324,\n",
       "     0.4954389731089274,\n",
       "     0.7689797878265381,\n",
       "     0.2681125005086263,\n",
       "     0.4986327489217122,\n",
       "     0.732312281926473,\n",
       "     0.2719395160675049,\n",
       "     0.5018893082936605,\n",
       "     0.8062237898508707,\n",
       "     0.2534663677215576,\n",
       "     0.4661884307861328,\n",
       "     0.7336252530415853,\n",
       "     0.2550913492838542,\n",
       "     0.4643060366312663,\n",
       "     0.7218894163767496,\n",
       "     0.26155638694763184,\n",
       "     0.49901994069417316,\n",
       "     0.7588942845662435,\n",
       "     0.24358534812927246,\n",
       "     0.48680996894836426,\n",
       "     0.6778452396392822,\n",
       "     0.2465395132700602,\n",
       "     0.44725743929545086,\n",
       "     0.541415294011434],\n",
       "    'std_fit_time': [0.0010994145923561745,\n",
       "     0.016842650018295012,\n",
       "     0.03210825756550951,\n",
       "     0.01608545772218771,\n",
       "     0.03436664183955619,\n",
       "     0.05057732514841114,\n",
       "     0.023277197513680445,\n",
       "     0.032890480619372234,\n",
       "     0.012926745728115887,\n",
       "     0.0173349902051694,\n",
       "     0.02861805257401284,\n",
       "     0.019489052053155858,\n",
       "     0.005959837388853711,\n",
       "     0.013212491668704925,\n",
       "     0.05033698417136122,\n",
       "     0.027897949485470322,\n",
       "     0.02643850957119894,\n",
       "     0.042294026662257324,\n",
       "     0.01293118943436146,\n",
       "     0.007272027204706472,\n",
       "     0.0554185095529315,\n",
       "     0.0055376873212679,\n",
       "     0.026464959495043412,\n",
       "     0.036571312159051905,\n",
       "     0.007148806544809578,\n",
       "     0.03648733312769869,\n",
       "     0.012278000680638852,\n",
       "     0.01294421013208887,\n",
       "     0.014807376201543215,\n",
       "     0.04479859019608971,\n",
       "     0.013852965682800245,\n",
       "     0.036927058125222456,\n",
       "     0.023918109517701784,\n",
       "     0.008002314802980984,\n",
       "     0.021938765389610957,\n",
       "     0.04862540275017107,\n",
       "     0.025947539658460226,\n",
       "     0.042074264437382186,\n",
       "     0.01967770971139559,\n",
       "     0.010402027925343966,\n",
       "     0.030928772462597863,\n",
       "     0.04160717964000296,\n",
       "     0.014885561823527212,\n",
       "     0.026361394316231728,\n",
       "     0.033047843567146754,\n",
       "     0.01893041511659229,\n",
       "     0.02196500315397756,\n",
       "     0.0506213885496542,\n",
       "     0.013191000491859235,\n",
       "     0.03607467762216388,\n",
       "     0.014877204828776015,\n",
       "     0.0034797515871623037,\n",
       "     0.014756904167018336,\n",
       "     0.04929561583242725,\n",
       "     0.01826961960941779,\n",
       "     0.03684623605897194,\n",
       "     0.05099206627253261,\n",
       "     0.021319028223361746,\n",
       "     0.012046169127647981,\n",
       "     0.013526681552006571,\n",
       "     0.014207998170946421,\n",
       "     0.015184030174932736,\n",
       "     0.033503718366692886,\n",
       "     0.020975530832642898,\n",
       "     0.02550092406499134,\n",
       "     0.00807888173911745,\n",
       "     0.007366201400185066,\n",
       "     0.02370141293449315,\n",
       "     0.04768482666787995,\n",
       "     0.020521499217280144,\n",
       "     0.029272808542693318,\n",
       "     0.02698429966668284,\n",
       "     0.016078371675152595,\n",
       "     0.0184359383762441,\n",
       "     0.004382068012693028,\n",
       "     0.021584147156726984,\n",
       "     0.014103494081551706,\n",
       "     0.05599388685411832,\n",
       "     0.020081955812516747,\n",
       "     0.02675363424817326,\n",
       "     0.02476692904262241,\n",
       "     0.017508461329056837,\n",
       "     0.01864289460050566,\n",
       "     0.0643889786098537,\n",
       "     0.028650063962279253,\n",
       "     0.011487200792857727,\n",
       "     0.047945885519861536,\n",
       "     0.010753198031566468,\n",
       "     0.035333708941471476,\n",
       "     0.07254296039054672,\n",
       "     0.01483682960982813,\n",
       "     0.027864991777920938,\n",
       "     0.01914498130065628,\n",
       "     0.006389778014212887,\n",
       "     0.01603985536225197,\n",
       "     0.05615692862998628,\n",
       "     0.01780771652134195,\n",
       "     0.0006770806780588114,\n",
       "     0.02765344646149274,\n",
       "     0.010059168465174826,\n",
       "     0.04550930170110641,\n",
       "     0.01065691622619487,\n",
       "     0.005623499641136325,\n",
       "     0.03858937461298908,\n",
       "     0.026745494085313615,\n",
       "     0.009782158724510801,\n",
       "     0.011984223076565407,\n",
       "     0.009434677154259647],\n",
       "    'mean_score_time': [0.028447071711222332,\n",
       "     0.033425092697143555,\n",
       "     0.050272067387898765,\n",
       "     0.026935418446858723,\n",
       "     0.04013911883036295,\n",
       "     0.0547341505686442,\n",
       "     0.02326210339864095,\n",
       "     0.03606843948364258,\n",
       "     0.056438048680623375,\n",
       "     0.025041739145914715,\n",
       "     0.03154293696085612,\n",
       "     0.05686759948730469,\n",
       "     0.018488725026448567,\n",
       "     0.03859361012776693,\n",
       "     0.04939079284667969,\n",
       "     0.03129108746846517,\n",
       "     0.031398932139078774,\n",
       "     0.06071694691975912,\n",
       "     0.02334419886271159,\n",
       "     0.03373638788859049,\n",
       "     0.05590923627217611,\n",
       "     0.030536095301310223,\n",
       "     0.042106072107950844,\n",
       "     0.05611824989318848,\n",
       "     0.023244698842366535,\n",
       "     0.043606201807657875,\n",
       "     0.04784289995829264,\n",
       "     0.029221614201863606,\n",
       "     0.03560821215311686,\n",
       "     0.0523987611134847,\n",
       "     0.026433865229288738,\n",
       "     0.03561083475748698,\n",
       "     0.054614623387654625,\n",
       "     0.023693243662516277,\n",
       "     0.0408471425374349,\n",
       "     0.0549315611521403,\n",
       "     0.026053508122762043,\n",
       "     0.03128933906555176,\n",
       "     0.05674004554748535,\n",
       "     0.016866207122802734,\n",
       "     0.04433337847391764,\n",
       "     0.05302111307779948,\n",
       "     0.018137772878011067,\n",
       "     0.0366206963857015,\n",
       "     0.054235219955444336,\n",
       "     0.020970900853474934,\n",
       "     0.044310569763183594,\n",
       "     0.05289777119954427,\n",
       "     0.03252204259236654,\n",
       "     0.04191184043884277,\n",
       "     0.06303882598876953,\n",
       "     0.02602561314900716,\n",
       "     0.04181750615437826,\n",
       "     0.058097124099731445,\n",
       "     0.02722764015197754,\n",
       "     0.046561479568481445,\n",
       "     0.05957277615865072,\n",
       "     0.032975991566975914,\n",
       "     0.03836743036905924,\n",
       "     0.05249905586242676,\n",
       "     0.015641530354817707,\n",
       "     0.0323179562886556,\n",
       "     0.052516778310139976,\n",
       "     0.02248064676920573,\n",
       "     0.03573791186014811,\n",
       "     0.050065199534098305,\n",
       "     0.02604389190673828,\n",
       "     0.03692181905110677,\n",
       "     0.05048815409342448,\n",
       "     0.026056925455729168,\n",
       "     0.034699201583862305,\n",
       "     0.06534242630004883,\n",
       "     0.02449337641398112,\n",
       "     0.03086678187052409,\n",
       "     0.053832451502482094,\n",
       "     0.026979843775431316,\n",
       "     0.04447325070699056,\n",
       "     0.05588221549987793,\n",
       "     0.022499720255533855,\n",
       "     0.03673219680786133,\n",
       "     0.05081017812093099,\n",
       "     0.03179272015889486,\n",
       "     0.03350957234700521,\n",
       "     0.048703511555989586,\n",
       "     0.0240476131439209,\n",
       "     0.04383730888366699,\n",
       "     0.059848626454671226,\n",
       "     0.026345252990722656,\n",
       "     0.04341499010721842,\n",
       "     0.06001909573872884,\n",
       "     0.02422618865966797,\n",
       "     0.03318031628926595,\n",
       "     0.056049187978108726,\n",
       "     0.016881783803304035,\n",
       "     0.03127098083496094,\n",
       "     0.06398614247639973,\n",
       "     0.03042300542195638,\n",
       "     0.03629016876220703,\n",
       "     0.045124451319376625,\n",
       "     0.020328998565673828,\n",
       "     0.025719165802001953,\n",
       "     0.043121894200642906,\n",
       "     0.022133270899454754,\n",
       "     0.040929714838663735,\n",
       "     0.0426485538482666,\n",
       "     0.01784515380859375,\n",
       "     0.026978095372517902,\n",
       "     0.028665622075398762],\n",
       "    'std_score_time': [0.002091704639514637,\n",
       "     0.0027261104854827177,\n",
       "     0.0049219310800474965,\n",
       "     0.008813788536912425,\n",
       "     0.006332273033024262,\n",
       "     0.005377472500496542,\n",
       "     0.006374659347657106,\n",
       "     0.009767328568302307,\n",
       "     0.004732743221832595,\n",
       "     0.004423331805585341,\n",
       "     0.00019297637038188014,\n",
       "     0.009095776796012194,\n",
       "     0.0020198092694113795,\n",
       "     0.0057393730870275534,\n",
       "     0.0032556748478884787,\n",
       "     0.001341415931900322,\n",
       "     0.00018876823518046033,\n",
       "     0.0018019053110033723,\n",
       "     0.0064220744319693325,\n",
       "     0.00321609419275673,\n",
       "     0.003469271240643772,\n",
       "     0.006634049998986601,\n",
       "     0.008426068106180646,\n",
       "     0.00913418516875638,\n",
       "     0.0004712579621498098,\n",
       "     0.0023103827665194835,\n",
       "     0.006703092289624894,\n",
       "     0.002883766442937369,\n",
       "     0.01239558566361503,\n",
       "     0.007462562172141899,\n",
       "     0.007354514220009522,\n",
       "     0.002783792416156865,\n",
       "     0.006415630482956079,\n",
       "     0.006388808124186135,\n",
       "     0.007957033140468675,\n",
       "     0.012711183853246983,\n",
       "     0.007373228672818842,\n",
       "     6.410253472541209e-05,\n",
       "     0.008439169581144665,\n",
       "     0.007750275067294745,\n",
       "     0.007075489246184752,\n",
       "     0.0007865493686202944,\n",
       "     0.00204320940880125,\n",
       "     0.004181533236248356,\n",
       "     0.009755148924761311,\n",
       "     0.007269111561143276,\n",
       "     0.006075814876840754,\n",
       "     0.008306336522876531,\n",
       "     0.0012061866085837725,\n",
       "     0.007545132261478217,\n",
       "     0.0012270712121145982,\n",
       "     0.004553539551628703,\n",
       "     0.00745839965569857,\n",
       "     0.007241200118956663,\n",
       "     0.00435576255966638,\n",
       "     0.009315148154404835,\n",
       "     0.008955853547343073,\n",
       "     0.0022006267011627167,\n",
       "     0.0063465019060283505,\n",
       "     0.007925293393988514,\n",
       "     8.689113425316244e-06,\n",
       "     0.0015140271901073427,\n",
       "     0.004094825282961224,\n",
       "     0.00654675242227565,\n",
       "     0.0031964705445807853,\n",
       "     0.005922791041601313,\n",
       "     0.007366426188521473,\n",
       "     0.003896216229635059,\n",
       "     0.009873197415527236,\n",
       "     0.003702765663133056,\n",
       "     0.0091817887508371,\n",
       "     0.0027093466253946164,\n",
       "     0.00847263331479334,\n",
       "     0.007351625517428505,\n",
       "     0.007290027085146776,\n",
       "     0.008120723944372004,\n",
       "     0.004423934664774129,\n",
       "     0.006331822109344201,\n",
       "     0.006512207151982761,\n",
       "     0.007464440358471092,\n",
       "     0.002949504911728643,\n",
       "     0.0043286316206306245,\n",
       "     0.001335411674113999,\n",
       "     0.001941910777779913,\n",
       "     0.00798435560229189,\n",
       "     0.0041121837155109085,\n",
       "     0.008586043587043303,\n",
       "     0.007283477431583205,\n",
       "     0.005857879610667999,\n",
       "     0.008821674427278528,\n",
       "     0.0025858734739391803,\n",
       "     0.002855656288221025,\n",
       "     0.008970940068606376,\n",
       "     0.0011972681928873858,\n",
       "     0.0,\n",
       "     0.0011436317427960232,\n",
       "     0.006953595229370229,\n",
       "     0.001532867948454622,\n",
       "     0.005510822039780867,\n",
       "     0.008314393099441087,\n",
       "     0.004779073440061378,\n",
       "     0.0075763037690617435,\n",
       "     0.006692822598234644,\n",
       "     0.009439856202119783,\n",
       "     0.008091703698736718,\n",
       "     0.00028052942368851066,\n",
       "     0.0046766587094251395,\n",
       "     0.005303887998516605],\n",
       "    'param_classifier__max_depth': [None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30],\n",
       "    'param_classifier__min_samples_leaf': [1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10],\n",
       "    'param_classifier__n_estimators': [100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300],\n",
       "    'params': [{'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300}],\n",
       "    'split0_test_score': [0.835820895522388,\n",
       "     0.8507462686567164,\n",
       "     0.8507462686567164,\n",
       "     0.8208955223880597,\n",
       "     0.8507462686567164,\n",
       "     0.835820895522388,\n",
       "     0.835820895522388,\n",
       "     0.8432835820895522,\n",
       "     0.8507462686567164,\n",
       "     0.8208955223880597,\n",
       "     0.8208955223880597,\n",
       "     0.8283582089552238,\n",
       "     0.8208955223880597,\n",
       "     0.835820895522388,\n",
       "     0.835820895522388,\n",
       "     0.8134328358208955,\n",
       "     0.8134328358208955,\n",
       "     0.8134328358208955,\n",
       "     0.8059701492537313,\n",
       "     0.8208955223880597,\n",
       "     0.8134328358208955,\n",
       "     0.8283582089552238,\n",
       "     0.8208955223880597,\n",
       "     0.8134328358208955,\n",
       "     0.8059701492537313,\n",
       "     0.8208955223880597,\n",
       "     0.8134328358208955,\n",
       "     0.8432835820895522,\n",
       "     0.8134328358208955,\n",
       "     0.8283582089552238,\n",
       "     0.8208955223880597,\n",
       "     0.8208955223880597,\n",
       "     0.8208955223880597,\n",
       "     0.8208955223880597,\n",
       "     0.8059701492537313,\n",
       "     0.8059701492537313,\n",
       "     0.8134328358208955,\n",
       "     0.8208955223880597,\n",
       "     0.8134328358208955,\n",
       "     0.835820895522388,\n",
       "     0.8059701492537313,\n",
       "     0.8059701492537313,\n",
       "     0.8134328358208955,\n",
       "     0.8134328358208955,\n",
       "     0.8059701492537313,\n",
       "     0.8208955223880597,\n",
       "     0.8134328358208955,\n",
       "     0.8134328358208955,\n",
       "     0.8134328358208955,\n",
       "     0.8208955223880597,\n",
       "     0.8283582089552238,\n",
       "     0.8283582089552238,\n",
       "     0.8283582089552238,\n",
       "     0.8134328358208955,\n",
       "     0.8432835820895522,\n",
       "     0.8507462686567164,\n",
       "     0.8507462686567164,\n",
       "     0.8283582089552238,\n",
       "     0.8432835820895522,\n",
       "     0.8507462686567164,\n",
       "     0.835820895522388,\n",
       "     0.8283582089552238,\n",
       "     0.8283582089552238,\n",
       "     0.8208955223880597,\n",
       "     0.8208955223880597,\n",
       "     0.8283582089552238,\n",
       "     0.8283582089552238,\n",
       "     0.8283582089552238,\n",
       "     0.8208955223880597,\n",
       "     0.8134328358208955,\n",
       "     0.8059701492537313,\n",
       "     0.8208955223880597,\n",
       "     0.8208955223880597,\n",
       "     0.8059701492537313,\n",
       "     0.8134328358208955,\n",
       "     0.8059701492537313,\n",
       "     0.8208955223880597,\n",
       "     0.8134328358208955,\n",
       "     0.8208955223880597,\n",
       "     0.8208955223880597,\n",
       "     0.8208955223880597,\n",
       "     0.8507462686567164,\n",
       "     0.8432835820895522,\n",
       "     0.8507462686567164,\n",
       "     0.835820895522388,\n",
       "     0.835820895522388,\n",
       "     0.8283582089552238,\n",
       "     0.7985074626865671,\n",
       "     0.835820895522388,\n",
       "     0.8134328358208955,\n",
       "     0.8208955223880597,\n",
       "     0.8208955223880597,\n",
       "     0.8283582089552238,\n",
       "     0.8134328358208955,\n",
       "     0.8134328358208955,\n",
       "     0.8059701492537313,\n",
       "     0.8134328358208955,\n",
       "     0.8208955223880597,\n",
       "     0.8208955223880597,\n",
       "     0.8283582089552238,\n",
       "     0.8134328358208955,\n",
       "     0.8134328358208955,\n",
       "     0.8059701492537313,\n",
       "     0.8059701492537313,\n",
       "     0.8059701492537313,\n",
       "     0.8134328358208955,\n",
       "     0.8208955223880597,\n",
       "     0.8134328358208955],\n",
       "    'split1_test_score': [0.8195488721804511,\n",
       "     0.8571428571428571,\n",
       "     0.8571428571428571,\n",
       "     0.8571428571428571,\n",
       "     0.849624060150376,\n",
       "     0.8270676691729323,\n",
       "     0.849624060150376,\n",
       "     0.8421052631578947,\n",
       "     0.8571428571428571,\n",
       "     0.8120300751879699,\n",
       "     0.8270676691729323,\n",
       "     0.8345864661654135,\n",
       "     0.849624060150376,\n",
       "     0.8345864661654135,\n",
       "     0.8421052631578947,\n",
       "     0.8195488721804511,\n",
       "     0.849624060150376,\n",
       "     0.8195488721804511,\n",
       "     0.8195488721804511,\n",
       "     0.8270676691729323,\n",
       "     0.8270676691729323,\n",
       "     0.8120300751879699,\n",
       "     0.8195488721804511,\n",
       "     0.8195488721804511,\n",
       "     0.8270676691729323,\n",
       "     0.8270676691729323,\n",
       "     0.8195488721804511,\n",
       "     0.8345864661654135,\n",
       "     0.8195488721804511,\n",
       "     0.8421052631578947,\n",
       "     0.8646616541353384,\n",
       "     0.8646616541353384,\n",
       "     0.8345864661654135,\n",
       "     0.849624060150376,\n",
       "     0.8345864661654135,\n",
       "     0.849624060150376,\n",
       "     0.8270676691729323,\n",
       "     0.8195488721804511,\n",
       "     0.8571428571428571,\n",
       "     0.8270676691729323,\n",
       "     0.8120300751879699,\n",
       "     0.8270676691729323,\n",
       "     0.8421052631578947,\n",
       "     0.8270676691729323,\n",
       "     0.8195488721804511,\n",
       "     0.8195488721804511,\n",
       "     0.8120300751879699,\n",
       "     0.8195488721804511,\n",
       "     0.8345864661654135,\n",
       "     0.8195488721804511,\n",
       "     0.8195488721804511,\n",
       "     0.8345864661654135,\n",
       "     0.8345864661654135,\n",
       "     0.8270676691729323,\n",
       "     0.8796992481203008,\n",
       "     0.8421052631578947,\n",
       "     0.8345864661654135,\n",
       "     0.8120300751879699,\n",
       "     0.8345864661654135,\n",
       "     0.8421052631578947,\n",
       "     0.8345864661654135,\n",
       "     0.849624060150376,\n",
       "     0.8270676691729323,\n",
       "     0.8345864661654135,\n",
       "     0.8195488721804511,\n",
       "     0.8345864661654135,\n",
       "     0.8421052631578947,\n",
       "     0.8270676691729323,\n",
       "     0.8345864661654135,\n",
       "     0.8345864661654135,\n",
       "     0.8345864661654135,\n",
       "     0.8345864661654135,\n",
       "     0.8045112781954887,\n",
       "     0.8120300751879699,\n",
       "     0.8195488721804511,\n",
       "     0.8270676691729323,\n",
       "     0.8270676691729323,\n",
       "     0.8270676691729323,\n",
       "     0.849624060150376,\n",
       "     0.8345864661654135,\n",
       "     0.8345864661654135,\n",
       "     0.8270676691729323,\n",
       "     0.8646616541353384,\n",
       "     0.849624060150376,\n",
       "     0.8045112781954887,\n",
       "     0.8571428571428571,\n",
       "     0.8421052631578947,\n",
       "     0.8270676691729323,\n",
       "     0.8270676691729323,\n",
       "     0.8345864661654135,\n",
       "     0.849624060150376,\n",
       "     0.8195488721804511,\n",
       "     0.8270676691729323,\n",
       "     0.8270676691729323,\n",
       "     0.8270676691729323,\n",
       "     0.849624060150376,\n",
       "     0.8345864661654135,\n",
       "     0.8421052631578947,\n",
       "     0.8345864661654135,\n",
       "     0.8270676691729323,\n",
       "     0.8195488721804511,\n",
       "     0.8195488721804511,\n",
       "     0.8270676691729323,\n",
       "     0.8195488721804511,\n",
       "     0.8345864661654135,\n",
       "     0.8421052631578947,\n",
       "     0.8270676691729323,\n",
       "     0.8195488721804511],\n",
       "    'split2_test_score': [0.8045112781954887,\n",
       "     0.8045112781954887,\n",
       "     0.8120300751879699,\n",
       "     0.8195488721804511,\n",
       "     0.8120300751879699,\n",
       "     0.8120300751879699,\n",
       "     0.8045112781954887,\n",
       "     0.8045112781954887,\n",
       "     0.7969924812030075,\n",
       "     0.8045112781954887,\n",
       "     0.7894736842105263,\n",
       "     0.8120300751879699,\n",
       "     0.7969924812030075,\n",
       "     0.7894736842105263,\n",
       "     0.7894736842105263,\n",
       "     0.7969924812030075,\n",
       "     0.7969924812030075,\n",
       "     0.7819548872180451,\n",
       "     0.8045112781954887,\n",
       "     0.7819548872180451,\n",
       "     0.8045112781954887,\n",
       "     0.7894736842105263,\n",
       "     0.8045112781954887,\n",
       "     0.7969924812030075,\n",
       "     0.7669172932330827,\n",
       "     0.7819548872180451,\n",
       "     0.8270676691729323,\n",
       "     0.8195488721804511,\n",
       "     0.8045112781954887,\n",
       "     0.8045112781954887,\n",
       "     0.8045112781954887,\n",
       "     0.8045112781954887,\n",
       "     0.7819548872180451,\n",
       "     0.8195488721804511,\n",
       "     0.7894736842105263,\n",
       "     0.7969924812030075,\n",
       "     0.7894736842105263,\n",
       "     0.7969924812030075,\n",
       "     0.7969924812030075,\n",
       "     0.7894736842105263,\n",
       "     0.7744360902255639,\n",
       "     0.8120300751879699,\n",
       "     0.7969924812030075,\n",
       "     0.8045112781954887,\n",
       "     0.7894736842105263,\n",
       "     0.7969924812030075,\n",
       "     0.8045112781954887,\n",
       "     0.8120300751879699,\n",
       "     0.7819548872180451,\n",
       "     0.7894736842105263,\n",
       "     0.8045112781954887,\n",
       "     0.7969924812030075,\n",
       "     0.8045112781954887,\n",
       "     0.7969924812030075,\n",
       "     0.7969924812030075,\n",
       "     0.8120300751879699,\n",
       "     0.8195488721804511,\n",
       "     0.8045112781954887,\n",
       "     0.8045112781954887,\n",
       "     0.7969924812030075,\n",
       "     0.8195488721804511,\n",
       "     0.7969924812030075,\n",
       "     0.8120300751879699,\n",
       "     0.7894736842105263,\n",
       "     0.7744360902255639,\n",
       "     0.7894736842105263,\n",
       "     0.7894736842105263,\n",
       "     0.7819548872180451,\n",
       "     0.7819548872180451,\n",
       "     0.7969924812030075,\n",
       "     0.7894736842105263,\n",
       "     0.7744360902255639,\n",
       "     0.7593984962406015,\n",
       "     0.8045112781954887,\n",
       "     0.7819548872180451,\n",
       "     0.7969924812030075,\n",
       "     0.7969924812030075,\n",
       "     0.7894736842105263,\n",
       "     0.7969924812030075,\n",
       "     0.7969924812030075,\n",
       "     0.7969924812030075,\n",
       "     0.7969924812030075,\n",
       "     0.8045112781954887,\n",
       "     0.7894736842105263,\n",
       "     0.7969924812030075,\n",
       "     0.8195488721804511,\n",
       "     0.7894736842105263,\n",
       "     0.8270676691729323,\n",
       "     0.7894736842105263,\n",
       "     0.7894736842105263,\n",
       "     0.7819548872180451,\n",
       "     0.8120300751879699,\n",
       "     0.7819548872180451,\n",
       "     0.7969924812030075,\n",
       "     0.7894736842105263,\n",
       "     0.7819548872180451,\n",
       "     0.7819548872180451,\n",
       "     0.7894736842105263,\n",
       "     0.7969924812030075,\n",
       "     0.8045112781954887,\n",
       "     0.7969924812030075,\n",
       "     0.7969924812030075,\n",
       "     0.7894736842105263,\n",
       "     0.7894736842105263,\n",
       "     0.7894736842105263,\n",
       "     0.7669172932330827,\n",
       "     0.7969924812030075,\n",
       "     0.8120300751879699],\n",
       "    'mean_test_score': [0.819960348632776,\n",
       "     0.8374668013316874,\n",
       "     0.839973066995848,\n",
       "     0.8325290839037893,\n",
       "     0.8374668013316874,\n",
       "     0.8249728799610967,\n",
       "     0.8299854112894175,\n",
       "     0.8299667078143118,\n",
       "     0.834960535667527,\n",
       "     0.8124789585905061,\n",
       "     0.8124789585905061,\n",
       "     0.8249915834362024,\n",
       "     0.8225040212471478,\n",
       "     0.819960348632776,\n",
       "     0.8224666142969363,\n",
       "     0.8099913964014513,\n",
       "     0.8200164590580931,\n",
       "     0.8049788650731307,\n",
       "     0.810010099876557,\n",
       "     0.8099726929263458,\n",
       "     0.8150039277297721,\n",
       "     0.8099539894512399,\n",
       "     0.8149852242546665,\n",
       "     0.8099913964014513,\n",
       "     0.7999850372199154,\n",
       "     0.8099726929263458,\n",
       "     0.8200164590580931,\n",
       "     0.8324729734784723,\n",
       "     0.8124976620656118,\n",
       "     0.8249915834362024,\n",
       "     0.830022818239629,\n",
       "     0.830022818239629,\n",
       "     0.8124789585905061,\n",
       "     0.830022818239629,\n",
       "     0.810010099876557,\n",
       "     0.8175288968690383,\n",
       "     0.8099913964014513,\n",
       "     0.8124789585905061,\n",
       "     0.8225227247222534,\n",
       "     0.8174540829686157,\n",
       "     0.7974787715557551,\n",
       "     0.815022631204878,\n",
       "     0.8175101933939325,\n",
       "     0.8150039277297721,\n",
       "     0.8049975685482362,\n",
       "     0.8124789585905061,\n",
       "     0.8099913964014513,\n",
       "     0.8150039277297721,\n",
       "     0.8099913964014513,\n",
       "     0.8099726929263458,\n",
       "     0.8174727864437212,\n",
       "     0.8199790521078816,\n",
       "     0.822485317772042,\n",
       "     0.8124976620656118,\n",
       "     0.8399917704709535,\n",
       "     0.8349605356675269,\n",
       "     0.834960535667527,\n",
       "     0.8149665207795608,\n",
       "     0.8274604421501515,\n",
       "     0.8299480043392062,\n",
       "     0.8299854112894175,\n",
       "     0.8249915834362024,\n",
       "     0.8224853177720419,\n",
       "     0.8149852242546665,\n",
       "     0.804960161598025,\n",
       "     0.8174727864437212,\n",
       "     0.8199790521078816,\n",
       "     0.8124602551154004,\n",
       "     0.8124789585905061,\n",
       "     0.8150039277297721,\n",
       "     0.810010099876557,\n",
       "     0.8099726929263458,\n",
       "     0.7949350989413834,\n",
       "     0.8075038342123966,\n",
       "     0.8049788650731307,\n",
       "     0.810010099876557,\n",
       "     0.8149852242546665,\n",
       "     0.8099913964014513,\n",
       "     0.8225040212471478,\n",
       "     0.8174914899188269,\n",
       "     0.8174914899188269,\n",
       "     0.8249354730108854,\n",
       "     0.8374855048067932,\n",
       "     0.8299480043392062,\n",
       "     0.8124415516402949,\n",
       "     0.8375042082818988,\n",
       "     0.8199790521078816,\n",
       "     0.8175476003441439,\n",
       "     0.8174540829686157,\n",
       "     0.8124976620656117,\n",
       "     0.8174914899188269,\n",
       "     0.8174914899188268,\n",
       "     0.8124602551154004,\n",
       "     0.8124976620656118,\n",
       "     0.8099913964014513,\n",
       "     0.8125163655407174,\n",
       "     0.8099913964014513,\n",
       "     0.8174914899188268,\n",
       "     0.8174914899188269,\n",
       "     0.8199790521078816,\n",
       "     0.8099913964014513,\n",
       "     0.8099913964014513,\n",
       "     0.8075038342123966,\n",
       "     0.8049975685482362,\n",
       "     0.810010099876557,\n",
       "     0.807485130737291,\n",
       "     0.8149852242546665,\n",
       "     0.8150039277297721],\n",
       "    'std_test_score': [0.012785408843478088,\n",
       "     0.023448936933269163,\n",
       "     0.01993049889736174,\n",
       "     0.01741324671035626,\n",
       "     0.0179923153163749,\n",
       "     0.009824862659859695,\n",
       "     0.0188737989658015,\n",
       "     0.018006133800926836,\n",
       "     0.026974172287959678,\n",
       "     0.006696366510889995,\n",
       "     0.016461183350681263,\n",
       "     0.009511337761528611,\n",
       "     0.021516834139157733,\n",
       "     0.021563216900630983,\n",
       "     0.02347017108174552,\n",
       "     0.009524716004168788,\n",
       "     0.02198528063379822,\n",
       "     0.01647076485557471,\n",
       "     0.006771174639125125,\n",
       "     0.019971178007561558,\n",
       "     0.009275377470177966,\n",
       "     0.015942274307532953,\n",
       "     0.007426575084713803,\n",
       "     0.009524716004168788,\n",
       "     0.02491830794107425,\n",
       "     0.019971178007561558,\n",
       "     0.005576208284641726,\n",
       "     0.009804225351708006,\n",
       "     0.006174583423388334,\n",
       "     0.01553120626088856,\n",
       "     0.02539025506761553,\n",
       "     0.02539025506761553,\n",
       "     0.022295734797519576,\n",
       "     0.013871070134831746,\n",
       "     0.018637447513066303,\n",
       "     0.022988754648726878,\n",
       "     0.015539402719038236,\n",
       "     0.010964384861922812,\n",
       "     0.025383544428173425,\n",
       "     0.02010525269471409,\n",
       "     0.01648038324282677,\n",
       "     0.008869155552475827,\n",
       "     0.01864152010094851,\n",
       "     0.009275377470177966,\n",
       "     0.012297389093573304,\n",
       "     0.010964384861922812,\n",
       "     0.003917116797834344,\n",
       "     0.003264386046731151,\n",
       "     0.021624113154555775,\n",
       "     0.014505410150327662,\n",
       "     0.009845527771687,\n",
       "     0.016451638792587906,\n",
       "     0.012961413785892812,\n",
       "     0.01229593822693782,\n",
       "     0.03384503253829259,\n",
       "     0.016593598311016713,\n",
       "     0.01273903012317215,\n",
       "     0.009954431549120232,\n",
       "     0.016611402730513588,\n",
       "     0.023568575446882147,\n",
       "     0.007396934743035095,\n",
       "     0.021618223811748345,\n",
       "     0.007411722532640014,\n",
       "     0.01888543516304726,\n",
       "     0.021590778379649855,\n",
       "     0.019960963426443875,\n",
       "     0.022288688876162255,\n",
       "     0.021576985828225512,\n",
       "     0.022295734797519576,\n",
       "     0.015387834451886696,\n",
       "     0.018637447513066303,\n",
       "     0.025742287958578657,\n",
       "     0.02600318522893377,\n",
       "     0.0032554794032894807,\n",
       "     0.01647076485557471,\n",
       "     0.012606086721176395,\n",
       "     0.012969912641077457,\n",
       "     0.015539402719038236,\n",
       "     0.021516834139157733,\n",
       "     0.015535282512764224,\n",
       "     0.015535282512764224,\n",
       "     0.021996622646211172,\n",
       "     0.024896187212221147,\n",
       "     0.028623332910897168,\n",
       "     0.01681424727865064,\n",
       "     0.015393766762841599,\n",
       "     0.022288688876162255,\n",
       "     0.013463410452397876,\n",
       "     0.02010525269471409,\n",
       "     0.01842908365223708,\n",
       "     0.02773048646195638,\n",
       "     0.0039007396599644853,\n",
       "     0.021576985828225512,\n",
       "     0.01229593822693782,\n",
       "     0.015539402719038236,\n",
       "     0.028010937769538374,\n",
       "     0.021624113154555775,\n",
       "     0.02162115250415606,\n",
       "     0.015535282512764224,\n",
       "     0.01095005009383049,\n",
       "     0.009524716004168788,\n",
       "     0.009524716004168788,\n",
       "     0.015385947452198678,\n",
       "     0.012297389093573304,\n",
       "     0.018637447513066303,\n",
       "     0.030982135736310597,\n",
       "     0.012969912641077457,\n",
       "     0.003264386046731151],\n",
       "    'rank_test_score': [38,\n",
       "     5,\n",
       "     2,\n",
       "     10,\n",
       "     5,\n",
       "     24,\n",
       "     15,\n",
       "     17,\n",
       "     7,\n",
       "     69,\n",
       "     69,\n",
       "     21,\n",
       "     27,\n",
       "     38,\n",
       "     31,\n",
       "     83,\n",
       "     32,\n",
       "     103,\n",
       "     78,\n",
       "     93,\n",
       "     54,\n",
       "     97,\n",
       "     59,\n",
       "     83,\n",
       "     106,\n",
       "     93,\n",
       "     32,\n",
       "     11,\n",
       "     65,\n",
       "     21,\n",
       "     12,\n",
       "     12,\n",
       "     69,\n",
       "     12,\n",
       "     78,\n",
       "     41,\n",
       "     83,\n",
       "     69,\n",
       "     26,\n",
       "     51,\n",
       "     107,\n",
       "     53,\n",
       "     42,\n",
       "     54,\n",
       "     101,\n",
       "     69,\n",
       "     83,\n",
       "     54,\n",
       "     83,\n",
       "     93,\n",
       "     49,\n",
       "     34,\n",
       "     29,\n",
       "     65,\n",
       "     1,\n",
       "     9,\n",
       "     7,\n",
       "     63,\n",
       "     20,\n",
       "     18,\n",
       "     15,\n",
       "     21,\n",
       "     30,\n",
       "     59,\n",
       "     105,\n",
       "     49,\n",
       "     34,\n",
       "     75,\n",
       "     69,\n",
       "     54,\n",
       "     78,\n",
       "     93,\n",
       "     108,\n",
       "     98,\n",
       "     103,\n",
       "     78,\n",
       "     59,\n",
       "     83,\n",
       "     27,\n",
       "     43,\n",
       "     43,\n",
       "     25,\n",
       "     4,\n",
       "     18,\n",
       "     77,\n",
       "     3,\n",
       "     34,\n",
       "     40,\n",
       "     51,\n",
       "     68,\n",
       "     43,\n",
       "     47,\n",
       "     75,\n",
       "     65,\n",
       "     83,\n",
       "     64,\n",
       "     83,\n",
       "     47,\n",
       "     43,\n",
       "     34,\n",
       "     83,\n",
       "     83,\n",
       "     98,\n",
       "     101,\n",
       "     78,\n",
       "     100,\n",
       "     59,\n",
       "     54]}}],\n",
       " 'money SVM': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__C': 1},\n",
       "   'best_validation_accuracy': 0.7905525846702318,\n",
       "   'train_accuracy': 0.88,\n",
       "   'test_accuracy': 0.795,\n",
       "   'cv_results': {'mean_fit_time': [0.021259784698486328,\n",
       "     0.01063394546508789,\n",
       "     0.011021137237548828,\n",
       "     0.010164499282836914,\n",
       "     0.00927734375,\n",
       "     0.01252134641011556,\n",
       "     0.006513833999633789,\n",
       "     0.010429064432779947,\n",
       "     0.015643596649169922,\n",
       "     0.010422309239705404,\n",
       "     0.015623331069946289],\n",
       "    'std_fit_time': [0.002260756954124356,\n",
       "     0.0005930254673018353,\n",
       "     0.0006975449926573793,\n",
       "     0.0029956379199818197,\n",
       "     0.004996192786358334,\n",
       "     0.004247952763514002,\n",
       "     0.0,\n",
       "     0.0073744621818501365,\n",
       "     0.0,\n",
       "     0.007369690182970687,\n",
       "     0.0],\n",
       "    'mean_score_time': [0.006278594334920247,\n",
       "     0.003627300262451172,\n",
       "     0.0004315376281738281,\n",
       "     0.008178790410359701,\n",
       "     0.005175034205118815,\n",
       "     0.0,\n",
       "     0.015643596649169922,\n",
       "     0.005214532216389974,\n",
       "     0.015623331069946289,\n",
       "     0.01041555404663086,\n",
       "     0.0],\n",
       "    'std_score_time': [0.0003770738046774653,\n",
       "     0.0004690101302292288,\n",
       "     0.0006102863664377456,\n",
       "     0.0011773019684043066,\n",
       "     0.003798686543488598,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0073744621818501365,\n",
       "     0.0,\n",
       "     0.0073649088961876665,\n",
       "     0.0],\n",
       "    'param_classifier__C': [1e-07,\n",
       "     1e-06,\n",
       "     1e-05,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     1000.0],\n",
       "    'params': [{'classifier__C': 1e-07},\n",
       "     {'classifier__C': 1e-06},\n",
       "     {'classifier__C': 1e-05},\n",
       "     {'classifier__C': 0.0001},\n",
       "     {'classifier__C': 0.001},\n",
       "     {'classifier__C': 0.01},\n",
       "     {'classifier__C': 0.1},\n",
       "     {'classifier__C': 1},\n",
       "     {'classifier__C': 10},\n",
       "     {'classifier__C': 100},\n",
       "     {'classifier__C': 1000}],\n",
       "    'split0_test_score': [0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7352941176470589,\n",
       "     0.6470588235294118,\n",
       "     0.6470588235294118,\n",
       "     0.6470588235294118],\n",
       "    'split1_test_score': [0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485,\n",
       "     0.8484848484848485],\n",
       "    'split2_test_score': [0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.8181818181818182,\n",
       "     0.6666666666666666,\n",
       "     0.6666666666666666,\n",
       "     0.6666666666666666],\n",
       "    'mean_test_score': [0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7905525846702318,\n",
       "     0.7207367795603089,\n",
       "     0.7207367795603089,\n",
       "     0.7207367795603089],\n",
       "    'std_test_score': [0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.039073636750058774,\n",
       "     0.09068551414489334,\n",
       "     0.09068551414489334,\n",
       "     0.09068551414489334],\n",
       "    'rank_test_score': [2, 2, 2, 2, 2, 2, 2, 1, 9, 9, 9]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__C': 1},\n",
       "   'best_validation_accuracy': 0.8161216293746415,\n",
       "   'train_accuracy': 0.876,\n",
       "   'test_accuracy': 0.816,\n",
       "   'cv_results': {'mean_fit_time': [0.0052289168039957685,\n",
       "     0.01869797706604004,\n",
       "     0.01869797706604004,\n",
       "     0.009681383768717447,\n",
       "     0.00867764155069987,\n",
       "     0.01564955711364746,\n",
       "     0.01564955711364746,\n",
       "     0.015630642573038738,\n",
       "     0.015621185302734375,\n",
       "     0.01562643051147461,\n",
       "     0.01562643051147461],\n",
       "    'std_fit_time': [0.007394805060731394,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.004716513327359115,\n",
       "     0.006136019185206025,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     1.337459992745704e-05,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0],\n",
       "    'mean_score_time': [0.007236401240030925,\n",
       "     0.004338820775349935,\n",
       "     0.013016462326049805,\n",
       "     0.014771858851114908,\n",
       "     0.01564955711364746,\n",
       "     0.01041412353515625,\n",
       "     0.015621185302734375,\n",
       "     0.005207061767578125,\n",
       "     0.010417620340983072,\n",
       "     0.0,\n",
       "     0.010422388712565104],\n",
       "    'std_score_time': [0.00819726221783984,\n",
       "     0.006136019185206026,\n",
       "     0.0,\n",
       "     0.0012412527865448366,\n",
       "     0.0,\n",
       "     0.007363897371823405,\n",
       "     0.0,\n",
       "     0.007363897371823405,\n",
       "     0.007366369986936045,\n",
       "     0.0,\n",
       "     0.0073697417348169165],\n",
       "    'param_classifier__C': [1e-07,\n",
       "     1e-06,\n",
       "     1e-05,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     1000.0],\n",
       "    'params': [{'classifier__C': 1e-07},\n",
       "     {'classifier__C': 1e-06},\n",
       "     {'classifier__C': 1e-05},\n",
       "     {'classifier__C': 0.0001},\n",
       "     {'classifier__C': 0.001},\n",
       "     {'classifier__C': 0.01},\n",
       "     {'classifier__C': 0.1},\n",
       "     {'classifier__C': 1},\n",
       "     {'classifier__C': 10},\n",
       "     {'classifier__C': 100},\n",
       "     {'classifier__C': 1000}],\n",
       "    'split0_test_score': [0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7857142857142857,\n",
       "     0.7619047619047619,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857],\n",
       "    'split1_test_score': [0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506],\n",
       "    'split2_test_score': [0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.8554216867469879,\n",
       "     0.8192771084337349,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506],\n",
       "    'mean_test_score': [0.7719927328361065,\n",
       "     0.7719927328361065,\n",
       "     0.7719927328361065,\n",
       "     0.7719927328361065,\n",
       "     0.7719927328361065,\n",
       "     0.7719927328361065,\n",
       "     0.7719927328361065,\n",
       "     0.8161216293746415,\n",
       "     0.7961369286670491,\n",
       "     0.8000573723465291,\n",
       "     0.8000573723465291],\n",
       "    'std_test_score': [0.0012846652173020019,\n",
       "     0.0012846652173020019,\n",
       "     0.0012846652173020019,\n",
       "     0.0012846652173020019,\n",
       "     0.0012846652173020019,\n",
       "     0.0012846652173020019,\n",
       "     0.0012846652173020019,\n",
       "     0.029144361462165834,\n",
       "     0.024700481347443227,\n",
       "     0.010142093820805357,\n",
       "     0.010142093820805357],\n",
       "    'rank_test_score': [5, 5, 5, 5, 5, 5, 5, 1, 4, 2, 2]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__C': 1},\n",
       "   'best_validation_accuracy': 0.8299667078143118,\n",
       "   'train_accuracy': 0.895,\n",
       "   'test_accuracy': 0.83,\n",
       "   'cv_results': {'mean_fit_time': [0.016749064127604168,\n",
       "     0.01677385965983073,\n",
       "     0.020624081293741863,\n",
       "     0.020655075709025066,\n",
       "     0.01647663116455078,\n",
       "     0.017951329549153645,\n",
       "     0.023282766342163086,\n",
       "     0.02964186668395996,\n",
       "     0.021276553471883137,\n",
       "     0.01952513058980306,\n",
       "     0.013574043909708658],\n",
       "    'std_fit_time': [0.00013358170274023408,\n",
       "     0.00026310872630400784,\n",
       "     0.0012475535859664214,\n",
       "     0.003069506934524902,\n",
       "     0.00042804349307532495,\n",
       "     0.00042565208123513786,\n",
       "     0.005493315972908792,\n",
       "     0.010899392838175408,\n",
       "     0.0013851176591112109,\n",
       "     0.0008455262347391525,\n",
       "     0.0029284293838652596],\n",
       "    'mean_score_time': [0.010668118794759115,\n",
       "     0.010665178298950195,\n",
       "     0.011000474294026693,\n",
       "     0.010799566904703775,\n",
       "     0.010097026824951172,\n",
       "     0.016210317611694336,\n",
       "     0.014022350311279297,\n",
       "     0.009131590525309244,\n",
       "     0.01118167241414388,\n",
       "     0.0025300979614257812,\n",
       "     0.0],\n",
       "    'std_score_time': [0.00047500278707157266,\n",
       "     0.00046816768904450685,\n",
       "     4.49566384116203e-07,\n",
       "     0.0005849946081018197,\n",
       "     0.0021361666411560134,\n",
       "     0.002350612779681192,\n",
       "     0.0014513061603955483,\n",
       "     0.006460637147628191,\n",
       "     0.002539532349760505,\n",
       "     0.0035780988511808598,\n",
       "     0.0],\n",
       "    'param_classifier__C': [1e-07,\n",
       "     1e-06,\n",
       "     1e-05,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     1000.0],\n",
       "    'params': [{'classifier__C': 1e-07},\n",
       "     {'classifier__C': 1e-06},\n",
       "     {'classifier__C': 1e-05},\n",
       "     {'classifier__C': 0.0001},\n",
       "     {'classifier__C': 0.001},\n",
       "     {'classifier__C': 0.01},\n",
       "     {'classifier__C': 0.1},\n",
       "     {'classifier__C': 1},\n",
       "     {'classifier__C': 10},\n",
       "     {'classifier__C': 100},\n",
       "     {'classifier__C': 1000}],\n",
       "    'split0_test_score': [0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.8432835820895522,\n",
       "     0.7686567164179104,\n",
       "     0.7313432835820896,\n",
       "     0.7611940298507462],\n",
       "    'split1_test_score': [0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.8421052631578947,\n",
       "     0.7969924812030075,\n",
       "     0.7593984962406015,\n",
       "     0.7744360902255639],\n",
       "    'split2_test_score': [0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.8045112781954887,\n",
       "     0.8045112781954887,\n",
       "     0.8045112781954887,\n",
       "     0.8195488721804511],\n",
       "    'mean_test_score': [0.7749971944787343,\n",
       "     0.7749971944787343,\n",
       "     0.7749971944787343,\n",
       "     0.7749971944787343,\n",
       "     0.7749971944787343,\n",
       "     0.7749971944787343,\n",
       "     0.7749971944787343,\n",
       "     0.8299667078143118,\n",
       "     0.7900534919388021,\n",
       "     0.7650843526727266,\n",
       "     0.785059664085587],\n",
       "    'std_test_score': [0.0007935212447385822,\n",
       "     0.0007935212447385822,\n",
       "     0.0007935212447385822,\n",
       "     0.0007935212447385822,\n",
       "     0.0007935212447385822,\n",
       "     0.0007935212447385822,\n",
       "     0.0007935212447385822,\n",
       "     0.018006133800926836,\n",
       "     0.015438039147338009,\n",
       "     0.03014006836379834,\n",
       "     0.02497955359890305],\n",
       "    'rank_test_score': [4, 4, 4, 4, 4, 4, 4, 1, 2, 11, 3]}}],\n",
       " 'money KNN': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__n_neighbors': 7},\n",
       "   'best_validation_accuracy': 0.7902554961378492,\n",
       "   'train_accuracy': 0.8,\n",
       "   'test_accuracy': 0.7825,\n",
       "   'cv_results': {'mean_fit_time': [0.022513151168823242,\n",
       "     0.00830229123433431,\n",
       "     0.004072666168212891,\n",
       "     0.010545969009399414,\n",
       "     0.015514850616455078],\n",
       "    'std_fit_time': [0.0015491543370466125,\n",
       "     0.0009851123391946299,\n",
       "     0.0013456265328532211,\n",
       "     0.00702705975852434,\n",
       "     0.0],\n",
       "    'mean_score_time': [0.0021114349365234375,\n",
       "     0.0,\n",
       "     0.015514850616455078,\n",
       "     0.010388771692911783,\n",
       "     0.0],\n",
       "    'std_score_time': [0.0015491543370466125,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0073461826277916465,\n",
       "     0.0],\n",
       "    'param_classifier__n_neighbors': [3, 5, 7, 9, 11],\n",
       "    'params': [{'classifier__n_neighbors': 3},\n",
       "     {'classifier__n_neighbors': 5},\n",
       "     {'classifier__n_neighbors': 7},\n",
       "     {'classifier__n_neighbors': 9},\n",
       "     {'classifier__n_neighbors': 11}],\n",
       "    'split0_test_score': [0.6764705882352942,\n",
       "     0.7058823529411765,\n",
       "     0.7647058823529411,\n",
       "     0.7058823529411765,\n",
       "     0.7058823529411765],\n",
       "    'split1_test_score': [0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878],\n",
       "    'split2_test_score': [0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182],\n",
       "    'mean_test_score': [0.7406417112299465,\n",
       "     0.7403446226975637,\n",
       "     0.7902554961378492,\n",
       "     0.7807486631016043,\n",
       "     0.7706476530005942],\n",
       "    'std_test_score': [0.058620619081659,\n",
       "     0.034727603556036706,\n",
       "     0.02189604964074666,\n",
       "     0.05293847559685382,\n",
       "     0.04743751314607741],\n",
       "    'rank_test_score': [4, 5, 1, 2, 3]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__n_neighbors': 5},\n",
       "   'best_validation_accuracy': 0.8041690571811054,\n",
       "   'train_accuracy': 0.86,\n",
       "   'test_accuracy': 0.792,\n",
       "   'cv_results': {'mean_fit_time': [0.015168587366739908,\n",
       "     0.01267568270365397,\n",
       "     0.012510458628336588,\n",
       "     0.012102286020914713,\n",
       "     0.006229241689046224],\n",
       "    'std_fit_time': [0.005929208810112021,\n",
       "     0.0009412796167433,\n",
       "     0.0010827921855612152,\n",
       "     0.0020223183728780474,\n",
       "     0.0016344322439838298],\n",
       "    'mean_score_time': [0.008663018544514975,\n",
       "     0.008692423502604166,\n",
       "     0.009025335311889648,\n",
       "     0.004485607147216797,\n",
       "     0.0],\n",
       "    'std_score_time': [0.00047092078736172264,\n",
       "     0.00022309731811766574,\n",
       "     0.0004055809547040035,\n",
       "     0.003197964703897475,\n",
       "     0.0],\n",
       "    'param_classifier__n_neighbors': [3, 5, 7, 9, 11],\n",
       "    'params': [{'classifier__n_neighbors': 3},\n",
       "     {'classifier__n_neighbors': 5},\n",
       "     {'classifier__n_neighbors': 7},\n",
       "     {'classifier__n_neighbors': 9},\n",
       "     {'classifier__n_neighbors': 11}],\n",
       "    'split0_test_score': [0.75,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7380952380952381,\n",
       "     0.75],\n",
       "    'split1_test_score': [0.8313253012048193,\n",
       "     0.8554216867469879,\n",
       "     0.8313253012048193,\n",
       "     0.7951807228915663,\n",
       "     0.7951807228915663],\n",
       "    'split2_test_score': [0.7469879518072289,\n",
       "     0.7951807228915663,\n",
       "     0.7831325301204819,\n",
       "     0.7831325301204819,\n",
       "     0.8072289156626506],\n",
       "    'mean_test_score': [0.7761044176706827,\n",
       "     0.8041690571811054,\n",
       "     0.796089118378275,\n",
       "     0.7721361637024288,\n",
       "     0.784136546184739],\n",
       "    'std_test_score': [0.03906641859105166,\n",
       "     0.03870354353253302,\n",
       "     0.025204775298975676,\n",
       "     0.024567976438282655,\n",
       "     0.02463422519354479],\n",
       "    'rank_test_score': [4, 1, 2, 5, 3]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__n_neighbors': 7},\n",
       "   'best_validation_accuracy': 0.8324916769535778,\n",
       "   'train_accuracy': 0.885,\n",
       "   'test_accuracy': 0.86,\n",
       "   'cv_results': {'mean_fit_time': [0.0212404727935791,\n",
       "     0.01937731107076009,\n",
       "     0.011516173680623373,\n",
       "     0.01602911949157715,\n",
       "     0.01603555679321289],\n",
       "    'std_fit_time': [0.0,\n",
       "     0.0026349085773050658,\n",
       "     0.0014681956943823295,\n",
       "     0.007132765736784226,\n",
       "     0.0],\n",
       "    'mean_score_time': [0.010013818740844727,\n",
       "     0.006675879160563151,\n",
       "     0.008016109466552734,\n",
       "     0.013070821762084961,\n",
       "     0.010537385940551758],\n",
       "    'std_score_time': [0.0,\n",
       "     0.004720559424816161,\n",
       "     0.005668245362533117,\n",
       "     0.002265242435503816,\n",
       "     0.0],\n",
       "    'param_classifier__n_neighbors': [3, 5, 7, 9, 11],\n",
       "    'params': [{'classifier__n_neighbors': 3},\n",
       "     {'classifier__n_neighbors': 5},\n",
       "     {'classifier__n_neighbors': 7},\n",
       "     {'classifier__n_neighbors': 9},\n",
       "     {'classifier__n_neighbors': 11}],\n",
       "    'split0_test_score': [0.8283582089552238,\n",
       "     0.8134328358208955,\n",
       "     0.835820895522388,\n",
       "     0.835820895522388,\n",
       "     0.8432835820895522],\n",
       "    'split1_test_score': [0.8120300751879699,\n",
       "     0.8270676691729323,\n",
       "     0.8345864661654135,\n",
       "     0.8120300751879699,\n",
       "     0.8345864661654135],\n",
       "    'split2_test_score': [0.7969924812030075,\n",
       "     0.8195488721804511,\n",
       "     0.8270676691729323,\n",
       "     0.8045112781954887,\n",
       "     0.7819548872180451],\n",
       "    'mean_test_score': [0.8124602551154004,\n",
       "     0.8200164590580931,\n",
       "     0.8324916769535778,\n",
       "     0.8174540829686155,\n",
       "     0.8199416451576703],\n",
       "    'std_test_score': [0.012808617162780476,\n",
       "     0.005576208284641727,\n",
       "     0.003868319985275147,\n",
       "     0.013345109705870955,\n",
       "     0.027094344925614227],\n",
       "    'rank_test_score': [5, 2, 1, 4, 3]}}],\n",
       " 'money log_reg': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__C': 0.1,\n",
       "    'classifier__max_iter': 500,\n",
       "    'classifier__penalty': 'l2'},\n",
       "   'best_validation_accuracy': 0.7905525846702318,\n",
       "   'train_accuracy': 0.82,\n",
       "   'test_accuracy': 0.7925,\n",
       "   'cv_results': {'mean_fit_time': [0.006261189778645833,\n",
       "     0.018308718999226887,\n",
       "     0.02525027592976888,\n",
       "     0.024081071217854817,\n",
       "     0.015702565511067707,\n",
       "     0.01136938730875651,\n",
       "     0.019164562225341797,\n",
       "     0.026395718256632488,\n",
       "     0.021172126134236652,\n",
       "     0.022785266240437824,\n",
       "     0.02381412188212077,\n",
       "     0.02824544906616211,\n",
       "     0.02794202168782552,\n",
       "     0.030252854029337566,\n",
       "     0.015129804611206055,\n",
       "     0.02348438898722331],\n",
       "    'std_fit_time': [0.006752219973579043,\n",
       "     0.003780178940841093,\n",
       "     0.002256486073475252,\n",
       "     0.005083326386034963,\n",
       "     0.0008143025774016552,\n",
       "     0.001243731800222753,\n",
       "     0.0012578601508975843,\n",
       "     0.00216200334991908,\n",
       "     0.0016007561576210788,\n",
       "     0.003503546887454676,\n",
       "     0.0033031150723757934,\n",
       "     0.003217740819177091,\n",
       "     0.009410783127392795,\n",
       "     0.006543858366030346,\n",
       "     0.007515931527234562,\n",
       "     0.0026670071431174128],\n",
       "    'mean_score_time': [0.013096809387207031,\n",
       "     0.010807275772094727,\n",
       "     0.009722232818603516,\n",
       "     0.007889747619628906,\n",
       "     0.005465586980183919,\n",
       "     0.009614149729410807,\n",
       "     0.010965744654337565,\n",
       "     0.009000539779663086,\n",
       "     0.009519418080647787,\n",
       "     0.009409348169962565,\n",
       "     0.00613101323445638,\n",
       "     0.006795247395833333,\n",
       "     0.0016682147979736328,\n",
       "     0.007954120635986328,\n",
       "     0.01613791783650716,\n",
       "     0.0064203739166259766],\n",
       "    'std_score_time': [0.0035905743183400844,\n",
       "     0.002872555463765254,\n",
       "     0.0015481417877200203,\n",
       "     0.0009617837987153588,\n",
       "     0.007729507233705908,\n",
       "     0.006986971214135413,\n",
       "     0.0028173821189237456,\n",
       "     0.0008130336665858048,\n",
       "     0.0010462440104813322,\n",
       "     0.0009283975862765171,\n",
       "     0.0018117525279882983,\n",
       "     0.0049580475907582055,\n",
       "     0.002359211992245804,\n",
       "     0.0018006866935614363,\n",
       "     0.006686607027971313,\n",
       "     0.001583126019536879],\n",
       "    'param_classifier__C': [0.0001,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     100.0,\n",
       "     1000.0,\n",
       "     1000.0],\n",
       "    'param_classifier__max_iter': [500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000],\n",
       "    'param_classifier__penalty': ['l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2'],\n",
       "    'params': [{'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'}],\n",
       "    'split0_test_score': [0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7647058823529411,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942,\n",
       "     0.7058823529411765,\n",
       "     0.7058823529411765,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942],\n",
       "    'split1_test_score': [0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.696969696969697,\n",
       "     0.696969696969697,\n",
       "     0.6666666666666666,\n",
       "     0.6666666666666666],\n",
       "    'split2_test_score': [0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.8181818181818182,\n",
       "     0.8181818181818182,\n",
       "     0.7575757575757576,\n",
       "     0.7575757575757576,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.6666666666666666,\n",
       "     0.6666666666666666,\n",
       "     0.6666666666666666,\n",
       "     0.6666666666666666],\n",
       "    'mean_test_score': [0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7700534759358288,\n",
       "     0.7905525846702318,\n",
       "     0.7905525846702318,\n",
       "     0.7406417112299465,\n",
       "     0.7406417112299465,\n",
       "     0.7201426024955436,\n",
       "     0.7201426024955436,\n",
       "     0.6800356506238859,\n",
       "     0.6800356506238859,\n",
       "     0.6699346405228758,\n",
       "     0.6699346405228758],\n",
       "    'std_test_score': [0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.012936150360711367,\n",
       "     0.039073636750058774,\n",
       "     0.039073636750058774,\n",
       "     0.04703203292213152,\n",
       "     0.04703203292213152,\n",
       "     0.010083519161305479,\n",
       "     0.010083519161305479,\n",
       "     0.012625388806224496,\n",
       "     0.012625388806224496,\n",
       "     0.004621612948931719,\n",
       "     0.004621612948931719],\n",
       "    'rank_test_score': [3,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     1,\n",
       "     1,\n",
       "     9,\n",
       "     9,\n",
       "     11,\n",
       "     11,\n",
       "     13,\n",
       "     13,\n",
       "     15,\n",
       "     15]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__C': 1,\n",
       "    'classifier__max_iter': 500,\n",
       "    'classifier__penalty': 'l2'},\n",
       "   'best_validation_accuracy': 0.8280742015681776,\n",
       "   'train_accuracy': 0.88,\n",
       "   'test_accuracy': 0.848,\n",
       "   'cv_results': {'mean_fit_time': [0.005209207534790039,\n",
       "     0.025644302368164062,\n",
       "     0.024445295333862305,\n",
       "     0.012693087259928385,\n",
       "     0.01242518424987793,\n",
       "     0.010811090469360352,\n",
       "     0.014276901880900065,\n",
       "     0.01563429832458496,\n",
       "     0.027719656626383465,\n",
       "     0.024183114369710285,\n",
       "     0.03139066696166992,\n",
       "     0.021112600962320965,\n",
       "     0.03660774230957031,\n",
       "     0.03153872489929199,\n",
       "     0.03780261675516764,\n",
       "     0.03594295183817545],\n",
       "    'std_fit_time': [0.00736693194491619,\n",
       "     0.0,\n",
       "     0.006436037107174144,\n",
       "     0.004721908123968509,\n",
       "     0.010864189339146388,\n",
       "     0.0,\n",
       "     0.005922479840797709,\n",
       "     0.0,\n",
       "     0.008794828410837693,\n",
       "     0.008793965520926383,\n",
       "     0.00019623572666672262,\n",
       "     0.007169572302289176,\n",
       "     0.008253058663190658,\n",
       "     0.004097290566170973,\n",
       "     0.006067387131214841,\n",
       "     0.0007853520139293525],\n",
       "    'mean_score_time': [0.0157624085744222,\n",
       "     0.006015300750732422,\n",
       "     0.0020051002502441406,\n",
       "     0.01043558120727539,\n",
       "     0.01302957534790039,\n",
       "     0.01563429832458496,\n",
       "     0.005211432774861653,\n",
       "     0.010416030883789062,\n",
       "     0.0,\n",
       "     0.008882443110148111,\n",
       "     0.010425090789794922,\n",
       "     0.01564176877339681,\n",
       "     0.010841846466064453,\n",
       "     0.007839202880859375,\n",
       "     0.005959272384643555,\n",
       "     0.004284779230753581],\n",
       "    'std_score_time': [0.0001906161468652701,\n",
       "     0.0,\n",
       "     0.0028356399678129505,\n",
       "     0.007379070237287327,\n",
       "     0.009750760013002853,\n",
       "     0.0,\n",
       "     0.007370078909605004,\n",
       "     0.007365246070975754,\n",
       "     0.0,\n",
       "     0.006556557407599706,\n",
       "     0.007371659342201717,\n",
       "     1.1688725987021277e-05,\n",
       "     0.0046798486481894,\n",
       "     0.007808304439081041,\n",
       "     0.0038075360045455985,\n",
       "     0.004820699405347311],\n",
       "    'param_classifier__C': [0.0001,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     100.0,\n",
       "     1000.0,\n",
       "     1000.0],\n",
       "    'param_classifier__max_iter': [500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000],\n",
       "    'param_classifier__penalty': ['l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2'],\n",
       "    'params': [{'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'}],\n",
       "    'split0_test_score': [0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7738095238095238,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.8095238095238095,\n",
       "     0.8095238095238095,\n",
       "     0.7619047619047619,\n",
       "     0.7619047619047619,\n",
       "     0.7857142857142857,\n",
       "     0.7857142857142857,\n",
       "     0.7976190476190477,\n",
       "     0.7976190476190477],\n",
       "    'split1_test_score': [0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8433734939759037,\n",
       "     0.8433734939759037,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.7831325301204819,\n",
       "     0.7831325301204819],\n",
       "    'split2_test_score': [0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.7831325301204819,\n",
       "     0.7831325301204819,\n",
       "     0.8433734939759037,\n",
       "     0.8433734939759037,\n",
       "     0.8072289156626506,\n",
       "     0.8072289156626506,\n",
       "     0.7831325301204819,\n",
       "     0.7831325301204819,\n",
       "     0.7590361445783133,\n",
       "     0.7590361445783133],\n",
       "    'mean_test_score': [0.7719927328361065,\n",
       "     0.7719927328361065,\n",
       "     0.7719927328361065,\n",
       "     0.7719927328361065,\n",
       "     0.7680244788678524,\n",
       "     0.7680244788678524,\n",
       "     0.7920252438324727,\n",
       "     0.7920252438324727,\n",
       "     0.8280742015681776,\n",
       "     0.8280742015681776,\n",
       "     0.8041690571811054,\n",
       "     0.8041690571811054,\n",
       "     0.7920252438324727,\n",
       "     0.7920252438324727,\n",
       "     0.7799292407726143,\n",
       "     0.7799292407726143],\n",
       "    'std_test_score': [0.0012846652173020019,\n",
       "     0.0012846652173020019,\n",
       "     0.0012846652173020019,\n",
       "     0.0012846652173020019,\n",
       "     0.004327293363543646,\n",
       "     0.004327293363543646,\n",
       "     0.01080216315763786,\n",
       "     0.01080216315763786,\n",
       "     0.014008985711847357,\n",
       "     0.014008985711847357,\n",
       "     0.033329772744151595,\n",
       "     0.033329772744151595,\n",
       "     0.01080216315763786,\n",
       "     0.01080216315763786,\n",
       "     0.015913430360281634,\n",
       "     0.015913430360281634],\n",
       "    'rank_test_score': [11,\n",
       "     11,\n",
       "     11,\n",
       "     11,\n",
       "     15,\n",
       "     15,\n",
       "     5,\n",
       "     5,\n",
       "     1,\n",
       "     1,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     9,\n",
       "     9]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__C': 0.1,\n",
       "    'classifier__max_iter': 500,\n",
       "    'classifier__penalty': 'l2'},\n",
       "   'best_validation_accuracy': 0.8325103804286836,\n",
       "   'train_accuracy': 0.855,\n",
       "   'test_accuracy': 0.86,\n",
       "   'cv_results': {'mean_fit_time': [0.021878401438395183,\n",
       "     0.01790467898050944,\n",
       "     0.021601438522338867,\n",
       "     0.023136218388875324,\n",
       "     0.019527196884155273,\n",
       "     0.01672212282816569,\n",
       "     0.010581890741984049,\n",
       "     0.01793646812438965,\n",
       "     0.03731369972229004,\n",
       "     0.03988114992777506,\n",
       "     0.04716022809346517,\n",
       "     0.035968621571858726,\n",
       "     0.04205799102783203,\n",
       "     0.04019800821940104,\n",
       "     0.03227567672729492,\n",
       "     0.05953423182169596],\n",
       "    'std_fit_time': [0.0025134132619976618,\n",
       "     0.0012070576326609556,\n",
       "     0.003969246528683422,\n",
       "     0.003957350934673376,\n",
       "     0.0004156809066887939,\n",
       "     0.001526117819387514,\n",
       "     0.001633264201521355,\n",
       "     0.008287540528973885,\n",
       "     0.014181998982550566,\n",
       "     0.011969185680774732,\n",
       "     0.021963740512486483,\n",
       "     0.00389039716602341,\n",
       "     0.014657325212936596,\n",
       "     0.02205639829793724,\n",
       "     0.006477730142638598,\n",
       "     0.011371606694223758],\n",
       "    'mean_score_time': [0.01026757558186849,\n",
       "     0.00596920649210612,\n",
       "     0.008188168207804361,\n",
       "     0.009998639424641928,\n",
       "     0.005048831303914388,\n",
       "     0.0005217393239339193,\n",
       "     0.015518426895141602,\n",
       "     0.010521809260050455,\n",
       "     0.0026727517445882163,\n",
       "     0.018943309783935547,\n",
       "     0.028046846389770508,\n",
       "     0.026677767435709637,\n",
       "     0.010045925776163736,\n",
       "     0.017427523930867512,\n",
       "     0.01794266700744629,\n",
       "     0.01269205411275228],\n",
       "    'std_score_time': [0.0014352406812909782,\n",
       "     0.0024541553744569056,\n",
       "     0.0015535217808778793,\n",
       "     1.969259849129338e-06,\n",
       "     0.0030537953648668743,\n",
       "     0.0007378508279307181,\n",
       "     0.0,\n",
       "     0.0035331448084006413,\n",
       "     0.0037798417660530057,\n",
       "     0.016973811629321725,\n",
       "     0.020400858655302126,\n",
       "     0.021308739670322627,\n",
       "     0.00711798981708537,\n",
       "     0.006026229741354552,\n",
       "     0.005681401472527395,\n",
       "     0.0066938353657443935],\n",
       "    'param_classifier__C': [0.0001,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     100.0,\n",
       "     1000.0,\n",
       "     1000.0],\n",
       "    'param_classifier__max_iter': [500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000],\n",
       "    'param_classifier__penalty': ['l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2'],\n",
       "    'params': [{'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'}],\n",
       "    'split0_test_score': [0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.8283582089552238,\n",
       "     0.8283582089552238,\n",
       "     0.8507462686567164,\n",
       "     0.8507462686567164,\n",
       "     0.835820895522388,\n",
       "     0.835820895522388,\n",
       "     0.8283582089552238,\n",
       "     0.8283582089552238,\n",
       "     0.8208955223880597,\n",
       "     0.8208955223880597],\n",
       "    'split1_test_score': [0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.7894736842105263,\n",
       "     0.7894736842105263,\n",
       "     0.8721804511278195,\n",
       "     0.8721804511278195,\n",
       "     0.8421052631578947,\n",
       "     0.8421052631578947,\n",
       "     0.8195488721804511,\n",
       "     0.8195488721804511,\n",
       "     0.7894736842105263,\n",
       "     0.7894736842105263,\n",
       "     0.7894736842105263,\n",
       "     0.7894736842105263],\n",
       "    'split2_test_score': [0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.7894736842105263,\n",
       "     0.7894736842105263,\n",
       "     0.7969924812030075,\n",
       "     0.7969924812030075,\n",
       "     0.7744360902255639,\n",
       "     0.7744360902255639,\n",
       "     0.7518796992481203,\n",
       "     0.7518796992481203,\n",
       "     0.7593984962406015,\n",
       "     0.7593984962406015,\n",
       "     0.7669172932330827,\n",
       "     0.7669172932330827],\n",
       "    'mean_test_score': [0.7749971944787343,\n",
       "     0.7749971944787343,\n",
       "     0.7749971944787343,\n",
       "     0.7749971944787343,\n",
       "     0.7850222571353758,\n",
       "     0.7850222571353758,\n",
       "     0.8325103804286836,\n",
       "     0.8325103804286836,\n",
       "     0.8224292073467251,\n",
       "     0.8224292073467251,\n",
       "     0.8024164889836531,\n",
       "     0.8024164889836531,\n",
       "     0.7924101298021172,\n",
       "     0.7924101298021172,\n",
       "     0.7924288332772229,\n",
       "     0.7924288332772229],\n",
       "    'std_test_score': [0.0007935212447385822,\n",
       "     0.0007935212447385822,\n",
       "     0.0007935212447385822,\n",
       "     0.0007935212447385822,\n",
       "     0.006295268541592721,\n",
       "     0.006295268541592721,\n",
       "     0.03083545687799863,\n",
       "     0.03083545687799863,\n",
       "     0.0341191169508804,\n",
       "     0.0341191169508804,\n",
       "     0.03634712298096628,\n",
       "     0.03634712298096628,\n",
       "     0.02822915194091728,\n",
       "     0.02822915194091728,\n",
       "     0.022135371168962473,\n",
       "     0.022135371168962473],\n",
       "    'rank_test_score': [13,\n",
       "     13,\n",
       "     13,\n",
       "     13,\n",
       "     11,\n",
       "     11,\n",
       "     1,\n",
       "     1,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     9,\n",
       "     9,\n",
       "     7,\n",
       "     7]}}],\n",
       " 'money decision_tree': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__criterion': 'entropy',\n",
       "    'classifier__max_depth': 3,\n",
       "    'classifier__min_samples_split': 5},\n",
       "   'best_validation_accuracy': 0.7602495543672014,\n",
       "   'train_accuracy': 0.86,\n",
       "   'test_accuracy': 0.81,\n",
       "   'cv_results': {'mean_fit_time': [0.00788736343383789,\n",
       "     0.01564168930053711,\n",
       "     0.01564168930053711,\n",
       "     0.022105932235717773,\n",
       "     0.020244757334391277,\n",
       "     0.008713324864705404,\n",
       "     0.007646481196085612,\n",
       "     0.015635967254638672,\n",
       "     0.014728228251139322,\n",
       "     0.02098242441813151,\n",
       "     0.013559500376383463,\n",
       "     0.014595985412597656,\n",
       "     0.013553460439046225,\n",
       "     0.014589945475260416,\n",
       "     0.025615771611531574,\n",
       "     0.015623728434244791,\n",
       "     0.02079168955485026,\n",
       "     0.012837727864583334,\n",
       "     0.016402403513590496,\n",
       "     0.01555029551188151,\n",
       "     0.018132845560709637,\n",
       "     0.01822527249654134,\n",
       "     0.014787117640177408,\n",
       "     0.0162200133005778],\n",
       "    'std_fit_time': [0.006386385795285515,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.006660869260750931,\n",
       "     0.0027426921178969254,\n",
       "     0.0020472129216691595,\n",
       "     0.006188664408368477,\n",
       "     0.0,\n",
       "     0.0015719178945083918,\n",
       "     0.00756171019914813,\n",
       "     0.0014743529567090878,\n",
       "     0.0014701006875780273,\n",
       "     0.00146581119541088,\n",
       "     0.00146581119541088,\n",
       "     0.00707188342376195,\n",
       "     1.9106571324938627e-06,\n",
       "     0.0073076455653460345,\n",
       "     0.002012490010078829,\n",
       "     0.0011031235150251331,\n",
       "     0.0025914305266393507,\n",
       "     0.0045312780999243385,\n",
       "     0.009304364260954679,\n",
       "     0.002342565725392621,\n",
       "     0.0031147083007530833],\n",
       "    'mean_score_time': [0.01042779286702474,\n",
       "     0.005210081736246745,\n",
       "     0.015630245208740234,\n",
       "     0.011733770370483398,\n",
       "     0.0019393761952718098,\n",
       "     0.010423978169759115,\n",
       "     0.010423978169759115,\n",
       "     0.010416984558105469,\n",
       "     0.005208492279052734,\n",
       "     0.010416269302368164,\n",
       "     0.005208810170491536,\n",
       "     0.010423660278320312,\n",
       "     0.01563715934753418,\n",
       "     0.010422309239705404,\n",
       "     0.013991753260294596,\n",
       "     0.013143142064412435,\n",
       "     0.017553091049194336,\n",
       "     0.014098167419433594,\n",
       "     0.01513051986694336,\n",
       "     0.00866246223449707,\n",
       "     0.00579531987508138,\n",
       "     0.007849852244059244,\n",
       "     0.0031773249308268228,\n",
       "     0.006874958674112956],\n",
       "    'std_score_time': [0.007373563049081904,\n",
       "     0.007368168252472509,\n",
       "     0.0,\n",
       "     0.006384302260171391,\n",
       "     0.002742692117896926,\n",
       "     0.007370865650777207,\n",
       "     0.007370865650777206,\n",
       "     0.007365920420551928,\n",
       "     0.007365920420551928,\n",
       "     0.007365414844235638,\n",
       "     0.007366369986936045,\n",
       "     0.0073706445796945675,\n",
       "     1.045241843070172e-05,\n",
       "     0.007369691098262708,\n",
       "     0.0023089173459323697,\n",
       "     0.009607059771733116,\n",
       "     0.007463352235621959,\n",
       "     0.0037616111751390888,\n",
       "     0.010698893200793428,\n",
       "     0.006182072835417132,\n",
       "     0.004103511097427944,\n",
       "     0.005844958115616232,\n",
       "     0.004493416009241449,\n",
       "     0.009722659797685093],\n",
       "    'param_classifier__criterion': ['gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy'],\n",
       "    'param_classifier__max_depth': [3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10],\n",
       "    'params': [{'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10}],\n",
       "    'split0_test_score': [0.7352941176470589,\n",
       "     0.7058823529411765,\n",
       "     0.7058823529411765,\n",
       "     0.7647058823529411,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7058823529411765,\n",
       "     0.6764705882352942,\n",
       "     0.7058823529411765,\n",
       "     0.7352941176470589,\n",
       "     0.7058823529411765,\n",
       "     0.6764705882352942,\n",
       "     0.7647058823529411,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942,\n",
       "     0.7352941176470589,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942,\n",
       "     0.6764705882352942],\n",
       "    'split1_test_score': [0.6666666666666666,\n",
       "     0.6666666666666666,\n",
       "     0.6666666666666666,\n",
       "     0.6666666666666666,\n",
       "     0.696969696969697,\n",
       "     0.696969696969697,\n",
       "     0.696969696969697,\n",
       "     0.696969696969697,\n",
       "     0.696969696969697,\n",
       "     0.696969696969697,\n",
       "     0.696969696969697,\n",
       "     0.696969696969697,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576,\n",
       "     0.8181818181818182,\n",
       "     0.7878787878787878,\n",
       "     0.7575757575757576],\n",
       "    'split2_test_score': [0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.7878787878787878,\n",
       "     0.696969696969697,\n",
       "     0.696969696969697,\n",
       "     0.7272727272727273,\n",
       "     0.696969696969697,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.7575757575757576,\n",
       "     0.696969696969697,\n",
       "     0.7272727272727273,\n",
       "     0.7272727272727273,\n",
       "     0.7575757575757576,\n",
       "     0.696969696969697,\n",
       "     0.6363636363636364,\n",
       "     0.6363636363636364,\n",
       "     0.6666666666666666,\n",
       "     0.6363636363636364,\n",
       "     0.6666666666666666,\n",
       "     0.6666666666666666,\n",
       "     0.696969696969697,\n",
       "     0.6666666666666666,\n",
       "     0.6060606060606061],\n",
       "    'mean_test_score': [0.729946524064171,\n",
       "     0.7201426024955436,\n",
       "     0.7201426024955436,\n",
       "     0.7094474153297682,\n",
       "     0.7097445038621509,\n",
       "     0.7198455139631611,\n",
       "     0.6999405822935234,\n",
       "     0.700237670825906,\n",
       "     0.7100415923945335,\n",
       "     0.7299465240641712,\n",
       "     0.6999405822935234,\n",
       "     0.700237670825906,\n",
       "     0.7599524658348188,\n",
       "     0.7602495543672014,\n",
       "     0.7400475341651812,\n",
       "     0.7198455139631611,\n",
       "     0.7198455139631611,\n",
       "     0.7299465240641712,\n",
       "     0.700237670825906,\n",
       "     0.7103386809269162,\n",
       "     0.7198455139631611,\n",
       "     0.7305407011289363,\n",
       "     0.7103386809269162,\n",
       "     0.6800356506238859],\n",
       "    'std_test_score': [0.04962890387688273,\n",
       "     0.05050155522489786,\n",
       "     0.05050155522489786,\n",
       "     0.04098529854065485,\n",
       "     0.01806630516400567,\n",
       "     0.01650379609308514,\n",
       "     0.004201466317210621,\n",
       "     0.020868222612995764,\n",
       "     0.012715944479520307,\n",
       "     0.0250295986569525,\n",
       "     0.004201466317210621,\n",
       "     0.020868222612995764,\n",
       "     0.024969579785443462,\n",
       "     0.021550696474536075,\n",
       "     0.03726537203110867,\n",
       "     0.06281297531296876,\n",
       "     0.06281297531296876,\n",
       "     0.04962890387688273,\n",
       "     0.06409818481993884,\n",
       "     0.05497502680982653,\n",
       "     0.03868772604083408,\n",
       "     0.06253413688236695,\n",
       "     0.05497502680982653,\n",
       "     0.06190714841352191],\n",
       "    'rank_test_score': [7,\n",
       "     8,\n",
       "     8,\n",
       "     18,\n",
       "     17,\n",
       "     10,\n",
       "     22,\n",
       "     19,\n",
       "     16,\n",
       "     5,\n",
       "     22,\n",
       "     19,\n",
       "     2,\n",
       "     1,\n",
       "     3,\n",
       "     10,\n",
       "     10,\n",
       "     5,\n",
       "     19,\n",
       "     14,\n",
       "     10,\n",
       "     4,\n",
       "     14,\n",
       "     24]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__criterion': 'gini',\n",
       "    'classifier__max_depth': 5,\n",
       "    'classifier__min_samples_split': 10},\n",
       "   'best_validation_accuracy': 0.8200898833428955,\n",
       "   'train_accuracy': 0.864,\n",
       "   'test_accuracy': 0.788,\n",
       "   'cv_results': {'mean_fit_time': [0.013521194458007812,\n",
       "     0.015190601348876953,\n",
       "     0.014985958735148111,\n",
       "     0.010894775390625,\n",
       "     0.01041873296101888,\n",
       "     0.015626192092895508,\n",
       "     0.015626192092895508,\n",
       "     0.015626192092895508,\n",
       "     0.012265761693318685,\n",
       "     0.0067444642384847,\n",
       "     0.010120073954264322,\n",
       "     0.011418898900349935,\n",
       "     0.016582965850830078,\n",
       "     0.022783199946085613,\n",
       "     0.017514467239379883,\n",
       "     0.01857471466064453,\n",
       "     0.02311118443806966,\n",
       "     0.01710931460062663,\n",
       "     0.015767653783162434,\n",
       "     0.015392541885375977,\n",
       "     0.015368779500325521,\n",
       "     0.0157012939453125,\n",
       "     0.010790586471557617,\n",
       "     0.014884392420450846],\n",
       "    'std_fit_time': [6.0691461855687405e-06,\n",
       "     0.00047103333986194185,\n",
       "     0.00041144122607820945,\n",
       "     0.0018826736748476518,\n",
       "     0.007367156892711721,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.004752366246492382,\n",
       "     0.00901921792198714,\n",
       "     0.008687676896682844,\n",
       "     0.0064149751265501305,\n",
       "     0.0011218133552627785,\n",
       "     0.00814813938279382,\n",
       "     0.0009110462774114854,\n",
       "     0.0005043624308697986,\n",
       "     0.007359922176123487,\n",
       "     0.0017418480699922158,\n",
       "     0.0005311067100108358,\n",
       "     0.0005317246408134391,\n",
       "     0.0013312841623005433,\n",
       "     0.004190069739459072,\n",
       "     0.006267871128706339,\n",
       "     0.009153059189009865],\n",
       "    'mean_score_time': [0.009001890818277994,\n",
       "     0.005381425221761067,\n",
       "     0.0009212493896484375,\n",
       "     0.005210002263387044,\n",
       "     0.005208730697631836,\n",
       "     0.015626192092895508,\n",
       "     0.015626192092895508,\n",
       "     0.0,\n",
       "     0.01814611752827962,\n",
       "     0.013271649678548178,\n",
       "     0.021471103032430012,\n",
       "     0.014908711115519205,\n",
       "     0.005935351053873698,\n",
       "     0.010803778966267904,\n",
       "     0.008984088897705078,\n",
       "     0.013080755869547525,\n",
       "     0.01110545794169108,\n",
       "     0.003315130869547526,\n",
       "     0.0066479841868082685,\n",
       "     0.0146485964457194,\n",
       "     0.007693688074747722,\n",
       "     0.013509194056193033,\n",
       "     0.012143214543660482,\n",
       "     0.00802151362101237],\n",
       "    'std_score_time': [8.316978106149756e-06,\n",
       "     0.001412987145277226,\n",
       "     0.00104416697176321,\n",
       "     0.0073680558608764804,\n",
       "     0.007366257595340015,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.002044032808390172,\n",
       "     0.009492481807686875,\n",
       "     0.009271049708574806,\n",
       "     0.0022980709640060006,\n",
       "     0.006689327102650304,\n",
       "     0.00910934801657434,\n",
       "     0.006667334682746901,\n",
       "     0.0020727009032525715,\n",
       "     0.007112281597723029,\n",
       "     0.004038495759968939,\n",
       "     0.0047749008233341364,\n",
       "     0.00592505854451497,\n",
       "     0.009541649542451291,\n",
       "     0.006631249472168552,\n",
       "     0.00406351815443033,\n",
       "     0.0049462417496424944],\n",
       "    'param_classifier__criterion': ['gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy'],\n",
       "    'param_classifier__max_depth': [3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10],\n",
       "    'params': [{'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10}],\n",
       "    'split0_test_score': [0.75,\n",
       "     0.75,\n",
       "     0.75,\n",
       "     0.7261904761904762,\n",
       "     0.7619047619047619,\n",
       "     0.7976190476190477,\n",
       "     0.7261904761904762,\n",
       "     0.7619047619047619,\n",
       "     0.7738095238095238,\n",
       "     0.7142857142857143,\n",
       "     0.7976190476190477,\n",
       "     0.7738095238095238,\n",
       "     0.7023809523809523,\n",
       "     0.7023809523809523,\n",
       "     0.7023809523809523,\n",
       "     0.7261904761904762,\n",
       "     0.7261904761904762,\n",
       "     0.7261904761904762,\n",
       "     0.7261904761904762,\n",
       "     0.7142857142857143,\n",
       "     0.7380952380952381,\n",
       "     0.7380952380952381,\n",
       "     0.7261904761904762,\n",
       "     0.7380952380952381],\n",
       "    'split1_test_score': [0.7951807228915663,\n",
       "     0.7951807228915663,\n",
       "     0.7951807228915663,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8313253012048193,\n",
       "     0.8433734939759037,\n",
       "     0.8554216867469879,\n",
       "     0.8554216867469879,\n",
       "     0.8433734939759037,\n",
       "     0.8554216867469879,\n",
       "     0.8554216867469879,\n",
       "     0.7831325301204819,\n",
       "     0.7831325301204819,\n",
       "     0.7831325301204819,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8192771084337349,\n",
       "     0.8795180722891566,\n",
       "     0.8795180722891566,\n",
       "     0.8554216867469879,\n",
       "     0.891566265060241,\n",
       "     0.891566265060241,\n",
       "     0.8554216867469879],\n",
       "    'split2_test_score': [0.7228915662650602,\n",
       "     0.7228915662650602,\n",
       "     0.8072289156626506,\n",
       "     0.8192771084337349,\n",
       "     0.7951807228915663,\n",
       "     0.8313253012048193,\n",
       "     0.7228915662650602,\n",
       "     0.7710843373493976,\n",
       "     0.8072289156626506,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.8072289156626506,\n",
       "     0.7710843373493976,\n",
       "     0.7710843373493976,\n",
       "     0.8072289156626506,\n",
       "     0.7469879518072289,\n",
       "     0.7469879518072289,\n",
       "     0.8313253012048193,\n",
       "     0.7228915662650602,\n",
       "     0.7228915662650602,\n",
       "     0.8072289156626506,\n",
       "     0.7951807228915663,\n",
       "     0.7228915662650602,\n",
       "     0.8072289156626506],\n",
       "    'mean_test_score': [0.7560240963855422,\n",
       "     0.7560240963855422,\n",
       "     0.784136546184739,\n",
       "     0.7922642952763436,\n",
       "     0.7961369286670492,\n",
       "     0.8200898833428955,\n",
       "     0.7641518454771467,\n",
       "     0.7961369286670491,\n",
       "     0.8121533754063875,\n",
       "     0.7762478485370051,\n",
       "     0.8080416905718111,\n",
       "     0.8121533754063875,\n",
       "     0.7521992732836106,\n",
       "     0.7521992732836106,\n",
       "     0.764247466054695,\n",
       "     0.7641518454771467,\n",
       "     0.7641518454771467,\n",
       "     0.7922642952763436,\n",
       "     0.776200038248231,\n",
       "     0.7722317842799771,\n",
       "     0.8002486135016257,\n",
       "     0.8082807420156818,\n",
       "     0.7802161025052592,\n",
       "     0.8002486135016257],\n",
       "    'std_test_score': [0.02981775583316767,\n",
       "     0.02981775583316767,\n",
       "     0.02463422519354479,\n",
       "     0.04697944170028874,\n",
       "     0.028348880827897535,\n",
       "     0.01588928031926166,\n",
       "     0.056034351932955404,\n",
       "     0.04208782925251741,\n",
       "     0.03349949265942755,\n",
       "     0.052826193642763544,\n",
       "     0.03521051680434316,\n",
       "     0.03349949265942755,\n",
       "     0.035568605636923524,\n",
       "     0.035568605636923524,\n",
       "     0.04483865954476299,\n",
       "     0.03989343897628704,\n",
       "     0.03989343897628704,\n",
       "     0.04697944170028874,\n",
       "     0.07306929505720532,\n",
       "     0.07594417189911752,\n",
       "     0.04815196328293948,\n",
       "     0.06333533455721906,\n",
       "     0.07874797236517547,\n",
       "     0.04815196328293948],\n",
       "    'rank_test_score': [21,\n",
       "     21,\n",
       "     12,\n",
       "     10,\n",
       "     8,\n",
       "     1,\n",
       "     18,\n",
       "     9,\n",
       "     2,\n",
       "     14,\n",
       "     5,\n",
       "     2,\n",
       "     23,\n",
       "     23,\n",
       "     17,\n",
       "     18,\n",
       "     18,\n",
       "     10,\n",
       "     15,\n",
       "     16,\n",
       "     6,\n",
       "     4,\n",
       "     13,\n",
       "     6]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__criterion': 'gini',\n",
       "    'classifier__max_depth': 10,\n",
       "    'classifier__min_samples_split': 10},\n",
       "   'best_validation_accuracy': 0.8124976620656117,\n",
       "   'train_accuracy': 0.92,\n",
       "   'test_accuracy': 0.81,\n",
       "   'cv_results': {'mean_fit_time': [0.013000408808390299,\n",
       "     0.01599582036336263,\n",
       "     0.016330957412719727,\n",
       "     0.01603523890177409,\n",
       "     0.009931325912475586,\n",
       "     0.015924930572509766,\n",
       "     0.015644311904907227,\n",
       "     0.020853439966837566,\n",
       "     0.020847082138061523,\n",
       "     0.020833651224772137,\n",
       "     0.015625158945719402,\n",
       "     0.0156250794728597,\n",
       "     0.010416030883789062,\n",
       "     0.020159403483072918,\n",
       "     0.016289313634236652,\n",
       "     0.02844866116841634,\n",
       "     0.015255053838094076,\n",
       "     0.019759416580200195,\n",
       "     0.01283701260884603,\n",
       "     0.015262365341186523,\n",
       "     0.014884392420450846,\n",
       "     0.015253623326619467,\n",
       "     0.025690555572509766,\n",
       "     0.027684132258097332],\n",
       "    'std_fit_time': [0.0029413045660208496,\n",
       "     9.199648620915592e-07,\n",
       "     0.0004703646302023766,\n",
       "     0.00041029449205964044,\n",
       "     0.005608829441781176,\n",
       "     0.000524981145051696,\n",
       "     0.0,\n",
       "     0.007366819553320161,\n",
       "     0.007371319329925559,\n",
       "     0.007364290794511344,\n",
       "     1.1239159602905075e-07,\n",
       "     1.1239159602905075e-07,\n",
       "     0.0073652461121372975,\n",
       "     0.0064139636494522576,\n",
       "     0.0009421787495115325,\n",
       "     0.014593868961719802,\n",
       "     0.0005231828795152312,\n",
       "     0.007416496638765001,\n",
       "     0.003970459635680923,\n",
       "     0.0005284613644328687,\n",
       "     0.0005221713551509698,\n",
       "     0.0005221713551509698,\n",
       "     0.007114430633448823,\n",
       "     0.005064312160254351],\n",
       "    'mean_score_time': [0.008997122446695963,\n",
       "     0.009190082550048828,\n",
       "     0.00861215591430664,\n",
       "     0.0025987625122070312,\n",
       "     0.010399341583251953,\n",
       "     0.01042954126993815,\n",
       "     0.0,\n",
       "     0.010418256123860678,\n",
       "     0.010416825612386068,\n",
       "     0.0052076975504557295,\n",
       "     0.010415395100911459,\n",
       "     0.016617298126220703,\n",
       "     0.011414527893066406,\n",
       "     0.009349664052327475,\n",
       "     0.011485099792480469,\n",
       "     0.01111443837483724,\n",
       "     0.019101063410441082,\n",
       "     0.002068042755126953,\n",
       "     0.010046005249023438,\n",
       "     0.010423978169759115,\n",
       "     0.010432720184326172,\n",
       "     0.005216360092163086,\n",
       "     0.001628875732421875,\n",
       "     0.001628875732421875],\n",
       "    'std_score_time': [2.570305129495657e-06,\n",
       "     0.00026872858814193975,\n",
       "     0.0012235278643032356,\n",
       "     0.001882483419634786,\n",
       "     0.00735353797258099,\n",
       "     0.007374799356638224,\n",
       "     0.0,\n",
       "     0.007366819553320161,\n",
       "     0.007365808237320315,\n",
       "     0.007364796504591637,\n",
       "     0.007364796504591638,\n",
       "     0.0008159829341132528,\n",
       "     0.008163523933653561,\n",
       "     0.0086346963271016,\n",
       "     0.0058547030203453115,\n",
       "     0.007905611665770236,\n",
       "     0.0024409206825589244,\n",
       "     0.0029246541118679585,\n",
       "     0.007117977797437161,\n",
       "     0.0073708734269444165,\n",
       "     0.007377047188558804,\n",
       "     0.007377047188558804,\n",
       "     0.002303578152211424,\n",
       "     0.002303578152211424],\n",
       "    'param_classifier__criterion': ['gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy'],\n",
       "    'param_classifier__max_depth': [3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10],\n",
       "    'params': [{'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10}],\n",
       "    'split0_test_score': [0.8208955223880597,\n",
       "     0.8208955223880597,\n",
       "     0.8208955223880597,\n",
       "     0.7761194029850746,\n",
       "     0.8059701492537313,\n",
       "     0.7910447761194029,\n",
       "     0.7985074626865671,\n",
       "     0.8134328358208955,\n",
       "     0.8134328358208955,\n",
       "     0.8208955223880597,\n",
       "     0.8208955223880597,\n",
       "     0.8059701492537313,\n",
       "     0.7985074626865671,\n",
       "     0.7985074626865671,\n",
       "     0.7985074626865671,\n",
       "     0.7910447761194029,\n",
       "     0.7910447761194029,\n",
       "     0.7910447761194029,\n",
       "     0.7761194029850746,\n",
       "     0.7761194029850746,\n",
       "     0.7835820895522388,\n",
       "     0.753731343283582,\n",
       "     0.7910447761194029,\n",
       "     0.7686567164179104],\n",
       "    'split1_test_score': [0.849624060150376,\n",
       "     0.849624060150376,\n",
       "     0.849624060150376,\n",
       "     0.8421052631578947,\n",
       "     0.849624060150376,\n",
       "     0.849624060150376,\n",
       "     0.8195488721804511,\n",
       "     0.8345864661654135,\n",
       "     0.8421052631578947,\n",
       "     0.8195488721804511,\n",
       "     0.8045112781954887,\n",
       "     0.8045112781954887,\n",
       "     0.849624060150376,\n",
       "     0.849624060150376,\n",
       "     0.849624060150376,\n",
       "     0.8270676691729323,\n",
       "     0.8421052631578947,\n",
       "     0.8421052631578947,\n",
       "     0.8270676691729323,\n",
       "     0.8195488721804511,\n",
       "     0.8195488721804511,\n",
       "     0.7669172932330827,\n",
       "     0.8045112781954887,\n",
       "     0.7894736842105263],\n",
       "    'split2_test_score': [0.7669172932330827,\n",
       "     0.7669172932330827,\n",
       "     0.7669172932330827,\n",
       "     0.7443609022556391,\n",
       "     0.7443609022556391,\n",
       "     0.7443609022556391,\n",
       "     0.7443609022556391,\n",
       "     0.7518796992481203,\n",
       "     0.7819548872180451,\n",
       "     0.7368421052631579,\n",
       "     0.7518796992481203,\n",
       "     0.7819548872180451,\n",
       "     0.7443609022556391,\n",
       "     0.7443609022556391,\n",
       "     0.7443609022556391,\n",
       "     0.7518796992481203,\n",
       "     0.7443609022556391,\n",
       "     0.7293233082706767,\n",
       "     0.7293233082706767,\n",
       "     0.7443609022556391,\n",
       "     0.7368421052631579,\n",
       "     0.7443609022556391,\n",
       "     0.7593984962406015,\n",
       "     0.7443609022556391],\n",
       "    'mean_test_score': [0.8124789585905061,\n",
       "     0.8124789585905061,\n",
       "     0.8124789585905061,\n",
       "     0.7875285227995361,\n",
       "     0.7999850372199154,\n",
       "     0.795009912841806,\n",
       "     0.787472412374219,\n",
       "     0.7999663337448096,\n",
       "     0.8124976620656117,\n",
       "     0.7924288332772229,\n",
       "     0.7924288332772229,\n",
       "     0.7974787715557551,\n",
       "     0.7974974750308608,\n",
       "     0.7974974750308608,\n",
       "     0.7974974750308608,\n",
       "     0.7899973815134852,\n",
       "     0.7925036471776455,\n",
       "     0.7874911158493246,\n",
       "     0.7775034601428944,\n",
       "     0.780009725807055,\n",
       "     0.7799910223319494,\n",
       "     0.7550031795907679,\n",
       "     0.7849848501851643,\n",
       "     0.7674971009613586],\n",
       "    'std_test_score': [0.034285383018584734,\n",
       "     0.034285383018584734,\n",
       "     0.034285383018584734,\n",
       "     0.04071130910245253,\n",
       "     0.04318139473612889,\n",
       "     0.04306487226200016,\n",
       "     0.03167161670329496,\n",
       "     0.03508192632588074,\n",
       "     0.024565190058166163,\n",
       "     0.03930959692134264,\n",
       "     0.029442430462662185,\n",
       "     0.010993189251807756,\n",
       "     0.04297943817526069,\n",
       "     0.04297943817526069,\n",
       "     0.04297943817526069,\n",
       "     0.03070429374912667,\n",
       "     0.03991729993057338,\n",
       "     0.04611155829819654,\n",
       "     0.03991596783836164,\n",
       "     0.03081837832742042,\n",
       "     0.03386024361315542,\n",
       "     0.009252418392904325,\n",
       "     0.018909130081764595,\n",
       "     0.0184354604848483],\n",
       "    'rank_test_score': [2,\n",
       "     2,\n",
       "     2,\n",
       "     16,\n",
       "     5,\n",
       "     11,\n",
       "     18,\n",
       "     6,\n",
       "     1,\n",
       "     13,\n",
       "     13,\n",
       "     10,\n",
       "     7,\n",
       "     7,\n",
       "     7,\n",
       "     15,\n",
       "     12,\n",
       "     17,\n",
       "     22,\n",
       "     20,\n",
       "     21,\n",
       "     24,\n",
       "     19,\n",
       "     23]}}],\n",
       " 'diabetes random_forest': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__max_depth': None,\n",
       "    'classifier__min_samples_leaf': 4,\n",
       "    'classifier__min_samples_split': 2,\n",
       "    'classifier__n_estimators': 100},\n",
       "   'best_validation_accuracy': 0.8554621848739495,\n",
       "   'train_accuracy': 0.8846153846153846,\n",
       "   'test_accuracy': 0.8677884615384616,\n",
       "   'cv_results': {'mean_fit_time': [0.232712189356486,\n",
       "     0.4634569485982259,\n",
       "     0.7064388593037924,\n",
       "     0.26201430956522626,\n",
       "     0.5055394172668457,\n",
       "     0.7065604527791342,\n",
       "     0.253631591796875,\n",
       "     0.42258254686991376,\n",
       "     0.7086464564005533,\n",
       "     0.23525778452555338,\n",
       "     0.44719282786051434,\n",
       "     0.6916094621022543,\n",
       "     0.24715240796407065,\n",
       "     0.4977194468180339,\n",
       "     0.7544693152109782,\n",
       "     0.23754398028055826,\n",
       "     0.526942253112793,\n",
       "     0.776996374130249,\n",
       "     0.2605441411336263,\n",
       "     0.5401235421498617,\n",
       "     0.7193400065104166,\n",
       "     0.2578600247701009,\n",
       "     0.5319844881693522,\n",
       "     0.8202618757883707,\n",
       "     0.2766335805257161,\n",
       "     0.4987434546152751,\n",
       "     0.7482108275095621,\n",
       "     0.26111547152201336,\n",
       "     0.5559282302856445,\n",
       "     0.8388063907623291,\n",
       "     0.29924535751342773,\n",
       "     0.5780522028605143,\n",
       "     0.8637320200602213,\n",
       "     0.28412524859110516,\n",
       "     0.517102320988973,\n",
       "     0.7307374477386475,\n",
       "     0.268752654393514,\n",
       "     0.46106775601704914,\n",
       "     0.7004400889078776,\n",
       "     0.2252656618754069,\n",
       "     0.44184120496114093,\n",
       "     0.671911875406901,\n",
       "     0.23795143763224283,\n",
       "     0.44838110605875653,\n",
       "     0.6540999412536621,\n",
       "     0.23273475964864096,\n",
       "     0.4236205418904622,\n",
       "     0.6350463231404623,\n",
       "     0.2401109536488851,\n",
       "     0.4209283192952474,\n",
       "     0.6723031202952067,\n",
       "     0.2200315793355306,\n",
       "     0.40216581026713055,\n",
       "     0.6340454419453939,\n",
       "     0.23749446868896484,\n",
       "     0.4608000119527181,\n",
       "     0.7292664051055908,\n",
       "     0.23794102668762207,\n",
       "     0.4574093023935954,\n",
       "     0.7320213317871094,\n",
       "     0.2431305249532064,\n",
       "     0.4758652051289876,\n",
       "     0.6758212248484293,\n",
       "     0.24994182586669922,\n",
       "     0.4540896415710449,\n",
       "     0.6787668069203695,\n",
       "     0.22107172012329102,\n",
       "     0.4214971860249837,\n",
       "     0.6312674681345621,\n",
       "     0.23224361737569174,\n",
       "     0.4282015959421794,\n",
       "     0.6260179678599039,\n",
       "     0.23181692759195963,\n",
       "     0.4519563515981038,\n",
       "     0.6381974220275879,\n",
       "     0.21376999219258627,\n",
       "     0.42907174428304035,\n",
       "     0.6353118419647217,\n",
       "     0.2500292460123698,\n",
       "     0.44472503662109375,\n",
       "     0.6434237162272135,\n",
       "     0.22446123758951822,\n",
       "     0.41399606068929035,\n",
       "     0.6761695543924967,\n",
       "     0.22850441932678223,\n",
       "     0.40677547454833984,\n",
       "     0.6682446797688802,\n",
       "     0.211531400680542,\n",
       "     0.45502567291259766,\n",
       "     0.640575091044108,\n",
       "     0.21463791529337564,\n",
       "     0.42380523681640625,\n",
       "     0.626880963643392,\n",
       "     0.22943909962972006,\n",
       "     0.4321550528208415,\n",
       "     0.6739166577657064,\n",
       "     0.2304072380065918,\n",
       "     0.40096179644266766,\n",
       "     0.6699443658192953,\n",
       "     0.23261205355326334,\n",
       "     0.4257626533508301,\n",
       "     0.6502774556477865,\n",
       "     0.20515775680541992,\n",
       "     0.42202432950337726,\n",
       "     0.6224816640218099,\n",
       "     0.2230683167775472,\n",
       "     0.3945771058400472,\n",
       "     0.47190101941426593],\n",
       "    'std_fit_time': [0.007383903075916576,\n",
       "     0.003950115034037018,\n",
       "     0.02375458827613963,\n",
       "     0.002023766505630982,\n",
       "     0.029454561557125176,\n",
       "     0.06013779121734534,\n",
       "     0.021245820379643565,\n",
       "     0.004473428243095675,\n",
       "     0.027308994703984034,\n",
       "     0.019895291458827968,\n",
       "     0.02305183214432653,\n",
       "     0.09171231127807691,\n",
       "     0.010886516986600982,\n",
       "     0.09547359129663131,\n",
       "     0.06501654239471809,\n",
       "     0.016318295694992147,\n",
       "     0.032396024406926086,\n",
       "     0.07097577566760303,\n",
       "     0.04122508043097216,\n",
       "     0.028743556476334406,\n",
       "     0.038770091992536664,\n",
       "     0.017052908532422677,\n",
       "     0.03937029668231969,\n",
       "     0.05758426675754807,\n",
       "     0.016076212542497647,\n",
       "     0.03926287684575017,\n",
       "     0.03936715525191547,\n",
       "     0.007482820121005793,\n",
       "     0.04332706323595957,\n",
       "     0.05115341860148268,\n",
       "     0.0062725402227069,\n",
       "     0.026248376075842936,\n",
       "     0.022106420282979655,\n",
       "     0.022144204992484196,\n",
       "     0.030757616897617128,\n",
       "     0.05716403609540553,\n",
       "     0.012736367319841319,\n",
       "     0.020198066987376334,\n",
       "     0.004413629950743784,\n",
       "     0.019656575623968484,\n",
       "     0.01282119008701572,\n",
       "     0.04107207517153761,\n",
       "     0.01387191593918717,\n",
       "     0.019965501558441956,\n",
       "     0.042171951162451565,\n",
       "     0.020431368107244673,\n",
       "     0.012065197132397116,\n",
       "     0.02536843089876675,\n",
       "     0.01722867805862366,\n",
       "     0.017442276570940444,\n",
       "     0.02068195291428466,\n",
       "     0.015205270902810191,\n",
       "     0.006160357439327286,\n",
       "     0.024154558819420732,\n",
       "     0.007375024139830281,\n",
       "     0.04687795116701438,\n",
       "     0.012058044771572738,\n",
       "     0.027635168501199663,\n",
       "     0.02167939344459098,\n",
       "     0.03128110127357539,\n",
       "     0.022225408694839695,\n",
       "     0.021417271077384364,\n",
       "     0.02402319495462469,\n",
       "     0.027923028656817356,\n",
       "     0.01283638293235647,\n",
       "     0.027871589600686492,\n",
       "     0.019855759820043912,\n",
       "     0.034293905934309726,\n",
       "     0.04211566355987644,\n",
       "     0.00986076708495061,\n",
       "     0.010928805750507826,\n",
       "     0.02880562857698481,\n",
       "     1.275384651930219e-05,\n",
       "     0.027942599626561912,\n",
       "     0.014985081844217917,\n",
       "     0.003913485052243436,\n",
       "     0.021941677861694472,\n",
       "     0.025001004858036677,\n",
       "     0.003525827501424297,\n",
       "     0.026824570380790978,\n",
       "     0.03337772572898516,\n",
       "     0.0065481112032213275,\n",
       "     0.009513567923318275,\n",
       "     0.007938175460663765,\n",
       "     0.022768814828657048,\n",
       "     0.014052266568934622,\n",
       "     0.025184306272380712,\n",
       "     0.0073649088961876665,\n",
       "     0.019506362969251758,\n",
       "     0.03853420229578767,\n",
       "     0.01624039759591368,\n",
       "     0.027976305221637854,\n",
       "     0.026965661293560178,\n",
       "     0.010608842451653576,\n",
       "     0.014359899479050472,\n",
       "     0.04564381019293696,\n",
       "     0.014430575537238218,\n",
       "     0.00463881920271767,\n",
       "     0.03917783419991341,\n",
       "     0.022684887462008266,\n",
       "     0.03322704759720559,\n",
       "     0.049848791934616186,\n",
       "     0.006795857895900374,\n",
       "     0.007699780604588797,\n",
       "     0.028985370542282944,\n",
       "     0.015985730587324082,\n",
       "     0.007332748775595169,\n",
       "     0.014017755075124939],\n",
       "    'mean_score_time': [0.025791645050048828,\n",
       "     0.03660734494527181,\n",
       "     0.056534528732299805,\n",
       "     0.020702679951985676,\n",
       "     0.030052582422892254,\n",
       "     0.04728825887044271,\n",
       "     0.020939429601033527,\n",
       "     0.035198609034220375,\n",
       "     0.048010031382242836,\n",
       "     0.01645549138387044,\n",
       "     0.037060181299845375,\n",
       "     0.05725963910420736,\n",
       "     0.01925508181254069,\n",
       "     0.03808784484863281,\n",
       "     0.04932697614034017,\n",
       "     0.030598799387613933,\n",
       "     0.029874722162882488,\n",
       "     0.06184037526448568,\n",
       "     0.02315966288248698,\n",
       "     0.04126572608947754,\n",
       "     0.044061899185180664,\n",
       "     0.02738046646118164,\n",
       "     0.033387978871663414,\n",
       "     0.04221638043721517,\n",
       "     0.016720692316691082,\n",
       "     0.03494779268900553,\n",
       "     0.05641857782999674,\n",
       "     0.020682414372762043,\n",
       "     0.036870320638020836,\n",
       "     0.0628509521484375,\n",
       "     0.01787678400675456,\n",
       "     0.046776533126831055,\n",
       "     0.048806349436442055,\n",
       "     0.024304946263631184,\n",
       "     0.03615037600199381,\n",
       "     0.0523070494333903,\n",
       "     0.02194801966349284,\n",
       "     0.03464325269063314,\n",
       "     0.05205663045247396,\n",
       "     0.01884174346923828,\n",
       "     0.03278978665669759,\n",
       "     0.04187234242757162,\n",
       "     0.019744157791137695,\n",
       "     0.029610951741536457,\n",
       "     0.041795969009399414,\n",
       "     0.02207183837890625,\n",
       "     0.03061389923095703,\n",
       "     0.04432980219523112,\n",
       "     0.02124508221944173,\n",
       "     0.03318007787068685,\n",
       "     0.03851779301961263,\n",
       "     0.0237576961517334,\n",
       "     0.03535620371500651,\n",
       "     0.045450051625569664,\n",
       "     0.025982141494750977,\n",
       "     0.045452276865641274,\n",
       "     0.05200060208638509,\n",
       "     0.018998384475708008,\n",
       "     0.03606804211934408,\n",
       "     0.050800482432047524,\n",
       "     0.022268056869506836,\n",
       "     0.028159697850545246,\n",
       "     0.05095672607421875,\n",
       "     0.0202944278717041,\n",
       "     0.027451753616333008,\n",
       "     0.047628164291381836,\n",
       "     0.022704203923543293,\n",
       "     0.034078359603881836,\n",
       "     0.05114308993021647,\n",
       "     0.019350369771321613,\n",
       "     0.034313042958577476,\n",
       "     0.04387195905049642,\n",
       "     0.022977908452351887,\n",
       "     0.031249443689982098,\n",
       "     0.038855950037638344,\n",
       "     0.015629132588704426,\n",
       "     0.03646135330200195,\n",
       "     0.048821051915486656,\n",
       "     0.02337368329366048,\n",
       "     0.030517180760701496,\n",
       "     0.05308675765991211,\n",
       "     0.02154692014058431,\n",
       "     0.029758294423421223,\n",
       "     0.047930240631103516,\n",
       "     0.02097765604654948,\n",
       "     0.03139106432596842,\n",
       "     0.04062406222025553,\n",
       "     0.016037702560424805,\n",
       "     0.03282356262207031,\n",
       "     0.04368925094604492,\n",
       "     0.01770504315694173,\n",
       "     0.03284096717834473,\n",
       "     0.04954973856608073,\n",
       "     0.015626033147176106,\n",
       "     0.027839501698811848,\n",
       "     0.04487967491149902,\n",
       "     0.01787114143371582,\n",
       "     0.03338503837585449,\n",
       "     0.04045573870340983,\n",
       "     0.014601627985636393,\n",
       "     0.030277490615844727,\n",
       "     0.04454342524210612,\n",
       "     0.028207858403523762,\n",
       "     0.026394128799438477,\n",
       "     0.034778594970703125,\n",
       "     0.020644108454386394,\n",
       "     0.025660276412963867,\n",
       "     0.02241341272989909],\n",
       "    'std_score_time': [0.004739570569862217,\n",
       "     0.006127683335647588,\n",
       "     0.0031837179468800184,\n",
       "     0.0004716145827473526,\n",
       "     0.0052508835631260645,\n",
       "     2.5768576898816964e-05,\n",
       "     0.002053203000330278,\n",
       "     0.0015622083025909747,\n",
       "     0.0016129345435096107,\n",
       "     0.0027977942592370326,\n",
       "     0.007916279033455292,\n",
       "     0.010137958637442306,\n",
       "     0.0019266037014771527,\n",
       "     0.0030248209825061126,\n",
       "     0.0012332289804098243,\n",
       "     0.008855348852591257,\n",
       "     0.003647310073540748,\n",
       "     0.0029357147203613017,\n",
       "     0.004991170748791381,\n",
       "     0.003136464060473378,\n",
       "     0.002954846993197159,\n",
       "     0.006253752164188527,\n",
       "     0.005352471026352599,\n",
       "     0.007550234215942904,\n",
       "     0.0034003740722208177,\n",
       "     0.000981629184140993,\n",
       "     0.006793361517297022,\n",
       "     0.004368730702115069,\n",
       "     0.00595842212760519,\n",
       "     0.01293045688915036,\n",
       "     0.006538499953833765,\n",
       "     0.013658883622868264,\n",
       "     0.003166783354573259,\n",
       "     0.004130898547256988,\n",
       "     0.005539183366424367,\n",
       "     0.0046945732379123735,\n",
       "     0.001809289278817753,\n",
       "     0.0031866313311221,\n",
       "     0.008605983243280274,\n",
       "     0.0015230175225128656,\n",
       "     0.0038363944371329088,\n",
       "     0.009077381248583422,\n",
       "     0.0028852349627077477,\n",
       "     0.006329369953309379,\n",
       "     0.007730414464821912,\n",
       "     0.006870462643848671,\n",
       "     0.005366191510810366,\n",
       "     0.00803289465980539,\n",
       "     0.00793046633422831,\n",
       "     0.002701556793750293,\n",
       "     0.010279391672299546,\n",
       "     0.007418680020785931,\n",
       "     0.0029030620828237445,\n",
       "     0.01465098613398064,\n",
       "     0.007335262152603007,\n",
       "     0.009804662318805845,\n",
       "     0.012420990308836685,\n",
       "     0.002577613163107961,\n",
       "     0.0073756490352257734,\n",
       "     0.0037922221411752716,\n",
       "     0.008308475058621608,\n",
       "     0.008912445660194272,\n",
       "     0.002569947126913943,\n",
       "     0.004310105316118067,\n",
       "     0.004044364611672072,\n",
       "     0.006777068785057417,\n",
       "     0.007996711628878609,\n",
       "     0.0036846369256475263,\n",
       "     0.0030232140833436286,\n",
       "     0.00345417817296136,\n",
       "     0.0022243275729903218,\n",
       "     0.004261777089881117,\n",
       "     0.006411041557627086,\n",
       "     1.2665889621185641e-06,\n",
       "     0.006277273797082894,\n",
       "     4.185738271797083e-06,\n",
       "     0.007371989566737497,\n",
       "     0.0021248335084495234,\n",
       "     0.008723699952708348,\n",
       "     0.0009816281997177293,\n",
       "     0.0008860974814389345,\n",
       "     0.0008135109852046433,\n",
       "     0.0064666634036990855,\n",
       "     0.001176952875023845,\n",
       "     0.007556481756380944,\n",
       "     0.00020438599468377837,\n",
       "     0.006661290218828969,\n",
       "     0.0,\n",
       "     0.006476597594474575,\n",
       "     0.00913768390542745,\n",
       "     0.007275975021480612,\n",
       "     0.0022477758280453584,\n",
       "     0.005164794803141948,\n",
       "     1.9106571324938627e-06,\n",
       "     0.006999467654860392,\n",
       "     0.004277963298014685,\n",
       "     0.001861941735008769,\n",
       "     0.0037571912582773643,\n",
       "     0.004833966072961142,\n",
       "     0.0034685233509360656,\n",
       "     0.00597343711894889,\n",
       "     0.007036309131703159,\n",
       "     0.0046006200098684955,\n",
       "     0.0068805646169118155,\n",
       "     0.008801691489141766,\n",
       "     0.007087640007735421,\n",
       "     0.007092471667413247,\n",
       "     0.006523749500344225],\n",
       "    'param_classifier__max_depth': [None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30],\n",
       "    'param_classifier__min_samples_leaf': [1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10],\n",
       "    'param_classifier__n_estimators': [100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300],\n",
       "    'params': [{'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300}],\n",
       "    'split0_test_score': [0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.7714285714285715,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8857142857142857,\n",
       "     0.7714285714285715,\n",
       "     0.8,\n",
       "     0.8857142857142857,\n",
       "     0.8,\n",
       "     0.8285714285714286,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8285714285714286,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8857142857142857,\n",
       "     0.8,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.7714285714285715,\n",
       "     0.8571428571428571,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.7714285714285715,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.7714285714285715,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.7714285714285715,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8571428571428571,\n",
       "     0.8,\n",
       "     0.8857142857142857,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8571428571428571,\n",
       "     0.8571428571428571,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8285714285714286,\n",
       "     0.8571428571428571,\n",
       "     0.8285714285714286,\n",
       "     0.8571428571428571,\n",
       "     0.8,\n",
       "     0.8857142857142857,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.7714285714285715,\n",
       "     0.8,\n",
       "     0.8857142857142857,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.7714285714285715,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8857142857142857,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8571428571428571,\n",
       "     0.8285714285714286,\n",
       "     0.8571428571428571,\n",
       "     0.8857142857142857,\n",
       "     0.8,\n",
       "     0.8285714285714286],\n",
       "    'split1_test_score': [0.7428571428571429,\n",
       "     0.7142857142857143,\n",
       "     0.7428571428571429,\n",
       "     0.7714285714285715,\n",
       "     0.8,\n",
       "     0.7714285714285715,\n",
       "     0.7428571428571429,\n",
       "     0.8,\n",
       "     0.7714285714285715,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8571428571428571,\n",
       "     0.7714285714285715,\n",
       "     0.8,\n",
       "     0.8285714285714286,\n",
       "     0.8285714285714286,\n",
       "     0.8285714285714286,\n",
       "     0.8285714285714286,\n",
       "     0.8571428571428571,\n",
       "     0.8571428571428571,\n",
       "     0.8571428571428571,\n",
       "     0.8571428571428571,\n",
       "     0.8285714285714286,\n",
       "     0.8285714285714286,\n",
       "     0.8571428571428571,\n",
       "     0.8285714285714286,\n",
       "     0.8857142857142857,\n",
       "     0.7142857142857143,\n",
       "     0.7428571428571429,\n",
       "     0.7428571428571429,\n",
       "     0.7714285714285715,\n",
       "     0.7714285714285715,\n",
       "     0.7714285714285715,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.7714285714285715,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.8571428571428571,\n",
       "     0.8571428571428571,\n",
       "     0.8285714285714286,\n",
       "     0.9142857142857143,\n",
       "     0.8857142857142857,\n",
       "     0.8,\n",
       "     0.8571428571428571,\n",
       "     0.8571428571428571,\n",
       "     0.8571428571428571,\n",
       "     0.9142857142857143,\n",
       "     0.8285714285714286,\n",
       "     0.8571428571428571,\n",
       "     0.7428571428571429,\n",
       "     0.7428571428571429,\n",
       "     0.7428571428571429,\n",
       "     0.7428571428571429,\n",
       "     0.7714285714285715,\n",
       "     0.7714285714285715,\n",
       "     0.8285714285714286,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.7714285714285715,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.8285714285714286,\n",
       "     0.8285714285714286,\n",
       "     0.8285714285714286,\n",
       "     0.8571428571428571,\n",
       "     0.8571428571428571,\n",
       "     0.8571428571428571,\n",
       "     0.8571428571428571,\n",
       "     0.8857142857142857,\n",
       "     0.8571428571428571,\n",
       "     0.8571428571428571,\n",
       "     0.8571428571428571,\n",
       "     0.8285714285714286,\n",
       "     0.7142857142857143,\n",
       "     0.7428571428571429,\n",
       "     0.7428571428571429,\n",
       "     0.8,\n",
       "     0.7714285714285715,\n",
       "     0.7714285714285715,\n",
       "     0.8,\n",
       "     0.7714285714285715,\n",
       "     0.8,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.8285714285714286,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8285714285714286,\n",
       "     0.8285714285714286,\n",
       "     0.8285714285714286,\n",
       "     0.8571428571428571,\n",
       "     0.8285714285714286,\n",
       "     0.8285714285714286,\n",
       "     0.8285714285714286,\n",
       "     0.8571428571428571,\n",
       "     0.8571428571428571,\n",
       "     0.8285714285714286,\n",
       "     0.8571428571428571,\n",
       "     0.8285714285714286],\n",
       "    'split2_test_score': [0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058],\n",
       "    'mean_test_score': [0.7887955182072829,\n",
       "     0.7792717086834733,\n",
       "     0.7887955182072829,\n",
       "     0.7983193277310926,\n",
       "     0.8078431372549021,\n",
       "     0.7983193277310926,\n",
       "     0.7887955182072829,\n",
       "     0.8078431372549021,\n",
       "     0.7887955182072829,\n",
       "     0.8173669467787116,\n",
       "     0.8078431372549021,\n",
       "     0.8268907563025211,\n",
       "     0.8078431372549021,\n",
       "     0.8078431372549021,\n",
       "     0.8173669467787116,\n",
       "     0.8173669467787116,\n",
       "     0.8173669467787116,\n",
       "     0.8173669467787116,\n",
       "     0.8554621848739495,\n",
       "     0.8173669467787116,\n",
       "     0.8268907563025211,\n",
       "     0.8554621848739495,\n",
       "     0.8173669467787116,\n",
       "     0.8268907563025211,\n",
       "     0.8364145658263306,\n",
       "     0.8173669467787116,\n",
       "     0.84593837535014,\n",
       "     0.7792717086834733,\n",
       "     0.7887955182072829,\n",
       "     0.7887955182072829,\n",
       "     0.7983193277310926,\n",
       "     0.7983193277310926,\n",
       "     0.8078431372549021,\n",
       "     0.8268907563025211,\n",
       "     0.8078431372549021,\n",
       "     0.7983193277310926,\n",
       "     0.8078431372549021,\n",
       "     0.8078431372549021,\n",
       "     0.8173669467787116,\n",
       "     0.8364145658263306,\n",
       "     0.8173669467787116,\n",
       "     0.8173669467787116,\n",
       "     0.8268907563025211,\n",
       "     0.8268907563025211,\n",
       "     0.8173669467787116,\n",
       "     0.8364145658263306,\n",
       "     0.8554621848739495,\n",
       "     0.8078431372549021,\n",
       "     0.8268907563025211,\n",
       "     0.8364145658263306,\n",
       "     0.8268907563025211,\n",
       "     0.84593837535014,\n",
       "     0.8268907563025211,\n",
       "     0.8268907563025211,\n",
       "     0.7792717086834733,\n",
       "     0.7887955182072829,\n",
       "     0.7887955182072829,\n",
       "     0.7887955182072829,\n",
       "     0.7887955182072829,\n",
       "     0.7983193277310926,\n",
       "     0.8173669467787116,\n",
       "     0.8173669467787116,\n",
       "     0.7983193277310926,\n",
       "     0.8078431372549021,\n",
       "     0.8078431372549021,\n",
       "     0.8078431372549021,\n",
       "     0.8173669467787116,\n",
       "     0.8173669467787116,\n",
       "     0.8364145658263306,\n",
       "     0.8173669467787116,\n",
       "     0.8173669467787116,\n",
       "     0.8364145658263306,\n",
       "     0.84593837535014,\n",
       "     0.8268907563025211,\n",
       "     0.8268907563025211,\n",
       "     0.8364145658263306,\n",
       "     0.8554621848739495,\n",
       "     0.8364145658263306,\n",
       "     0.84593837535014,\n",
       "     0.8268907563025211,\n",
       "     0.84593837535014,\n",
       "     0.7887955182072829,\n",
       "     0.7887955182072829,\n",
       "     0.7887955182072829,\n",
       "     0.8078431372549021,\n",
       "     0.7887955182072829,\n",
       "     0.7983193277310926,\n",
       "     0.8364145658263306,\n",
       "     0.7983193277310926,\n",
       "     0.8078431372549021,\n",
       "     0.8173669467787116,\n",
       "     0.8173669467787116,\n",
       "     0.8173669467787116,\n",
       "     0.8173669467787116,\n",
       "     0.8078431372549021,\n",
       "     0.8078431372549021,\n",
       "     0.8078431372549021,\n",
       "     0.8173669467787116,\n",
       "     0.8173669467787116,\n",
       "     0.8554621848739495,\n",
       "     0.8173669467787116,\n",
       "     0.8173669467787116,\n",
       "     0.8364145658263306,\n",
       "     0.8364145658263306,\n",
       "     0.84593837535014,\n",
       "     0.84593837535014,\n",
       "     0.8268907563025211,\n",
       "     0.8268907563025211],\n",
       "    'std_test_score': [0.03387387441530748,\n",
       "     0.04694530793307925,\n",
       "     0.03387387441530748,\n",
       "     0.021303253044068927,\n",
       "     0.011091871077436,\n",
       "     0.021303253044068927,\n",
       "     0.03387387441530748,\n",
       "     0.011091871077436,\n",
       "     0.02456057167146548,\n",
       "     0.012451602672769103,\n",
       "     0.011091871077436,\n",
       "     0.023449243178102316,\n",
       "     0.025831130270921005,\n",
       "     0.011091871077436,\n",
       "     0.012451602672769103,\n",
       "     0.012451602672769103,\n",
       "     0.012451602672769103,\n",
       "     0.012451602672769103,\n",
       "     0.02541466940552102,\n",
       "     0.03526298035149849,\n",
       "     0.023449243178102316,\n",
       "     0.02541466940552102,\n",
       "     0.012451602672769103,\n",
       "     0.002376829516593481,\n",
       "     0.014800946569885589,\n",
       "     0.012451602672769103,\n",
       "     0.028201037419951173,\n",
       "     0.04694530793307925,\n",
       "     0.03387387441530748,\n",
       "     0.03387387441530748,\n",
       "     0.021303253044068927,\n",
       "     0.021303253044068927,\n",
       "     0.025831130270921005,\n",
       "     0.002376829516593481,\n",
       "     0.011091871077436,\n",
       "     0.021303253044068927,\n",
       "     0.011091871077436,\n",
       "     0.011091871077436,\n",
       "     0.012451602672769103,\n",
       "     0.03615941638791017,\n",
       "     0.012451602672769103,\n",
       "     0.012451602672769103,\n",
       "     0.023449243178102316,\n",
       "     0.023449243178102316,\n",
       "     0.012451602672769103,\n",
       "     0.0590285874963444,\n",
       "     0.02541466940552102,\n",
       "     0.011091871077436,\n",
       "     0.023449243178102316,\n",
       "     0.014800946569885589,\n",
       "     0.023449243178102316,\n",
       "     0.0492742485765737,\n",
       "     0.002376829516593481,\n",
       "     0.023449243178102316,\n",
       "     0.03339800237711791,\n",
       "     0.03387387441530748,\n",
       "     0.03387387441530748,\n",
       "     0.03387387441530748,\n",
       "     0.02456057167146548,\n",
       "     0.021303253044068927,\n",
       "     0.012451602672769103,\n",
       "     0.012451602672769103,\n",
       "     0.021303253044068927,\n",
       "     0.011091871077436,\n",
       "     0.011091871077436,\n",
       "     0.011091871077436,\n",
       "     0.03526298035149849,\n",
       "     0.012451602672769103,\n",
       "     0.03615941638791017,\n",
       "     0.012451602672769103,\n",
       "     0.012451602672769103,\n",
       "     0.014800946569885589,\n",
       "     0.01584553011062291,\n",
       "     0.023449243178102316,\n",
       "     0.023449243178102316,\n",
       "     0.014800946569885589,\n",
       "     0.02541466940552102,\n",
       "     0.014800946569885589,\n",
       "     0.01584553011062291,\n",
       "     0.023449243178102316,\n",
       "     0.028201037419951173,\n",
       "     0.05272658180774204,\n",
       "     0.03387387441530748,\n",
       "     0.03387387441530748,\n",
       "     0.011091871077436,\n",
       "     0.02456057167146548,\n",
       "     0.021303253044068927,\n",
       "     0.03615941638791017,\n",
       "     0.021303253044068927,\n",
       "     0.011091871077436,\n",
       "     0.012451602672769103,\n",
       "     0.012451602672769103,\n",
       "     0.012451602672769103,\n",
       "     0.012451602672769103,\n",
       "     0.011091871077436,\n",
       "     0.011091871077436,\n",
       "     0.025831130270921005,\n",
       "     0.012451602672769103,\n",
       "     0.012451602672769103,\n",
       "     0.02541466940552102,\n",
       "     0.012451602672769103,\n",
       "     0.012451602672769103,\n",
       "     0.014800946569885589,\n",
       "     0.014800946569885589,\n",
       "     0.01584553011062291,\n",
       "     0.028201037419951173,\n",
       "     0.023449243178102316,\n",
       "     0.002376829516593481],\n",
       "    'rank_test_score': [92,\n",
       "     106,\n",
       "     92,\n",
       "     83,\n",
       "     65,\n",
       "     83,\n",
       "     92,\n",
       "     65,\n",
       "     92,\n",
       "     39,\n",
       "     65,\n",
       "     24,\n",
       "     65,\n",
       "     65,\n",
       "     39,\n",
       "     39,\n",
       "     39,\n",
       "     39,\n",
       "     1,\n",
       "     39,\n",
       "     24,\n",
       "     1,\n",
       "     39,\n",
       "     24,\n",
       "     13,\n",
       "     39,\n",
       "     6,\n",
       "     106,\n",
       "     92,\n",
       "     92,\n",
       "     83,\n",
       "     83,\n",
       "     65,\n",
       "     24,\n",
       "     65,\n",
       "     83,\n",
       "     65,\n",
       "     65,\n",
       "     39,\n",
       "     13,\n",
       "     39,\n",
       "     39,\n",
       "     24,\n",
       "     24,\n",
       "     39,\n",
       "     13,\n",
       "     1,\n",
       "     65,\n",
       "     24,\n",
       "     13,\n",
       "     24,\n",
       "     6,\n",
       "     24,\n",
       "     24,\n",
       "     106,\n",
       "     92,\n",
       "     92,\n",
       "     92,\n",
       "     92,\n",
       "     83,\n",
       "     39,\n",
       "     39,\n",
       "     83,\n",
       "     65,\n",
       "     65,\n",
       "     65,\n",
       "     39,\n",
       "     39,\n",
       "     13,\n",
       "     39,\n",
       "     39,\n",
       "     13,\n",
       "     6,\n",
       "     24,\n",
       "     24,\n",
       "     13,\n",
       "     1,\n",
       "     13,\n",
       "     6,\n",
       "     24,\n",
       "     6,\n",
       "     92,\n",
       "     92,\n",
       "     92,\n",
       "     65,\n",
       "     92,\n",
       "     83,\n",
       "     13,\n",
       "     83,\n",
       "     65,\n",
       "     39,\n",
       "     39,\n",
       "     39,\n",
       "     39,\n",
       "     65,\n",
       "     65,\n",
       "     65,\n",
       "     39,\n",
       "     39,\n",
       "     1,\n",
       "     39,\n",
       "     39,\n",
       "     13,\n",
       "     13,\n",
       "     6,\n",
       "     6,\n",
       "     24,\n",
       "     24]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__max_depth': 30,\n",
       "    'classifier__min_samples_leaf': 1,\n",
       "    'classifier__min_samples_split': 2,\n",
       "    'classifier__n_estimators': 200},\n",
       "   'best_validation_accuracy': 0.9538447830348392,\n",
       "   'train_accuracy': 0.9961538461538462,\n",
       "   'test_accuracy': 0.9653846153846154,\n",
       "   'cv_results': {'mean_fit_time': [0.20386187235514322,\n",
       "     0.49128882090250653,\n",
       "     0.6830120881398519,\n",
       "     0.2550505797068278,\n",
       "     0.4912274678548177,\n",
       "     0.7768666744232178,\n",
       "     0.2518659432729085,\n",
       "     0.5066818396250407,\n",
       "     0.7317506472269694,\n",
       "     0.27188460032145184,\n",
       "     0.4888494809468587,\n",
       "     0.7570687929789225,\n",
       "     0.24769282341003418,\n",
       "     0.4536770184834798,\n",
       "     0.7278585433959961,\n",
       "     0.26850183804829914,\n",
       "     0.5044840971628824,\n",
       "     0.6948471864064535,\n",
       "     0.25373514493306476,\n",
       "     0.4787150224049886,\n",
       "     0.6918438275655111,\n",
       "     0.2503691514333089,\n",
       "     0.43539198239644367,\n",
       "     0.7121439774831136,\n",
       "     0.2722342809041341,\n",
       "     0.4722348054250081,\n",
       "     0.7171754042307535,\n",
       "     0.2199383576711019,\n",
       "     0.4878996213277181,\n",
       "     0.6967183748881022,\n",
       "     0.24361578623453775,\n",
       "     0.46437883377075195,\n",
       "     0.7152198155721029,\n",
       "     0.2576986948649089,\n",
       "     0.4798738161722819,\n",
       "     0.7380975087483724,\n",
       "     0.2759080727895101,\n",
       "     0.5689109961191813,\n",
       "     0.7719131310780843,\n",
       "     0.2917059262593587,\n",
       "     0.5034826596577963,\n",
       "     0.7106584707895914,\n",
       "     0.2622777620951335,\n",
       "     0.467955748240153,\n",
       "     0.6793199380238851,\n",
       "     0.25566943486531574,\n",
       "     0.45958463350931805,\n",
       "     0.67601211865743,\n",
       "     0.26897462209065753,\n",
       "     0.46067094802856445,\n",
       "     0.7303926944732666,\n",
       "     0.2530368169148763,\n",
       "     0.4231383005777995,\n",
       "     0.7006640434265137,\n",
       "     0.25064269701639813,\n",
       "     0.44581762949625653,\n",
       "     0.7072148323059082,\n",
       "     0.2260445753733317,\n",
       "     0.47741444905598956,\n",
       "     0.748202403386434,\n",
       "     0.23599163691202799,\n",
       "     0.6173820495605469,\n",
       "     0.834556500116984,\n",
       "     0.3367334206899007,\n",
       "     0.5823421478271484,\n",
       "     0.8054386774698893,\n",
       "     0.25328811009724933,\n",
       "     0.48580296834309894,\n",
       "     0.696735699971517,\n",
       "     0.26277701059977215,\n",
       "     0.4457503954569499,\n",
       "     0.6290011405944824,\n",
       "     0.2440931797027588,\n",
       "     0.44924060503641766,\n",
       "     0.678511381149292,\n",
       "     0.24223637580871582,\n",
       "     0.4385286172231038,\n",
       "     0.6586708227793375,\n",
       "     0.22420342763264975,\n",
       "     0.44789687792460126,\n",
       "     0.6768054167429606,\n",
       "     0.2307103474934896,\n",
       "     0.4553390343983968,\n",
       "     0.651041587193807,\n",
       "     0.22579391797383627,\n",
       "     0.45494453112284344,\n",
       "     0.6679886976877848,\n",
       "     0.23348379135131836,\n",
       "     0.4280429681142171,\n",
       "     0.6750083764394125,\n",
       "     0.23655390739440918,\n",
       "     0.4708726406097412,\n",
       "     0.6996448040008545,\n",
       "     0.21028566360473633,\n",
       "     0.4273232618967692,\n",
       "     0.7045674324035645,\n",
       "     0.23700888951619467,\n",
       "     0.42565004030863446,\n",
       "     0.6768659750620524,\n",
       "     0.25360107421875,\n",
       "     0.4767908255259196,\n",
       "     0.6611249446868896,\n",
       "     0.2213157812754313,\n",
       "     0.4310613473256429,\n",
       "     0.6505239009857178,\n",
       "     0.24818245569864908,\n",
       "     0.42359232902526855,\n",
       "     0.5353395938873291],\n",
       "    'std_fit_time': [0.025896260781891136,\n",
       "     0.01473397628142841,\n",
       "     0.017343405334933913,\n",
       "     0.02748157648525502,\n",
       "     0.01861929625632935,\n",
       "     0.05716702004984717,\n",
       "     0.013754796655986177,\n",
       "     0.03744152211703252,\n",
       "     0.09276449075379271,\n",
       "     0.006217674981844933,\n",
       "     0.015085820338457328,\n",
       "     0.07287202637718843,\n",
       "     0.03424737426692998,\n",
       "     0.008898099501294542,\n",
       "     0.042567921560916204,\n",
       "     0.01626114421121188,\n",
       "     0.027134689312143388,\n",
       "     0.056501045307570066,\n",
       "     0.008851645568120656,\n",
       "     0.03668115481168899,\n",
       "     0.05089557076938127,\n",
       "     0.015674807414878093,\n",
       "     0.008519643968563854,\n",
       "     0.05591817098898758,\n",
       "     0.014223178086753665,\n",
       "     0.05176339417508708,\n",
       "     0.02556930084338169,\n",
       "     0.0017532101779887963,\n",
       "     0.04019448738396509,\n",
       "     0.07346038016184057,\n",
       "     0.013828268342088116,\n",
       "     0.048752411394717705,\n",
       "     0.05501439025713535,\n",
       "     0.021623599380942157,\n",
       "     0.04832050714726664,\n",
       "     0.02877637762398665,\n",
       "     0.01389560323208616,\n",
       "     0.01848351136031783,\n",
       "     0.06137212429882187,\n",
       "     0.025540549854165946,\n",
       "     0.05216448221706845,\n",
       "     0.06243187147393957,\n",
       "     0.03030074793013122,\n",
       "     0.039974374739398036,\n",
       "     0.040922194271254424,\n",
       "     0.02168180347609725,\n",
       "     0.03728809765020204,\n",
       "     0.036901824926149254,\n",
       "     0.01564060500139429,\n",
       "     0.04823571529551507,\n",
       "     0.017341364138867,\n",
       "     0.03127882396826139,\n",
       "     0.008515962031911723,\n",
       "     0.018595210072678225,\n",
       "     0.023622263695230544,\n",
       "     0.04470641880882414,\n",
       "     0.032280173341922846,\n",
       "     0.017442840799245598,\n",
       "     0.04371750879196729,\n",
       "     0.054480047587125865,\n",
       "     0.01044623661721638,\n",
       "     0.08230141229101717,\n",
       "     0.06634642946300034,\n",
       "     0.022580212178542666,\n",
       "     0.010714443632196502,\n",
       "     0.025483098181463958,\n",
       "     0.019051973745295873,\n",
       "     0.01746712041601889,\n",
       "     0.01814699859210102,\n",
       "     0.00847871536061364,\n",
       "     0.03215482312544825,\n",
       "     0.034254970269339144,\n",
       "     0.02007104560315416,\n",
       "     0.020824550997246796,\n",
       "     0.027100550045515228,\n",
       "     0.014399051472821502,\n",
       "     0.007521807654930007,\n",
       "     0.04595727768156346,\n",
       "     0.011093106085474026,\n",
       "     0.022478233464626823,\n",
       "     0.05140805377532674,\n",
       "     0.02647570537065099,\n",
       "     0.034540895228805844,\n",
       "     0.043545719892203245,\n",
       "     0.007440596705118639,\n",
       "     0.011825170160127529,\n",
       "     0.035866193352308645,\n",
       "     0.02810233477590256,\n",
       "     0.007273818608127656,\n",
       "     0.02152263776344681,\n",
       "     0.009935892994952221,\n",
       "     0.0411917798994552,\n",
       "     0.02496030024747579,\n",
       "     0.00956548015113368,\n",
       "     0.007467393765322782,\n",
       "     0.044132360490719266,\n",
       "     0.0160549723100688,\n",
       "     0.017098582062974616,\n",
       "     0.04215709839156719,\n",
       "     0.012802617559386928,\n",
       "     0.008752608298212651,\n",
       "     0.05163477849339043,\n",
       "     0.010509534969452144,\n",
       "     0.03545630906535288,\n",
       "     0.012770557612114757,\n",
       "     0.0001994950829515651,\n",
       "     0.00736187498198119,\n",
       "     0.0],\n",
       "    'mean_score_time': [0.031995932261149086,\n",
       "     0.0378262996673584,\n",
       "     0.04117361704508463,\n",
       "     0.03780364990234375,\n",
       "     0.03877393404642741,\n",
       "     0.05139923095703125,\n",
       "     0.02474220593770345,\n",
       "     0.03630423545837402,\n",
       "     0.04572765032450358,\n",
       "     0.021490971247355144,\n",
       "     0.03668340047200521,\n",
       "     0.050001939137776695,\n",
       "     0.018454790115356445,\n",
       "     0.03573449452718099,\n",
       "     0.0518332322438558,\n",
       "     0.032342116038004555,\n",
       "     0.03420813878377279,\n",
       "     0.04451131820678711,\n",
       "     0.019355932871500652,\n",
       "     0.03456195195515951,\n",
       "     0.050258636474609375,\n",
       "     0.021623531977335613,\n",
       "     0.03524907430013021,\n",
       "     0.04752763112386068,\n",
       "     0.022245248158772785,\n",
       "     0.035190741221110024,\n",
       "     0.0447989304860433,\n",
       "     0.024309635162353516,\n",
       "     0.035568793614705406,\n",
       "     0.047629594802856445,\n",
       "     0.019845962524414062,\n",
       "     0.03534372647603353,\n",
       "     0.05455899238586426,\n",
       "     0.02072588602701823,\n",
       "     0.04629111289978027,\n",
       "     0.05273866653442383,\n",
       "     0.026024659474690754,\n",
       "     0.034020423889160156,\n",
       "     0.0482939879099528,\n",
       "     0.024059295654296875,\n",
       "     0.03033765157063802,\n",
       "     0.05138023694356283,\n",
       "     0.024674018224080402,\n",
       "     0.034037113189697266,\n",
       "     0.05237126350402832,\n",
       "     0.021935542424519856,\n",
       "     0.03287998835245768,\n",
       "     0.049414634704589844,\n",
       "     0.020874579747517902,\n",
       "     0.03361670176188151,\n",
       "     0.047031243642171226,\n",
       "     0.02114717165629069,\n",
       "     0.02924497922261556,\n",
       "     0.04245177904764811,\n",
       "     0.02419416109720866,\n",
       "     0.03891293207804362,\n",
       "     0.05759557088216146,\n",
       "     0.022710800170898438,\n",
       "     0.03907903035481771,\n",
       "     0.06317512194315593,\n",
       "     0.01862756411234538,\n",
       "     0.054931084314982094,\n",
       "     0.053983847300211586,\n",
       "     0.023891369501749676,\n",
       "     0.03488794962565104,\n",
       "     0.05606691042582194,\n",
       "     0.02276460329691569,\n",
       "     0.03505786259969076,\n",
       "     0.049332777659098305,\n",
       "     0.020842949549357098,\n",
       "     0.030532677968343098,\n",
       "     0.04437589645385742,\n",
       "     0.015014886856079102,\n",
       "     0.02904502550760905,\n",
       "     0.04367399215698242,\n",
       "     0.015640099843343098,\n",
       "     0.028179327646891277,\n",
       "     0.04911557833353678,\n",
       "     0.02444291114807129,\n",
       "     0.027283747990926106,\n",
       "     0.04766511917114258,\n",
       "     0.017376422882080078,\n",
       "     0.02788821856180827,\n",
       "     0.04689351717631022,\n",
       "     0.02290622393290202,\n",
       "     0.03155064582824707,\n",
       "     0.0425107479095459,\n",
       "     0.027932087580362957,\n",
       "     0.027004162470499676,\n",
       "     0.05014514923095703,\n",
       "     0.02342565854390462,\n",
       "     0.03956913948059082,\n",
       "     0.05040987332661947,\n",
       "     0.019284804662068684,\n",
       "     0.02297218640645345,\n",
       "     0.0423887570699056,\n",
       "     0.01618615786234538,\n",
       "     0.03931776682535807,\n",
       "     0.0489194393157959,\n",
       "     0.020837863286336262,\n",
       "     0.0345306396484375,\n",
       "     0.045981407165527344,\n",
       "     0.02388604482014974,\n",
       "     0.03401962916056315,\n",
       "     0.03367861111958822,\n",
       "     0.01591380437215169,\n",
       "     0.02098218599955241,\n",
       "     0.031913201014200844],\n",
       "    'std_score_time': [0.009272158472334978,\n",
       "     0.006940308340976869,\n",
       "     0.0007123688701354509,\n",
       "     0.014341203535776397,\n",
       "     0.0029353134586777557,\n",
       "     0.0009788572021517156,\n",
       "     0.003570395915318795,\n",
       "     0.0004349259837292188,\n",
       "     0.0033511253248713012,\n",
       "     0.001585939771142657,\n",
       "     0.0013624360299714997,\n",
       "     0.0003925665176434377,\n",
       "     0.002379914200358517,\n",
       "     0.003095814112593179,\n",
       "     0.004197524432472776,\n",
       "     0.00346166469912295,\n",
       "     0.0034892061349293354,\n",
       "     0.002892778441387111,\n",
       "     0.003553545981018706,\n",
       "     0.0037508904409699704,\n",
       "     0.004371596754669567,\n",
       "     0.0060612331428536795,\n",
       "     0.001816694340710396,\n",
       "     0.0033892778633910444,\n",
       "     0.00018421496881536935,\n",
       "     0.000900025753687055,\n",
       "     0.001077706241601173,\n",
       "     0.0033653144894155956,\n",
       "     0.0006974451141457801,\n",
       "     0.00785391265258592,\n",
       "     0.0037014395462355173,\n",
       "     0.0035510992263518572,\n",
       "     0.004836580854274638,\n",
       "     0.0007774495206941188,\n",
       "     0.005884828648558135,\n",
       "     0.005495530067766835,\n",
       "     0.0030114592389957192,\n",
       "     0.0033790416860913133,\n",
       "     0.004569709939496011,\n",
       "     0.004821621778933499,\n",
       "     0.0033508748135038274,\n",
       "     0.0016846804737106506,\n",
       "     0.007360079973225249,\n",
       "     1.6927159438932637e-05,\n",
       "     0.003354414967913645,\n",
       "     0.003070537348299562,\n",
       "     0.003355042229635954,\n",
       "     0.0028626428296620442,\n",
       "     0.0005408829532124656,\n",
       "     0.004020426912437518,\n",
       "     0.0011129319400929585,\n",
       "     0.0030908948873838247,\n",
       "     0.003505499415040457,\n",
       "     0.0067735032865960726,\n",
       "     0.003348846499390349,\n",
       "     0.004743397837010673,\n",
       "     0.011530321660843435,\n",
       "     0.006468571921128807,\n",
       "     0.006277515430567803,\n",
       "     0.006762890113499616,\n",
       "     0.005069033860409667,\n",
       "     0.03633404560327188,\n",
       "     0.007517236579088275,\n",
       "     0.0024719204656521833,\n",
       "     0.0029581132883800825,\n",
       "     0.006657569968144551,\n",
       "     0.0038891722321454836,\n",
       "     0.004774844565698193,\n",
       "     0.007053468527783641,\n",
       "     0.0073624385972951385,\n",
       "     0.008604417235274511,\n",
       "     0.0086347609659845,\n",
       "     0.0008369769255227829,\n",
       "     0.005674973931492448,\n",
       "     0.009029958219164412,\n",
       "     5.538066670158496e-06,\n",
       "     0.004942759818231383,\n",
       "     0.00962065689344684,\n",
       "     0.006532578792551566,\n",
       "     0.0030595930252357113,\n",
       "     0.007725872658521151,\n",
       "     0.002459718743022578,\n",
       "     0.0045451330285254275,\n",
       "     2.551289229859452e-05,\n",
       "     0.006416178243968025,\n",
       "     0.0001736299569204013,\n",
       "     0.005632528705964912,\n",
       "     0.008957612557815783,\n",
       "     0.007812057600358304,\n",
       "     0.01040796227302043,\n",
       "     0.006355172058187647,\n",
       "     0.011443498508320177,\n",
       "     0.0031280397419614723,\n",
       "     0.0025883784565490387,\n",
       "     0.0062842210312567745,\n",
       "     0.0019133264458973326,\n",
       "     0.0007937661303383482,\n",
       "     0.00616685102109807,\n",
       "     0.00822384337791135,\n",
       "     0.007360300840750476,\n",
       "     0.0023086357740327314,\n",
       "     0.006779779065967755,\n",
       "     0.005227450764188803,\n",
       "     0.005536722902132826,\n",
       "     0.0026959324417413165,\n",
       "     0.00019140288803747344,\n",
       "     0.007567102101091661,\n",
       "     0.005111671981675659],\n",
       "    'param_classifier__max_depth': [None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30],\n",
       "    'param_classifier__min_samples_leaf': [1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10],\n",
       "    'param_classifier__n_estimators': [100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300],\n",
       "    'params': [{'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300}],\n",
       "    'split0_test_score': [0.9540229885057471,\n",
       "     0.9540229885057471,\n",
       "     0.9540229885057471,\n",
       "     0.9425287356321839,\n",
       "     0.9540229885057471,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9310344827586207,\n",
       "     0.9080459770114943,\n",
       "     0.9310344827586207,\n",
       "     0.9080459770114943,\n",
       "     0.9195402298850575,\n",
       "     0.9195402298850575,\n",
       "     0.9310344827586207,\n",
       "     0.9195402298850575,\n",
       "     0.9080459770114943,\n",
       "     0.9195402298850575,\n",
       "     0.9195402298850575,\n",
       "     0.8850574712643678,\n",
       "     0.8850574712643678,\n",
       "     0.896551724137931,\n",
       "     0.896551724137931,\n",
       "     0.9080459770114943,\n",
       "     0.9195402298850575,\n",
       "     0.9195402298850575,\n",
       "     0.896551724137931,\n",
       "     0.896551724137931,\n",
       "     0.9540229885057471,\n",
       "     0.9540229885057471,\n",
       "     0.9540229885057471,\n",
       "     0.9540229885057471,\n",
       "     0.9540229885057471,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9195402298850575,\n",
       "     0.9195402298850575,\n",
       "     0.9195402298850575,\n",
       "     0.9080459770114943,\n",
       "     0.9195402298850575,\n",
       "     0.9310344827586207,\n",
       "     0.9195402298850575,\n",
       "     0.9080459770114943,\n",
       "     0.9080459770114943,\n",
       "     0.9195402298850575,\n",
       "     0.9080459770114943,\n",
       "     0.896551724137931,\n",
       "     0.9080459770114943,\n",
       "     0.896551724137931,\n",
       "     0.896551724137931,\n",
       "     0.9195402298850575,\n",
       "     0.9080459770114943,\n",
       "     0.896551724137931,\n",
       "     0.9425287356321839,\n",
       "     0.9540229885057471,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9540229885057471,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9195402298850575,\n",
       "     0.9195402298850575,\n",
       "     0.9080459770114943,\n",
       "     0.9310344827586207,\n",
       "     0.9310344827586207,\n",
       "     0.9195402298850575,\n",
       "     0.9195402298850575,\n",
       "     0.9080459770114943,\n",
       "     0.9080459770114943,\n",
       "     0.896551724137931,\n",
       "     0.9080459770114943,\n",
       "     0.896551724137931,\n",
       "     0.9080459770114943,\n",
       "     0.9080459770114943,\n",
       "     0.9080459770114943,\n",
       "     0.9080459770114943,\n",
       "     0.9195402298850575,\n",
       "     0.9540229885057471,\n",
       "     0.9540229885057471,\n",
       "     0.9540229885057471,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9195402298850575,\n",
       "     0.9080459770114943,\n",
       "     0.9195402298850575,\n",
       "     0.9080459770114943,\n",
       "     0.9310344827586207,\n",
       "     0.9195402298850575,\n",
       "     0.9195402298850575,\n",
       "     0.9080459770114943,\n",
       "     0.9080459770114943,\n",
       "     0.896551724137931,\n",
       "     0.896551724137931,\n",
       "     0.9080459770114943,\n",
       "     0.896551724137931,\n",
       "     0.9080459770114943,\n",
       "     0.896551724137931,\n",
       "     0.896551724137931],\n",
       "    'split1_test_score': [0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9310344827586207,\n",
       "     0.9540229885057471,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9540229885057471,\n",
       "     0.9540229885057471,\n",
       "     0.9425287356321839,\n",
       "     0.9540229885057471,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9540229885057471,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9540229885057471,\n",
       "     0.9310344827586207,\n",
       "     0.9540229885057471,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9540229885057471,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9310344827586207,\n",
       "     0.9540229885057471,\n",
       "     0.9425287356321839,\n",
       "     0.9540229885057471,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9540229885057471,\n",
       "     0.9540229885057471,\n",
       "     0.9425287356321839,\n",
       "     0.9540229885057471,\n",
       "     0.9540229885057471,\n",
       "     0.9540229885057471,\n",
       "     0.9425287356321839,\n",
       "     0.9540229885057471,\n",
       "     0.9195402298850575,\n",
       "     0.9540229885057471,\n",
       "     0.9310344827586207,\n",
       "     0.9540229885057471,\n",
       "     0.9540229885057471,\n",
       "     0.9540229885057471,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9540229885057471,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9310344827586207,\n",
       "     0.9310344827586207,\n",
       "     0.9655172413793104,\n",
       "     0.9540229885057471,\n",
       "     0.9540229885057471,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9195402298850575,\n",
       "     0.9540229885057471,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9310344827586207,\n",
       "     0.9425287356321839,\n",
       "     0.9540229885057471,\n",
       "     0.9540229885057471,\n",
       "     0.9540229885057471,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839,\n",
       "     0.9425287356321839],\n",
       "    'split2_test_score': [0.9418604651162791,\n",
       "     0.9418604651162791,\n",
       "     0.9418604651162791,\n",
       "     0.9418604651162791,\n",
       "     0.9069767441860465,\n",
       "     0.9418604651162791,\n",
       "     0.872093023255814,\n",
       "     0.872093023255814,\n",
       "     0.8604651162790697,\n",
       "     0.9069767441860465,\n",
       "     0.9302325581395349,\n",
       "     0.9186046511627907,\n",
       "     0.9069767441860465,\n",
       "     0.9418604651162791,\n",
       "     0.9186046511627907,\n",
       "     0.872093023255814,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.872093023255814,\n",
       "     0.872093023255814,\n",
       "     0.8604651162790697,\n",
       "     0.872093023255814,\n",
       "     0.872093023255814,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.9418604651162791,\n",
       "     0.9418604651162791,\n",
       "     0.9418604651162791,\n",
       "     0.9069767441860465,\n",
       "     0.9302325581395349,\n",
       "     0.9418604651162791,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.872093023255814,\n",
       "     0.9302325581395349,\n",
       "     0.9069767441860465,\n",
       "     0.8837209302325582,\n",
       "     0.8837209302325582,\n",
       "     0.9186046511627907,\n",
       "     0.872093023255814,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8837209302325582,\n",
       "     0.872093023255814,\n",
       "     0.8604651162790697,\n",
       "     0.8488372093023255,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.9418604651162791,\n",
       "     0.9418604651162791,\n",
       "     0.9418604651162791,\n",
       "     0.9186046511627907,\n",
       "     0.9418604651162791,\n",
       "     0.9302325581395349,\n",
       "     0.9302325581395349,\n",
       "     0.8604651162790697,\n",
       "     0.872093023255814,\n",
       "     0.9186046511627907,\n",
       "     0.8837209302325582,\n",
       "     0.9302325581395349,\n",
       "     0.9186046511627907,\n",
       "     0.9186046511627907,\n",
       "     0.9186046511627907,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8488372093023255,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.872093023255814,\n",
       "     0.872093023255814,\n",
       "     0.9418604651162791,\n",
       "     0.9534883720930233,\n",
       "     0.9418604651162791,\n",
       "     0.8953488372093024,\n",
       "     0.9302325581395349,\n",
       "     0.9418604651162791,\n",
       "     0.872093023255814,\n",
       "     0.8604651162790697,\n",
       "     0.872093023255814,\n",
       "     0.9186046511627907,\n",
       "     0.9186046511627907,\n",
       "     0.9186046511627907,\n",
       "     0.872093023255814,\n",
       "     0.872093023255814,\n",
       "     0.9186046511627907,\n",
       "     0.872093023255814,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.872093023255814,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697],\n",
       "    'mean_test_score': [0.94613739641807,\n",
       "     0.94613739641807,\n",
       "     0.94613739641807,\n",
       "     0.9384745611690278,\n",
       "     0.9306780718168047,\n",
       "     0.94613739641807,\n",
       "     0.9152187472155395,\n",
       "     0.9152187472155395,\n",
       "     0.9036799429742493,\n",
       "     0.9230152365677626,\n",
       "     0.9269357569277377,\n",
       "     0.9268912055600107,\n",
       "     0.9230152365677626,\n",
       "     0.9346431435445068,\n",
       "     0.9268912055600107,\n",
       "     0.9037244943419763,\n",
       "     0.9075113605987704,\n",
       "     0.9113427782232915,\n",
       "     0.9037244943419763,\n",
       "     0.8998930767174551,\n",
       "     0.9036799429742493,\n",
       "     0.9037244943419763,\n",
       "     0.9075559119664973,\n",
       "     0.9075113605987704,\n",
       "     0.9036799429742493,\n",
       "     0.8998485253497283,\n",
       "     0.896017107725207,\n",
       "     0.94613739641807,\n",
       "     0.94613739641807,\n",
       "     0.9499688140425911,\n",
       "     0.9306780718168047,\n",
       "     0.942261427425822,\n",
       "     0.9346431435445068,\n",
       "     0.9190056134723337,\n",
       "     0.9113427782232915,\n",
       "     0.9190056134723337,\n",
       "     0.9113873295910184,\n",
       "     0.9269357569277377,\n",
       "     0.9230152365677626,\n",
       "     0.9114318809587454,\n",
       "     0.9152632985832665,\n",
       "     0.9345540408090528,\n",
       "     0.9075559119664973,\n",
       "     0.9036799429742493,\n",
       "     0.8998485253497283,\n",
       "     0.9114318809587454,\n",
       "     0.9113873295910184,\n",
       "     0.8998485253497283,\n",
       "     0.9036353916065223,\n",
       "     0.896017107725207,\n",
       "     0.8998485253497283,\n",
       "     0.9113427782232915,\n",
       "     0.9075113605987704,\n",
       "     0.8998485253497283,\n",
       "     0.94613739641807,\n",
       "     0.9499688140425911,\n",
       "     0.94613739641807,\n",
       "     0.9345540408090528,\n",
       "     0.9499688140425911,\n",
       "     0.9307671745522588,\n",
       "     0.9384300098013009,\n",
       "     0.9113427782232915,\n",
       "     0.9228815824645817,\n",
       "     0.9345540408090528,\n",
       "     0.9190947162077876,\n",
       "     0.9307671745522588,\n",
       "     0.9230597879354896,\n",
       "     0.9307226231845317,\n",
       "     0.9307226231845317,\n",
       "     0.9036799429742493,\n",
       "     0.9075113605987704,\n",
       "     0.8998485253497283,\n",
       "     0.9036799429742493,\n",
       "     0.892141138732959,\n",
       "     0.9036799429742493,\n",
       "     0.9036799429742493,\n",
       "     0.9036799429742493,\n",
       "     0.9036799429742493,\n",
       "     0.8998485253497283,\n",
       "     0.9037244943419763,\n",
       "     0.9075559119664973,\n",
       "     0.9538002316671123,\n",
       "     0.9538447830348392,\n",
       "     0.9499688140425911,\n",
       "     0.9229706852000357,\n",
       "     0.9384300098013009,\n",
       "     0.9423059787935489,\n",
       "     0.9113873295910184,\n",
       "     0.9151741958478125,\n",
       "     0.9113873295910184,\n",
       "     0.9230597879354896,\n",
       "     0.9383854584335739,\n",
       "     0.9268912055600107,\n",
       "     0.9075559119664973,\n",
       "     0.9113873295910184,\n",
       "     0.9230597879354896,\n",
       "     0.9152187472155395,\n",
       "     0.9036799429742493,\n",
       "     0.9075113605987704,\n",
       "     0.8998485253497283,\n",
       "     0.9075559119664973,\n",
       "     0.9036799429742493,\n",
       "     0.9036799429742493,\n",
       "     0.9075113605987704,\n",
       "     0.8998485253497283,\n",
       "     0.9036799429742493,\n",
       "     0.8998485253497283,\n",
       "     0.8998485253497283],\n",
       "    'std_test_score': [0.0055826259233765175,\n",
       "     0.0055826259233765175,\n",
       "     0.0055826259233765175,\n",
       "     0.005267999078420729,\n",
       "     0.019208202201435116,\n",
       "     0.0055826259233765175,\n",
       "     0.03085342242029981,\n",
       "     0.03085342242029981,\n",
       "     0.033644277326602294,\n",
       "     0.011340926723120263,\n",
       "     0.014269240442195153,\n",
       "     0.01106399828136226,\n",
       "     0.014720570132305585,\n",
       "     0.005103417025404128,\n",
       "     0.01106399828136226,\n",
       "     0.024256000239493446,\n",
       "     0.034565200974034926,\n",
       "     0.038632175917716255,\n",
       "     0.03595805996248766,\n",
       "     0.03060902684243582,\n",
       "     0.03852598682906255,\n",
       "     0.029199130909346224,\n",
       "     0.028757347087923154,\n",
       "     0.034565200974034926,\n",
       "     0.030915696089000445,\n",
       "     0.03358333990741821,\n",
       "     0.028812303302152672,\n",
       "     0.0055826259233765175,\n",
       "     0.0055826259233765175,\n",
       "     0.005733468510021875,\n",
       "     0.019208202201435116,\n",
       "     0.009714241590238846,\n",
       "     0.005103417025404128,\n",
       "     0.04165950728630261,\n",
       "     0.036280681966791746,\n",
       "     0.04165950728630261,\n",
       "     0.02932745848626146,\n",
       "     0.005239665126254707,\n",
       "     0.014720570132305585,\n",
       "     0.02412727023010919,\n",
       "     0.024197914510693426,\n",
       "     0.014672085098072832,\n",
       "     0.025511328451756375,\n",
       "     0.033644277326602294,\n",
       "     0.02938715741772852,\n",
       "     0.02014864850541657,\n",
       "     0.03353111270903817,\n",
       "     0.03358333990741821,\n",
       "     0.0430550189437395,\n",
       "     0.028812303302152672,\n",
       "     0.03358333990741821,\n",
       "     0.038632175917716255,\n",
       "     0.038196712117906914,\n",
       "     0.03358333990741821,\n",
       "     0.0055826259233765175,\n",
       "     0.005733468510021875,\n",
       "     0.0055826259233765175,\n",
       "     0.011277921574658466,\n",
       "     0.005733468510021875,\n",
       "     0.009392628675473169,\n",
       "     0.01103076030717915,\n",
       "     0.036280681966791746,\n",
       "     0.03621820695135923,\n",
       "     0.014672085098072832,\n",
       "     0.02870242395326207,\n",
       "     0.009392628675473169,\n",
       "     0.014425702600353685,\n",
       "     0.009769455690062044,\n",
       "     0.009769455690062044,\n",
       "     0.030915696089000445,\n",
       "     0.034565200974034926,\n",
       "     0.02938715741772852,\n",
       "     0.033644277326602294,\n",
       "     0.03370151221753661,\n",
       "     0.033644277326602294,\n",
       "     0.03852598682906255,\n",
       "     0.033644277326602294,\n",
       "     0.033644277326602294,\n",
       "     0.02938715741772852,\n",
       "     0.024256000239493446,\n",
       "     0.025511328451756375,\n",
       "     0.009659122846533887,\n",
       "     0.0002520205938470774,\n",
       "     0.005733468510021875,\n",
       "     0.020087381231305983,\n",
       "     0.00579647365848367,\n",
       "     0.0003150257423088729,\n",
       "     0.0277852704716446,\n",
       "     0.038685161155532395,\n",
       "     0.0277852704716446,\n",
       "     0.005651881399318559,\n",
       "     0.014753298263851742,\n",
       "     0.01106399828136226,\n",
       "     0.028757347087923154,\n",
       "     0.02932745848626146,\n",
       "     0.014425702600353685,\n",
       "     0.03085342242029981,\n",
       "     0.030915696089000445,\n",
       "     0.034565200974034926,\n",
       "     0.02938715741772852,\n",
       "     0.028757347087923154,\n",
       "     0.03852598682906255,\n",
       "     0.03852598682906255,\n",
       "     0.038196712117906914,\n",
       "     0.03358333990741821,\n",
       "     0.033644277326602294,\n",
       "     0.03358333990741821,\n",
       "     0.03358333990741821],\n",
       "    'rank_test_score': [7,\n",
       "     7,\n",
       "     7,\n",
       "     17,\n",
       "     30,\n",
       "     7,\n",
       "     49,\n",
       "     49,\n",
       "     79,\n",
       "     40,\n",
       "     32,\n",
       "     34,\n",
       "     40,\n",
       "     21,\n",
       "     34,\n",
       "     75,\n",
       "     69,\n",
       "     60,\n",
       "     75,\n",
       "     94,\n",
       "     79,\n",
       "     75,\n",
       "     64,\n",
       "     69,\n",
       "     79,\n",
       "     95,\n",
       "     106,\n",
       "     7,\n",
       "     7,\n",
       "     3,\n",
       "     30,\n",
       "     16,\n",
       "     21,\n",
       "     46,\n",
       "     60,\n",
       "     46,\n",
       "     55,\n",
       "     32,\n",
       "     40,\n",
       "     53,\n",
       "     48,\n",
       "     23,\n",
       "     64,\n",
       "     79,\n",
       "     95,\n",
       "     53,\n",
       "     55,\n",
       "     95,\n",
       "     93,\n",
       "     106,\n",
       "     95,\n",
       "     60,\n",
       "     69,\n",
       "     95,\n",
       "     7,\n",
       "     3,\n",
       "     7,\n",
       "     23,\n",
       "     3,\n",
       "     26,\n",
       "     18,\n",
       "     60,\n",
       "     44,\n",
       "     23,\n",
       "     45,\n",
       "     26,\n",
       "     37,\n",
       "     28,\n",
       "     28,\n",
       "     79,\n",
       "     69,\n",
       "     95,\n",
       "     79,\n",
       "     108,\n",
       "     79,\n",
       "     79,\n",
       "     79,\n",
       "     79,\n",
       "     95,\n",
       "     75,\n",
       "     64,\n",
       "     2,\n",
       "     1,\n",
       "     3,\n",
       "     43,\n",
       "     18,\n",
       "     15,\n",
       "     55,\n",
       "     52,\n",
       "     55,\n",
       "     37,\n",
       "     20,\n",
       "     34,\n",
       "     64,\n",
       "     55,\n",
       "     37,\n",
       "     49,\n",
       "     79,\n",
       "     69,\n",
       "     95,\n",
       "     64,\n",
       "     79,\n",
       "     79,\n",
       "     69,\n",
       "     95,\n",
       "     79,\n",
       "     95,\n",
       "     95]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__max_depth': 10,\n",
       "    'classifier__min_samples_leaf': 1,\n",
       "    'classifier__min_samples_split': 2,\n",
       "    'classifier__n_estimators': 300},\n",
       "   'best_validation_accuracy': 0.9591804817015953,\n",
       "   'train_accuracy': 0.9855769230769231,\n",
       "   'test_accuracy': 1.0,\n",
       "   'cv_results': {'mean_fit_time': [0.19234824180603027,\n",
       "     0.40508683522542316,\n",
       "     0.6575438181559244,\n",
       "     0.22769840558369955,\n",
       "     0.49139849344889325,\n",
       "     0.7210421562194824,\n",
       "     0.22121620178222656,\n",
       "     0.43444053332010907,\n",
       "     0.6767686208089193,\n",
       "     0.24240557352701822,\n",
       "     0.46005431811014813,\n",
       "     0.7632853984832764,\n",
       "     0.23641419410705566,\n",
       "     0.45070473353068036,\n",
       "     0.6863681475321451,\n",
       "     0.24020942052205405,\n",
       "     0.47248609860738117,\n",
       "     0.6720578670501709,\n",
       "     0.24119957288106283,\n",
       "     0.4509321053822835,\n",
       "     0.7299609978993734,\n",
       "     0.2440030574798584,\n",
       "     0.45615601539611816,\n",
       "     0.6857966581980387,\n",
       "     0.24500219027201334,\n",
       "     0.4848966598510742,\n",
       "     0.6948617299397787,\n",
       "     0.2574012279510498,\n",
       "     0.48189059893290204,\n",
       "     0.6524173418680826,\n",
       "     0.23216605186462402,\n",
       "     0.4707246621449788,\n",
       "     0.7037619749704996,\n",
       "     0.2556446393330892,\n",
       "     0.4474732081095378,\n",
       "     0.713361660639445,\n",
       "     0.23268556594848633,\n",
       "     0.44757310549418133,\n",
       "     0.7131446997324625,\n",
       "     0.25473570823669434,\n",
       "     0.4866538842519124,\n",
       "     0.6525242328643799,\n",
       "     0.2625609238942464,\n",
       "     0.46340203285217285,\n",
       "     0.7166452407836914,\n",
       "     0.23260116577148438,\n",
       "     0.4575103123982747,\n",
       "     0.676481564839681,\n",
       "     0.2478322982788086,\n",
       "     0.4647655487060547,\n",
       "     0.6699396769205729,\n",
       "     0.23899555206298828,\n",
       "     0.4602345625559489,\n",
       "     0.7163730462392172,\n",
       "     0.261303186416626,\n",
       "     0.4488492012023926,\n",
       "     0.6975563367207845,\n",
       "     0.24925955136617026,\n",
       "     0.4635165532430013,\n",
       "     0.7142000993092855,\n",
       "     0.26400311787923175,\n",
       "     0.460310697555542,\n",
       "     0.6780131657918295,\n",
       "     0.2568521499633789,\n",
       "     0.4742344220479329,\n",
       "     0.6903283596038818,\n",
       "     0.26249853769938153,\n",
       "     0.43596529960632324,\n",
       "     0.6932441393534342,\n",
       "     0.24879558881123862,\n",
       "     0.4607282479604085,\n",
       "     0.7021950085957845,\n",
       "     0.24076604843139648,\n",
       "     0.46146615346272785,\n",
       "     0.7034479777018229,\n",
       "     0.23536046346028647,\n",
       "     0.4559037685394287,\n",
       "     0.6694878737131754,\n",
       "     0.24506847063700357,\n",
       "     0.43784546852111816,\n",
       "     0.6989640394846598,\n",
       "     0.2568495273590088,\n",
       "     0.45594104131062824,\n",
       "     0.7064109643300375,\n",
       "     0.24217144648234049,\n",
       "     0.4556039174397786,\n",
       "     0.7222306728363037,\n",
       "     0.22110843658447266,\n",
       "     0.4577013651529948,\n",
       "     0.6940407752990723,\n",
       "     0.23679208755493164,\n",
       "     0.46104129155476886,\n",
       "     0.6885597705841064,\n",
       "     0.25327738126118976,\n",
       "     0.4851713180541992,\n",
       "     0.7171071370442709,\n",
       "     0.238142728805542,\n",
       "     0.48137704531351727,\n",
       "     0.6904805501302084,\n",
       "     0.2540574868520101,\n",
       "     0.49682895342508954,\n",
       "     0.7280296484629313,\n",
       "     0.2429806391398112,\n",
       "     0.45002039273579914,\n",
       "     0.6756759484608968,\n",
       "     0.2562367916107178,\n",
       "     0.4526983896891276,\n",
       "     0.5549099445343018],\n",
       "    'std_fit_time': [0.007363897371823405,\n",
       "     0.012761652911702514,\n",
       "     0.019651256201747003,\n",
       "     0.010955122957311346,\n",
       "     0.02916882827351245,\n",
       "     0.025678871664966862,\n",
       "     0.007470577232968228,\n",
       "     0.00325834476047821,\n",
       "     0.037091468042013076,\n",
       "     0.018432171382183567,\n",
       "     0.009147232203908413,\n",
       "     0.017507061819124002,\n",
       "     0.014727629568500801,\n",
       "     0.01753740128355549,\n",
       "     0.04312560138987196,\n",
       "     0.01067779325406754,\n",
       "     0.02704243415220457,\n",
       "     0.028615314570169584,\n",
       "     0.018221974054631607,\n",
       "     0.022904605226554377,\n",
       "     0.05158969457282541,\n",
       "     0.028433090621126384,\n",
       "     0.03212589557342784,\n",
       "     0.03206930836176369,\n",
       "     0.01732724985414434,\n",
       "     0.022604029253120154,\n",
       "     0.047691633162181564,\n",
       "     0.022962078646125476,\n",
       "     0.01850908014529158,\n",
       "     0.010915186648288036,\n",
       "     0.007278480200528484,\n",
       "     0.02895072189646173,\n",
       "     0.05357763938237063,\n",
       "     0.012114447308152707,\n",
       "     0.02778863346398693,\n",
       "     0.04120930750345186,\n",
       "     0.011496010861525904,\n",
       "     0.016142110218925722,\n",
       "     0.03553590200944006,\n",
       "     0.01410080094236502,\n",
       "     0.010064006390127939,\n",
       "     0.007973238697048697,\n",
       "     0.01283573804768438,\n",
       "     0.038364249505937004,\n",
       "     0.018211784009919293,\n",
       "     0.01931509745468444,\n",
       "     0.010400398312586477,\n",
       "     0.04084599284364468,\n",
       "     0.00841195414196489,\n",
       "     0.020843474108023452,\n",
       "     0.03263699415345646,\n",
       "     0.021476524125782933,\n",
       "     0.03450683590177258,\n",
       "     0.041408453055639796,\n",
       "     0.03590480727659946,\n",
       "     0.009669927188003025,\n",
       "     0.0440452977340025,\n",
       "     0.012934239286881788,\n",
       "     0.02011304134953593,\n",
       "     0.050162825857561925,\n",
       "     0.007468961169366186,\n",
       "     0.03442328657702891,\n",
       "     0.041409633586152725,\n",
       "     0.017910741279260938,\n",
       "     0.027418716753705004,\n",
       "     0.03429514453668912,\n",
       "     0.040772423197451654,\n",
       "     0.017934759046889355,\n",
       "     0.04801703234080201,\n",
       "     0.01835882933302188,\n",
       "     0.02587687046302895,\n",
       "     0.031804763957624285,\n",
       "     0.006742870484256569,\n",
       "     0.029096882904546005,\n",
       "     0.038235653428006694,\n",
       "     0.006414604880497906,\n",
       "     0.016140879557451398,\n",
       "     0.01373402336630558,\n",
       "     0.017550285604400844,\n",
       "     0.01875578489820226,\n",
       "     0.036528851077427454,\n",
       "     0.01830262957439487,\n",
       "     0.009258497597902322,\n",
       "     0.039779094757350024,\n",
       "     0.021261563340526275,\n",
       "     0.018206012515142065,\n",
       "     0.04136586742210096,\n",
       "     0.009361890952459453,\n",
       "     0.03845871894147855,\n",
       "     0.03569523314685825,\n",
       "     0.014562547699885964,\n",
       "     0.02393600463472315,\n",
       "     0.0306222554269675,\n",
       "     0.007388051760298851,\n",
       "     0.012759803100543197,\n",
       "     0.050085497029832456,\n",
       "     0.009214649785690055,\n",
       "     0.025303650744143976,\n",
       "     0.040816160051140915,\n",
       "     0.012928629636696993,\n",
       "     0.02962209793248936,\n",
       "     0.02360455186172119,\n",
       "     0.00715990714724889,\n",
       "     0.012067648012674077,\n",
       "     0.032114509701010145,\n",
       "     0.0068247771851588455,\n",
       "     0.005153071902143609,\n",
       "     0.014793978970444313],\n",
       "    'mean_score_time': [0.03480378786722819,\n",
       "     0.03139193852742513,\n",
       "     0.05044722557067871,\n",
       "     0.02515435218811035,\n",
       "     0.030333439509073894,\n",
       "     0.049155473709106445,\n",
       "     0.015631993611653645,\n",
       "     0.03511381149291992,\n",
       "     0.053243796030680336,\n",
       "     0.01605995496114095,\n",
       "     0.03337653477986654,\n",
       "     0.05149348576863607,\n",
       "     0.01767309506734212,\n",
       "     0.034981489181518555,\n",
       "     0.050526936848958336,\n",
       "     0.02269911766052246,\n",
       "     0.030996402104695637,\n",
       "     0.04479861259460449,\n",
       "     0.022919575373331707,\n",
       "     0.02827175458272298,\n",
       "     0.05585273106892904,\n",
       "     0.02048349380493164,\n",
       "     0.03345616658528646,\n",
       "     0.05004779497782389,\n",
       "     0.015601793924967447,\n",
       "     0.028545618057250977,\n",
       "     0.048798720041910805,\n",
       "     0.020645538965861004,\n",
       "     0.0332645575205485,\n",
       "     0.04897395769755045,\n",
       "     0.02604842185974121,\n",
       "     0.028172016143798828,\n",
       "     0.040497938791910805,\n",
       "     0.01834559440612793,\n",
       "     0.029459238052368164,\n",
       "     0.04492759704589844,\n",
       "     0.015914042790730793,\n",
       "     0.03423921267191569,\n",
       "     0.051998297373453774,\n",
       "     0.01287237803141276,\n",
       "     0.0334319273630778,\n",
       "     0.047251383463541664,\n",
       "     0.020167748133341473,\n",
       "     0.03386727968851725,\n",
       "     0.046824137369791664,\n",
       "     0.020483096440633137,\n",
       "     0.041844685872395836,\n",
       "     0.04238486289978027,\n",
       "     0.02073081334431966,\n",
       "     0.031434218088785805,\n",
       "     0.0474698543548584,\n",
       "     0.018561522165934246,\n",
       "     0.040151755015055336,\n",
       "     0.05200997988382975,\n",
       "     0.028995513916015625,\n",
       "     0.03658064206441244,\n",
       "     0.04741716384887695,\n",
       "     0.027298688888549805,\n",
       "     0.029873450597127277,\n",
       "     0.05504417419433594,\n",
       "     0.015917221705118816,\n",
       "     0.03339163462320963,\n",
       "     0.05073897043863932,\n",
       "     0.02100364367167155,\n",
       "     0.03416911760965983,\n",
       "     0.05061205228169759,\n",
       "     0.027515649795532227,\n",
       "     0.03722318013509115,\n",
       "     0.037551561991373696,\n",
       "     0.025531291961669922,\n",
       "     0.031044801076253254,\n",
       "     0.05280351638793945,\n",
       "     0.02365414301554362,\n",
       "     0.03345815340677897,\n",
       "     0.050166924794514976,\n",
       "     0.02677186330159505,\n",
       "     0.03337876001993815,\n",
       "     0.04780427614847819,\n",
       "     0.02774532636006673,\n",
       "     0.04213674863179525,\n",
       "     0.05125157038370768,\n",
       "     0.02054770787556966,\n",
       "     0.03317530949910482,\n",
       "     0.04631543159484863,\n",
       "     0.01914064089457194,\n",
       "     0.03944977124532064,\n",
       "     0.05676531791687012,\n",
       "     0.024559656778971355,\n",
       "     0.03669571876525879,\n",
       "     0.04835955301920573,\n",
       "     0.02369403839111328,\n",
       "     0.033559958140055336,\n",
       "     0.05389404296875,\n",
       "     0.015625874201456707,\n",
       "     0.03673966725667318,\n",
       "     0.04944117863972982,\n",
       "     0.015873034795125324,\n",
       "     0.03373074531555176,\n",
       "     0.056441863377889,\n",
       "     0.020840009053548176,\n",
       "     0.03154492378234863,\n",
       "     0.0509499708811442,\n",
       "     0.02089373270670573,\n",
       "     0.03741097450256348,\n",
       "     0.04773171742757162,\n",
       "     0.019011497497558594,\n",
       "     0.02429827054341634,\n",
       "     0.01908556620279948],\n",
       "    'std_score_time': [0.005303812562398238,\n",
       "     0.00019317499901802537,\n",
       "     0.0023318563795030637,\n",
       "     0.004417173917915711,\n",
       "     0.009340375493725175,\n",
       "     0.0025940553734485005,\n",
       "     1.3936557907602293e-05,\n",
       "     0.0028917132288725257,\n",
       "     0.006705637612473923,\n",
       "     0.0005852793091626861,\n",
       "     0.0027759651450240453,\n",
       "     0.004789651282800521,\n",
       "     0.002897287780085484,\n",
       "     0.00528420327890185,\n",
       "     0.0032674976023858975,\n",
       "     0.0021762443305942776,\n",
       "     0.004321843276902142,\n",
       "     0.005393319174095632,\n",
       "     0.00640143124833102,\n",
       "     0.0045198404821879075,\n",
       "     0.005057374199076276,\n",
       "     0.007384278033795189,\n",
       "     0.0027436187049986113,\n",
       "     0.00503724417085037,\n",
       "     0.00045627981551973353,\n",
       "     0.008796640897000883,\n",
       "     0.0044087397917578755,\n",
       "     0.007085454285268674,\n",
       "     0.004783107266315185,\n",
       "     0.0028213873630284986,\n",
       "     0.007370978042373235,\n",
       "     0.007532087211610245,\n",
       "     0.005002745479385398,\n",
       "     0.0019600332467150264,\n",
       "     0.00701602807819741,\n",
       "     0.0037679063115337295,\n",
       "     0.004118455630565959,\n",
       "     0.002481583643760084,\n",
       "     0.003882038062883768,\n",
       "     0.002225921994694187,\n",
       "     0.0030793049480039325,\n",
       "     0.0068322590731832115,\n",
       "     0.006284686431035908,\n",
       "     0.0018279369178164815,\n",
       "     7.125627188241817e-05,\n",
       "     0.0068508375049889545,\n",
       "     0.00749667104324459,\n",
       "     0.004634439488972321,\n",
       "     0.007329804204741058,\n",
       "     0.0056058172398277,\n",
       "     0.008030057981335412,\n",
       "     0.004132985036441701,\n",
       "     0.009604645228681779,\n",
       "     0.0009625778291119154,\n",
       "     0.0037913743199763797,\n",
       "     0.007367156728108248,\n",
       "     0.004903779799672541,\n",
       "     0.0083412170522827,\n",
       "     0.0019140453529652534,\n",
       "     0.007305715119430941,\n",
       "     0.00018994179728909578,\n",
       "     0.002746582102536418,\n",
       "     0.005857389980861049,\n",
       "     0.004124918646919226,\n",
       "     0.003827223508724569,\n",
       "     0.0035120878127769778,\n",
       "     0.008787516862306015,\n",
       "     0.002660980681403207,\n",
       "     0.002455082093118689,\n",
       "     0.005001163049089498,\n",
       "     0.0051143188699195995,\n",
       "     0.004980609487896353,\n",
       "     0.006215262006947203,\n",
       "     0.0031084821014373968,\n",
       "     0.003496545874079795,\n",
       "     0.003942048472744676,\n",
       "     0.0030162532689135364,\n",
       "     0.001026573616135062,\n",
       "     0.0056173168051912034,\n",
       "     0.008561233482639237,\n",
       "     0.003061659467427372,\n",
       "     0.0035061588859604804,\n",
       "     0.0018861287045248902,\n",
       "     0.005561940159652613,\n",
       "     0.004955859857461748,\n",
       "     0.0012045748718026617,\n",
       "     0.0019838957766334696,\n",
       "     0.006662321132429565,\n",
       "     0.004798145690977184,\n",
       "     0.002098800664246494,\n",
       "     0.005439027248340065,\n",
       "     0.0102322602828624,\n",
       "     0.00648294243996295,\n",
       "     1.5854785715150835e-06,\n",
       "     0.007466557638312802,\n",
       "     0.00303822608314619,\n",
       "     0.0003494254720543188,\n",
       "     0.010354652686824345,\n",
       "     0.00025159297463534853,\n",
       "     0.0073680567892296,\n",
       "     0.00019696097305058952,\n",
       "     0.0019148781427632145,\n",
       "     0.010204736818112656,\n",
       "     0.006176814818135897,\n",
       "     0.008665887888489153,\n",
       "     0.002588383336770058,\n",
       "     0.00767134650993594,\n",
       "     0.008944675035869473],\n",
       "    'param_classifier__max_depth': [None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     20,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30,\n",
       "     30],\n",
       "    'param_classifier__min_samples_leaf': [1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     1,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4,\n",
       "     4],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     2,\n",
       "     2,\n",
       "     2,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10],\n",
       "    'param_classifier__n_estimators': [100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300,\n",
       "     100,\n",
       "     200,\n",
       "     300],\n",
       "    'params': [{'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': None,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 20,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 1,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 2,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 2,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 5,\n",
       "      'classifier__n_estimators': 300},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 100},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 200},\n",
       "     {'classifier__max_depth': 30,\n",
       "      'classifier__min_samples_leaf': 4,\n",
       "      'classifier__min_samples_split': 10,\n",
       "      'classifier__n_estimators': 300}],\n",
       "    'split0_test_score': [0.9568345323741008,\n",
       "     0.9712230215827338,\n",
       "     0.9712230215827338,\n",
       "     0.9712230215827338,\n",
       "     0.9712230215827338,\n",
       "     0.9640287769784173,\n",
       "     0.9640287769784173,\n",
       "     0.9568345323741008,\n",
       "     0.9568345323741008,\n",
       "     0.9640287769784173,\n",
       "     0.9640287769784173,\n",
       "     0.9784172661870504,\n",
       "     0.9784172661870504,\n",
       "     0.9496402877697842,\n",
       "     0.9712230215827338,\n",
       "     0.9640287769784173,\n",
       "     0.9424460431654677,\n",
       "     0.9712230215827338,\n",
       "     0.9568345323741008,\n",
       "     0.9496402877697842,\n",
       "     0.9496402877697842,\n",
       "     0.9568345323741008,\n",
       "     0.9496402877697842,\n",
       "     0.9496402877697842,\n",
       "     0.9568345323741008,\n",
       "     0.9568345323741008,\n",
       "     0.9424460431654677,\n",
       "     0.9784172661870504,\n",
       "     0.9568345323741008,\n",
       "     0.9784172661870504,\n",
       "     0.9712230215827338,\n",
       "     0.9712230215827338,\n",
       "     0.9712230215827338,\n",
       "     0.9640287769784173,\n",
       "     0.9640287769784173,\n",
       "     0.9784172661870504,\n",
       "     0.9784172661870504,\n",
       "     0.9784172661870504,\n",
       "     0.9784172661870504,\n",
       "     0.9784172661870504,\n",
       "     0.9568345323741008,\n",
       "     0.9784172661870504,\n",
       "     0.9640287769784173,\n",
       "     0.9712230215827338,\n",
       "     0.9568345323741008,\n",
       "     0.9568345323741008,\n",
       "     0.935251798561151,\n",
       "     0.9424460431654677,\n",
       "     0.935251798561151,\n",
       "     0.9496402877697842,\n",
       "     0.9424460431654677,\n",
       "     0.9424460431654677,\n",
       "     0.9568345323741008,\n",
       "     0.9424460431654677,\n",
       "     0.9640287769784173,\n",
       "     0.9712230215827338,\n",
       "     0.9640287769784173,\n",
       "     0.9496402877697842,\n",
       "     0.9496402877697842,\n",
       "     0.9712230215827338,\n",
       "     0.9640287769784173,\n",
       "     0.9568345323741008,\n",
       "     0.9640287769784173,\n",
       "     0.9568345323741008,\n",
       "     0.9568345323741008,\n",
       "     0.9712230215827338,\n",
       "     0.9496402877697842,\n",
       "     0.9568345323741008,\n",
       "     0.9712230215827338,\n",
       "     0.9712230215827338,\n",
       "     0.9640287769784173,\n",
       "     0.9568345323741008,\n",
       "     0.9496402877697842,\n",
       "     0.935251798561151,\n",
       "     0.9568345323741008,\n",
       "     0.9496402877697842,\n",
       "     0.9496402877697842,\n",
       "     0.9568345323741008,\n",
       "     0.9496402877697842,\n",
       "     0.9568345323741008,\n",
       "     0.9496402877697842,\n",
       "     0.9784172661870504,\n",
       "     0.9496402877697842,\n",
       "     0.9712230215827338,\n",
       "     0.9640287769784173,\n",
       "     0.9640287769784173,\n",
       "     0.9640287769784173,\n",
       "     0.9712230215827338,\n",
       "     0.9640287769784173,\n",
       "     0.9496402877697842,\n",
       "     0.9640287769784173,\n",
       "     0.9712230215827338,\n",
       "     0.9712230215827338,\n",
       "     0.9856115107913669,\n",
       "     0.9640287769784173,\n",
       "     0.9712230215827338,\n",
       "     0.9424460431654677,\n",
       "     0.9568345323741008,\n",
       "     0.9640287769784173,\n",
       "     0.9496402877697842,\n",
       "     0.935251798561151,\n",
       "     0.9496402877697842,\n",
       "     0.9496402877697842,\n",
       "     0.9496402877697842,\n",
       "     0.9568345323741008,\n",
       "     0.935251798561151,\n",
       "     0.9496402877697842,\n",
       "     0.9568345323741008],\n",
       "    'split1_test_score': [0.9064748201438849,\n",
       "     0.920863309352518,\n",
       "     0.920863309352518,\n",
       "     0.920863309352518,\n",
       "     0.9136690647482014,\n",
       "     0.9136690647482014,\n",
       "     0.8920863309352518,\n",
       "     0.9136690647482014,\n",
       "     0.9064748201438849,\n",
       "     0.9136690647482014,\n",
       "     0.9136690647482014,\n",
       "     0.9136690647482014,\n",
       "     0.9280575539568345,\n",
       "     0.920863309352518,\n",
       "     0.9280575539568345,\n",
       "     0.9136690647482014,\n",
       "     0.8848920863309353,\n",
       "     0.920863309352518,\n",
       "     0.9064748201438849,\n",
       "     0.8992805755395683,\n",
       "     0.8992805755395683,\n",
       "     0.8920863309352518,\n",
       "     0.8920863309352518,\n",
       "     0.8848920863309353,\n",
       "     0.8992805755395683,\n",
       "     0.9136690647482014,\n",
       "     0.9064748201438849,\n",
       "     0.9136690647482014,\n",
       "     0.9064748201438849,\n",
       "     0.920863309352518,\n",
       "     0.920863309352518,\n",
       "     0.9136690647482014,\n",
       "     0.9136690647482014,\n",
       "     0.920863309352518,\n",
       "     0.9136690647482014,\n",
       "     0.9064748201438849,\n",
       "     0.9064748201438849,\n",
       "     0.9064748201438849,\n",
       "     0.920863309352518,\n",
       "     0.9136690647482014,\n",
       "     0.9136690647482014,\n",
       "     0.920863309352518,\n",
       "     0.9064748201438849,\n",
       "     0.8920863309352518,\n",
       "     0.9064748201438849,\n",
       "     0.8776978417266187,\n",
       "     0.9136690647482014,\n",
       "     0.8992805755395683,\n",
       "     0.8920863309352518,\n",
       "     0.9064748201438849,\n",
       "     0.8848920863309353,\n",
       "     0.8992805755395683,\n",
       "     0.8992805755395683,\n",
       "     0.8992805755395683,\n",
       "     0.8992805755395683,\n",
       "     0.920863309352518,\n",
       "     0.920863309352518,\n",
       "     0.920863309352518,\n",
       "     0.920863309352518,\n",
       "     0.920863309352518,\n",
       "     0.8992805755395683,\n",
       "     0.9136690647482014,\n",
       "     0.9064748201438849,\n",
       "     0.9136690647482014,\n",
       "     0.920863309352518,\n",
       "     0.920863309352518,\n",
       "     0.920863309352518,\n",
       "     0.9064748201438849,\n",
       "     0.920863309352518,\n",
       "     0.8848920863309353,\n",
       "     0.9064748201438849,\n",
       "     0.8920863309352518,\n",
       "     0.8705035971223022,\n",
       "     0.9064748201438849,\n",
       "     0.8992805755395683,\n",
       "     0.9064748201438849,\n",
       "     0.8705035971223022,\n",
       "     0.8848920863309353,\n",
       "     0.8848920863309353,\n",
       "     0.8848920863309353,\n",
       "     0.9064748201438849,\n",
       "     0.9064748201438849,\n",
       "     0.9064748201438849,\n",
       "     0.9136690647482014,\n",
       "     0.9280575539568345,\n",
       "     0.9280575539568345,\n",
       "     0.920863309352518,\n",
       "     0.8920863309352518,\n",
       "     0.8920863309352518,\n",
       "     0.9136690647482014,\n",
       "     0.9064748201438849,\n",
       "     0.920863309352518,\n",
       "     0.920863309352518,\n",
       "     0.920863309352518,\n",
       "     0.9136690647482014,\n",
       "     0.920863309352518,\n",
       "     0.9136690647482014,\n",
       "     0.8992805755395683,\n",
       "     0.9136690647482014,\n",
       "     0.8920863309352518,\n",
       "     0.9136690647482014,\n",
       "     0.9136690647482014,\n",
       "     0.9064748201438849,\n",
       "     0.8992805755395683,\n",
       "     0.8848920863309353,\n",
       "     0.8992805755395683,\n",
       "     0.8848920863309353,\n",
       "     0.8848920863309353],\n",
       "    'split2_test_score': [0.9710144927536232,\n",
       "     0.9710144927536232,\n",
       "     0.9710144927536232,\n",
       "     0.9420289855072463,\n",
       "     0.9420289855072463,\n",
       "     0.9420289855072463,\n",
       "     0.9202898550724637,\n",
       "     0.9130434782608695,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.9202898550724637,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.9202898550724637,\n",
       "     0.9130434782608695,\n",
       "     0.9202898550724637,\n",
       "     0.8913043478260869,\n",
       "     0.8913043478260869,\n",
       "     0.8913043478260869,\n",
       "     0.8985507246376812,\n",
       "     0.9202898550724637,\n",
       "     0.8985507246376812,\n",
       "     0.8985507246376812,\n",
       "     0.8840579710144928,\n",
       "     0.8913043478260869,\n",
       "     0.9782608695652174,\n",
       "     0.9782608695652174,\n",
       "     0.9782608695652174,\n",
       "     0.9420289855072463,\n",
       "     0.9420289855072463,\n",
       "     0.9420289855072463,\n",
       "     0.9130434782608695,\n",
       "     0.9202898550724637,\n",
       "     0.9130434782608695,\n",
       "     0.9202898550724637,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.9130434782608695,\n",
       "     0.9130434782608695,\n",
       "     0.9130434782608695,\n",
       "     0.8985507246376812,\n",
       "     0.8840579710144928,\n",
       "     0.9130434782608695,\n",
       "     0.8840579710144928,\n",
       "     0.8985507246376812,\n",
       "     0.8985507246376812,\n",
       "     0.9130434782608695,\n",
       "     0.8913043478260869,\n",
       "     0.9130434782608695,\n",
       "     0.9710144927536232,\n",
       "     0.9710144927536232,\n",
       "     0.9710144927536232,\n",
       "     0.9637681159420289,\n",
       "     0.9420289855072463,\n",
       "     0.9420289855072463,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.9202898550724637,\n",
       "     0.9130434782608695,\n",
       "     0.9202898550724637,\n",
       "     0.8913043478260869,\n",
       "     0.8913043478260869,\n",
       "     0.8913043478260869,\n",
       "     0.8985507246376812,\n",
       "     0.8913043478260869,\n",
       "     0.8913043478260869,\n",
       "     0.9202898550724637,\n",
       "     0.8840579710144928,\n",
       "     0.8985507246376812,\n",
       "     0.9710144927536232,\n",
       "     0.9710144927536232,\n",
       "     0.9710144927536232,\n",
       "     0.9637681159420289,\n",
       "     0.9420289855072463,\n",
       "     0.9420289855072463,\n",
       "     0.9347826086956522,\n",
       "     0.9202898550724637,\n",
       "     0.9130434782608695,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.927536231884058,\n",
       "     0.9202898550724637,\n",
       "     0.9202898550724637,\n",
       "     0.8985507246376812,\n",
       "     0.8913043478260869,\n",
       "     0.8985507246376812,\n",
       "     0.8913043478260869,\n",
       "     0.8913043478260869,\n",
       "     0.8913043478260869,\n",
       "     0.8985507246376812,\n",
       "     0.8985507246376812,\n",
       "     0.8913043478260869],\n",
       "    'mean_test_score': [0.9447746150905362,\n",
       "     0.9543669412296251,\n",
       "     0.9543669412296251,\n",
       "     0.9447051054808328,\n",
       "     0.9423070239460604,\n",
       "     0.9399089424112882,\n",
       "     0.9254683209953777,\n",
       "     0.9278490251277239,\n",
       "     0.9302818614673479,\n",
       "     0.9350780245368923,\n",
       "     0.9350780245368923,\n",
       "     0.9398741876064366,\n",
       "     0.942254891738783,\n",
       "     0.9326799430021201,\n",
       "     0.9422722691412088,\n",
       "     0.9326625655996942,\n",
       "     0.9134605359190909,\n",
       "     0.9374587286692385,\n",
       "     0.9182045667813575,\n",
       "     0.9134084037118132,\n",
       "     0.9134084037118132,\n",
       "     0.9158238626490113,\n",
       "     0.9206721579258333,\n",
       "     0.9110276995794669,\n",
       "     0.9182219441837834,\n",
       "     0.9181871893789316,\n",
       "     0.9134084037118132,\n",
       "     0.9567824001668231,\n",
       "     0.9471900740277343,\n",
       "     0.9591804817015953,\n",
       "     0.9447051054808328,\n",
       "     0.9423070239460604,\n",
       "     0.9423070239460604,\n",
       "     0.9326451881972683,\n",
       "     0.9326625655996942,\n",
       "     0.9326451881972683,\n",
       "     0.9350606471344663,\n",
       "     0.9374761060716644,\n",
       "     0.9422722691412089,\n",
       "     0.9398741876064366,\n",
       "     0.9326799430021201,\n",
       "     0.9422722691412089,\n",
       "     0.9278490251277239,\n",
       "     0.9254509435929518,\n",
       "     0.9254509435929518,\n",
       "     0.9110276995794669,\n",
       "     0.9109929447746151,\n",
       "     0.9182566989886353,\n",
       "     0.9037987001702986,\n",
       "     0.9182219441837834,\n",
       "     0.9086296180446948,\n",
       "     0.9182566989886353,\n",
       "     0.9158064852465854,\n",
       "     0.9182566989886353,\n",
       "     0.9447746150905362,\n",
       "     0.9543669412296251,\n",
       "     0.9519688596948529,\n",
       "     0.9447572376881103,\n",
       "     0.937510860876516,\n",
       "     0.9447051054808328,\n",
       "     0.9302818614673479,\n",
       "     0.9326799430021201,\n",
       "     0.9326799430021201,\n",
       "     0.9326799430021201,\n",
       "     0.9350780245368923,\n",
       "     0.9398741876064366,\n",
       "     0.9326799430021201,\n",
       "     0.9302818614673479,\n",
       "     0.9398741876064366,\n",
       "     0.9254683209953777,\n",
       "     0.9278490251277239,\n",
       "     0.9230702394606055,\n",
       "     0.9038160775727245,\n",
       "     0.911010322177041,\n",
       "     0.9158064852465854,\n",
       "     0.9182219441837834,\n",
       "     0.9038160775727245,\n",
       "     0.911010322177041,\n",
       "     0.9182740763910612,\n",
       "     0.908594863239843,\n",
       "     0.9182219441837834,\n",
       "     0.9519688596948529,\n",
       "     0.942376533555764,\n",
       "     0.9519688596948527,\n",
       "     0.951951482292427,\n",
       "     0.9447051054808328,\n",
       "     0.9423070239460606,\n",
       "     0.932697320404546,\n",
       "     0.9254683209953777,\n",
       "     0.9254509435929518,\n",
       "     0.9326799430021201,\n",
       "     0.9398741876064366,\n",
       "     0.9398741876064366,\n",
       "     0.944670350675981,\n",
       "     0.9350780245368923,\n",
       "     0.9398741876064366,\n",
       "     0.9278837799325758,\n",
       "     0.9254683209953777,\n",
       "     0.9326625655996942,\n",
       "     0.9134257811142391,\n",
       "     0.9134084037118132,\n",
       "     0.9206200257185556,\n",
       "     0.9158064852465854,\n",
       "     0.9134084037118132,\n",
       "     0.911010322177041,\n",
       "     0.9110276995794667,\n",
       "     0.9110276995794669,\n",
       "     0.911010322177041],\n",
       "    'std_test_score': [0.0276938445484174,\n",
       "     0.023690798252847253,\n",
       "     0.023690798252847253,\n",
       "     0.02064616780522568,\n",
       "     0.02349712699966951,\n",
       "     0.020613847951059135,\n",
       "     0.02959776193852646,\n",
       "     0.020497439878524787,\n",
       "     0.020650730662360197,\n",
       "     0.021239650519587122,\n",
       "     0.021239650519587122,\n",
       "     0.027835843331299452,\n",
       "     0.025766545244976045,\n",
       "     0.01229829106709564,\n",
       "     0.020472379675614015,\n",
       "     0.022343352901486032,\n",
       "     0.02349815509985857,\n",
       "     0.023876108273251703,\n",
       "     0.02800882585732175,\n",
       "     0.02582591875005958,\n",
       "     0.02582591875005958,\n",
       "     0.029118761076669945,\n",
       "     0.0234978595256614,\n",
       "     0.027866809112453695,\n",
       "     0.02730484872266002,\n",
       "     0.029882180403113207,\n",
       "     0.021446432280865003,\n",
       "     0.030485798695619595,\n",
       "     0.030089543094754086,\n",
       "     0.02709440763451008,\n",
       "     0.02064616780522568,\n",
       "     0.02349712699966951,\n",
       "     0.02349712699966951,\n",
       "     0.022420001087773898,\n",
       "     0.022343352901486032,\n",
       "     0.03247664966291401,\n",
       "     0.031172221707503545,\n",
       "     0.030199665669424523,\n",
       "     0.02570314614155118,\n",
       "     0.027835843331299452,\n",
       "     0.01799366040008161,\n",
       "     0.02570314614155118,\n",
       "     0.025723110884284188,\n",
       "     0.03347748346410296,\n",
       "     0.022352987137482013,\n",
       "     0.03349039792171562,\n",
       "     0.02098528386439756,\n",
       "     0.018003659842893892,\n",
       "     0.022480905817201084,\n",
       "     0.022450420302878596,\n",
       "     0.02455337798973574,\n",
       "     0.018003659842893892,\n",
       "     0.029193384415623438,\n",
       "     0.018003659842893892,\n",
       "     0.032295312169846636,\n",
       "     0.023690798252847253,\n",
       "     0.022179066749191425,\n",
       "     0.017852894082770545,\n",
       "     0.012174802102185151,\n",
       "     0.02064616780522568,\n",
       "     0.02650454374565385,\n",
       "     0.01799366040008161,\n",
       "     0.02377614784999678,\n",
       "     0.01799366040008161,\n",
       "     0.015623512168755349,\n",
       "     0.022333741551489105,\n",
       "     0.01229829106709564,\n",
       "     0.020650730662360197,\n",
       "     0.022333741551489105,\n",
       "     0.03543416409200439,\n",
       "     0.025723110884284188,\n",
       "     0.026506355217831654,\n",
       "     0.03349688032835779,\n",
       "     0.018225855088258438,\n",
       "     0.029193384415623438,\n",
       "     0.022450420302878596,\n",
       "     0.03349688032835779,\n",
       "     0.03250818311860147,\n",
       "     0.02647174493884294,\n",
       "     0.034112296861271596,\n",
       "     0.022450420302878596,\n",
       "     0.032310792723437766,\n",
       "     0.026844166704696696,\n",
       "     0.02708217852862898,\n",
       "     0.01689589387048011,\n",
       "     0.014806607421505706,\n",
       "     0.01762332503380548,\n",
       "     0.032341049994308924,\n",
       "     0.02959776193852646,\n",
       "     0.017106355902455805,\n",
       "     0.02377614784999678,\n",
       "     0.022333741551489105,\n",
       "     0.022333741551489105,\n",
       "     0.029077665168455707,\n",
       "     0.021239650519587122,\n",
       "     0.022333741551489105,\n",
       "     0.011750722359114011,\n",
       "     0.023779919663641867,\n",
       "     0.022343352901486032,\n",
       "     0.025743153985909772,\n",
       "     0.017942418355387887,\n",
       "     0.021428528633044695,\n",
       "     0.02471275584889148,\n",
       "     0.02582591875005958,\n",
       "     0.03250818311860147,\n",
       "     0.01713161598119243,\n",
       "     0.027866809112453695,\n",
       "     0.03250818311860147],\n",
       "    'rank_test_score': [11,\n",
       "     3,\n",
       "     3,\n",
       "     14,\n",
       "     21,\n",
       "     28,\n",
       "     64,\n",
       "     61,\n",
       "     57,\n",
       "     39,\n",
       "     39,\n",
       "     29,\n",
       "     27,\n",
       "     45,\n",
       "     26,\n",
       "     52,\n",
       "     88,\n",
       "     38,\n",
       "     82,\n",
       "     90,\n",
       "     90,\n",
       "     84,\n",
       "     72,\n",
       "     95,\n",
       "     78,\n",
       "     83,\n",
       "     90,\n",
       "     2,\n",
       "     10,\n",
       "     1,\n",
       "     14,\n",
       "     21,\n",
       "     21,\n",
       "     55,\n",
       "     52,\n",
       "     55,\n",
       "     43,\n",
       "     37,\n",
       "     24,\n",
       "     29,\n",
       "     45,\n",
       "     24,\n",
       "     61,\n",
       "     68,\n",
       "     68,\n",
       "     95,\n",
       "     103,\n",
       "     75,\n",
       "     108,\n",
       "     78,\n",
       "     104,\n",
       "     75,\n",
       "     85,\n",
       "     75,\n",
       "     11,\n",
       "     3,\n",
       "     6,\n",
       "     13,\n",
       "     36,\n",
       "     14,\n",
       "     57,\n",
       "     45,\n",
       "     45,\n",
       "     45,\n",
       "     39,\n",
       "     29,\n",
       "     45,\n",
       "     57,\n",
       "     29,\n",
       "     64,\n",
       "     61,\n",
       "     71,\n",
       "     106,\n",
       "     99,\n",
       "     85,\n",
       "     78,\n",
       "     106,\n",
       "     99,\n",
       "     74,\n",
       "     105,\n",
       "     78,\n",
       "     6,\n",
       "     19,\n",
       "     8,\n",
       "     9,\n",
       "     14,\n",
       "     20,\n",
       "     44,\n",
       "     64,\n",
       "     68,\n",
       "     45,\n",
       "     29,\n",
       "     29,\n",
       "     18,\n",
       "     39,\n",
       "     29,\n",
       "     60,\n",
       "     64,\n",
       "     52,\n",
       "     89,\n",
       "     90,\n",
       "     73,\n",
       "     85,\n",
       "     90,\n",
       "     99,\n",
       "     98,\n",
       "     95,\n",
       "     99]}}],\n",
       " 'diabetes SVM': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__C': 1},\n",
       "   'best_validation_accuracy': 0.8268907563025211,\n",
       "   'train_accuracy': 0.9615384615384616,\n",
       "   'test_accuracy': 0.9350961538461539,\n",
       "   'cv_results': {'mean_fit_time': [0.0,\n",
       "     0.0,\n",
       "     0.005211194356282552,\n",
       "     0.015633583068847656,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.011972188949584961,\n",
       "     0.013254801432291666,\n",
       "     0.00019979476928710938,\n",
       "     0.009093761444091797,\n",
       "     0.015980641047159832],\n",
       "    'std_fit_time': [0.0,\n",
       "     0.0,\n",
       "     0.0073697417348169165,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.008485395762623287,\n",
       "     0.00765465443075056,\n",
       "     0.0002825524724170336,\n",
       "     0.0064302603836100805,\n",
       "     0.0004732810108783327],\n",
       "    'mean_score_time': [0.0,\n",
       "     0.010422388712565104,\n",
       "     0.005211194356282552,\n",
       "     0.0,\n",
       "     0.005412658055623372,\n",
       "     0.01244497299194336,\n",
       "     0.006695270538330078,\n",
       "     0.0,\n",
       "     0.013300418853759766,\n",
       "     0.008886098861694336,\n",
       "     0.0033311049143473306],\n",
       "    'std_score_time': [0.0,\n",
       "     0.0073697417348169165,\n",
       "     0.0073697417348169165,\n",
       "     0.0,\n",
       "     0.00765465443075056,\n",
       "     0.008799924794286587,\n",
       "     0.008485395762623287,\n",
       "     0.0,\n",
       "     0.0009525187763462052,\n",
       "     0.005489879899635013,\n",
       "     0.00047244032988962394],\n",
       "    'param_classifier__C': [1e-07,\n",
       "     1e-06,\n",
       "     1e-05,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     1000.0],\n",
       "    'params': [{'classifier__C': 1e-07},\n",
       "     {'classifier__C': 1e-06},\n",
       "     {'classifier__C': 1e-05},\n",
       "     {'classifier__C': 0.0001},\n",
       "     {'classifier__C': 0.001},\n",
       "     {'classifier__C': 0.01},\n",
       "     {'classifier__C': 0.1},\n",
       "     {'classifier__C': 1},\n",
       "     {'classifier__C': 10},\n",
       "     {'classifier__C': 100},\n",
       "     {'classifier__C': 1000}],\n",
       "    'split0_test_score': [0.6285714285714286,\n",
       "     0.6285714285714286,\n",
       "     0.6285714285714286,\n",
       "     0.6285714285714286,\n",
       "     0.6285714285714286,\n",
       "     0.6285714285714286,\n",
       "     0.6285714285714286,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.7714285714285715,\n",
       "     0.7714285714285715],\n",
       "    'split1_test_score': [0.6,\n",
       "     0.6,\n",
       "     0.6,\n",
       "     0.6,\n",
       "     0.6,\n",
       "     0.6,\n",
       "     0.6,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.7428571428571429,\n",
       "     0.7714285714285715],\n",
       "    'split2_test_score': [0.6176470588235294,\n",
       "     0.6176470588235294,\n",
       "     0.6176470588235294,\n",
       "     0.6176470588235294,\n",
       "     0.6176470588235294,\n",
       "     0.6176470588235294,\n",
       "     0.6176470588235294,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058],\n",
       "    'mean_test_score': [0.615406162464986,\n",
       "     0.615406162464986,\n",
       "     0.615406162464986,\n",
       "     0.615406162464986,\n",
       "     0.615406162464986,\n",
       "     0.615406162464986,\n",
       "     0.615406162464986,\n",
       "     0.8268907563025211,\n",
       "     0.8078431372549021,\n",
       "     0.7792717086834733,\n",
       "     0.7887955182072829],\n",
       "    'std_test_score': [0.011771373327423363,\n",
       "     0.011771373327423363,\n",
       "     0.011771373327423363,\n",
       "     0.011771373327423363,\n",
       "     0.011771373327423363,\n",
       "     0.011771373327423363,\n",
       "     0.011771373327423363,\n",
       "     0.002376829516593481,\n",
       "     0.011091871077436,\n",
       "     0.03339800237711791,\n",
       "     0.02456057167146548],\n",
       "    'rank_test_score': [5, 5, 5, 5, 5, 5, 5, 1, 2, 4, 3]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__C': 1},\n",
       "   'best_validation_accuracy': 0.9460928450503431,\n",
       "   'train_accuracy': 0.9769230769230769,\n",
       "   'test_accuracy': 0.9423076923076923,\n",
       "   'cv_results': {'mean_fit_time': [0.0,\n",
       "     0.0,\n",
       "     0.010008811950683594,\n",
       "     0.01501321792602539,\n",
       "     0.005004405975341797,\n",
       "     0.011624733606974283,\n",
       "     0.02215298016866048,\n",
       "     0.020064751307169598,\n",
       "     0.0031473636627197266,\n",
       "     0.010434309641520182,\n",
       "     0.010434309641520182],\n",
       "    'std_fit_time': [0.0,\n",
       "     0.0,\n",
       "     0.007077298801949326,\n",
       "     0.0,\n",
       "     0.007077298801949326,\n",
       "     0.008349043339919884,\n",
       "     0.0015234284584694077,\n",
       "     0.006936018968873703,\n",
       "     0.0023710557118066474,\n",
       "     0.007378171104519095,\n",
       "     0.007378171104519095],\n",
       "    'mean_score_time': [0.005004405975341797,\n",
       "     0.01501321792602539,\n",
       "     0.005004405975341797,\n",
       "     0.005215247472127278,\n",
       "     0.013870318730672201,\n",
       "     0.012637058893839518,\n",
       "     0.0038122336069742837,\n",
       "     0.0006852149963378906,\n",
       "     0.005217154820760091,\n",
       "     0.005217154820760091,\n",
       "     0.005217154820760091],\n",
       "    'std_score_time': [0.007077298801949326,\n",
       "     0.0,\n",
       "     0.007077298801949326,\n",
       "     0.007375473706214398,\n",
       "     0.010674336155828378,\n",
       "     0.006853131458485115,\n",
       "     0.0015234284584694077,\n",
       "     0.0009262171994438774,\n",
       "     0.007378171104519095,\n",
       "     0.007378171104519095,\n",
       "     0.007378171104519095],\n",
       "    'param_classifier__C': [1e-07,\n",
       "     1e-06,\n",
       "     1e-05,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     1000.0],\n",
       "    'params': [{'classifier__C': 1e-07},\n",
       "     {'classifier__C': 1e-06},\n",
       "     {'classifier__C': 1e-05},\n",
       "     {'classifier__C': 0.0001},\n",
       "     {'classifier__C': 0.001},\n",
       "     {'classifier__C': 0.01},\n",
       "     {'classifier__C': 0.1},\n",
       "     {'classifier__C': 1},\n",
       "     {'classifier__C': 10},\n",
       "     {'classifier__C': 100},\n",
       "     {'classifier__C': 1000}],\n",
       "    'split0_test_score': [0.6206896551724138,\n",
       "     0.6206896551724138,\n",
       "     0.6206896551724138,\n",
       "     0.6206896551724138,\n",
       "     0.6206896551724138,\n",
       "     0.6206896551724138,\n",
       "     0.8620689655172413,\n",
       "     0.9540229885057471,\n",
       "     0.9310344827586207,\n",
       "     0.9195402298850575,\n",
       "     0.9195402298850575],\n",
       "    'split1_test_score': [0.6091954022988506,\n",
       "     0.6091954022988506,\n",
       "     0.6091954022988506,\n",
       "     0.6091954022988506,\n",
       "     0.6091954022988506,\n",
       "     0.6091954022988506,\n",
       "     0.8505747126436781,\n",
       "     0.9540229885057471,\n",
       "     0.9425287356321839,\n",
       "     0.9080459770114943,\n",
       "     0.9080459770114943],\n",
       "    'split2_test_score': [0.6162790697674418,\n",
       "     0.6162790697674418,\n",
       "     0.6162790697674418,\n",
       "     0.6162790697674418,\n",
       "     0.6162790697674418,\n",
       "     0.6162790697674418,\n",
       "     0.8604651162790697,\n",
       "     0.9302325581395349,\n",
       "     0.9418604651162791,\n",
       "     0.9418604651162791,\n",
       "     0.9418604651162791],\n",
       "    'mean_test_score': [0.6153880424129021,\n",
       "     0.6153880424129021,\n",
       "     0.6153880424129021,\n",
       "     0.6153880424129021,\n",
       "     0.6153880424129021,\n",
       "     0.6153880424129021,\n",
       "     0.8577029314799963,\n",
       "     0.9460928450503431,\n",
       "     0.9384745611690278,\n",
       "     0.9231488906709435,\n",
       "     0.9231488906709435],\n",
       "    'std_test_score': [0.004734617871962325,\n",
       "     0.004734617871962325,\n",
       "     0.004734617871962325,\n",
       "     0.004734617871962325,\n",
       "     0.004734617871962325,\n",
       "     0.004734617871962325,\n",
       "     0.00508276243320027,\n",
       "     0.011214916426196672,\n",
       "     0.005267999078420729,\n",
       "     0.014038559421532606,\n",
       "     0.014038559421532606],\n",
       "    'rank_test_score': [6, 6, 6, 6, 6, 6, 5, 1, 2, 3, 3]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__C': 10},\n",
       "   'best_validation_accuracy': 0.9447746150905362,\n",
       "   'train_accuracy': 0.9879807692307693,\n",
       "   'test_accuracy': 0.9903846153846154,\n",
       "   'cv_results': {'mean_fit_time': [0.01471098264058431,\n",
       "     0.01605391502380371,\n",
       "     0.007901191711425781,\n",
       "     0.0052153269449869795,\n",
       "     0.01673436164855957,\n",
       "     0.019084850947062176,\n",
       "     0.02441708246866862,\n",
       "     0.030280590057373047,\n",
       "     0.01307829221089681,\n",
       "     0.014415979385375977,\n",
       "     0.01345205307006836],\n",
       "    'std_fit_time': [0.0018991931896988996,\n",
       "     0.0,\n",
       "     0.005476392908111527,\n",
       "     0.007375586097810426,\n",
       "     0.00153920290761785,\n",
       "     0.0014376248924940333,\n",
       "     0.009151319877695234,\n",
       "     0.007718268135476247,\n",
       "     0.0008503873098617705,\n",
       "     0.0018453958213767178,\n",
       "     0.00201807102803172],\n",
       "    'mean_score_time': [0.0013429323832194011,\n",
       "     0.0,\n",
       "     0.014918963114420572,\n",
       "     0.010430653889973959,\n",
       "     0.017454067866007488,\n",
       "     0.010312875111897787,\n",
       "     0.011046250661214193,\n",
       "     0.007526715596516927,\n",
       "     0.007750590642293294,\n",
       "     0.007663329442342122,\n",
       "     0.006675402323404948],\n",
       "    'std_score_time': [0.0018991931896988996,\n",
       "     0.0,\n",
       "     0.0010281583204737562,\n",
       "     0.007375586097810427,\n",
       "     0.004874011969576622,\n",
       "     0.0002153731800023923,\n",
       "     0.001258261986547887,\n",
       "     0.0031562034624300454,\n",
       "     0.0010066060707638396,\n",
       "     0.0004127742144520197,\n",
       "     0.0008812719862442759],\n",
       "    'param_classifier__C': [1e-07,\n",
       "     1e-06,\n",
       "     1e-05,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     1000.0],\n",
       "    'params': [{'classifier__C': 1e-07},\n",
       "     {'classifier__C': 1e-06},\n",
       "     {'classifier__C': 1e-05},\n",
       "     {'classifier__C': 0.0001},\n",
       "     {'classifier__C': 0.001},\n",
       "     {'classifier__C': 0.01},\n",
       "     {'classifier__C': 0.1},\n",
       "     {'classifier__C': 1},\n",
       "     {'classifier__C': 10},\n",
       "     {'classifier__C': 100},\n",
       "     {'classifier__C': 1000}],\n",
       "    'split0_test_score': [0.6187050359712231,\n",
       "     0.6187050359712231,\n",
       "     0.6187050359712231,\n",
       "     0.6187050359712231,\n",
       "     0.6187050359712231,\n",
       "     0.6187050359712231,\n",
       "     0.935251798561151,\n",
       "     0.9640287769784173,\n",
       "     0.9640287769784173,\n",
       "     0.9784172661870504,\n",
       "     0.9568345323741008],\n",
       "    'split1_test_score': [0.6115107913669064,\n",
       "     0.6115107913669064,\n",
       "     0.6115107913669064,\n",
       "     0.6115107913669064,\n",
       "     0.6115107913669064,\n",
       "     0.6115107913669064,\n",
       "     0.8201438848920863,\n",
       "     0.9136690647482014,\n",
       "     0.8992805755395683,\n",
       "     0.8776978417266187,\n",
       "     0.8776978417266187],\n",
       "    'split2_test_score': [0.6159420289855072,\n",
       "     0.6159420289855072,\n",
       "     0.6159420289855072,\n",
       "     0.6159420289855072,\n",
       "     0.6159420289855072,\n",
       "     0.6159420289855072,\n",
       "     0.8695652173913043,\n",
       "     0.9347826086956522,\n",
       "     0.9710144927536232,\n",
       "     0.9565217391304348,\n",
       "     0.9710144927536232],\n",
       "    'mean_test_score': [0.6153859521078789,\n",
       "     0.6153859521078789,\n",
       "     0.6153859521078789,\n",
       "     0.6153859521078789,\n",
       "     0.6153859521078789,\n",
       "     0.6153859521078789,\n",
       "     0.8749869669481806,\n",
       "     0.9374934834740903,\n",
       "     0.9447746150905362,\n",
       "     0.9375456156813678,\n",
       "     0.9351822889514475],\n",
       "    'std_test_score': [0.0029632420282588354,\n",
       "     0.0029632420282588354,\n",
       "     0.0029632420282588354,\n",
       "     0.0029632420282588354,\n",
       "     0.0029632420282588354,\n",
       "     0.0029632420282588354,\n",
       "     0.04714873256341276,\n",
       "     0.020648434735282262,\n",
       "     0.032295312169846636,\n",
       "     0.043252518707206096,\n",
       "     0.04105779725906158],\n",
       "    'rank_test_score': [6, 6, 6, 6, 6, 6, 5, 3, 1, 2, 4]}}],\n",
       " 'diabetes KNN': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__n_neighbors': 3},\n",
       "   'best_validation_accuracy': 0.8268907563025211,\n",
       "   'train_accuracy': 0.9230769230769231,\n",
       "   'test_accuracy': 0.8701923076923077,\n",
       "   'cv_results': {'mean_fit_time': [0.005211591720581055,\n",
       "     0.005211591720581055,\n",
       "     0.01327363650004069,\n",
       "     0.020776987075805664,\n",
       "     0.0],\n",
       "    'std_fit_time': [0.007370303692797061,\n",
       "     0.007370303692797061,\n",
       "     0.009399478606426955,\n",
       "     0.0,\n",
       "     0.0],\n",
       "    'mean_score_time': [0.01556539535522461,\n",
       "     0.01556539535522461,\n",
       "     0.007503350575764974,\n",
       "     0.0,\n",
       "     0.01563262939453125],\n",
       "    'std_score_time': [0.007370303692797061,\n",
       "     0.007370303692797061,\n",
       "     0.009399478606426955,\n",
       "     0.0,\n",
       "     0.0],\n",
       "    'param_classifier__n_neighbors': [3, 5, 7, 9, 11],\n",
       "    'params': [{'classifier__n_neighbors': 3},\n",
       "     {'classifier__n_neighbors': 5},\n",
       "     {'classifier__n_neighbors': 7},\n",
       "     {'classifier__n_neighbors': 9},\n",
       "     {'classifier__n_neighbors': 11}],\n",
       "    'split0_test_score': [0.7714285714285715,\n",
       "     0.8285714285714286,\n",
       "     0.7714285714285715,\n",
       "     0.7714285714285715,\n",
       "     0.8285714285714286],\n",
       "    'split1_test_score': [0.8857142857142857,\n",
       "     0.8571428571428571,\n",
       "     0.8857142857142857,\n",
       "     0.8857142857142857,\n",
       "     0.8857142857142857],\n",
       "    'split2_test_score': [0.8235294117647058,\n",
       "     0.7941176470588235,\n",
       "     0.7647058823529411,\n",
       "     0.7352941176470589,\n",
       "     0.7352941176470589],\n",
       "    'mean_test_score': [0.8268907563025211,\n",
       "     0.8266106442577031,\n",
       "     0.807282913165266,\n",
       "     0.7974789915966386,\n",
       "     0.8165266106442578],\n",
       "    'std_test_score': [0.04671744927594257,\n",
       "     0.025767263247227182,\n",
       "     0.055527223275580344,\n",
       "     0.06411201152952449,\n",
       "     0.06199658576361128],\n",
       "    'rank_test_score': [1, 2, 4, 5, 3]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__n_neighbors': 3},\n",
       "   'best_validation_accuracy': 0.9231043393032166,\n",
       "   'train_accuracy': 0.9807692307692307,\n",
       "   'test_accuracy': 0.9423076923076923,\n",
       "   'cv_results': {'mean_fit_time': [0.0,\n",
       "     0.015517711639404297,\n",
       "     0.015517711639404297,\n",
       "     0.01038662592569987,\n",
       "     0.0052140553792317705],\n",
       "    'std_fit_time': [0.0, 0.0, 0.0, 0.00734462936758789, 0.007373787832273962],\n",
       "    'mean_score_time': [0.015517711639404297,\n",
       "     0.0,\n",
       "     0.010428110758463541,\n",
       "     0.010428110758463541,\n",
       "     0.010428110758463541],\n",
       "    'std_score_time': [0.0,\n",
       "     0.0,\n",
       "     0.007373787832273962,\n",
       "     0.007373787832273962,\n",
       "     0.007373787832273962],\n",
       "    'param_classifier__n_neighbors': [3, 5, 7, 9, 11],\n",
       "    'params': [{'classifier__n_neighbors': 3},\n",
       "     {'classifier__n_neighbors': 5},\n",
       "     {'classifier__n_neighbors': 7},\n",
       "     {'classifier__n_neighbors': 9},\n",
       "     {'classifier__n_neighbors': 11}],\n",
       "    'split0_test_score': [0.9195402298850575,\n",
       "     0.896551724137931,\n",
       "     0.8850574712643678,\n",
       "     0.8505747126436781,\n",
       "     0.8735632183908046],\n",
       "    'split1_test_score': [0.9195402298850575,\n",
       "     0.896551724137931,\n",
       "     0.9195402298850575,\n",
       "     0.896551724137931,\n",
       "     0.8735632183908046],\n",
       "    'split2_test_score': [0.9302325581395349,\n",
       "     0.8953488372093024,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697],\n",
       "    'mean_test_score': [0.9231043393032166,\n",
       "     0.896150761828388,\n",
       "     0.8883542724761652,\n",
       "     0.8691971843535597,\n",
       "     0.8691971843535597],\n",
       "    'std_test_score': [0.005040411876942333,\n",
       "     0.0005670463361560026,\n",
       "     0.02422971915592735,\n",
       "     0.019759523545686532,\n",
       "     0.006174504549254391],\n",
       "    'rank_test_score': [1, 2, 3, 4, 4]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__n_neighbors': 3},\n",
       "   'best_validation_accuracy': 0.913443158516665,\n",
       "   'train_accuracy': 0.9783653846153846,\n",
       "   'test_accuracy': 0.9615384615384616,\n",
       "   'cv_results': {'mean_fit_time': [0.0,\n",
       "     0.015675783157348633,\n",
       "     0.010431687037150065,\n",
       "     0.015619277954101562,\n",
       "     0.010412851969401041],\n",
       "    'std_fit_time': [0.0,\n",
       "     0.0,\n",
       "     0.007376352713922242,\n",
       "     0.0,\n",
       "     0.007362998239055173],\n",
       "    'mean_score_time': [0.015675783157348633,\n",
       "     0.0052064259847005205,\n",
       "     0.010378281275431315,\n",
       "     0.010343710581461588,\n",
       "     0.010343710581461588],\n",
       "    'std_score_time': [0.0,\n",
       "     0.007362998239055173,\n",
       "     0.007338675208462795,\n",
       "     0.007314107894782536,\n",
       "     0.007314107894782536],\n",
       "    'param_classifier__n_neighbors': [3, 5, 7, 9, 11],\n",
       "    'params': [{'classifier__n_neighbors': 3},\n",
       "     {'classifier__n_neighbors': 5},\n",
       "     {'classifier__n_neighbors': 7},\n",
       "     {'classifier__n_neighbors': 9},\n",
       "     {'classifier__n_neighbors': 11}],\n",
       "    'split0_test_score': [0.935251798561151,\n",
       "     0.920863309352518,\n",
       "     0.8776978417266187,\n",
       "     0.8920863309352518,\n",
       "     0.8920863309352518],\n",
       "    'split1_test_score': [0.8992805755395683,\n",
       "     0.8633093525179856,\n",
       "     0.8776978417266187,\n",
       "     0.8489208633093526,\n",
       "     0.7913669064748201],\n",
       "    'split2_test_score': [0.9057971014492754,\n",
       "     0.8913043478260869,\n",
       "     0.8695652173913043,\n",
       "     0.8768115942028986,\n",
       "     0.8840579710144928],\n",
       "    'mean_test_score': [0.913443158516665,\n",
       "     0.8918256698988635,\n",
       "     0.8749869669481806,\n",
       "     0.8726062628158343,\n",
       "     0.8558370694748549],\n",
       "    'std_test_score': [0.015648830902561462,\n",
       "     0.023499196005473316,\n",
       "     0.003833755877562351,\n",
       "     0.017871355253531826,\n",
       "     0.04570496018809194],\n",
       "    'rank_test_score': [1, 2, 3, 4, 5]}}],\n",
       " 'diabetes log_reg': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__C': 1,\n",
       "    'classifier__max_iter': 500,\n",
       "    'classifier__penalty': 'l2'},\n",
       "   'best_validation_accuracy': 0.8364145658263306,\n",
       "   'train_accuracy': 0.875,\n",
       "   'test_accuracy': 0.8629807692307693,\n",
       "   'cv_results': {'mean_fit_time': [0.019457260767618816,\n",
       "     0.022791465123494465,\n",
       "     0.0162661870320638,\n",
       "     0.012405713399251303,\n",
       "     0.009327014287312826,\n",
       "     0.011681556701660156,\n",
       "     0.0110170046488444,\n",
       "     0.01124135653177897,\n",
       "     0.01158285140991211,\n",
       "     0.01104736328125,\n",
       "     0.011001189549763998,\n",
       "     0.006842692693074544,\n",
       "     0.009666760762532553,\n",
       "     0.015424092610677084,\n",
       "     0.015389521916707357,\n",
       "     0.01451412836710612],\n",
       "    'std_fit_time': [0.0012491477295560707,\n",
       "     0.0016330695335740645,\n",
       "     0.006745180279830383,\n",
       "     0.0011792252068583168,\n",
       "     0.0012443059679164636,\n",
       "     0.0009415608422502699,\n",
       "     0.0008140095012429745,\n",
       "     0.0005351564880295309,\n",
       "     0.0009146717000432056,\n",
       "     0.0006545126597091653,\n",
       "     0.0026418207052874335,\n",
       "     0.0037362187309994297,\n",
       "     0.006847668942508707,\n",
       "     0.00030098469416579794,\n",
       "     0.0008350641355459135,\n",
       "     0.001587868468698429],\n",
       "    'mean_score_time': [0.0050000349680582685,\n",
       "     0.0047232309977213545,\n",
       "     0.004407803217569987,\n",
       "     0.00500178337097168,\n",
       "     0.006349484125773112,\n",
       "     0.005663235982259114,\n",
       "     0.006623427073160808,\n",
       "     0.006292502085367839,\n",
       "     0.004753271738688151,\n",
       "     0.002088626225789388,\n",
       "     0.0036688645680745444,\n",
       "     0.002001682917277018,\n",
       "     0.008632500966389975,\n",
       "     0.00042247772216796875,\n",
       "     0.003222862879435221,\n",
       "     0.0042752424875895185],\n",
       "    'std_score_time': [3.429325264357156e-06,\n",
       "     0.0006306237168541179,\n",
       "     0.0011688548806811402,\n",
       "     0.0008077810287895703,\n",
       "     0.0004736181856664198,\n",
       "     0.0004719323518753975,\n",
       "     0.0008834556901606219,\n",
       "     0.0004073659561710582,\n",
       "     0.0003453813495822495,\n",
       "     0.002121616193963735,\n",
       "     0.002626124334181268,\n",
       "     0.0028308071291837014,\n",
       "     0.005003028703027289,\n",
       "     0.0005974737244904337,\n",
       "     0.004557816393766095,\n",
       "     0.006046105908382784],\n",
       "    'param_classifier__C': [0.0001,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     100.0,\n",
       "     1000.0,\n",
       "     1000.0],\n",
       "    'param_classifier__max_iter': [500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000],\n",
       "    'param_classifier__penalty': ['l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2'],\n",
       "    'params': [{'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'}],\n",
       "    'split0_test_score': [0.6285714285714286,\n",
       "     0.6285714285714286,\n",
       "     0.6285714285714286,\n",
       "     0.6285714285714286,\n",
       "     0.6285714285714286,\n",
       "     0.6285714285714286,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.9142857142857143,\n",
       "     0.9142857142857143,\n",
       "     0.8571428571428571,\n",
       "     0.8571428571428571,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.7714285714285715,\n",
       "     0.7714285714285715],\n",
       "    'split1_test_score': [0.6,\n",
       "     0.6,\n",
       "     0.6,\n",
       "     0.6,\n",
       "     0.6,\n",
       "     0.6,\n",
       "     0.7714285714285715,\n",
       "     0.7714285714285715,\n",
       "     0.7714285714285715,\n",
       "     0.7714285714285715,\n",
       "     0.7428571428571429,\n",
       "     0.7428571428571429,\n",
       "     0.7142857142857143,\n",
       "     0.7142857142857143,\n",
       "     0.7142857142857143,\n",
       "     0.7142857142857143],\n",
       "    'split2_test_score': [0.6176470588235294,\n",
       "     0.6176470588235294,\n",
       "     0.6176470588235294,\n",
       "     0.6176470588235294,\n",
       "     0.6176470588235294,\n",
       "     0.6176470588235294,\n",
       "     0.8529411764705882,\n",
       "     0.8529411764705882,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8823529411764706,\n",
       "     0.8823529411764706],\n",
       "    'mean_test_score': [0.615406162464986,\n",
       "     0.615406162464986,\n",
       "     0.615406162464986,\n",
       "     0.615406162464986,\n",
       "     0.615406162464986,\n",
       "     0.615406162464986,\n",
       "     0.80812324929972,\n",
       "     0.80812324929972,\n",
       "     0.8364145658263306,\n",
       "     0.8364145658263306,\n",
       "     0.8078431372549021,\n",
       "     0.8078431372549021,\n",
       "     0.7792717086834733,\n",
       "     0.7792717086834733,\n",
       "     0.7893557422969187,\n",
       "     0.7893557422969187],\n",
       "    'std_test_score': [0.011771373327423363,\n",
       "     0.011771373327423363,\n",
       "     0.011771373327423363,\n",
       "     0.011771373327423363,\n",
       "     0.011771373327423363,\n",
       "     0.011771373327423363,\n",
       "     0.03376947911525043,\n",
       "     0.03376947911525043,\n",
       "     0.0590285874963444,\n",
       "     0.0590285874963444,\n",
       "     0.04795727632276231,\n",
       "     0.04795727632276231,\n",
       "     0.04694530793307925,\n",
       "     0.04694530793307925,\n",
       "     0.06977433042886391,\n",
       "     0.06977433042886391],\n",
       "    'rank_test_score': [11,\n",
       "     11,\n",
       "     11,\n",
       "     11,\n",
       "     11,\n",
       "     11,\n",
       "     3,\n",
       "     3,\n",
       "     1,\n",
       "     1,\n",
       "     5,\n",
       "     5,\n",
       "     9,\n",
       "     9,\n",
       "     7,\n",
       "     7]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__C': 0.1,\n",
       "    'classifier__max_iter': 500,\n",
       "    'classifier__penalty': 'l2'},\n",
       "   'best_validation_accuracy': 0.884567406219371,\n",
       "   'train_accuracy': 0.9,\n",
       "   'test_accuracy': 0.8769230769230769,\n",
       "   'cv_results': {'mean_fit_time': [0.010027408599853516,\n",
       "     0.0,\n",
       "     0.010676225026448568,\n",
       "     0.010426680246988932,\n",
       "     0.010426680246988932,\n",
       "     0.005209604899088542,\n",
       "     0.015628814697265625,\n",
       "     0.015628814697265625,\n",
       "     0.00591890017191569,\n",
       "     0.017785390218098957,\n",
       "     0.019206682840983074,\n",
       "     0.021608750025431316,\n",
       "     0.0243679682413737,\n",
       "     0.012428919474283854,\n",
       "     0.00603334108988444,\n",
       "     0.015213092168172201],\n",
       "    'std_fit_time': [0.0,\n",
       "     0.0,\n",
       "     0.00754923111367531,\n",
       "     0.0073727763079097005,\n",
       "     0.0073727763079097005,\n",
       "     0.007367493902896334,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.006916498944245408,\n",
       "     0.003016140871035606,\n",
       "     0.0026598447229645534,\n",
       "     0.004693064015486053,\n",
       "     0.0032768893738230036,\n",
       "     0.005334048362957411,\n",
       "     0.00494226423223187,\n",
       "     0.004783820257445841],\n",
       "    'mean_score_time': [0.0,\n",
       "     0.010676225026448568,\n",
       "     0.005338112513224284,\n",
       "     0.005213340123494466,\n",
       "     0.005209604899088542,\n",
       "     0.010419209798177084,\n",
       "     0.0,\n",
       "     0.010414918263753256,\n",
       "     0.013653834660847982,\n",
       "     0.004797935485839844,\n",
       "     0.0007114410400390625,\n",
       "     0.006886482238769531,\n",
       "     0.007581949234008789,\n",
       "     0.0037709871927897134,\n",
       "     0.007199287414550781,\n",
       "     0.0044078826904296875],\n",
       "    'std_score_time': [0.0,\n",
       "     0.00754923111367531,\n",
       "     0.00754923111367531,\n",
       "     0.0073727763079097005,\n",
       "     0.007367493902896334,\n",
       "     0.007367493902896335,\n",
       "     0.0,\n",
       "     0.007364459329803551,\n",
       "     0.005276289100184488,\n",
       "     0.006785305435465852,\n",
       "     0.0010061295676520624,\n",
       "     0.0058926224867604455,\n",
       "     0.00639950923427694,\n",
       "     0.0027124814672849977,\n",
       "     0.006451405792038756,\n",
       "     0.0006750647941845993],\n",
       "    'param_classifier__C': [0.0001,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     100.0,\n",
       "     1000.0,\n",
       "     1000.0],\n",
       "    'param_classifier__max_iter': [500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000],\n",
       "    'param_classifier__penalty': ['l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2'],\n",
       "    'params': [{'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'}],\n",
       "    'split0_test_score': [0.6206896551724138,\n",
       "     0.6206896551724138,\n",
       "     0.6206896551724138,\n",
       "     0.6206896551724138,\n",
       "     0.7816091954022989,\n",
       "     0.7816091954022989,\n",
       "     0.8735632183908046,\n",
       "     0.8735632183908046,\n",
       "     0.8505747126436781,\n",
       "     0.8505747126436781,\n",
       "     0.8620689655172413,\n",
       "     0.8620689655172413,\n",
       "     0.8620689655172413,\n",
       "     0.8620689655172413,\n",
       "     0.8735632183908046,\n",
       "     0.8735632183908046],\n",
       "    'split1_test_score': [0.6091954022988506,\n",
       "     0.6091954022988506,\n",
       "     0.6091954022988506,\n",
       "     0.6091954022988506,\n",
       "     0.632183908045977,\n",
       "     0.632183908045977,\n",
       "     0.9080459770114943,\n",
       "     0.9080459770114943,\n",
       "     0.9080459770114943,\n",
       "     0.9080459770114943,\n",
       "     0.896551724137931,\n",
       "     0.896551724137931,\n",
       "     0.8850574712643678,\n",
       "     0.8850574712643678,\n",
       "     0.8850574712643678,\n",
       "     0.8850574712643678],\n",
       "    'split2_test_score': [0.6162790697674418,\n",
       "     0.6162790697674418,\n",
       "     0.6162790697674418,\n",
       "     0.6162790697674418,\n",
       "     0.6976744186046512,\n",
       "     0.6976744186046512,\n",
       "     0.872093023255814,\n",
       "     0.872093023255814,\n",
       "     0.872093023255814,\n",
       "     0.872093023255814,\n",
       "     0.8837209302325582,\n",
       "     0.8837209302325582,\n",
       "     0.8837209302325582,\n",
       "     0.8837209302325582,\n",
       "     0.8837209302325582,\n",
       "     0.8837209302325582],\n",
       "    'mean_test_score': [0.6153880424129021,\n",
       "     0.6153880424129021,\n",
       "     0.6153880424129021,\n",
       "     0.6153880424129021,\n",
       "     0.7038225073509756,\n",
       "     0.7038225073509756,\n",
       "     0.884567406219371,\n",
       "     0.884567406219371,\n",
       "     0.8769045709703288,\n",
       "     0.8769045709703288,\n",
       "     0.8807805399625769,\n",
       "     0.8807805399625769,\n",
       "     0.8769491223380559,\n",
       "     0.8769491223380559,\n",
       "     0.8807805399625769,\n",
       "     0.8807805399625769],\n",
       "    'std_test_score': [0.004734617871962325,\n",
       "     0.004734617871962325,\n",
       "     0.004734617871962325,\n",
       "     0.004734617871962325,\n",
       "     0.061157329197212625,\n",
       "     0.061157329197212625,\n",
       "     0.01661270263511824,\n",
       "     0.01661270263511824,\n",
       "     0.02370794241832109,\n",
       "     0.02370794241832109,\n",
       "     0.014230239673035225,\n",
       "     0.014230239673035225,\n",
       "     0.010535998156841487,\n",
       "     0.010535998156841487,\n",
       "     0.005132503189491096,\n",
       "     0.005132503189491096],\n",
       "    'rank_test_score': [13,\n",
       "     13,\n",
       "     13,\n",
       "     13,\n",
       "     11,\n",
       "     11,\n",
       "     1,\n",
       "     1,\n",
       "     9,\n",
       "     9,\n",
       "     3,\n",
       "     3,\n",
       "     7,\n",
       "     7,\n",
       "     3,\n",
       "     3]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__C': 0.1,\n",
       "    'classifier__max_iter': 500,\n",
       "    'classifier__penalty': 'l2'},\n",
       "   'best_validation_accuracy': 0.8653077537969626,\n",
       "   'train_accuracy': 0.875,\n",
       "   'test_accuracy': 0.9423076923076923,\n",
       "   'cv_results': {'mean_fit_time': [0.007843732833862305,\n",
       "     0.008519490559895834,\n",
       "     0.010999759038289389,\n",
       "     0.01042954126993815,\n",
       "     0.011095523834228516,\n",
       "     0.018455108006795246,\n",
       "     0.01884937286376953,\n",
       "     0.010456164677937826,\n",
       "     0.013561328252156576,\n",
       "     0.014603535334269205,\n",
       "     0.008346080780029297,\n",
       "     0.010417302449544271,\n",
       "     0.01563914616902669,\n",
       "     0.01563254992167155,\n",
       "     0.01563914616902669,\n",
       "     0.01563254992167155],\n",
       "    'std_fit_time': [0.0019691869402635597,\n",
       "     0.0033963034822088807,\n",
       "     0.006568389655129785,\n",
       "     0.007374799356638224,\n",
       "     0.007890082994597177,\n",
       "     0.0005575747079001208,\n",
       "     0.0,\n",
       "     0.007832264740826666,\n",
       "     0.0014739033903249715,\n",
       "     0.0014739033903249715,\n",
       "     0.005901570315889426,\n",
       "     0.007366145203743986,\n",
       "     9.328502470411212e-06,\n",
       "     9.328502470411212e-06,\n",
       "     9.328502470411212e-06,\n",
       "     9.328502470411212e-06],\n",
       "    'mean_score_time': [0.0037555694580078125,\n",
       "     0.0005702177683512369,\n",
       "     0.0,\n",
       "     0.005206664403279622,\n",
       "     0.007753849029541016,\n",
       "     0.00039426485697428387,\n",
       "     0.0041730403900146484,\n",
       "     0.008346080780029297,\n",
       "     0.005208651224772136,\n",
       "     0.010417302449544271,\n",
       "     0.01563914616902669,\n",
       "     0.005215247472127278,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0104217529296875],\n",
       "    'std_score_time': [0.0007735162226993788,\n",
       "     0.0008064097015084391,\n",
       "     0.0,\n",
       "     0.00736333541384326,\n",
       "     0.007890082994597177,\n",
       "     0.0005575747079001207,\n",
       "     0.005901570315889426,\n",
       "     0.005901570315889426,\n",
       "     0.007366145203743986,\n",
       "     0.007366145203743986,\n",
       "     9.328502470411212e-06,\n",
       "     0.007375473706214398,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007369292168432799],\n",
       "    'param_classifier__C': [0.0001,\n",
       "     0.0001,\n",
       "     0.001,\n",
       "     0.001,\n",
       "     0.01,\n",
       "     0.01,\n",
       "     0.1,\n",
       "     0.1,\n",
       "     1.0,\n",
       "     1.0,\n",
       "     10.0,\n",
       "     10.0,\n",
       "     100.0,\n",
       "     100.0,\n",
       "     1000.0,\n",
       "     1000.0],\n",
       "    'param_classifier__max_iter': [500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000,\n",
       "     500,\n",
       "     1000],\n",
       "    'param_classifier__penalty': ['l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2',\n",
       "     'l2'],\n",
       "    'params': [{'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.0001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.001,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.01,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 0.1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 10,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 100,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 500,\n",
       "      'classifier__penalty': 'l2'},\n",
       "     {'classifier__C': 1000,\n",
       "      'classifier__max_iter': 1000,\n",
       "      'classifier__penalty': 'l2'}],\n",
       "    'split0_test_score': [0.6187050359712231,\n",
       "     0.6187050359712231,\n",
       "     0.6187050359712231,\n",
       "     0.6187050359712231,\n",
       "     0.7410071942446043,\n",
       "     0.7410071942446043,\n",
       "     0.9424460431654677,\n",
       "     0.9424460431654677,\n",
       "     0.9136690647482014,\n",
       "     0.9136690647482014,\n",
       "     0.8992805755395683,\n",
       "     0.8992805755395683,\n",
       "     0.8992805755395683,\n",
       "     0.8992805755395683,\n",
       "     0.8992805755395683,\n",
       "     0.8992805755395683],\n",
       "    'split1_test_score': [0.6115107913669064,\n",
       "     0.6115107913669064,\n",
       "     0.6115107913669064,\n",
       "     0.6115107913669064,\n",
       "     0.762589928057554,\n",
       "     0.762589928057554,\n",
       "     0.8201438848920863,\n",
       "     0.8201438848920863,\n",
       "     0.7985611510791367,\n",
       "     0.7985611510791367,\n",
       "     0.8129496402877698,\n",
       "     0.8129496402877698,\n",
       "     0.8129496402877698,\n",
       "     0.8129496402877698,\n",
       "     0.8129496402877698,\n",
       "     0.8129496402877698],\n",
       "    'split2_test_score': [0.6159420289855072,\n",
       "     0.6159420289855072,\n",
       "     0.6159420289855072,\n",
       "     0.6159420289855072,\n",
       "     0.782608695652174,\n",
       "     0.782608695652174,\n",
       "     0.8333333333333334,\n",
       "     0.8333333333333334,\n",
       "     0.855072463768116,\n",
       "     0.855072463768116,\n",
       "     0.8768115942028986,\n",
       "     0.8768115942028986,\n",
       "     0.8695652173913043,\n",
       "     0.8695652173913043,\n",
       "     0.8695652173913043,\n",
       "     0.8695652173913043],\n",
       "    'mean_test_score': [0.6153859521078789,\n",
       "     0.6153859521078789,\n",
       "     0.6153859521078789,\n",
       "     0.6153859521078789,\n",
       "     0.7620686059847773,\n",
       "     0.7620686059847773,\n",
       "     0.8653077537969626,\n",
       "     0.8653077537969626,\n",
       "     0.8557675598651514,\n",
       "     0.8557675598651514,\n",
       "     0.8630139366767455,\n",
       "     0.8630139366767455,\n",
       "     0.8605984777395475,\n",
       "     0.8605984777395475,\n",
       "     0.8605984777395475,\n",
       "     0.8605984777395475],\n",
       "    'std_test_score': [0.0029632420282588354,\n",
       "     0.0029632420282588354,\n",
       "     0.0029632420282588354,\n",
       "     0.0029632420282588354,\n",
       "     0.01698774190151394,\n",
       "     0.01698774190151394,\n",
       "     0.0548101398926057,\n",
       "     0.0548101398926057,\n",
       "     0.046995179300642446,\n",
       "     0.046995179300642446,\n",
       "     0.03656992489527708,\n",
       "     0.03656992489527708,\n",
       "     0.03581023513233189,\n",
       "     0.03581023513233189,\n",
       "     0.03581023513233189,\n",
       "     0.03581023513233189],\n",
       "    'rank_test_score': [13,\n",
       "     13,\n",
       "     13,\n",
       "     13,\n",
       "     11,\n",
       "     11,\n",
       "     1,\n",
       "     1,\n",
       "     9,\n",
       "     9,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     5]}}],\n",
       " 'diabetes decision_tree': [{'split_ratio': 0.2,\n",
       "   'best_params': {'classifier__criterion': 'gini',\n",
       "    'classifier__max_depth': 3,\n",
       "    'classifier__min_samples_split': 2},\n",
       "   'best_validation_accuracy': 0.8652661064425771,\n",
       "   'train_accuracy': 0.9038461538461539,\n",
       "   'test_accuracy': 0.8557692307692307,\n",
       "   'cv_results': {'mean_fit_time': [0.015512704849243164,\n",
       "     0.015512704849243164,\n",
       "     0.005170901616414388,\n",
       "     0.0,\n",
       "     0.005349874496459961,\n",
       "     0.010428905487060547,\n",
       "     0.010428905487060547,\n",
       "     0.0,\n",
       "     0.011095682779947916,\n",
       "     0.011716047922770182,\n",
       "     0.017831961313883465,\n",
       "     0.016365607579549152,\n",
       "     0.016789356867472332,\n",
       "     0.013965288798014322,\n",
       "     0.01993417739868164,\n",
       "     0.014379501342773438,\n",
       "     0.013094584147135416,\n",
       "     0.008725325266520182,\n",
       "     0.010194142659505209,\n",
       "     0.007973114649454752,\n",
       "     0.009041468302408854,\n",
       "     0.004616340001424153,\n",
       "     0.010668436686197916,\n",
       "     0.010762929916381836],\n",
       "    'std_fit_time': [0.0,\n",
       "     0.0,\n",
       "     0.007312759195630188,\n",
       "     0.0,\n",
       "     0.007565865069887609,\n",
       "     0.007374349790254107,\n",
       "     0.007374349790254107,\n",
       "     0.0,\n",
       "     0.007865893672482013,\n",
       "     0.008286871471821654,\n",
       "     0.0007082918381750778,\n",
       "     0.005641199733951064,\n",
       "     0.004757474393682209,\n",
       "     0.0066187085816272395,\n",
       "     0.008471708461919048,\n",
       "     0.003997053985178535,\n",
       "     0.0032695456330769554,\n",
       "     0.002185553324741565,\n",
       "     0.0009323221752904269,\n",
       "     0.006224016967497927,\n",
       "     0.0010101056305125465,\n",
       "     0.004769766342634782,\n",
       "     0.007453136469401854,\n",
       "     0.00797509175125617],\n",
       "    'mean_score_time': [0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.016049623489379883,\n",
       "     0.010428905487060547,\n",
       "     0.0052144527435302734,\n",
       "     0.0,\n",
       "     0.01733112335205078,\n",
       "     0.005881786346435547,\n",
       "     0.009147008260091146,\n",
       "     0.002161741256713867,\n",
       "     0.006495952606201172,\n",
       "     0.005473534266153972,\n",
       "     0.005803982416788737,\n",
       "     0.008252938588460287,\n",
       "     0.00605312983194987,\n",
       "     0.01212604840596517,\n",
       "     0.002784093221028646,\n",
       "     0.004949172337849935,\n",
       "     0.0077826182047526045,\n",
       "     0.003998676935831706,\n",
       "     0.008449395497639975,\n",
       "     0.006199280420939128,\n",
       "     0.002665837605794271],\n",
       "    'std_score_time': [0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007374349790254107,\n",
       "     0.007374349790254107,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007367113117488556,\n",
       "     0.008750449671415715,\n",
       "     0.0030571638035862096,\n",
       "     0.0006692669842681353,\n",
       "     0.00038213008771418054,\n",
       "     0.0005964140182515417,\n",
       "     0.0015951869804959283,\n",
       "     7.451545864731514e-05,\n",
       "     0.00433140353340824,\n",
       "     0.0031506067663797177,\n",
       "     0.001617032333152002,\n",
       "     0.007337877109282896,\n",
       "     0.0028274943933114,\n",
       "     0.007210775066859058,\n",
       "     0.00675738796871654,\n",
       "     0.0018850323411332976],\n",
       "    'param_classifier__criterion': ['gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy'],\n",
       "    'param_classifier__max_depth': [3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10],\n",
       "    'params': [{'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10}],\n",
       "    'split0_test_score': [0.8857142857142857,\n",
       "     0.8857142857142857,\n",
       "     0.8571428571428571,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8571428571428571,\n",
       "     0.8,\n",
       "     0.8,\n",
       "     0.8571428571428571,\n",
       "     0.7428571428571429,\n",
       "     0.7714285714285715,\n",
       "     0.7714285714285715,\n",
       "     0.8857142857142857,\n",
       "     0.8857142857142857,\n",
       "     0.8571428571428571,\n",
       "     0.8857142857142857,\n",
       "     0.8857142857142857,\n",
       "     0.8571428571428571,\n",
       "     0.8285714285714286,\n",
       "     0.7714285714285715,\n",
       "     0.7714285714285715,\n",
       "     0.8857142857142857,\n",
       "     0.8,\n",
       "     0.8571428571428571],\n",
       "    'split1_test_score': [0.8571428571428571,\n",
       "     0.8571428571428571,\n",
       "     0.8857142857142857,\n",
       "     0.8285714285714286,\n",
       "     0.8,\n",
       "     0.7428571428571429,\n",
       "     0.6571428571428571,\n",
       "     0.7714285714285715,\n",
       "     0.7714285714285715,\n",
       "     0.6571428571428571,\n",
       "     0.6857142857142857,\n",
       "     0.7714285714285715,\n",
       "     0.8857142857142857,\n",
       "     0.7428571428571429,\n",
       "     0.7714285714285715,\n",
       "     0.7428571428571429,\n",
       "     0.8571428571428571,\n",
       "     0.7714285714285715,\n",
       "     0.7428571428571429,\n",
       "     0.7714285714285715,\n",
       "     0.7142857142857143,\n",
       "     0.6571428571428571,\n",
       "     0.7428571428571429,\n",
       "     0.7142857142857143],\n",
       "    'split2_test_score': [0.8529411764705882,\n",
       "     0.8529411764705882,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.7647058823529411,\n",
       "     0.8235294117647058,\n",
       "     0.8529411764705882,\n",
       "     0.7647058823529411,\n",
       "     0.8235294117647058,\n",
       "     0.8529411764705882,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058,\n",
       "     0.8235294117647058],\n",
       "    'mean_test_score': [0.8652661064425771,\n",
       "     0.8652661064425771,\n",
       "     0.8554621848739495,\n",
       "     0.8173669467787116,\n",
       "     0.788235294117647,\n",
       "     0.8078431372549021,\n",
       "     0.7700280112044818,\n",
       "     0.7787114845938375,\n",
       "     0.8173669467787116,\n",
       "     0.7509803921568627,\n",
       "     0.7602240896358543,\n",
       "     0.7887955182072829,\n",
       "     0.864985994397759,\n",
       "     0.8173669467787116,\n",
       "     0.8173669467787116,\n",
       "     0.8173669467787116,\n",
       "     0.8554621848739495,\n",
       "     0.8173669467787116,\n",
       "     0.7983193277310926,\n",
       "     0.7887955182072829,\n",
       "     0.7697478991596638,\n",
       "     0.7887955182072828,\n",
       "     0.7887955182072829,\n",
       "     0.7983193277310924],\n",
       "    'std_test_score': [0.014560438563996667,\n",
       "     0.014560438563996667,\n",
       "     0.02541466940552102,\n",
       "     0.012451602672769103,\n",
       "     0.016637806616154105,\n",
       "     0.04795727632276231,\n",
       "     0.08269617301568451,\n",
       "     0.015301400878148673,\n",
       "     0.03526298035149849,\n",
       "     0.08014044275428849,\n",
       "     0.05681788187566653,\n",
       "     0.02456057167146548,\n",
       "     0.029314230704652392,\n",
       "     0.05848374587498212,\n",
       "     0.03526298035149849,\n",
       "     0.05848374587498212,\n",
       "     0.02541466940552102,\n",
       "     0.03526298035149849,\n",
       "     0.03927166872453083,\n",
       "     0.02456057167146548,\n",
       "     0.04461438373571885,\n",
       "     0.09649199279746724,\n",
       "     0.03387387441530748,\n",
       "     0.060984708843353594],\n",
       "    'rank_test_score': [1,\n",
       "     1,\n",
       "     4,\n",
       "     6,\n",
       "     19,\n",
       "     12,\n",
       "     21,\n",
       "     20,\n",
       "     6,\n",
       "     24,\n",
       "     23,\n",
       "     15,\n",
       "     3,\n",
       "     6,\n",
       "     6,\n",
       "     6,\n",
       "     4,\n",
       "     6,\n",
       "     13,\n",
       "     15,\n",
       "     22,\n",
       "     18,\n",
       "     15,\n",
       "     14]}},\n",
       "  {'split_ratio': 0.5,\n",
       "   'best_params': {'classifier__criterion': 'entropy',\n",
       "    'classifier__max_depth': 10,\n",
       "    'classifier__min_samples_split': 2},\n",
       "   'best_validation_accuracy': 0.9269357569277377,\n",
       "   'train_accuracy': 0.9846153846153847,\n",
       "   'test_accuracy': 0.9115384615384615,\n",
       "   'cv_results': {'mean_fit_time': [0.010455608367919922,\n",
       "     0.015683412551879883,\n",
       "     0.015683412551879883,\n",
       "     0.0,\n",
       "     0.010388374328613281,\n",
       "     0.015643835067749023,\n",
       "     0.015643835067749023,\n",
       "     0.0,\n",
       "     0.01041706403096517,\n",
       "     0.015625556310017902,\n",
       "     0.015625635782877605,\n",
       "     0.005208492279052734,\n",
       "     0.0,\n",
       "     0.005208492279052734,\n",
       "     0.015624920527140299,\n",
       "     0.015624364217122396,\n",
       "     0.011100848515828451,\n",
       "     0.0055522918701171875,\n",
       "     0.008174737294514975,\n",
       "     0.013685782750447592,\n",
       "     0.009509801864624023,\n",
       "     0.0002040863037109375,\n",
       "     0.005361000696818034,\n",
       "     0.010578234990437826],\n",
       "    'std_fit_time': [0.007393231578386988,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.00734586030108187,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007365976616993028,\n",
       "     1.1239159602905075e-07,\n",
       "     1.1239159602905075e-07,\n",
       "     0.007365920420551928,\n",
       "     0.0,\n",
       "     0.007365920420551928,\n",
       "     7.867411722033552e-07,\n",
       "     7.867411722033552e-07,\n",
       "     0.006409243155152648,\n",
       "     0.00714029208081584,\n",
       "     0.0064021758264419144,\n",
       "     0.0033901801026202873,\n",
       "     0.0051331734394760645,\n",
       "     0.00028862161860260233,\n",
       "     0.0075815998933316765,\n",
       "     0.007482013828141084],\n",
       "    'mean_score_time': [0.005227804183959961,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.01552128791809082,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.005208571751912435,\n",
       "     0.015625715255737305,\n",
       "     0.005208571751912435,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.010416428248087565,\n",
       "     0.015624920527140299,\n",
       "     0.010415871938069662,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.009226083755493164,\n",
       "     0.01099379857381185,\n",
       "     0.008324782053629557,\n",
       "     0.0,\n",
       "     0.0043544769287109375,\n",
       "     0.0043544769287109375,\n",
       "     0.005361000696818034,\n",
       "     0.005217234293619792],\n",
       "    'std_score_time': [0.007393231578386988,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007366032812147957,\n",
       "     0.0,\n",
       "     0.007366032812147957,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007365527081478931,\n",
       "     7.867411722033552e-07,\n",
       "     0.007365133679379725,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.002827021556766345,\n",
       "     0.0029269019437885395,\n",
       "     0.006578068786989708,\n",
       "     0.0,\n",
       "     0.006158160329623749,\n",
       "     0.006158160329623749,\n",
       "     0.0075815998933316765,\n",
       "     0.007378283496115123],\n",
       "    'param_classifier__criterion': ['gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy'],\n",
       "    'param_classifier__max_depth': [3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10],\n",
       "    'params': [{'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10}],\n",
       "    'split0_test_score': [0.8850574712643678,\n",
       "     0.8850574712643678,\n",
       "     0.8850574712643678,\n",
       "     0.9310344827586207,\n",
       "     0.9195402298850575,\n",
       "     0.8735632183908046,\n",
       "     0.9425287356321839,\n",
       "     0.9080459770114943,\n",
       "     0.8620689655172413,\n",
       "     0.9310344827586207,\n",
       "     0.8850574712643678,\n",
       "     0.8620689655172413,\n",
       "     0.896551724137931,\n",
       "     0.896551724137931,\n",
       "     0.896551724137931,\n",
       "     0.9195402298850575,\n",
       "     0.9195402298850575,\n",
       "     0.9195402298850575,\n",
       "     0.9310344827586207,\n",
       "     0.9080459770114943,\n",
       "     0.9080459770114943,\n",
       "     0.9195402298850575,\n",
       "     0.9080459770114943,\n",
       "     0.9080459770114943],\n",
       "    'split1_test_score': [0.896551724137931,\n",
       "     0.896551724137931,\n",
       "     0.896551724137931,\n",
       "     0.9310344827586207,\n",
       "     0.9195402298850575,\n",
       "     0.9080459770114943,\n",
       "     0.9080459770114943,\n",
       "     0.9080459770114943,\n",
       "     0.9080459770114943,\n",
       "     0.9080459770114943,\n",
       "     0.9310344827586207,\n",
       "     0.9080459770114943,\n",
       "     0.896551724137931,\n",
       "     0.896551724137931,\n",
       "     0.896551724137931,\n",
       "     0.9080459770114943,\n",
       "     0.9195402298850575,\n",
       "     0.8850574712643678,\n",
       "     0.9195402298850575,\n",
       "     0.9310344827586207,\n",
       "     0.8735632183908046,\n",
       "     0.9195402298850575,\n",
       "     0.9195402298850575,\n",
       "     0.8735632183908046],\n",
       "    'split2_test_score': [0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8488372093023255,\n",
       "     0.8372093023255814,\n",
       "     0.8255813953488372,\n",
       "     0.8488372093023255,\n",
       "     0.8604651162790697,\n",
       "     0.8372093023255814,\n",
       "     0.8488372093023255,\n",
       "     0.872093023255814,\n",
       "     0.813953488372093,\n",
       "     0.8488372093023255,\n",
       "     0.8488372093023255,\n",
       "     0.8488372093023255,\n",
       "     0.8488372093023255,\n",
       "     0.8837209302325582,\n",
       "     0.8837209302325582,\n",
       "     0.8488372093023255,\n",
       "     0.9302325581395349,\n",
       "     0.8604651162790697,\n",
       "     0.8604651162790697,\n",
       "     0.8837209302325582,\n",
       "     0.872093023255814,\n",
       "     0.8604651162790697],\n",
       "    'mean_test_score': [0.880691437227123,\n",
       "     0.880691437227123,\n",
       "     0.8768154682348749,\n",
       "     0.8997594226142742,\n",
       "     0.888220618372984,\n",
       "     0.8768154682348749,\n",
       "     0.9036799429742493,\n",
       "     0.8844337521161899,\n",
       "     0.8729840506103536,\n",
       "     0.9037244943419763,\n",
       "     0.8766818141316938,\n",
       "     0.8729840506103536,\n",
       "     0.8806468858593958,\n",
       "     0.8806468858593958,\n",
       "     0.8806468858593958,\n",
       "     0.9037690457097032,\n",
       "     0.9076004633342244,\n",
       "     0.8844783034839171,\n",
       "     0.9269357569277377,\n",
       "     0.8998485253497283,\n",
       "     0.880691437227123,\n",
       "     0.9076004633342244,\n",
       "     0.8998930767174551,\n",
       "     0.880691437227123],\n",
       "    'std_test_score': [0.015052297866673467,\n",
       "     0.015052297866673467,\n",
       "     0.02033251405922599,\n",
       "     0.04422961422016894,\n",
       "     0.044292619368630735,\n",
       "     0.024281026751982925,\n",
       "     0.033644277326602294,\n",
       "     0.03339272868474293,\n",
       "     0.025374184457856483,\n",
       "     0.024256000239493446,\n",
       "     0.04816363452466057,\n",
       "     0.025374184457856483,\n",
       "     0.02249283800085519,\n",
       "     0.02249283800085519,\n",
       "     0.02249283800085519,\n",
       "     0.014932618946879651,\n",
       "     0.016885379787756803,\n",
       "     0.028867292407024573,\n",
       "     0.005239665126254707,\n",
       "     0.02938715741772852,\n",
       "     0.02006810412642287,\n",
       "     0.016885379787756803,\n",
       "     0.020209926465855645,\n",
       "     0.02006810412642287],\n",
       "    'rank_test_score': [13,\n",
       "     13,\n",
       "     20,\n",
       "     9,\n",
       "     10,\n",
       "     20,\n",
       "     6,\n",
       "     12,\n",
       "     23,\n",
       "     5,\n",
       "     22,\n",
       "     23,\n",
       "     17,\n",
       "     17,\n",
       "     17,\n",
       "     4,\n",
       "     2,\n",
       "     11,\n",
       "     1,\n",
       "     8,\n",
       "     13,\n",
       "     2,\n",
       "     7,\n",
       "     13]}},\n",
       "  {'split_ratio': 0.8,\n",
       "   'best_params': {'classifier__criterion': 'gini',\n",
       "    'classifier__max_depth': 10,\n",
       "    'classifier__min_samples_split': 5},\n",
       "   'best_validation_accuracy': 0.9207069127306852,\n",
       "   'train_accuracy': 0.9783653846153846,\n",
       "   'test_accuracy': 0.9711538461538461,\n",
       "   'cv_results': {'mean_fit_time': [0.0,\n",
       "     0.015627384185791016,\n",
       "     0.015627384185791016,\n",
       "     0.015128453572591146,\n",
       "     0.007306734720865886,\n",
       "     0.008157730102539062,\n",
       "     0.011054277420043945,\n",
       "     0.009323199590047201,\n",
       "     0.005123058954874675,\n",
       "     0.00966795285542806,\n",
       "     0.009665330251057943,\n",
       "     0.009050130844116211,\n",
       "     0.009331941604614258,\n",
       "     0.0077733198801676435,\n",
       "     0.008379379908243815,\n",
       "     0.005102952321370442,\n",
       "     0.009316444396972656,\n",
       "     0.0,\n",
       "     0.015630245208740234,\n",
       "     0.015625476837158203,\n",
       "     0.01042334238688151,\n",
       "     0.015625476837158203,\n",
       "     0.0,\n",
       "     0.01653734842936198],\n",
       "    'std_fit_time': [0.0,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.006559037271881295,\n",
       "     0.0008428183962370801,\n",
       "     0.0021245721051078204,\n",
       "     0.0011922142602811855,\n",
       "     0.004411245035486519,\n",
       "     0.001240750235147047,\n",
       "     0.00046957273382843825,\n",
       "     0.0009448766491465179,\n",
       "     0.001700368623014703,\n",
       "     0.00046917880848962757,\n",
       "     0.0016254918796700444,\n",
       "     0.002277899835479787,\n",
       "     0.0034826824901640708,\n",
       "     0.00553499601925486,\n",
       "     0.0,\n",
       "     6.743495761743045e-06,\n",
       "     6.743495761743045e-06,\n",
       "     0.007370416084393091,\n",
       "     6.743495761743045e-06,\n",
       "     0.0,\n",
       "     0.0016859427376743363],\n",
       "    'mean_score_time': [0.015627384185791016,\n",
       "     0.0,\n",
       "     0.01119526227315267,\n",
       "     0.0045622984568278,\n",
       "     0.006333351135253906,\n",
       "     0.007747650146484375,\n",
       "     0.003931522369384766,\n",
       "     0.0,\n",
       "     0.007340590159098308,\n",
       "     0.005386034647623698,\n",
       "     0.005387147267659505,\n",
       "     0.0033878485361735025,\n",
       "     0.004384517669677734,\n",
       "     0.0016647179921468098,\n",
       "     0.004001299540201823,\n",
       "     0.007213036219278972,\n",
       "     0.005211671193440755,\n",
       "     0.015625476837158203,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.010975360870361328,\n",
       "     0.0,\n",
       "     0.01618226369222005,\n",
       "     0.0012707710266113281],\n",
       "    'std_score_time': [0.0,\n",
       "     0.0,\n",
       "     0.00012902555224135026,\n",
       "     0.0035754262773703143,\n",
       "     0.0019394814044797733,\n",
       "     0.002241034564698849,\n",
       "     0.0011922142602811855,\n",
       "     0.0,\n",
       "     0.0018970019755816419,\n",
       "     0.00043856203123904356,\n",
       "     0.0008665969809016141,\n",
       "     0.0025106258290596597,\n",
       "     0.0022814932056679665,\n",
       "     0.0023542667620205264,\n",
       "     0.0028293460987072923,\n",
       "     0.006439956854275926,\n",
       "     0.007370416084393091,\n",
       "     6.743495761743045e-06,\n",
       "     0.0,\n",
       "     0.0,\n",
       "     0.007791167404579745,\n",
       "     0.0,\n",
       "     0.0007941590175412726,\n",
       "     0.0017971416205045216],\n",
       "    'param_classifier__criterion': ['gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'gini',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy',\n",
       "     'entropy'],\n",
       "    'param_classifier__max_depth': [3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None,\n",
       "     3,\n",
       "     3,\n",
       "     3,\n",
       "     5,\n",
       "     5,\n",
       "     5,\n",
       "     10,\n",
       "     10,\n",
       "     10,\n",
       "     None,\n",
       "     None,\n",
       "     None],\n",
       "    'param_classifier__min_samples_split': [2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10,\n",
       "     2,\n",
       "     5,\n",
       "     10],\n",
       "    'params': [{'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'gini',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 3,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 5,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': 10,\n",
       "      'classifier__min_samples_split': 10},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 2},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 5},\n",
       "     {'classifier__criterion': 'entropy',\n",
       "      'classifier__max_depth': None,\n",
       "      'classifier__min_samples_split': 10}],\n",
       "    'split0_test_score': [0.8848920863309353,\n",
       "     0.8848920863309353,\n",
       "     0.8848920863309353,\n",
       "     0.8776978417266187,\n",
       "     0.8633093525179856,\n",
       "     0.8633093525179856,\n",
       "     0.8992805755395683,\n",
       "     0.9064748201438849,\n",
       "     0.8920863309352518,\n",
       "     0.8992805755395683,\n",
       "     0.8992805755395683,\n",
       "     0.8920863309352518,\n",
       "     0.8561151079136691,\n",
       "     0.8561151079136691,\n",
       "     0.8561151079136691,\n",
       "     0.8776978417266187,\n",
       "     0.8776978417266187,\n",
       "     0.8776978417266187,\n",
       "     0.9064748201438849,\n",
       "     0.9064748201438849,\n",
       "     0.8992805755395683,\n",
       "     0.8992805755395683,\n",
       "     0.9064748201438849,\n",
       "     0.8992805755395683],\n",
       "    'split1_test_score': [0.8201438848920863,\n",
       "     0.8201438848920863,\n",
       "     0.8201438848920863,\n",
       "     0.8776978417266187,\n",
       "     0.8776978417266187,\n",
       "     0.8201438848920863,\n",
       "     0.8920863309352518,\n",
       "     0.920863309352518,\n",
       "     0.8705035971223022,\n",
       "     0.8992805755395683,\n",
       "     0.9136690647482014,\n",
       "     0.8561151079136691,\n",
       "     0.8201438848920863,\n",
       "     0.8201438848920863,\n",
       "     0.8201438848920863,\n",
       "     0.8489208633093526,\n",
       "     0.8633093525179856,\n",
       "     0.8345323741007195,\n",
       "     0.8992805755395683,\n",
       "     0.9064748201438849,\n",
       "     0.8633093525179856,\n",
       "     0.8992805755395683,\n",
       "     0.9064748201438849,\n",
       "     0.8345323741007195],\n",
       "    'split2_test_score': [0.8405797101449275,\n",
       "     0.8405797101449275,\n",
       "     0.8333333333333334,\n",
       "     0.8623188405797102,\n",
       "     0.8623188405797102,\n",
       "     0.8405797101449275,\n",
       "     0.927536231884058,\n",
       "     0.9347826086956522,\n",
       "     0.8768115942028986,\n",
       "     0.9347826086956522,\n",
       "     0.9202898550724637,\n",
       "     0.8840579710144928,\n",
       "     0.8333333333333334,\n",
       "     0.8333333333333334,\n",
       "     0.8333333333333334,\n",
       "     0.8985507246376812,\n",
       "     0.8985507246376812,\n",
       "     0.8260869565217391,\n",
       "     0.9420289855072463,\n",
       "     0.927536231884058,\n",
       "     0.8695652173913043,\n",
       "     0.9420289855072463,\n",
       "     0.9347826086956522,\n",
       "     0.8695652173913043],\n",
       "    'mean_test_score': [0.8485385604559831,\n",
       "     0.8485385604559831,\n",
       "     0.846123101518785,\n",
       "     0.8725715080109825,\n",
       "     0.867775344941438,\n",
       "     0.8413443158516665,\n",
       "     0.906301046119626,\n",
       "     0.9207069127306852,\n",
       "     0.8798005074201508,\n",
       "     0.9111145865915963,\n",
       "     0.9110798317867445,\n",
       "     0.8774198032878046,\n",
       "     0.8365307753796962,\n",
       "     0.8365307753796962,\n",
       "     0.8365307753796962,\n",
       "     0.8750564765578841,\n",
       "     0.8798526396274284,\n",
       "     0.8461057241163591,\n",
       "     0.9159281270635665,\n",
       "     0.9134952907239425,\n",
       "     0.8773850484829527,\n",
       "     0.9135300455287944,\n",
       "     0.9159107496611406,\n",
       "     0.867792722343864],\n",
       "    'std_test_score': [0.027025788561998613,\n",
       "     0.027025788561998613,\n",
       "     0.027937621290649563,\n",
       "     0.007249730665903123,\n",
       "     0.007027907953955433,\n",
       "     0.017630520227826935,\n",
       "     0.015300089862353409,\n",
       "     0.011557135403446148,\n",
       "     0.009061044876295403,\n",
       "     0.016735818927051054,\n",
       "     0.00877023572922857,\n",
       "     0.015417115477997062,\n",
       "     0.014858217662223103,\n",
       "     0.014858217662223103,\n",
       "     0.014858217662223103,\n",
       "     0.020347209330900628,\n",
       "     0.0144676868161365,\n",
       "     0.02260350549282409,\n",
       "     0.01868832786312433,\n",
       "     0.009928444708558892,\n",
       "     0.015691707791984578,\n",
       "     0.020151793715391827,\n",
       "     0.013344419496899716,\n",
       "     0.026463039651702117],\n",
       "    'rank_test_score': [17,\n",
       "     17,\n",
       "     19,\n",
       "     14,\n",
       "     16,\n",
       "     21,\n",
       "     8,\n",
       "     1,\n",
       "     10,\n",
       "     6,\n",
       "     7,\n",
       "     11,\n",
       "     22,\n",
       "     22,\n",
       "     22,\n",
       "     13,\n",
       "     9,\n",
       "     20,\n",
       "     2,\n",
       "     5,\n",
       "     12,\n",
       "     4,\n",
       "     3,\n",
       "     15]}}]}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_accuracy_summary_df(results):\n",
    "\n",
    "    data = []\n",
    "    \n",
    "    for key, value in results.items():\n",
    "        dataset, classifier = key.split(' ', 1)\n",
    "        \n",
    "        # have to basically remove cv_results because unescessary in the df\n",
    "        for split_info in value:\n",
    "            data.append({\n",
    "                'Dataset': dataset,\n",
    "                'Classifier': classifier,\n",
    "                'Split Ratio': split_info['split_ratio'],\n",
    "                'Validation Accuracy': split_info['best_validation_accuracy'],\n",
    "                'Train Accuracy': split_info['train_accuracy'],\n",
    "                'Test Accuracy': split_info['test_accuracy']\n",
    "            })\n",
    "   \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    df = df.sort_values(['Dataset', 'Classifier', 'Split Ratio'])\n",
    "    \n",
    "    # round for readability \n",
    "    accuracy_columns = ['Validation Accuracy', 'Train Accuracy', 'Test Accuracy']\n",
    "    df[accuracy_columns] = df[accuracy_columns].round(4)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create df\n",
    "df = create_accuracy_summary_df(results_summary)\n",
    "\n",
    "# Get mean accuracies by dataset and classifier\n",
    "mean_accuracies = df.groupby(['Dataset', 'Classifier'])[\n",
    "    ['Validation Accuracy', 'Train Accuracy', 'Test Accuracy']\n",
    "].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">diabetes</th>\n",
       "      <th>KNN</th>\n",
       "      <td>0.887800</td>\n",
       "      <td>0.960767</td>\n",
       "      <td>0.924667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.905933</td>\n",
       "      <td>0.975467</td>\n",
       "      <td>0.955933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.904300</td>\n",
       "      <td>0.955600</td>\n",
       "      <td>0.912833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_reg</th>\n",
       "      <td>0.862100</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.894067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.922833</td>\n",
       "      <td>0.955467</td>\n",
       "      <td>0.944400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">money</th>\n",
       "      <th>KNN</th>\n",
       "      <td>0.809000</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.811500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.812233</td>\n",
       "      <td>0.883667</td>\n",
       "      <td>0.813667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.797600</td>\n",
       "      <td>0.881333</td>\n",
       "      <td>0.802667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_reg</th>\n",
       "      <td>0.817067</td>\n",
       "      <td>0.851667</td>\n",
       "      <td>0.833500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.820400</td>\n",
       "      <td>0.957000</td>\n",
       "      <td>0.829667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">taiwan</th>\n",
       "      <th>KNN</th>\n",
       "      <td>0.957467</td>\n",
       "      <td>0.963833</td>\n",
       "      <td>0.941500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.947033</td>\n",
       "      <td>0.972833</td>\n",
       "      <td>0.939167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.965033</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.938167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_reg</th>\n",
       "      <td>0.958367</td>\n",
       "      <td>0.968167</td>\n",
       "      <td>0.953500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.962567</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.941167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">vegas</th>\n",
       "      <th>KNN</th>\n",
       "      <td>0.785767</td>\n",
       "      <td>0.795900</td>\n",
       "      <td>0.758767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.779067</td>\n",
       "      <td>0.779000</td>\n",
       "      <td>0.773633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.758400</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.752667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_reg</th>\n",
       "      <td>0.781600</td>\n",
       "      <td>0.778167</td>\n",
       "      <td>0.772800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.784233</td>\n",
       "      <td>0.911000</td>\n",
       "      <td>0.766200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Validation Accuracy  Train Accuracy  Test Accuracy\n",
       "Dataset  Classifier                                                       \n",
       "diabetes KNN                       0.887800        0.960767       0.924667\n",
       "         SVM                       0.905933        0.975467       0.955933\n",
       "         decision_tree             0.904300        0.955600       0.912833\n",
       "         log_reg                   0.862100        0.883333       0.894067\n",
       "         random_forest             0.922833        0.955467       0.944400\n",
       "money    KNN                       0.809000        0.848333       0.811500\n",
       "         SVM                       0.812233        0.883667       0.813667\n",
       "         decision_tree             0.797600        0.881333       0.802667\n",
       "         log_reg                   0.817067        0.851667       0.833500\n",
       "         random_forest             0.820400        0.957000       0.829667\n",
       "taiwan   KNN                       0.957467        0.963833       0.941500\n",
       "         SVM                       0.947033        0.972833       0.939167\n",
       "         decision_tree             0.965033        0.999167       0.938167\n",
       "         log_reg                   0.958367        0.968167       0.953500\n",
       "         random_forest             0.962567        0.998667       0.941167\n",
       "vegas    KNN                       0.785767        0.795900       0.758767\n",
       "         SVM                       0.779067        0.779000       0.773633\n",
       "         decision_tree             0.758400        0.815367       0.752667\n",
       "         log_reg                   0.781600        0.778167       0.772800\n",
       "         random_forest             0.784233        0.911000       0.766200"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
